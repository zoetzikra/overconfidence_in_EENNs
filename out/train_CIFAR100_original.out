============================================================================================== 
Warning! Mixing Conda and module environments may lead to corruption of the
user environment. 
We do not recommend users mixing those two environments unless absolutely
necessary. Note that 
SURF does not provide any support for Conda environment.
For more information, please refer to our software policy page:
https://servicedesk.surf.nl/wiki/display/WIKI/Software+policy+Snellius#SoftwarepolicySnellius-UseofAnacondaandMinicondaenvironmentsonSnellius 

Remember that many packages have already been installed on the system and can
be loaded using 
the 'module load <package__name>' command. If you are uncertain if a package is
already available 
on the system, please use 'module avail' or 'module spider' to search for it.
============================================================================================== 
building network of steps: 
[1, 2, 3, 4] 10
 ********************** Block 1  **********************
|		inScales 3 outScales 3 inChannels 16 outChannels 6		|

 ********************** Block 2  **********************
|		inScales 3 outScales 3 inChannels 22 outChannels 6		|

|		inScales 3 outScales 3 inChannels 28 outChannels 6		|

 ********************** Block 3  **********************
|		inScales 3 outScales 3 inChannels 34 outChannels 6		|

|		inScales 3 outScales 2 inChannels 40 outChannels 6		|
|		Transition layer inserted! (max), inChannels 46, outChannels 23	|

|		inScales 2 outScales 2 inChannels 23 outChannels 6		|

 ********************** Block 4  **********************
|		inScales 2 outScales 2 inChannels 29 outChannels 6		|

|		inScales 2 outScales 2 inChannels 35 outChannels 6		|

|		inScales 2 outScales 1 inChannels 41 outChannels 6		|
|		Transition layer inserted! (max), inChannels 47, outChannels 23	|

|		inScales 1 outScales 1 inChannels 23 outChannels 6		|

---------------------
FLOPs: 6.86M, Params: 0.30M
---------------------
FLOPs: 14.35M, Params: 0.65M
---------------------
FLOPs: 26.13M, Params: 1.02M
---------------------
FLOPs: 38.04M, Params: 1.42M
building network of steps: 
[1, 2, 3, 4] 10
 ********************** Block 1  **********************
|		inScales 3 outScales 3 inChannels 16 outChannels 6		|

 ********************** Block 2  **********************
|		inScales 3 outScales 3 inChannels 22 outChannels 6		|

|		inScales 3 outScales 3 inChannels 28 outChannels 6		|

 ********************** Block 3  **********************
|		inScales 3 outScales 3 inChannels 34 outChannels 6		|

|		inScales 3 outScales 2 inChannels 40 outChannels 6		|
|		Transition layer inserted! (max), inChannels 46, outChannels 23	|

|		inScales 2 outScales 2 inChannels 23 outChannels 6		|

 ********************** Block 4  **********************
|		inScales 2 outScales 2 inChannels 29 outChannels 6		|

|		inScales 2 outScales 2 inChannels 35 outChannels 6		|

|		inScales 2 outScales 1 inChannels 41 outChannels 6		|
|		Transition layer inserted! (max), inChannels 47, outChannels 23	|

|		inScales 1 outScales 1 inChannels 23 outChannels 6		|

Files already downloaded and verified
Files already downloaded and verified
Number of training samples:  50000
Number of test samples:  10000
!!!!!! Load train_set_index !!!!!!
Epoch: [0][1/704]	Time 1.479	Data 1.065	Loss 18.59	Acc@1 0.0	Acc@5 6.2
Epoch: [0][11/704]	Time 0.244	Data 0.097	Loss 18.07	Acc@1 1.6	Acc@5 7.8
Epoch: [0][21/704]	Time 0.185	Data 0.051	Loss 17.48	Acc@1 4.7	Acc@5 12.5
Epoch: [0][31/704]	Time 0.164	Data 0.035	Loss 17.68	Acc@1 3.1	Acc@5 17.2
Epoch: [0][41/704]	Time 0.153	Data 0.026	Loss 17.40	Acc@1 1.6	Acc@5 10.9
Epoch: [0][51/704]	Time 0.147	Data 0.021	Loss 16.90	Acc@1 6.2	Acc@5 20.3
Epoch: [0][61/704]	Time 0.142	Data 0.018	Loss 17.00	Acc@1 1.6	Acc@5 12.5
Epoch: [0][71/704]	Time 0.139	Data 0.015	Loss 16.32	Acc@1 4.7	Acc@5 25.0
Epoch: [0][81/704]	Time 0.137	Data 0.013	Loss 16.97	Acc@1 6.2	Acc@5 23.4
Epoch: [0][91/704]	Time 0.135	Data 0.012	Loss 17.07	Acc@1 0.0	Acc@5 14.1
Epoch: [0][101/704]	Time 0.133	Data 0.011	Loss 16.61	Acc@1 6.2	Acc@5 21.9
Epoch: [0][111/704]	Time 0.132	Data 0.010	Loss 16.04	Acc@1 4.7	Acc@5 29.7
Epoch: [0][121/704]	Time 0.131	Data 0.009	Loss 15.95	Acc@1 4.7	Acc@5 23.4
Epoch: [0][131/704]	Time 0.130	Data 0.008	Loss 16.19	Acc@1 4.7	Acc@5 23.4
Epoch: [0][141/704]	Time 0.130	Data 0.008	Loss 16.35	Acc@1 4.7	Acc@5 25.0
Epoch: [0][151/704]	Time 0.129	Data 0.007	Loss 15.61	Acc@1 7.8	Acc@5 26.6
Epoch: [0][161/704]	Time 0.129	Data 0.007	Loss 15.61	Acc@1 12.5	Acc@5 32.8
Epoch: [0][171/704]	Time 0.128	Data 0.007	Loss 15.67	Acc@1 0.0	Acc@5 20.3
Epoch: [0][181/704]	Time 0.128	Data 0.006	Loss 16.37	Acc@1 9.4	Acc@5 20.3
Epoch: [0][191/704]	Time 0.127	Data 0.006	Loss 16.36	Acc@1 3.1	Acc@5 23.4
Epoch: [0][201/704]	Time 0.127	Data 0.006	Loss 16.07	Acc@1 9.4	Acc@5 26.6
Epoch: [0][211/704]	Time 0.127	Data 0.005	Loss 15.67	Acc@1 10.9	Acc@5 31.2
Epoch: [0][221/704]	Time 0.126	Data 0.005	Loss 15.32	Acc@1 12.5	Acc@5 31.2
Epoch: [0][231/704]	Time 0.126	Data 0.005	Loss 15.48	Acc@1 10.9	Acc@5 28.1
Epoch: [0][241/704]	Time 0.126	Data 0.005	Loss 15.28	Acc@1 15.6	Acc@5 35.9
Epoch: [0][251/704]	Time 0.126	Data 0.005	Loss 16.24	Acc@1 14.1	Acc@5 23.4
Epoch: [0][261/704]	Time 0.125	Data 0.004	Loss 15.06	Acc@1 4.7	Acc@5 29.7
Epoch: [0][271/704]	Time 0.125	Data 0.004	Loss 16.21	Acc@1 7.8	Acc@5 17.2
Epoch: [0][281/704]	Time 0.125	Data 0.004	Loss 15.51	Acc@1 7.8	Acc@5 29.7
Epoch: [0][291/704]	Time 0.125	Data 0.004	Loss 15.64	Acc@1 10.9	Acc@5 28.1
Epoch: [0][301/704]	Time 0.125	Data 0.004	Loss 15.88	Acc@1 6.2	Acc@5 25.0
Epoch: [0][311/704]	Time 0.124	Data 0.004	Loss 15.01	Acc@1 7.8	Acc@5 21.9
Epoch: [0][321/704]	Time 0.124	Data 0.004	Loss 15.15	Acc@1 12.5	Acc@5 32.8
Epoch: [0][331/704]	Time 0.124	Data 0.003	Loss 15.74	Acc@1 4.7	Acc@5 34.4
Epoch: [0][341/704]	Time 0.124	Data 0.003	Loss 13.80	Acc@1 7.8	Acc@5 42.2
Epoch: [0][351/704]	Time 0.124	Data 0.003	Loss 14.63	Acc@1 12.5	Acc@5 45.3
Epoch: [0][361/704]	Time 0.124	Data 0.003	Loss 14.65	Acc@1 17.2	Acc@5 31.2
Epoch: [0][371/704]	Time 0.124	Data 0.003	Loss 14.90	Acc@1 12.5	Acc@5 37.5
Epoch: [0][381/704]	Time 0.124	Data 0.003	Loss 14.95	Acc@1 17.2	Acc@5 32.8
Epoch: [0][391/704]	Time 0.124	Data 0.003	Loss 14.16	Acc@1 10.9	Acc@5 37.5
Epoch: [0][401/704]	Time 0.123	Data 0.003	Loss 15.38	Acc@1 9.4	Acc@5 34.4
Epoch: [0][411/704]	Time 0.123	Data 0.003	Loss 14.52	Acc@1 14.1	Acc@5 39.1
Epoch: [0][421/704]	Time 0.123	Data 0.003	Loss 15.18	Acc@1 9.4	Acc@5 34.4
Epoch: [0][431/704]	Time 0.123	Data 0.003	Loss 14.52	Acc@1 14.1	Acc@5 40.6
Epoch: [0][441/704]	Time 0.123	Data 0.003	Loss 13.89	Acc@1 17.2	Acc@5 42.2
Epoch: [0][451/704]	Time 0.123	Data 0.003	Loss 14.16	Acc@1 14.1	Acc@5 35.9
Epoch: [0][461/704]	Time 0.123	Data 0.003	Loss 14.02	Acc@1 14.1	Acc@5 35.9
Epoch: [0][471/704]	Time 0.123	Data 0.003	Loss 15.24	Acc@1 4.7	Acc@5 37.5
Epoch: [0][481/704]	Time 0.123	Data 0.002	Loss 15.09	Acc@1 7.8	Acc@5 39.1
Epoch: [0][491/704]	Time 0.123	Data 0.002	Loss 15.07	Acc@1 7.8	Acc@5 34.4
Epoch: [0][501/704]	Time 0.123	Data 0.002	Loss 13.26	Acc@1 18.8	Acc@5 48.4
Epoch: [0][511/704]	Time 0.123	Data 0.002	Loss 13.32	Acc@1 18.8	Acc@5 42.2
Epoch: [0][521/704]	Time 0.123	Data 0.002	Loss 15.61	Acc@1 12.5	Acc@5 31.2
Epoch: [0][531/704]	Time 0.123	Data 0.002	Loss 13.47	Acc@1 18.8	Acc@5 43.8
Epoch: [0][541/704]	Time 0.122	Data 0.002	Loss 14.81	Acc@1 14.1	Acc@5 32.8
Epoch: [0][551/704]	Time 0.122	Data 0.002	Loss 14.90	Acc@1 12.5	Acc@5 37.5
Epoch: [0][561/704]	Time 0.122	Data 0.002	Loss 14.95	Acc@1 9.4	Acc@5 32.8
Epoch: [0][571/704]	Time 0.122	Data 0.002	Loss 14.35	Acc@1 15.6	Acc@5 42.2
Epoch: [0][581/704]	Time 0.122	Data 0.002	Loss 14.49	Acc@1 15.6	Acc@5 46.9
Epoch: [0][591/704]	Time 0.122	Data 0.002	Loss 13.80	Acc@1 12.5	Acc@5 40.6
Epoch: [0][601/704]	Time 0.122	Data 0.002	Loss 14.16	Acc@1 12.5	Acc@5 37.5
Epoch: [0][611/704]	Time 0.122	Data 0.002	Loss 14.72	Acc@1 17.2	Acc@5 37.5
Epoch: [0][621/704]	Time 0.122	Data 0.002	Loss 13.50	Acc@1 17.2	Acc@5 48.4
Epoch: [0][631/704]	Time 0.122	Data 0.002	Loss 14.20	Acc@1 14.1	Acc@5 43.8
Epoch: [0][641/704]	Time 0.122	Data 0.002	Loss 15.17	Acc@1 14.1	Acc@5 37.5
Epoch: [0][651/704]	Time 0.122	Data 0.002	Loss 14.49	Acc@1 9.4	Acc@5 43.8
Epoch: [0][661/704]	Time 0.122	Data 0.002	Loss 13.53	Acc@1 20.3	Acc@5 42.2
Epoch: [0][671/704]	Time 0.122	Data 0.002	Loss 13.28	Acc@1 12.5	Acc@5 40.6
Epoch: [0][681/704]	Time 0.122	Data 0.002	Loss 14.68	Acc@1 17.2	Acc@5 35.9
Epoch: [0][691/704]	Time 0.122	Data 0.002	Loss 13.96	Acc@1 18.8	Acc@5 40.6
Epoch: [0][701/704]	Time 0.122	Data 0.002	Loss 13.91	Acc@1 12.5	Acc@5 40.6
Epoch: [1/79]	Time 0.096	Data 0.079	Loss 14.9800	Acc@1 14.0625	Acc@5 34.3750
Epoch: [11/79]	Time 0.023	Data 0.011	Loss 13.9546	Acc@1 17.1875	Acc@5 39.0625
Epoch: [21/79]	Time 0.020	Data 0.007	Loss 12.9381	Acc@1 18.7500	Acc@5 48.4375
Epoch: [31/79]	Time 0.019	Data 0.006	Loss 15.0950	Acc@1 9.3750	Acc@5 39.0625
Epoch: [41/79]	Time 0.018	Data 0.006	Loss 13.1473	Acc@1 31.2500	Acc@5 46.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 14.7085	Acc@1 10.9375	Acc@5 32.8125
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 12.6813	Acc@1 21.8750	Acc@5 50.0000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 13.6282	Acc@1 18.7500	Acc@5 48.4375
 * prec@1 16.680 prec@5 42.400
 * prec@1 16.760 prec@5 44.000
 * prec@1 16.780 prec@5 43.580
 * prec@1 15.140 prec@5 41.820
New best validation last_bloc_accuracy 15.14
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_000.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_000.pth.tar'
Epoch: [1][1/704]	Time 0.295	Data 0.121	Loss 14.00	Acc@1 20.3	Acc@5 39.1
Epoch: [1][11/704]	Time 0.136	Data 0.011	Loss 14.65	Acc@1 14.1	Acc@5 28.1
Epoch: [1][21/704]	Time 0.128	Data 0.006	Loss 13.63	Acc@1 17.2	Acc@5 40.6
Epoch: [1][31/704]	Time 0.126	Data 0.004	Loss 13.40	Acc@1 20.3	Acc@5 45.3
Epoch: [1][41/704]	Time 0.124	Data 0.003	Loss 13.40	Acc@1 12.5	Acc@5 46.9
Epoch: [1][51/704]	Time 0.123	Data 0.003	Loss 13.40	Acc@1 18.8	Acc@5 50.0
Epoch: [1][61/704]	Time 0.123	Data 0.002	Loss 13.26	Acc@1 14.1	Acc@5 46.9
Epoch: [1][71/704]	Time 0.123	Data 0.002	Loss 13.28	Acc@1 21.9	Acc@5 46.9
Epoch: [1][81/704]	Time 0.123	Data 0.002	Loss 13.21	Acc@1 17.2	Acc@5 48.4
Epoch: [1][91/704]	Time 0.122	Data 0.002	Loss 13.48	Acc@1 12.5	Acc@5 50.0
Epoch: [1][101/704]	Time 0.122	Data 0.002	Loss 14.41	Acc@1 20.3	Acc@5 39.1
Epoch: [1][111/704]	Time 0.122	Data 0.001	Loss 12.59	Acc@1 21.9	Acc@5 56.2
Epoch: [1][121/704]	Time 0.122	Data 0.001	Loss 13.36	Acc@1 18.8	Acc@5 43.8
Epoch: [1][131/704]	Time 0.122	Data 0.001	Loss 12.84	Acc@1 10.9	Acc@5 43.8
Epoch: [1][141/704]	Time 0.122	Data 0.001	Loss 13.42	Acc@1 20.3	Acc@5 45.3
Epoch: [1][151/704]	Time 0.121	Data 0.001	Loss 13.43	Acc@1 21.9	Acc@5 54.7
Epoch: [1][161/704]	Time 0.121	Data 0.001	Loss 13.97	Acc@1 17.2	Acc@5 42.2
Epoch: [1][171/704]	Time 0.121	Data 0.001	Loss 13.39	Acc@1 14.1	Acc@5 43.8
Epoch: [1][181/704]	Time 0.121	Data 0.001	Loss 14.67	Acc@1 14.1	Acc@5 40.6
Epoch: [1][191/704]	Time 0.121	Data 0.001	Loss 12.78	Acc@1 12.5	Acc@5 53.1
Epoch: [1][201/704]	Time 0.121	Data 0.001	Loss 12.56	Acc@1 23.4	Acc@5 51.6
Epoch: [1][211/704]	Time 0.121	Data 0.001	Loss 12.86	Acc@1 15.6	Acc@5 48.4
Epoch: [1][221/704]	Time 0.121	Data 0.001	Loss 13.26	Acc@1 12.5	Acc@5 42.2
Epoch: [1][231/704]	Time 0.121	Data 0.001	Loss 12.64	Acc@1 25.0	Acc@5 48.4
Epoch: [1][241/704]	Time 0.121	Data 0.001	Loss 13.70	Acc@1 12.5	Acc@5 42.2
Epoch: [1][251/704]	Time 0.121	Data 0.001	Loss 13.05	Acc@1 21.9	Acc@5 53.1
Epoch: [1][261/704]	Time 0.121	Data 0.001	Loss 13.10	Acc@1 23.4	Acc@5 37.5
Epoch: [1][271/704]	Time 0.121	Data 0.001	Loss 12.39	Acc@1 18.8	Acc@5 59.4
Epoch: [1][281/704]	Time 0.121	Data 0.001	Loss 12.87	Acc@1 25.0	Acc@5 50.0
Epoch: [1][291/704]	Time 0.121	Data 0.001	Loss 13.75	Acc@1 18.8	Acc@5 45.3
Epoch: [1][301/704]	Time 0.121	Data 0.001	Loss 12.86	Acc@1 14.1	Acc@5 54.7
Epoch: [1][311/704]	Time 0.121	Data 0.001	Loss 12.39	Acc@1 17.2	Acc@5 48.4
Epoch: [1][321/704]	Time 0.121	Data 0.001	Loss 13.49	Acc@1 10.9	Acc@5 40.6
Epoch: [1][331/704]	Time 0.121	Data 0.001	Loss 11.75	Acc@1 25.0	Acc@5 60.9
Epoch: [1][341/704]	Time 0.121	Data 0.001	Loss 12.14	Acc@1 28.1	Acc@5 54.7
Epoch: [1][351/704]	Time 0.121	Data 0.001	Loss 11.74	Acc@1 28.1	Acc@5 60.9
Epoch: [1][361/704]	Time 0.121	Data 0.001	Loss 13.62	Acc@1 14.1	Acc@5 46.9
Epoch: [1][371/704]	Time 0.121	Data 0.001	Loss 12.28	Acc@1 18.8	Acc@5 56.2
Epoch: [1][381/704]	Time 0.121	Data 0.001	Loss 12.24	Acc@1 21.9	Acc@5 56.2
Epoch: [1][391/704]	Time 0.121	Data 0.001	Loss 12.77	Acc@1 17.2	Acc@5 59.4
Epoch: [1][401/704]	Time 0.121	Data 0.001	Loss 12.54	Acc@1 17.2	Acc@5 54.7
Epoch: [1][411/704]	Time 0.121	Data 0.001	Loss 12.43	Acc@1 15.6	Acc@5 53.1
Epoch: [1][421/704]	Time 0.121	Data 0.001	Loss 11.60	Acc@1 31.2	Acc@5 64.1
Epoch: [1][431/704]	Time 0.121	Data 0.001	Loss 12.18	Acc@1 28.1	Acc@5 50.0
Epoch: [1][441/704]	Time 0.121	Data 0.001	Loss 13.73	Acc@1 15.6	Acc@5 51.6
Epoch: [1][451/704]	Time 0.121	Data 0.001	Loss 12.64	Acc@1 15.6	Acc@5 57.8
Epoch: [1][461/704]	Time 0.121	Data 0.001	Loss 13.84	Acc@1 20.3	Acc@5 50.0
Epoch: [1][471/704]	Time 0.121	Data 0.001	Loss 13.40	Acc@1 21.9	Acc@5 48.4
Epoch: [1][481/704]	Time 0.121	Data 0.001	Loss 11.99	Acc@1 23.4	Acc@5 59.4
Epoch: [1][491/704]	Time 0.121	Data 0.001	Loss 12.26	Acc@1 20.3	Acc@5 57.8
Epoch: [1][501/704]	Time 0.121	Data 0.001	Loss 12.69	Acc@1 21.9	Acc@5 53.1
Epoch: [1][511/704]	Time 0.121	Data 0.001	Loss 11.41	Acc@1 31.2	Acc@5 68.8
Epoch: [1][521/704]	Time 0.121	Data 0.001	Loss 12.93	Acc@1 23.4	Acc@5 50.0
Epoch: [1][531/704]	Time 0.121	Data 0.001	Loss 13.26	Acc@1 21.9	Acc@5 43.8
Epoch: [1][541/704]	Time 0.121	Data 0.001	Loss 12.09	Acc@1 28.1	Acc@5 54.7
Epoch: [1][551/704]	Time 0.121	Data 0.001	Loss 12.96	Acc@1 18.8	Acc@5 50.0
Epoch: [1][561/704]	Time 0.121	Data 0.001	Loss 11.97	Acc@1 21.9	Acc@5 53.1
Epoch: [1][571/704]	Time 0.121	Data 0.001	Loss 12.32	Acc@1 20.3	Acc@5 53.1
Epoch: [1][581/704]	Time 0.121	Data 0.001	Loss 11.20	Acc@1 34.4	Acc@5 62.5
Epoch: [1][591/704]	Time 0.121	Data 0.001	Loss 11.75	Acc@1 28.1	Acc@5 56.2
Epoch: [1][601/704]	Time 0.121	Data 0.001	Loss 11.55	Acc@1 35.9	Acc@5 62.5
Epoch: [1][611/704]	Time 0.121	Data 0.001	Loss 11.42	Acc@1 23.4	Acc@5 56.2
Epoch: [1][621/704]	Time 0.121	Data 0.001	Loss 11.81	Acc@1 23.4	Acc@5 57.8
Epoch: [1][631/704]	Time 0.121	Data 0.001	Loss 13.47	Acc@1 20.3	Acc@5 45.3
Epoch: [1][641/704]	Time 0.121	Data 0.001	Loss 12.13	Acc@1 18.8	Acc@5 53.1
Epoch: [1][651/704]	Time 0.121	Data 0.001	Loss 12.44	Acc@1 18.8	Acc@5 48.4
Epoch: [1][661/704]	Time 0.121	Data 0.001	Loss 11.77	Acc@1 28.1	Acc@5 54.7
Epoch: [1][671/704]	Time 0.121	Data 0.001	Loss 11.61	Acc@1 29.7	Acc@5 60.9
Epoch: [1][681/704]	Time 0.121	Data 0.001	Loss 11.51	Acc@1 37.5	Acc@5 59.4
Epoch: [1][691/704]	Time 0.121	Data 0.001	Loss 13.41	Acc@1 17.2	Acc@5 46.9
Epoch: [1][701/704]	Time 0.121	Data 0.001	Loss 11.84	Acc@1 32.8	Acc@5 50.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 11.8460	Acc@1 29.6875	Acc@5 57.8125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 11.9591	Acc@1 28.1250	Acc@5 54.6875
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 11.9126	Acc@1 23.4375	Acc@5 57.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 11.3969	Acc@1 26.5625	Acc@5 59.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 11.8026	Acc@1 32.8125	Acc@5 56.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 11.7269	Acc@1 18.7500	Acc@5 57.8125
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 13.6136	Acc@1 23.4375	Acc@5 45.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 13.1931	Acc@1 9.3750	Acc@5 43.7500
 * prec@1 21.360 prec@5 51.280
 * prec@1 22.180 prec@5 52.760
 * prec@1 23.180 prec@5 53.780
 * prec@1 22.620 prec@5 53.220
New best validation last_bloc_accuracy 22.62
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_001.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_001.pth.tar'
Epoch: [2][1/704]	Time 0.331	Data 0.165	Loss 10.91	Acc@1 32.8	Acc@5 65.6
Epoch: [2][11/704]	Time 0.139	Data 0.015	Loss 13.44	Acc@1 18.8	Acc@5 50.0
Epoch: [2][21/704]	Time 0.130	Data 0.008	Loss 11.70	Acc@1 21.9	Acc@5 60.9
Epoch: [2][31/704]	Time 0.127	Data 0.006	Loss 10.31	Acc@1 35.9	Acc@5 67.2
Epoch: [2][41/704]	Time 0.125	Data 0.004	Loss 11.27	Acc@1 37.5	Acc@5 64.1
Epoch: [2][51/704]	Time 0.124	Data 0.004	Loss 11.28	Acc@1 29.7	Acc@5 53.1
Epoch: [2][61/704]	Time 0.123	Data 0.003	Loss 11.84	Acc@1 32.8	Acc@5 54.7
Epoch: [2][71/704]	Time 0.123	Data 0.003	Loss 12.12	Acc@1 23.4	Acc@5 54.7
Epoch: [2][81/704]	Time 0.123	Data 0.002	Loss 12.33	Acc@1 25.0	Acc@5 48.4
Epoch: [2][91/704]	Time 0.122	Data 0.002	Loss 12.57	Acc@1 25.0	Acc@5 50.0
Epoch: [2][101/704]	Time 0.122	Data 0.002	Loss 13.70	Acc@1 18.8	Acc@5 42.2
Epoch: [2][111/704]	Time 0.122	Data 0.002	Loss 11.09	Acc@1 21.9	Acc@5 70.3
Epoch: [2][121/704]	Time 0.122	Data 0.002	Loss 13.40	Acc@1 18.8	Acc@5 45.3
Epoch: [2][131/704]	Time 0.122	Data 0.002	Loss 10.56	Acc@1 29.7	Acc@5 67.2
Epoch: [2][141/704]	Time 0.122	Data 0.002	Loss 10.83	Acc@1 28.1	Acc@5 64.1
Epoch: [2][151/704]	Time 0.121	Data 0.001	Loss 11.79	Acc@1 28.1	Acc@5 62.5
Epoch: [2][161/704]	Time 0.121	Data 0.001	Loss 13.08	Acc@1 25.0	Acc@5 53.1
Epoch: [2][171/704]	Time 0.121	Data 0.001	Loss 11.78	Acc@1 29.7	Acc@5 53.1
Epoch: [2][181/704]	Time 0.121	Data 0.001	Loss 11.83	Acc@1 23.4	Acc@5 59.4
Epoch: [2][191/704]	Time 0.121	Data 0.001	Loss 11.26	Acc@1 29.7	Acc@5 54.7
Epoch: [2][201/704]	Time 0.121	Data 0.001	Loss 11.49	Acc@1 31.2	Acc@5 57.8
Epoch: [2][211/704]	Time 0.121	Data 0.001	Loss 10.48	Acc@1 37.5	Acc@5 71.9
Epoch: [2][221/704]	Time 0.121	Data 0.001	Loss 12.88	Acc@1 25.0	Acc@5 51.6
Epoch: [2][231/704]	Time 0.121	Data 0.001	Loss 12.28	Acc@1 18.8	Acc@5 46.9
Epoch: [2][241/704]	Time 0.121	Data 0.001	Loss 11.59	Acc@1 29.7	Acc@5 60.9
Epoch: [2][251/704]	Time 0.121	Data 0.001	Loss 10.69	Acc@1 34.4	Acc@5 62.5
Epoch: [2][261/704]	Time 0.121	Data 0.001	Loss 11.67	Acc@1 23.4	Acc@5 65.6
Epoch: [2][271/704]	Time 0.121	Data 0.001	Loss 11.27	Acc@1 29.7	Acc@5 57.8
Epoch: [2][281/704]	Time 0.121	Data 0.001	Loss 10.62	Acc@1 26.6	Acc@5 62.5
Epoch: [2][291/704]	Time 0.121	Data 0.001	Loss 12.80	Acc@1 21.9	Acc@5 51.6
Epoch: [2][301/704]	Time 0.121	Data 0.001	Loss 11.30	Acc@1 37.5	Acc@5 59.4
Epoch: [2][311/704]	Time 0.121	Data 0.001	Loss 11.33	Acc@1 28.1	Acc@5 68.8
Epoch: [2][321/704]	Time 0.121	Data 0.001	Loss 11.02	Acc@1 29.7	Acc@5 67.2
Epoch: [2][331/704]	Time 0.121	Data 0.001	Loss 10.17	Acc@1 40.6	Acc@5 67.2
Epoch: [2][341/704]	Time 0.121	Data 0.001	Loss 11.59	Acc@1 26.6	Acc@5 56.2
Epoch: [2][351/704]	Time 0.121	Data 0.001	Loss 12.51	Acc@1 26.6	Acc@5 56.2
Epoch: [2][361/704]	Time 0.121	Data 0.001	Loss 11.40	Acc@1 31.2	Acc@5 60.9
Epoch: [2][371/704]	Time 0.121	Data 0.001	Loss 11.71	Acc@1 23.4	Acc@5 60.9
Epoch: [2][381/704]	Time 0.121	Data 0.001	Loss 12.40	Acc@1 21.9	Acc@5 53.1
Epoch: [2][391/704]	Time 0.121	Data 0.001	Loss 11.35	Acc@1 28.1	Acc@5 57.8
Epoch: [2][401/704]	Time 0.121	Data 0.001	Loss 11.40	Acc@1 31.2	Acc@5 65.6
Epoch: [2][411/704]	Time 0.120	Data 0.001	Loss 11.45	Acc@1 25.0	Acc@5 53.1
Epoch: [2][421/704]	Time 0.120	Data 0.001	Loss 12.86	Acc@1 25.0	Acc@5 54.7
Epoch: [2][431/704]	Time 0.120	Data 0.001	Loss 11.30	Acc@1 25.0	Acc@5 54.7
Epoch: [2][441/704]	Time 0.120	Data 0.001	Loss 10.12	Acc@1 37.5	Acc@5 76.6
Epoch: [2][451/704]	Time 0.120	Data 0.001	Loss 10.45	Acc@1 34.4	Acc@5 65.6
Epoch: [2][461/704]	Time 0.121	Data 0.001	Loss 10.55	Acc@1 25.0	Acc@5 65.6
Epoch: [2][471/704]	Time 0.121	Data 0.001	Loss 11.30	Acc@1 32.8	Acc@5 62.5
Epoch: [2][481/704]	Time 0.121	Data 0.001	Loss 11.01	Acc@1 31.2	Acc@5 57.8
Epoch: [2][491/704]	Time 0.121	Data 0.001	Loss 11.58	Acc@1 31.2	Acc@5 59.4
Epoch: [2][501/704]	Time 0.121	Data 0.001	Loss 10.36	Acc@1 37.5	Acc@5 71.9
Epoch: [2][511/704]	Time 0.121	Data 0.001	Loss 11.86	Acc@1 28.1	Acc@5 60.9
Epoch: [2][521/704]	Time 0.120	Data 0.001	Loss 11.08	Acc@1 28.1	Acc@5 64.1
Epoch: [2][531/704]	Time 0.120	Data 0.001	Loss 10.76	Acc@1 29.7	Acc@5 65.6
Epoch: [2][541/704]	Time 0.120	Data 0.001	Loss 10.54	Acc@1 28.1	Acc@5 67.2
Epoch: [2][551/704]	Time 0.120	Data 0.001	Loss 11.65	Acc@1 29.7	Acc@5 59.4
Epoch: [2][561/704]	Time 0.120	Data 0.001	Loss 10.68	Acc@1 34.4	Acc@5 56.2
Epoch: [2][571/704]	Time 0.120	Data 0.001	Loss 11.46	Acc@1 21.9	Acc@5 53.1
Epoch: [2][581/704]	Time 0.120	Data 0.001	Loss 11.54	Acc@1 29.7	Acc@5 59.4
Epoch: [2][591/704]	Time 0.120	Data 0.001	Loss 11.90	Acc@1 26.6	Acc@5 56.2
Epoch: [2][601/704]	Time 0.120	Data 0.001	Loss 11.36	Acc@1 31.2	Acc@5 65.6
Epoch: [2][611/704]	Time 0.120	Data 0.001	Loss 9.82	Acc@1 43.8	Acc@5 71.9
Epoch: [2][621/704]	Time 0.120	Data 0.001	Loss 11.71	Acc@1 21.9	Acc@5 53.1
Epoch: [2][631/704]	Time 0.120	Data 0.001	Loss 11.65	Acc@1 26.6	Acc@5 62.5
Epoch: [2][641/704]	Time 0.120	Data 0.001	Loss 12.14	Acc@1 29.7	Acc@5 59.4
Epoch: [2][651/704]	Time 0.120	Data 0.001	Loss 10.31	Acc@1 32.8	Acc@5 67.2
Epoch: [2][661/704]	Time 0.120	Data 0.001	Loss 10.87	Acc@1 32.8	Acc@5 67.2
Epoch: [2][671/704]	Time 0.120	Data 0.001	Loss 9.99	Acc@1 42.2	Acc@5 67.2
Epoch: [2][681/704]	Time 0.120	Data 0.001	Loss 13.07	Acc@1 25.0	Acc@5 51.6
Epoch: [2][691/704]	Time 0.120	Data 0.001	Loss 10.81	Acc@1 32.8	Acc@5 59.4
Epoch: [2][701/704]	Time 0.120	Data 0.001	Loss 11.01	Acc@1 28.1	Acc@5 53.1
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 12.6286	Acc@1 25.0000	Acc@5 59.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 11.2975	Acc@1 26.5625	Acc@5 59.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 11.6678	Acc@1 29.6875	Acc@5 54.6875
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 10.6621	Acc@1 31.2500	Acc@5 73.4375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 11.1452	Acc@1 31.2500	Acc@5 62.5000
Epoch: [51/79]	Time 0.019	Data 0.006	Loss 12.0264	Acc@1 26.5625	Acc@5 64.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 10.4480	Acc@1 37.5000	Acc@5 68.7500
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 12.2259	Acc@1 20.3125	Acc@5 59.3750
 * prec@1 26.020 prec@5 56.540
 * prec@1 28.420 prec@5 59.620
 * prec@1 30.740 prec@5 62.380
 * prec@1 29.900 prec@5 62.340
New best validation last_bloc_accuracy 29.9
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_002.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_002.pth.tar'
Epoch: [3][1/704]	Time 0.328	Data 0.163	Loss 9.39	Acc@1 35.9	Acc@5 73.4
Epoch: [3][11/704]	Time 0.139	Data 0.015	Loss 11.49	Acc@1 31.2	Acc@5 65.6
Epoch: [3][21/704]	Time 0.130	Data 0.008	Loss 11.46	Acc@1 39.1	Acc@5 62.5
Epoch: [3][31/704]	Time 0.126	Data 0.006	Loss 11.19	Acc@1 34.4	Acc@5 65.6
Epoch: [3][41/704]	Time 0.125	Data 0.004	Loss 9.52	Acc@1 42.2	Acc@5 68.8
Epoch: [3][51/704]	Time 0.124	Data 0.004	Loss 11.47	Acc@1 29.7	Acc@5 60.9
Epoch: [3][61/704]	Time 0.123	Data 0.003	Loss 9.59	Acc@1 45.3	Acc@5 70.3
Epoch: [3][71/704]	Time 0.122	Data 0.003	Loss 10.78	Acc@1 37.5	Acc@5 64.1
Epoch: [3][81/704]	Time 0.122	Data 0.002	Loss 10.90	Acc@1 31.2	Acc@5 62.5
Epoch: [3][91/704]	Time 0.122	Data 0.002	Loss 10.65	Acc@1 37.5	Acc@5 70.3
Epoch: [3][101/704]	Time 0.121	Data 0.002	Loss 11.14	Acc@1 32.8	Acc@5 60.9
Epoch: [3][111/704]	Time 0.121	Data 0.002	Loss 11.79	Acc@1 29.7	Acc@5 65.6
Epoch: [3][121/704]	Time 0.121	Data 0.002	Loss 12.11	Acc@1 21.9	Acc@5 62.5
Epoch: [3][131/704]	Time 0.121	Data 0.002	Loss 11.27	Acc@1 31.2	Acc@5 67.2
Epoch: [3][141/704]	Time 0.121	Data 0.001	Loss 11.30	Acc@1 31.2	Acc@5 64.1
Epoch: [3][151/704]	Time 0.121	Data 0.001	Loss 10.84	Acc@1 29.7	Acc@5 70.3
Epoch: [3][161/704]	Time 0.121	Data 0.001	Loss 12.03	Acc@1 25.0	Acc@5 56.2
Epoch: [3][171/704]	Time 0.121	Data 0.001	Loss 9.34	Acc@1 40.6	Acc@5 70.3
Epoch: [3][181/704]	Time 0.121	Data 0.001	Loss 9.09	Acc@1 43.8	Acc@5 79.7
Epoch: [3][191/704]	Time 0.121	Data 0.001	Loss 10.42	Acc@1 34.4	Acc@5 59.4
Epoch: [3][201/704]	Time 0.121	Data 0.001	Loss 10.72	Acc@1 29.7	Acc@5 73.4
Epoch: [3][211/704]	Time 0.121	Data 0.001	Loss 9.92	Acc@1 40.6	Acc@5 67.2
Epoch: [3][221/704]	Time 0.120	Data 0.001	Loss 10.77	Acc@1 40.6	Acc@5 73.4
Epoch: [3][231/704]	Time 0.120	Data 0.001	Loss 11.72	Acc@1 26.6	Acc@5 53.1
Epoch: [3][241/704]	Time 0.120	Data 0.001	Loss 11.31	Acc@1 29.7	Acc@5 64.1
Epoch: [3][251/704]	Time 0.120	Data 0.001	Loss 10.77	Acc@1 32.8	Acc@5 59.4
Epoch: [3][261/704]	Time 0.120	Data 0.001	Loss 10.24	Acc@1 31.2	Acc@5 67.2
Epoch: [3][271/704]	Time 0.120	Data 0.001	Loss 10.11	Acc@1 31.2	Acc@5 65.6
Epoch: [3][281/704]	Time 0.120	Data 0.001	Loss 11.25	Acc@1 34.4	Acc@5 64.1
Epoch: [3][291/704]	Time 0.120	Data 0.001	Loss 10.72	Acc@1 26.6	Acc@5 67.2
Epoch: [3][301/704]	Time 0.120	Data 0.001	Loss 10.83	Acc@1 32.8	Acc@5 71.9
Epoch: [3][311/704]	Time 0.120	Data 0.001	Loss 10.93	Acc@1 31.2	Acc@5 60.9
Epoch: [3][321/704]	Time 0.120	Data 0.001	Loss 11.32	Acc@1 34.4	Acc@5 65.6
Epoch: [3][331/704]	Time 0.120	Data 0.001	Loss 11.79	Acc@1 35.9	Acc@5 56.2
Epoch: [3][341/704]	Time 0.120	Data 0.001	Loss 10.29	Acc@1 35.9	Acc@5 68.8
Epoch: [3][351/704]	Time 0.120	Data 0.001	Loss 9.75	Acc@1 37.5	Acc@5 75.0
Epoch: [3][361/704]	Time 0.120	Data 0.001	Loss 10.48	Acc@1 29.7	Acc@5 71.9
Epoch: [3][371/704]	Time 0.120	Data 0.001	Loss 10.52	Acc@1 37.5	Acc@5 70.3
Epoch: [3][381/704]	Time 0.120	Data 0.001	Loss 10.63	Acc@1 17.2	Acc@5 71.9
Epoch: [3][391/704]	Time 0.120	Data 0.001	Loss 11.19	Acc@1 31.2	Acc@5 59.4
Epoch: [3][401/704]	Time 0.120	Data 0.001	Loss 10.12	Acc@1 29.7	Acc@5 62.5
Epoch: [3][411/704]	Time 0.120	Data 0.001	Loss 11.75	Acc@1 29.7	Acc@5 60.9
Epoch: [3][421/704]	Time 0.120	Data 0.001	Loss 9.78	Acc@1 34.4	Acc@5 70.3
Epoch: [3][431/704]	Time 0.120	Data 0.001	Loss 9.33	Acc@1 35.9	Acc@5 68.8
Epoch: [3][441/704]	Time 0.120	Data 0.001	Loss 9.72	Acc@1 39.1	Acc@5 68.8
Epoch: [3][451/704]	Time 0.120	Data 0.001	Loss 9.25	Acc@1 39.1	Acc@5 71.9
Epoch: [3][461/704]	Time 0.120	Data 0.001	Loss 10.87	Acc@1 29.7	Acc@5 71.9
Epoch: [3][471/704]	Time 0.120	Data 0.001	Loss 10.44	Acc@1 29.7	Acc@5 65.6
Epoch: [3][481/704]	Time 0.120	Data 0.001	Loss 10.85	Acc@1 37.5	Acc@5 68.8
Epoch: [3][491/704]	Time 0.120	Data 0.001	Loss 9.20	Acc@1 45.3	Acc@5 70.3
Epoch: [3][501/704]	Time 0.120	Data 0.001	Loss 9.92	Acc@1 34.4	Acc@5 73.4
Epoch: [3][511/704]	Time 0.120	Data 0.001	Loss 9.85	Acc@1 40.6	Acc@5 65.6
Epoch: [3][521/704]	Time 0.120	Data 0.001	Loss 9.13	Acc@1 45.3	Acc@5 82.8
Epoch: [3][531/704]	Time 0.120	Data 0.001	Loss 10.10	Acc@1 48.4	Acc@5 76.6
Epoch: [3][541/704]	Time 0.120	Data 0.001	Loss 10.49	Acc@1 32.8	Acc@5 73.4
Epoch: [3][551/704]	Time 0.120	Data 0.001	Loss 9.75	Acc@1 37.5	Acc@5 70.3
Epoch: [3][561/704]	Time 0.120	Data 0.001	Loss 11.00	Acc@1 35.9	Acc@5 60.9
Epoch: [3][571/704]	Time 0.120	Data 0.001	Loss 9.05	Acc@1 43.8	Acc@5 76.6
Epoch: [3][581/704]	Time 0.120	Data 0.001	Loss 9.25	Acc@1 40.6	Acc@5 75.0
Epoch: [3][591/704]	Time 0.120	Data 0.001	Loss 10.76	Acc@1 39.1	Acc@5 68.8
Epoch: [3][601/704]	Time 0.120	Data 0.001	Loss 12.09	Acc@1 25.0	Acc@5 64.1
Epoch: [3][611/704]	Time 0.120	Data 0.001	Loss 11.22	Acc@1 29.7	Acc@5 65.6
Epoch: [3][621/704]	Time 0.120	Data 0.001	Loss 11.38	Acc@1 31.2	Acc@5 62.5
Epoch: [3][631/704]	Time 0.120	Data 0.001	Loss 10.61	Acc@1 34.4	Acc@5 67.2
Epoch: [3][641/704]	Time 0.120	Data 0.001	Loss 10.55	Acc@1 40.6	Acc@5 65.6
Epoch: [3][651/704]	Time 0.120	Data 0.001	Loss 9.44	Acc@1 42.2	Acc@5 78.1
Epoch: [3][661/704]	Time 0.120	Data 0.001	Loss 10.26	Acc@1 37.5	Acc@5 62.5
Epoch: [3][671/704]	Time 0.120	Data 0.001	Loss 9.21	Acc@1 46.9	Acc@5 70.3
Epoch: [3][681/704]	Time 0.120	Data 0.001	Loss 10.06	Acc@1 40.6	Acc@5 64.1
Epoch: [3][691/704]	Time 0.120	Data 0.001	Loss 8.89	Acc@1 32.8	Acc@5 73.4
Epoch: [3][701/704]	Time 0.120	Data 0.001	Loss 10.43	Acc@1 34.4	Acc@5 68.8
Epoch: [1/79]	Time 0.132	Data 0.118	Loss 10.2595	Acc@1 37.5000	Acc@5 65.6250
Epoch: [11/79]	Time 0.027	Data 0.015	Loss 9.6010	Acc@1 40.6250	Acc@5 73.4375
Epoch: [21/79]	Time 0.022	Data 0.010	Loss 11.4651	Acc@1 26.5625	Acc@5 65.6250
Epoch: [31/79]	Time 0.020	Data 0.008	Loss 11.8642	Acc@1 23.4375	Acc@5 68.7500
Epoch: [41/79]	Time 0.019	Data 0.007	Loss 9.8582	Acc@1 42.1875	Acc@5 67.1875
Epoch: [51/79]	Time 0.019	Data 0.007	Loss 10.4975	Acc@1 28.1250	Acc@5 70.3125
Epoch: [61/79]	Time 0.019	Data 0.006	Loss 10.9392	Acc@1 28.1250	Acc@5 64.0625
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 9.1855	Acc@1 40.6250	Acc@5 73.4375
 * prec@1 27.840 prec@5 59.540
 * prec@1 32.760 prec@5 65.580
 * prec@1 36.160 prec@5 68.120
 * prec@1 35.120 prec@5 68.260
New best validation last_bloc_accuracy 35.12
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_003.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_003.pth.tar'
Epoch: [4][1/704]	Time 0.294	Data 0.128	Loss 9.63	Acc@1 42.2	Acc@5 68.8
Epoch: [4][11/704]	Time 0.136	Data 0.012	Loss 10.04	Acc@1 32.8	Acc@5 70.3
Epoch: [4][21/704]	Time 0.128	Data 0.006	Loss 10.62	Acc@1 34.4	Acc@5 67.2
Epoch: [4][31/704]	Time 0.125	Data 0.004	Loss 9.30	Acc@1 42.2	Acc@5 79.7
Epoch: [4][41/704]	Time 0.124	Data 0.003	Loss 9.78	Acc@1 29.7	Acc@5 67.2
Epoch: [4][51/704]	Time 0.123	Data 0.003	Loss 9.93	Acc@1 37.5	Acc@5 71.9
Epoch: [4][61/704]	Time 0.123	Data 0.002	Loss 10.22	Acc@1 34.4	Acc@5 70.3
Epoch: [4][71/704]	Time 0.123	Data 0.002	Loss 10.80	Acc@1 26.6	Acc@5 62.5
Epoch: [4][81/704]	Time 0.122	Data 0.002	Loss 8.56	Acc@1 48.4	Acc@5 79.7
Epoch: [4][91/704]	Time 0.122	Data 0.002	Loss 9.68	Acc@1 40.6	Acc@5 70.3
Epoch: [4][101/704]	Time 0.122	Data 0.002	Loss 9.35	Acc@1 39.1	Acc@5 73.4
Epoch: [4][111/704]	Time 0.122	Data 0.001	Loss 9.62	Acc@1 43.8	Acc@5 76.6
Epoch: [4][121/704]	Time 0.122	Data 0.001	Loss 9.45	Acc@1 45.3	Acc@5 73.4
Epoch: [4][131/704]	Time 0.122	Data 0.001	Loss 9.08	Acc@1 48.4	Acc@5 76.6
Epoch: [4][141/704]	Time 0.121	Data 0.001	Loss 8.80	Acc@1 39.1	Acc@5 81.2
Epoch: [4][151/704]	Time 0.121	Data 0.001	Loss 9.78	Acc@1 31.2	Acc@5 73.4
Epoch: [4][161/704]	Time 0.121	Data 0.001	Loss 8.79	Acc@1 50.0	Acc@5 81.2
Epoch: [4][171/704]	Time 0.121	Data 0.001	Loss 10.23	Acc@1 31.2	Acc@5 75.0
Epoch: [4][181/704]	Time 0.121	Data 0.001	Loss 8.04	Acc@1 45.3	Acc@5 76.6
Epoch: [4][191/704]	Time 0.121	Data 0.001	Loss 9.99	Acc@1 37.5	Acc@5 75.0
Epoch: [4][201/704]	Time 0.121	Data 0.001	Loss 9.44	Acc@1 35.9	Acc@5 76.6
Epoch: [4][211/704]	Time 0.121	Data 0.001	Loss 9.55	Acc@1 32.8	Acc@5 78.1
Epoch: [4][221/704]	Time 0.121	Data 0.001	Loss 8.70	Acc@1 40.6	Acc@5 75.0
Epoch: [4][231/704]	Time 0.121	Data 0.001	Loss 9.27	Acc@1 43.8	Acc@5 76.6
Epoch: [4][241/704]	Time 0.121	Data 0.001	Loss 9.59	Acc@1 39.1	Acc@5 76.6
Epoch: [4][251/704]	Time 0.121	Data 0.001	Loss 9.60	Acc@1 37.5	Acc@5 73.4
Epoch: [4][261/704]	Time 0.121	Data 0.001	Loss 8.30	Acc@1 46.9	Acc@5 82.8
Epoch: [4][271/704]	Time 0.121	Data 0.001	Loss 10.49	Acc@1 32.8	Acc@5 67.2
Epoch: [4][281/704]	Time 0.121	Data 0.001	Loss 8.99	Acc@1 34.4	Acc@5 73.4
Epoch: [4][291/704]	Time 0.120	Data 0.001	Loss 10.03	Acc@1 45.3	Acc@5 76.6
Epoch: [4][301/704]	Time 0.120	Data 0.001	Loss 10.30	Acc@1 37.5	Acc@5 70.3
Epoch: [4][311/704]	Time 0.120	Data 0.001	Loss 10.24	Acc@1 32.8	Acc@5 64.1
Epoch: [4][321/704]	Time 0.120	Data 0.001	Loss 8.09	Acc@1 43.8	Acc@5 79.7
Epoch: [4][331/704]	Time 0.120	Data 0.001	Loss 10.10	Acc@1 39.1	Acc@5 73.4
Epoch: [4][341/704]	Time 0.120	Data 0.001	Loss 9.84	Acc@1 35.9	Acc@5 64.1
Epoch: [4][351/704]	Time 0.120	Data 0.001	Loss 11.29	Acc@1 29.7	Acc@5 60.9
Epoch: [4][361/704]	Time 0.120	Data 0.001	Loss 9.35	Acc@1 40.6	Acc@5 71.9
Epoch: [4][371/704]	Time 0.120	Data 0.001	Loss 9.62	Acc@1 32.8	Acc@5 76.6
Epoch: [4][381/704]	Time 0.120	Data 0.001	Loss 9.66	Acc@1 43.8	Acc@5 73.4
Epoch: [4][391/704]	Time 0.120	Data 0.001	Loss 10.77	Acc@1 29.7	Acc@5 70.3
Epoch: [4][401/704]	Time 0.120	Data 0.001	Loss 8.87	Acc@1 42.2	Acc@5 78.1
Epoch: [4][411/704]	Time 0.120	Data 0.001	Loss 10.44	Acc@1 37.5	Acc@5 71.9
Epoch: [4][421/704]	Time 0.120	Data 0.001	Loss 10.18	Acc@1 31.2	Acc@5 70.3
Epoch: [4][431/704]	Time 0.120	Data 0.001	Loss 9.26	Acc@1 42.2	Acc@5 81.2
Epoch: [4][441/704]	Time 0.120	Data 0.001	Loss 9.99	Acc@1 35.9	Acc@5 73.4
Epoch: [4][451/704]	Time 0.120	Data 0.001	Loss 10.60	Acc@1 31.2	Acc@5 70.3
Epoch: [4][461/704]	Time 0.120	Data 0.001	Loss 9.40	Acc@1 39.1	Acc@5 71.9
Epoch: [4][471/704]	Time 0.120	Data 0.001	Loss 9.42	Acc@1 46.9	Acc@5 73.4
Epoch: [4][481/704]	Time 0.120	Data 0.001	Loss 9.55	Acc@1 39.1	Acc@5 71.9
Epoch: [4][491/704]	Time 0.120	Data 0.001	Loss 10.35	Acc@1 39.1	Acc@5 65.6
Epoch: [4][501/704]	Time 0.120	Data 0.001	Loss 9.79	Acc@1 42.2	Acc@5 70.3
Epoch: [4][511/704]	Time 0.120	Data 0.001	Loss 10.13	Acc@1 35.9	Acc@5 70.3
Epoch: [4][521/704]	Time 0.120	Data 0.001	Loss 10.19	Acc@1 34.4	Acc@5 64.1
Epoch: [4][531/704]	Time 0.120	Data 0.001	Loss 10.23	Acc@1 32.8	Acc@5 71.9
Epoch: [4][541/704]	Time 0.120	Data 0.001	Loss 9.54	Acc@1 40.6	Acc@5 81.2
Epoch: [4][551/704]	Time 0.120	Data 0.001	Loss 8.86	Acc@1 43.8	Acc@5 71.9
Epoch: [4][561/704]	Time 0.120	Data 0.001	Loss 10.45	Acc@1 32.8	Acc@5 65.6
Epoch: [4][571/704]	Time 0.120	Data 0.001	Loss 9.90	Acc@1 40.6	Acc@5 70.3
Epoch: [4][581/704]	Time 0.120	Data 0.001	Loss 8.72	Acc@1 48.4	Acc@5 75.0
Epoch: [4][591/704]	Time 0.120	Data 0.001	Loss 9.04	Acc@1 45.3	Acc@5 75.0
Epoch: [4][601/704]	Time 0.120	Data 0.001	Loss 10.16	Acc@1 37.5	Acc@5 70.3
Epoch: [4][611/704]	Time 0.120	Data 0.001	Loss 9.28	Acc@1 42.2	Acc@5 73.4
Epoch: [4][621/704]	Time 0.120	Data 0.001	Loss 10.14	Acc@1 29.7	Acc@5 73.4
Epoch: [4][631/704]	Time 0.120	Data 0.001	Loss 9.73	Acc@1 31.2	Acc@5 73.4
Epoch: [4][641/704]	Time 0.120	Data 0.001	Loss 9.47	Acc@1 31.2	Acc@5 73.4
Epoch: [4][651/704]	Time 0.120	Data 0.001	Loss 10.82	Acc@1 37.5	Acc@5 62.5
Epoch: [4][661/704]	Time 0.120	Data 0.001	Loss 8.30	Acc@1 50.0	Acc@5 76.6
Epoch: [4][671/704]	Time 0.120	Data 0.001	Loss 10.15	Acc@1 37.5	Acc@5 68.8
Epoch: [4][681/704]	Time 0.120	Data 0.001	Loss 8.93	Acc@1 39.1	Acc@5 79.7
Epoch: [4][691/704]	Time 0.120	Data 0.001	Loss 9.02	Acc@1 42.2	Acc@5 73.4
Epoch: [4][701/704]	Time 0.120	Data 0.001	Loss 8.94	Acc@1 39.1	Acc@5 79.7
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 10.1182	Acc@1 28.1250	Acc@5 64.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 10.1071	Acc@1 43.7500	Acc@5 65.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 11.0019	Acc@1 32.8125	Acc@5 59.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 10.4006	Acc@1 37.5000	Acc@5 64.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 10.4379	Acc@1 29.6875	Acc@5 60.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 10.2757	Acc@1 39.0625	Acc@5 68.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 10.2250	Acc@1 29.6875	Acc@5 71.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 10.2817	Acc@1 32.8125	Acc@5 70.3125
 * prec@1 29.240 prec@5 61.080
 * prec@1 33.020 prec@5 65.760
 * prec@1 36.760 prec@5 69.300
 * prec@1 35.180 prec@5 67.520
New best validation last_bloc_accuracy 35.18
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_004.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_004.pth.tar'
Epoch: [5][1/704]	Time 0.295	Data 0.129	Loss 10.65	Acc@1 26.6	Acc@5 73.4
Epoch: [5][11/704]	Time 0.135	Data 0.012	Loss 9.19	Acc@1 37.5	Acc@5 75.0
Epoch: [5][21/704]	Time 0.128	Data 0.006	Loss 9.17	Acc@1 39.1	Acc@5 73.4
Epoch: [5][31/704]	Time 0.125	Data 0.004	Loss 9.00	Acc@1 40.6	Acc@5 76.6
Epoch: [5][41/704]	Time 0.125	Data 0.003	Loss 8.76	Acc@1 42.2	Acc@5 82.8
Epoch: [5][51/704]	Time 0.124	Data 0.003	Loss 9.29	Acc@1 39.1	Acc@5 76.6
Epoch: [5][61/704]	Time 0.123	Data 0.002	Loss 8.79	Acc@1 35.9	Acc@5 79.7
Epoch: [5][71/704]	Time 0.122	Data 0.002	Loss 9.05	Acc@1 34.4	Acc@5 73.4
Epoch: [5][81/704]	Time 0.122	Data 0.002	Loss 9.49	Acc@1 35.9	Acc@5 78.1
Epoch: [5][91/704]	Time 0.122	Data 0.002	Loss 9.26	Acc@1 42.2	Acc@5 70.3
Epoch: [5][101/704]	Time 0.122	Data 0.002	Loss 9.55	Acc@1 32.8	Acc@5 76.6
Epoch: [5][111/704]	Time 0.122	Data 0.002	Loss 8.48	Acc@1 56.2	Acc@5 78.1
Epoch: [5][121/704]	Time 0.121	Data 0.001	Loss 8.67	Acc@1 43.8	Acc@5 79.7
Epoch: [5][131/704]	Time 0.121	Data 0.001	Loss 9.21	Acc@1 39.1	Acc@5 73.4
Epoch: [5][141/704]	Time 0.121	Data 0.001	Loss 8.78	Acc@1 40.6	Acc@5 73.4
Epoch: [5][151/704]	Time 0.121	Data 0.001	Loss 9.38	Acc@1 43.8	Acc@5 68.8
Epoch: [5][161/704]	Time 0.121	Data 0.001	Loss 9.10	Acc@1 48.4	Acc@5 75.0
Epoch: [5][171/704]	Time 0.121	Data 0.001	Loss 8.38	Acc@1 54.7	Acc@5 84.4
Epoch: [5][181/704]	Time 0.121	Data 0.001	Loss 9.54	Acc@1 35.9	Acc@5 76.6
Epoch: [5][191/704]	Time 0.121	Data 0.001	Loss 8.97	Acc@1 37.5	Acc@5 73.4
Epoch: [5][201/704]	Time 0.121	Data 0.001	Loss 8.98	Acc@1 43.8	Acc@5 75.0
Epoch: [5][211/704]	Time 0.120	Data 0.001	Loss 9.17	Acc@1 43.8	Acc@5 75.0
Epoch: [5][221/704]	Time 0.120	Data 0.001	Loss 8.39	Acc@1 43.8	Acc@5 78.1
Epoch: [5][231/704]	Time 0.120	Data 0.001	Loss 9.58	Acc@1 35.9	Acc@5 71.9
Epoch: [5][241/704]	Time 0.120	Data 0.001	Loss 9.37	Acc@1 39.1	Acc@5 78.1
Epoch: [5][251/704]	Time 0.120	Data 0.001	Loss 9.48	Acc@1 37.5	Acc@5 70.3
Epoch: [5][261/704]	Time 0.120	Data 0.001	Loss 9.58	Acc@1 37.5	Acc@5 67.2
Epoch: [5][271/704]	Time 0.120	Data 0.001	Loss 9.03	Acc@1 45.3	Acc@5 78.1
Epoch: [5][281/704]	Time 0.120	Data 0.001	Loss 10.04	Acc@1 35.9	Acc@5 70.3
Epoch: [5][291/704]	Time 0.120	Data 0.001	Loss 9.80	Acc@1 43.8	Acc@5 70.3
Epoch: [5][301/704]	Time 0.120	Data 0.001	Loss 10.95	Acc@1 28.1	Acc@5 67.2
Epoch: [5][311/704]	Time 0.120	Data 0.001	Loss 9.73	Acc@1 39.1	Acc@5 64.1
Epoch: [5][321/704]	Time 0.120	Data 0.001	Loss 9.74	Acc@1 37.5	Acc@5 73.4
Epoch: [5][331/704]	Time 0.120	Data 0.001	Loss 10.38	Acc@1 32.8	Acc@5 60.9
Epoch: [5][341/704]	Time 0.120	Data 0.001	Loss 8.80	Acc@1 43.8	Acc@5 78.1
Epoch: [5][351/704]	Time 0.120	Data 0.001	Loss 8.29	Acc@1 39.1	Acc@5 76.6
Epoch: [5][361/704]	Time 0.120	Data 0.001	Loss 8.64	Acc@1 46.9	Acc@5 78.1
Epoch: [5][371/704]	Time 0.120	Data 0.001	Loss 9.69	Acc@1 35.9	Acc@5 76.6
Epoch: [5][381/704]	Time 0.120	Data 0.001	Loss 7.86	Acc@1 48.4	Acc@5 89.1
Epoch: [5][391/704]	Time 0.120	Data 0.001	Loss 8.45	Acc@1 40.6	Acc@5 79.7
Epoch: [5][401/704]	Time 0.120	Data 0.001	Loss 9.27	Acc@1 51.6	Acc@5 71.9
Epoch: [5][411/704]	Time 0.120	Data 0.001	Loss 9.55	Acc@1 40.6	Acc@5 68.8
Epoch: [5][421/704]	Time 0.120	Data 0.001	Loss 9.88	Acc@1 29.7	Acc@5 67.2
Epoch: [5][431/704]	Time 0.120	Data 0.001	Loss 8.36	Acc@1 45.3	Acc@5 78.1
Epoch: [5][441/704]	Time 0.120	Data 0.001	Loss 8.69	Acc@1 50.0	Acc@5 84.4
Epoch: [5][451/704]	Time 0.120	Data 0.001	Loss 9.73	Acc@1 37.5	Acc@5 68.8
Epoch: [5][461/704]	Time 0.120	Data 0.001	Loss 8.92	Acc@1 37.5	Acc@5 76.6
Epoch: [5][471/704]	Time 0.120	Data 0.001	Loss 7.44	Acc@1 53.1	Acc@5 85.9
Epoch: [5][481/704]	Time 0.120	Data 0.001	Loss 7.43	Acc@1 53.1	Acc@5 90.6
Epoch: [5][491/704]	Time 0.120	Data 0.001	Loss 7.92	Acc@1 50.0	Acc@5 75.0
Epoch: [5][501/704]	Time 0.120	Data 0.001	Loss 9.31	Acc@1 46.9	Acc@5 70.3
Epoch: [5][511/704]	Time 0.120	Data 0.001	Loss 7.94	Acc@1 46.9	Acc@5 81.2
Epoch: [5][521/704]	Time 0.120	Data 0.001	Loss 9.40	Acc@1 37.5	Acc@5 73.4
Epoch: [5][531/704]	Time 0.120	Data 0.001	Loss 8.77	Acc@1 43.8	Acc@5 81.2
Epoch: [5][541/704]	Time 0.119	Data 0.001	Loss 8.22	Acc@1 46.9	Acc@5 79.7
Epoch: [5][551/704]	Time 0.120	Data 0.001	Loss 9.08	Acc@1 43.8	Acc@5 70.3
Epoch: [5][561/704]	Time 0.120	Data 0.001	Loss 9.39	Acc@1 39.1	Acc@5 76.6
Epoch: [5][571/704]	Time 0.120	Data 0.001	Loss 9.28	Acc@1 40.6	Acc@5 76.6
Epoch: [5][581/704]	Time 0.120	Data 0.001	Loss 9.39	Acc@1 39.1	Acc@5 71.9
Epoch: [5][591/704]	Time 0.119	Data 0.001	Loss 8.66	Acc@1 46.9	Acc@5 73.4
Epoch: [5][601/704]	Time 0.119	Data 0.001	Loss 9.39	Acc@1 35.9	Acc@5 68.8
Epoch: [5][611/704]	Time 0.119	Data 0.001	Loss 9.61	Acc@1 34.4	Acc@5 71.9
Epoch: [5][621/704]	Time 0.119	Data 0.001	Loss 9.08	Acc@1 40.6	Acc@5 76.6
Epoch: [5][631/704]	Time 0.119	Data 0.001	Loss 8.91	Acc@1 39.1	Acc@5 78.1
Epoch: [5][641/704]	Time 0.119	Data 0.001	Loss 8.96	Acc@1 48.4	Acc@5 76.6
Epoch: [5][651/704]	Time 0.119	Data 0.001	Loss 7.90	Acc@1 53.1	Acc@5 82.8
Epoch: [5][661/704]	Time 0.119	Data 0.001	Loss 9.57	Acc@1 39.1	Acc@5 75.0
Epoch: [5][671/704]	Time 0.119	Data 0.001	Loss 8.75	Acc@1 39.1	Acc@5 82.8
Epoch: [5][681/704]	Time 0.119	Data 0.001	Loss 9.00	Acc@1 39.1	Acc@5 73.4
Epoch: [5][691/704]	Time 0.119	Data 0.001	Loss 8.63	Acc@1 40.6	Acc@5 85.9
Epoch: [5][701/704]	Time 0.119	Data 0.001	Loss 8.87	Acc@1 40.6	Acc@5 70.3
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 8.8426	Acc@1 48.4375	Acc@5 76.5625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.4524	Acc@1 42.1875	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 10.0265	Acc@1 35.9375	Acc@5 68.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 10.2363	Acc@1 40.6250	Acc@5 65.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 10.3560	Acc@1 31.2500	Acc@5 70.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.8311	Acc@1 50.0000	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 9.7823	Acc@1 43.7500	Acc@5 70.3125
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 10.9692	Acc@1 29.6875	Acc@5 71.8750
 * prec@1 32.140 prec@5 64.180
 * prec@1 37.880 prec@5 70.600
 * prec@1 39.960 prec@5 73.740
 * prec@1 40.540 prec@5 74.200
New best validation last_bloc_accuracy 40.54
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_005.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_005.pth.tar'
Epoch: [6][1/704]	Time 0.331	Data 0.165	Loss 9.15	Acc@1 50.0	Acc@5 70.3
Epoch: [6][11/704]	Time 0.139	Data 0.015	Loss 8.76	Acc@1 43.8	Acc@5 73.4
Epoch: [6][21/704]	Time 0.130	Data 0.008	Loss 8.57	Acc@1 42.2	Acc@5 78.1
Epoch: [6][31/704]	Time 0.127	Data 0.006	Loss 8.73	Acc@1 43.8	Acc@5 73.4
Epoch: [6][41/704]	Time 0.125	Data 0.004	Loss 8.02	Acc@1 51.6	Acc@5 78.1
Epoch: [6][51/704]	Time 0.124	Data 0.003	Loss 9.32	Acc@1 32.8	Acc@5 76.6
Epoch: [6][61/704]	Time 0.123	Data 0.003	Loss 7.77	Acc@1 48.4	Acc@5 79.7
Epoch: [6][71/704]	Time 0.123	Data 0.003	Loss 9.24	Acc@1 37.5	Acc@5 75.0
Epoch: [6][81/704]	Time 0.122	Data 0.002	Loss 9.72	Acc@1 48.4	Acc@5 76.6
Epoch: [6][91/704]	Time 0.122	Data 0.002	Loss 8.66	Acc@1 48.4	Acc@5 79.7
Epoch: [6][101/704]	Time 0.122	Data 0.002	Loss 9.43	Acc@1 48.4	Acc@5 70.3
Epoch: [6][111/704]	Time 0.122	Data 0.002	Loss 8.43	Acc@1 51.6	Acc@5 75.0
Epoch: [6][121/704]	Time 0.122	Data 0.002	Loss 7.88	Acc@1 45.3	Acc@5 81.2
Epoch: [6][131/704]	Time 0.121	Data 0.002	Loss 8.25	Acc@1 48.4	Acc@5 73.4
Epoch: [6][141/704]	Time 0.121	Data 0.001	Loss 10.00	Acc@1 42.2	Acc@5 71.9
Epoch: [6][151/704]	Time 0.121	Data 0.001	Loss 8.68	Acc@1 34.4	Acc@5 79.7
Epoch: [6][161/704]	Time 0.121	Data 0.001	Loss 8.23	Acc@1 42.2	Acc@5 82.8
Epoch: [6][171/704]	Time 0.121	Data 0.001	Loss 9.05	Acc@1 29.7	Acc@5 78.1
Epoch: [6][181/704]	Time 0.121	Data 0.001	Loss 8.88	Acc@1 45.3	Acc@5 82.8
Epoch: [6][191/704]	Time 0.121	Data 0.001	Loss 8.50	Acc@1 42.2	Acc@5 73.4
Epoch: [6][201/704]	Time 0.121	Data 0.001	Loss 8.61	Acc@1 48.4	Acc@5 71.9
Epoch: [6][211/704]	Time 0.121	Data 0.001	Loss 9.42	Acc@1 50.0	Acc@5 76.6
Epoch: [6][221/704]	Time 0.121	Data 0.001	Loss 7.97	Acc@1 51.6	Acc@5 75.0
Epoch: [6][231/704]	Time 0.121	Data 0.001	Loss 7.77	Acc@1 46.9	Acc@5 76.6
Epoch: [6][241/704]	Time 0.121	Data 0.001	Loss 8.99	Acc@1 48.4	Acc@5 75.0
Epoch: [6][251/704]	Time 0.121	Data 0.001	Loss 8.20	Acc@1 54.7	Acc@5 81.2
Epoch: [6][261/704]	Time 0.121	Data 0.001	Loss 8.21	Acc@1 46.9	Acc@5 73.4
Epoch: [6][271/704]	Time 0.121	Data 0.001	Loss 8.52	Acc@1 45.3	Acc@5 75.0
Epoch: [6][281/704]	Time 0.121	Data 0.001	Loss 9.86	Acc@1 35.9	Acc@5 70.3
Epoch: [6][291/704]	Time 0.121	Data 0.001	Loss 7.91	Acc@1 42.2	Acc@5 76.6
Epoch: [6][301/704]	Time 0.121	Data 0.001	Loss 9.37	Acc@1 35.9	Acc@5 82.8
Epoch: [6][311/704]	Time 0.121	Data 0.001	Loss 9.47	Acc@1 40.6	Acc@5 75.0
Epoch: [6][321/704]	Time 0.121	Data 0.001	Loss 8.01	Acc@1 45.3	Acc@5 90.6
Epoch: [6][331/704]	Time 0.121	Data 0.001	Loss 8.57	Acc@1 43.8	Acc@5 75.0
Epoch: [6][341/704]	Time 0.121	Data 0.001	Loss 8.69	Acc@1 50.0	Acc@5 76.6
Epoch: [6][351/704]	Time 0.121	Data 0.001	Loss 9.63	Acc@1 43.8	Acc@5 68.8
Epoch: [6][361/704]	Time 0.120	Data 0.001	Loss 8.68	Acc@1 42.2	Acc@5 76.6
Epoch: [6][371/704]	Time 0.120	Data 0.001	Loss 8.76	Acc@1 40.6	Acc@5 76.6
Epoch: [6][381/704]	Time 0.120	Data 0.001	Loss 9.71	Acc@1 43.8	Acc@5 68.8
Epoch: [6][391/704]	Time 0.120	Data 0.001	Loss 8.31	Acc@1 37.5	Acc@5 84.4
Epoch: [6][401/704]	Time 0.120	Data 0.001	Loss 10.97	Acc@1 32.8	Acc@5 60.9
Epoch: [6][411/704]	Time 0.120	Data 0.001	Loss 9.19	Acc@1 34.4	Acc@5 75.0
Epoch: [6][421/704]	Time 0.120	Data 0.001	Loss 7.64	Acc@1 53.1	Acc@5 82.8
Epoch: [6][431/704]	Time 0.120	Data 0.001	Loss 9.71	Acc@1 35.9	Acc@5 75.0
Epoch: [6][441/704]	Time 0.120	Data 0.001	Loss 8.40	Acc@1 48.4	Acc@5 81.2
Epoch: [6][451/704]	Time 0.120	Data 0.001	Loss 8.87	Acc@1 46.9	Acc@5 75.0
Epoch: [6][461/704]	Time 0.120	Data 0.001	Loss 8.39	Acc@1 51.6	Acc@5 76.6
Epoch: [6][471/704]	Time 0.120	Data 0.001	Loss 8.38	Acc@1 50.0	Acc@5 79.7
Epoch: [6][481/704]	Time 0.120	Data 0.001	Loss 7.94	Acc@1 45.3	Acc@5 78.1
Epoch: [6][491/704]	Time 0.120	Data 0.001	Loss 8.03	Acc@1 45.3	Acc@5 78.1
Epoch: [6][501/704]	Time 0.120	Data 0.001	Loss 8.20	Acc@1 39.1	Acc@5 76.6
Epoch: [6][511/704]	Time 0.120	Data 0.001	Loss 8.51	Acc@1 40.6	Acc@5 81.2
Epoch: [6][521/704]	Time 0.120	Data 0.001	Loss 8.63	Acc@1 45.3	Acc@5 70.3
Epoch: [6][531/704]	Time 0.120	Data 0.001	Loss 9.75	Acc@1 40.6	Acc@5 73.4
Epoch: [6][541/704]	Time 0.120	Data 0.001	Loss 8.72	Acc@1 51.6	Acc@5 81.2
Epoch: [6][551/704]	Time 0.120	Data 0.001	Loss 9.16	Acc@1 40.6	Acc@5 73.4
Epoch: [6][561/704]	Time 0.120	Data 0.001	Loss 7.52	Acc@1 48.4	Acc@5 85.9
Epoch: [6][571/704]	Time 0.120	Data 0.001	Loss 8.81	Acc@1 39.1	Acc@5 76.6
Epoch: [6][581/704]	Time 0.120	Data 0.001	Loss 8.27	Acc@1 45.3	Acc@5 81.2
Epoch: [6][591/704]	Time 0.120	Data 0.001	Loss 9.26	Acc@1 43.8	Acc@5 79.7
Epoch: [6][601/704]	Time 0.120	Data 0.001	Loss 8.98	Acc@1 39.1	Acc@5 76.6
Epoch: [6][611/704]	Time 0.120	Data 0.001	Loss 7.97	Acc@1 45.3	Acc@5 76.6
Epoch: [6][621/704]	Time 0.120	Data 0.001	Loss 7.87	Acc@1 42.2	Acc@5 78.1
Epoch: [6][631/704]	Time 0.120	Data 0.001	Loss 9.75	Acc@1 37.5	Acc@5 70.3
Epoch: [6][641/704]	Time 0.120	Data 0.001	Loss 7.90	Acc@1 54.7	Acc@5 81.2
Epoch: [6][651/704]	Time 0.120	Data 0.001	Loss 8.93	Acc@1 43.8	Acc@5 79.7
Epoch: [6][661/704]	Time 0.120	Data 0.001	Loss 9.03	Acc@1 48.4	Acc@5 76.6
Epoch: [6][671/704]	Time 0.120	Data 0.001	Loss 8.04	Acc@1 43.8	Acc@5 76.6
Epoch: [6][681/704]	Time 0.120	Data 0.000	Loss 8.76	Acc@1 40.6	Acc@5 79.7
Epoch: [6][691/704]	Time 0.120	Data 0.000	Loss 8.91	Acc@1 40.6	Acc@5 76.6
Epoch: [6][701/704]	Time 0.120	Data 0.000	Loss 7.96	Acc@1 46.9	Acc@5 78.1
Epoch: [1/79]	Time 0.132	Data 0.118	Loss 8.9301	Acc@1 39.0625	Acc@5 73.4375
Epoch: [11/79]	Time 0.027	Data 0.015	Loss 8.2702	Acc@1 43.7500	Acc@5 81.2500
Epoch: [21/79]	Time 0.022	Data 0.010	Loss 9.1409	Acc@1 37.5000	Acc@5 70.3125
Epoch: [31/79]	Time 0.020	Data 0.008	Loss 8.9657	Acc@1 51.5625	Acc@5 73.4375
Epoch: [41/79]	Time 0.019	Data 0.007	Loss 9.2997	Acc@1 32.8125	Acc@5 71.8750
Epoch: [51/79]	Time 0.019	Data 0.007	Loss 10.2430	Acc@1 43.7500	Acc@5 70.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.2126	Acc@1 45.3125	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 7.9332	Acc@1 51.5625	Acc@5 76.5625
 * prec@1 32.920 prec@5 64.620
 * prec@1 38.500 prec@5 70.480
 * prec@1 40.540 prec@5 73.280
 * prec@1 40.460 prec@5 73.100
Current best validation last_bloc_accuracy 40.54
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_006.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_006.pth.tar'
Epoch: [7][1/704]	Time 0.295	Data 0.129	Loss 9.04	Acc@1 37.5	Acc@5 76.6
Epoch: [7][11/704]	Time 0.135	Data 0.012	Loss 9.20	Acc@1 48.4	Acc@5 75.0
Epoch: [7][21/704]	Time 0.128	Data 0.007	Loss 7.97	Acc@1 43.8	Acc@5 85.9
Epoch: [7][31/704]	Time 0.125	Data 0.004	Loss 8.15	Acc@1 48.4	Acc@5 78.1
Epoch: [7][41/704]	Time 0.123	Data 0.003	Loss 7.60	Acc@1 56.2	Acc@5 82.8
Epoch: [7][51/704]	Time 0.123	Data 0.003	Loss 7.94	Acc@1 40.6	Acc@5 76.6
Epoch: [7][61/704]	Time 0.122	Data 0.002	Loss 8.23	Acc@1 51.6	Acc@5 78.1
Epoch: [7][71/704]	Time 0.122	Data 0.002	Loss 7.91	Acc@1 54.7	Acc@5 78.1
Epoch: [7][81/704]	Time 0.121	Data 0.002	Loss 8.35	Acc@1 48.4	Acc@5 81.2
Epoch: [7][91/704]	Time 0.121	Data 0.002	Loss 9.07	Acc@1 39.1	Acc@5 75.0
Epoch: [7][101/704]	Time 0.121	Data 0.002	Loss 7.94	Acc@1 46.9	Acc@5 81.2
Epoch: [7][111/704]	Time 0.121	Data 0.001	Loss 7.97	Acc@1 51.6	Acc@5 87.5
Epoch: [7][121/704]	Time 0.121	Data 0.001	Loss 7.67	Acc@1 43.8	Acc@5 79.7
Epoch: [7][131/704]	Time 0.121	Data 0.001	Loss 9.56	Acc@1 45.3	Acc@5 78.1
Epoch: [7][141/704]	Time 0.121	Data 0.001	Loss 7.73	Acc@1 53.1	Acc@5 79.7
Epoch: [7][151/704]	Time 0.121	Data 0.001	Loss 8.89	Acc@1 46.9	Acc@5 75.0
Epoch: [7][161/704]	Time 0.121	Data 0.001	Loss 7.56	Acc@1 54.7	Acc@5 85.9
Epoch: [7][171/704]	Time 0.120	Data 0.001	Loss 9.89	Acc@1 32.8	Acc@5 76.6
Epoch: [7][181/704]	Time 0.120	Data 0.001	Loss 7.56	Acc@1 42.2	Acc@5 82.8
Epoch: [7][191/704]	Time 0.120	Data 0.001	Loss 8.75	Acc@1 39.1	Acc@5 78.1
Epoch: [7][201/704]	Time 0.120	Data 0.001	Loss 8.40	Acc@1 43.8	Acc@5 78.1
Epoch: [7][211/704]	Time 0.120	Data 0.001	Loss 7.95	Acc@1 51.6	Acc@5 85.9
Epoch: [7][221/704]	Time 0.120	Data 0.001	Loss 9.08	Acc@1 35.9	Acc@5 70.3
Epoch: [7][231/704]	Time 0.120	Data 0.001	Loss 8.24	Acc@1 45.3	Acc@5 78.1
Epoch: [7][241/704]	Time 0.120	Data 0.001	Loss 9.31	Acc@1 46.9	Acc@5 79.7
Epoch: [7][251/704]	Time 0.120	Data 0.001	Loss 8.58	Acc@1 43.8	Acc@5 82.8
Epoch: [7][261/704]	Time 0.120	Data 0.001	Loss 7.81	Acc@1 46.9	Acc@5 81.2
Epoch: [7][271/704]	Time 0.120	Data 0.001	Loss 8.86	Acc@1 53.1	Acc@5 75.0
Epoch: [7][281/704]	Time 0.120	Data 0.001	Loss 8.31	Acc@1 45.3	Acc@5 76.6
Epoch: [7][291/704]	Time 0.120	Data 0.001	Loss 7.94	Acc@1 53.1	Acc@5 81.2
Epoch: [7][301/704]	Time 0.120	Data 0.001	Loss 8.28	Acc@1 37.5	Acc@5 84.4
Epoch: [7][311/704]	Time 0.120	Data 0.001	Loss 8.26	Acc@1 46.9	Acc@5 78.1
Epoch: [7][321/704]	Time 0.120	Data 0.001	Loss 10.10	Acc@1 34.4	Acc@5 76.6
Epoch: [7][331/704]	Time 0.120	Data 0.001	Loss 8.11	Acc@1 46.9	Acc@5 79.7
Epoch: [7][341/704]	Time 0.120	Data 0.001	Loss 8.50	Acc@1 45.3	Acc@5 78.1
Epoch: [7][351/704]	Time 0.120	Data 0.001	Loss 9.19	Acc@1 45.3	Acc@5 73.4
Epoch: [7][361/704]	Time 0.120	Data 0.001	Loss 8.23	Acc@1 45.3	Acc@5 85.9
Epoch: [7][371/704]	Time 0.120	Data 0.001	Loss 8.73	Acc@1 48.4	Acc@5 78.1
Epoch: [7][381/704]	Time 0.120	Data 0.001	Loss 9.39	Acc@1 53.1	Acc@5 71.9
Epoch: [7][391/704]	Time 0.120	Data 0.001	Loss 8.85	Acc@1 46.9	Acc@5 79.7
Epoch: [7][401/704]	Time 0.120	Data 0.001	Loss 8.90	Acc@1 45.3	Acc@5 76.6
Epoch: [7][411/704]	Time 0.120	Data 0.001	Loss 8.37	Acc@1 37.5	Acc@5 76.6
Epoch: [7][421/704]	Time 0.120	Data 0.001	Loss 8.19	Acc@1 48.4	Acc@5 78.1
Epoch: [7][431/704]	Time 0.120	Data 0.001	Loss 9.01	Acc@1 45.3	Acc@5 78.1
Epoch: [7][441/704]	Time 0.120	Data 0.001	Loss 9.47	Acc@1 42.2	Acc@5 76.6
Epoch: [7][451/704]	Time 0.120	Data 0.001	Loss 7.83	Acc@1 50.0	Acc@5 81.2
Epoch: [7][461/704]	Time 0.120	Data 0.001	Loss 8.45	Acc@1 51.6	Acc@5 78.1
Epoch: [7][471/704]	Time 0.120	Data 0.001	Loss 8.93	Acc@1 32.8	Acc@5 75.0
Epoch: [7][481/704]	Time 0.120	Data 0.001	Loss 8.09	Acc@1 40.6	Acc@5 75.0
Epoch: [7][491/704]	Time 0.120	Data 0.001	Loss 8.13	Acc@1 50.0	Acc@5 81.2
Epoch: [7][501/704]	Time 0.120	Data 0.001	Loss 8.89	Acc@1 37.5	Acc@5 75.0
Epoch: [7][511/704]	Time 0.120	Data 0.001	Loss 8.21	Acc@1 46.9	Acc@5 76.6
Epoch: [7][521/704]	Time 0.120	Data 0.001	Loss 9.37	Acc@1 40.6	Acc@5 76.6
Epoch: [7][531/704]	Time 0.120	Data 0.001	Loss 7.42	Acc@1 53.1	Acc@5 85.9
Epoch: [7][541/704]	Time 0.120	Data 0.001	Loss 9.21	Acc@1 37.5	Acc@5 79.7
Epoch: [7][551/704]	Time 0.120	Data 0.001	Loss 8.88	Acc@1 45.3	Acc@5 75.0
Epoch: [7][561/704]	Time 0.120	Data 0.001	Loss 9.24	Acc@1 46.9	Acc@5 71.9
Epoch: [7][571/704]	Time 0.120	Data 0.001	Loss 7.25	Acc@1 54.7	Acc@5 90.6
Epoch: [7][581/704]	Time 0.120	Data 0.001	Loss 8.05	Acc@1 56.2	Acc@5 78.1
Epoch: [7][591/704]	Time 0.120	Data 0.001	Loss 8.29	Acc@1 48.4	Acc@5 79.7
Epoch: [7][601/704]	Time 0.119	Data 0.001	Loss 7.66	Acc@1 51.6	Acc@5 81.2
Epoch: [7][611/704]	Time 0.119	Data 0.001	Loss 7.86	Acc@1 54.7	Acc@5 81.2
Epoch: [7][621/704]	Time 0.119	Data 0.001	Loss 8.15	Acc@1 56.2	Acc@5 79.7
Epoch: [7][631/704]	Time 0.120	Data 0.000	Loss 7.79	Acc@1 48.4	Acc@5 79.7
Epoch: [7][641/704]	Time 0.120	Data 0.000	Loss 9.21	Acc@1 48.4	Acc@5 70.3
Epoch: [7][651/704]	Time 0.120	Data 0.000	Loss 9.66	Acc@1 35.9	Acc@5 76.6
Epoch: [7][661/704]	Time 0.120	Data 0.000	Loss 7.04	Acc@1 56.2	Acc@5 82.8
Epoch: [7][671/704]	Time 0.120	Data 0.000	Loss 9.38	Acc@1 32.8	Acc@5 73.4
Epoch: [7][681/704]	Time 0.120	Data 0.000	Loss 7.86	Acc@1 51.6	Acc@5 82.8
Epoch: [7][691/704]	Time 0.120	Data 0.000	Loss 8.45	Acc@1 50.0	Acc@5 81.2
Epoch: [7][701/704]	Time 0.120	Data 0.000	Loss 9.96	Acc@1 43.8	Acc@5 78.1
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.8947	Acc@1 43.7500	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 8.6989	Acc@1 46.8750	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.4977	Acc@1 39.0625	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.8137	Acc@1 40.6250	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.0189	Acc@1 43.7500	Acc@5 75.0000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.9574	Acc@1 34.3750	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.0734	Acc@1 46.8750	Acc@5 78.1250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 10.2607	Acc@1 43.7500	Acc@5 70.3125
 * prec@1 35.080 prec@5 67.400
 * prec@1 41.140 prec@5 72.400
 * prec@1 43.300 prec@5 75.500
 * prec@1 41.760 prec@5 74.980
New best validation last_bloc_accuracy 41.76
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_007.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_007.pth.tar'
Epoch: [8][1/704]	Time 0.296	Data 0.130	Loss 7.42	Acc@1 59.4	Acc@5 79.7
Epoch: [8][11/704]	Time 0.135	Data 0.012	Loss 9.70	Acc@1 39.1	Acc@5 73.4
Epoch: [8][21/704]	Time 0.128	Data 0.006	Loss 8.82	Acc@1 39.1	Acc@5 76.6
Epoch: [8][31/704]	Time 0.125	Data 0.004	Loss 8.69	Acc@1 45.3	Acc@5 73.4
Epoch: [8][41/704]	Time 0.124	Data 0.003	Loss 8.87	Acc@1 57.8	Acc@5 76.6
Epoch: [8][51/704]	Time 0.123	Data 0.003	Loss 8.41	Acc@1 46.9	Acc@5 79.7
Epoch: [8][61/704]	Time 0.123	Data 0.002	Loss 8.53	Acc@1 51.6	Acc@5 73.4
Epoch: [8][71/704]	Time 0.122	Data 0.002	Loss 9.47	Acc@1 40.6	Acc@5 67.2
Epoch: [8][81/704]	Time 0.122	Data 0.002	Loss 8.24	Acc@1 42.2	Acc@5 81.2
Epoch: [8][91/704]	Time 0.122	Data 0.002	Loss 8.03	Acc@1 48.4	Acc@5 79.7
Epoch: [8][101/704]	Time 0.121	Data 0.002	Loss 8.04	Acc@1 45.3	Acc@5 76.6
Epoch: [8][111/704]	Time 0.121	Data 0.001	Loss 7.81	Acc@1 50.0	Acc@5 79.7
Epoch: [8][121/704]	Time 0.121	Data 0.001	Loss 8.56	Acc@1 40.6	Acc@5 85.9
Epoch: [8][131/704]	Time 0.121	Data 0.001	Loss 7.93	Acc@1 50.0	Acc@5 82.8
Epoch: [8][141/704]	Time 0.121	Data 0.001	Loss 7.33	Acc@1 50.0	Acc@5 81.2
Epoch: [8][151/704]	Time 0.121	Data 0.001	Loss 8.68	Acc@1 46.9	Acc@5 82.8
Epoch: [8][161/704]	Time 0.121	Data 0.001	Loss 8.85	Acc@1 42.2	Acc@5 79.7
Epoch: [8][171/704]	Time 0.120	Data 0.001	Loss 9.65	Acc@1 37.5	Acc@5 73.4
Epoch: [8][181/704]	Time 0.120	Data 0.001	Loss 7.99	Acc@1 59.4	Acc@5 78.1
Epoch: [8][191/704]	Time 0.120	Data 0.001	Loss 7.37	Acc@1 57.8	Acc@5 90.6
Epoch: [8][201/704]	Time 0.120	Data 0.001	Loss 7.29	Acc@1 56.2	Acc@5 85.9
Epoch: [8][211/704]	Time 0.120	Data 0.001	Loss 7.51	Acc@1 46.9	Acc@5 90.6
Epoch: [8][221/704]	Time 0.120	Data 0.001	Loss 8.61	Acc@1 42.2	Acc@5 78.1
Epoch: [8][231/704]	Time 0.120	Data 0.001	Loss 7.30	Acc@1 50.0	Acc@5 82.8
Epoch: [8][241/704]	Time 0.120	Data 0.001	Loss 7.49	Acc@1 53.1	Acc@5 76.6
Epoch: [8][251/704]	Time 0.120	Data 0.001	Loss 6.81	Acc@1 59.4	Acc@5 93.8
Epoch: [8][261/704]	Time 0.120	Data 0.001	Loss 8.06	Acc@1 40.6	Acc@5 79.7
Epoch: [8][271/704]	Time 0.120	Data 0.001	Loss 7.34	Acc@1 51.6	Acc@5 85.9
Epoch: [8][281/704]	Time 0.120	Data 0.001	Loss 7.73	Acc@1 53.1	Acc@5 81.2
Epoch: [8][291/704]	Time 0.120	Data 0.001	Loss 7.82	Acc@1 54.7	Acc@5 81.2
Epoch: [8][301/704]	Time 0.120	Data 0.001	Loss 7.98	Acc@1 50.0	Acc@5 79.7
Epoch: [8][311/704]	Time 0.120	Data 0.001	Loss 8.11	Acc@1 46.9	Acc@5 79.7
Epoch: [8][321/704]	Time 0.120	Data 0.001	Loss 9.16	Acc@1 46.9	Acc@5 76.6
Epoch: [8][331/704]	Time 0.120	Data 0.001	Loss 8.70	Acc@1 43.8	Acc@5 85.9
Epoch: [8][341/704]	Time 0.120	Data 0.001	Loss 8.60	Acc@1 46.9	Acc@5 82.8
Epoch: [8][351/704]	Time 0.120	Data 0.001	Loss 7.63	Acc@1 62.5	Acc@5 89.1
Epoch: [8][361/704]	Time 0.120	Data 0.001	Loss 8.81	Acc@1 43.8	Acc@5 76.6
Epoch: [8][371/704]	Time 0.120	Data 0.001	Loss 8.80	Acc@1 35.9	Acc@5 75.0
Epoch: [8][381/704]	Time 0.120	Data 0.001	Loss 10.12	Acc@1 39.1	Acc@5 76.6
Epoch: [8][391/704]	Time 0.120	Data 0.001	Loss 7.26	Acc@1 43.8	Acc@5 85.9
Epoch: [8][401/704]	Time 0.120	Data 0.001	Loss 9.82	Acc@1 45.3	Acc@5 68.8
Epoch: [8][411/704]	Time 0.120	Data 0.001	Loss 7.48	Acc@1 57.8	Acc@5 82.8
Epoch: [8][421/704]	Time 0.120	Data 0.001	Loss 6.74	Acc@1 46.9	Acc@5 81.2
Epoch: [8][431/704]	Time 0.120	Data 0.001	Loss 8.14	Acc@1 50.0	Acc@5 79.7
Epoch: [8][441/704]	Time 0.120	Data 0.001	Loss 7.94	Acc@1 51.6	Acc@5 82.8
Epoch: [8][451/704]	Time 0.120	Data 0.001	Loss 8.55	Acc@1 51.6	Acc@5 79.7
Epoch: [8][461/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 67.2	Acc@5 89.1
Epoch: [8][471/704]	Time 0.120	Data 0.001	Loss 8.73	Acc@1 42.2	Acc@5 71.9
Epoch: [8][481/704]	Time 0.120	Data 0.001	Loss 8.34	Acc@1 46.9	Acc@5 81.2
Epoch: [8][491/704]	Time 0.120	Data 0.001	Loss 8.81	Acc@1 43.8	Acc@5 79.7
Epoch: [8][501/704]	Time 0.120	Data 0.001	Loss 7.79	Acc@1 53.1	Acc@5 81.2
Epoch: [8][511/704]	Time 0.120	Data 0.001	Loss 8.69	Acc@1 39.1	Acc@5 75.0
Epoch: [8][521/704]	Time 0.120	Data 0.001	Loss 9.01	Acc@1 46.9	Acc@5 75.0
Epoch: [8][531/704]	Time 0.120	Data 0.001	Loss 9.28	Acc@1 37.5	Acc@5 82.8
Epoch: [8][541/704]	Time 0.120	Data 0.001	Loss 8.51	Acc@1 48.4	Acc@5 73.4
Epoch: [8][551/704]	Time 0.120	Data 0.001	Loss 6.72	Acc@1 57.8	Acc@5 89.1
Epoch: [8][561/704]	Time 0.120	Data 0.001	Loss 8.37	Acc@1 46.9	Acc@5 82.8
Epoch: [8][571/704]	Time 0.120	Data 0.001	Loss 7.20	Acc@1 53.1	Acc@5 82.8
Epoch: [8][581/704]	Time 0.120	Data 0.001	Loss 7.76	Acc@1 51.6	Acc@5 82.8
Epoch: [8][591/704]	Time 0.120	Data 0.000	Loss 8.28	Acc@1 39.1	Acc@5 84.4
Epoch: [8][601/704]	Time 0.120	Data 0.000	Loss 8.34	Acc@1 48.4	Acc@5 76.6
Epoch: [8][611/704]	Time 0.120	Data 0.000	Loss 7.88	Acc@1 56.2	Acc@5 84.4
Epoch: [8][621/704]	Time 0.120	Data 0.000	Loss 7.57	Acc@1 46.9	Acc@5 79.7
Epoch: [8][631/704]	Time 0.120	Data 0.000	Loss 8.18	Acc@1 39.1	Acc@5 78.1
Epoch: [8][641/704]	Time 0.120	Data 0.000	Loss 7.65	Acc@1 45.3	Acc@5 84.4
Epoch: [8][651/704]	Time 0.120	Data 0.000	Loss 7.52	Acc@1 56.2	Acc@5 78.1
Epoch: [8][661/704]	Time 0.120	Data 0.000	Loss 7.62	Acc@1 54.7	Acc@5 82.8
Epoch: [8][671/704]	Time 0.120	Data 0.000	Loss 6.40	Acc@1 53.1	Acc@5 81.2
Epoch: [8][681/704]	Time 0.120	Data 0.000	Loss 9.83	Acc@1 40.6	Acc@5 75.0
Epoch: [8][691/704]	Time 0.120	Data 0.000	Loss 7.25	Acc@1 54.7	Acc@5 82.8
Epoch: [8][701/704]	Time 0.120	Data 0.000	Loss 7.44	Acc@1 45.3	Acc@5 79.7
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 10.0683	Acc@1 37.5000	Acc@5 71.8750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 9.5635	Acc@1 39.0625	Acc@5 71.8750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.9089	Acc@1 57.8125	Acc@5 78.1250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 9.2080	Acc@1 45.3125	Acc@5 75.0000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 10.2322	Acc@1 35.9375	Acc@5 71.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.6942	Acc@1 46.8750	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.3076	Acc@1 40.6250	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.5935	Acc@1 46.8750	Acc@5 82.8125
 * prec@1 37.100 prec@5 68.200
 * prec@1 42.800 prec@5 74.000
 * prec@1 43.920 prec@5 76.840
 * prec@1 43.700 prec@5 77.440
New best validation last_bloc_accuracy 43.7
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_008.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_008.pth.tar'
Epoch: [9][1/704]	Time 0.332	Data 0.166	Loss 8.62	Acc@1 45.3	Acc@5 75.0
Epoch: [9][11/704]	Time 0.139	Data 0.015	Loss 8.49	Acc@1 46.9	Acc@5 82.8
Epoch: [9][21/704]	Time 0.130	Data 0.008	Loss 9.00	Acc@1 40.6	Acc@5 78.1
Epoch: [9][31/704]	Time 0.126	Data 0.006	Loss 8.14	Acc@1 45.3	Acc@5 79.7
Epoch: [9][41/704]	Time 0.125	Data 0.004	Loss 7.00	Acc@1 54.7	Acc@5 90.6
Epoch: [9][51/704]	Time 0.124	Data 0.004	Loss 7.51	Acc@1 57.8	Acc@5 81.2
Epoch: [9][61/704]	Time 0.123	Data 0.003	Loss 8.64	Acc@1 45.3	Acc@5 75.0
Epoch: [9][71/704]	Time 0.122	Data 0.003	Loss 8.03	Acc@1 50.0	Acc@5 81.2
Epoch: [9][81/704]	Time 0.122	Data 0.002	Loss 7.78	Acc@1 59.4	Acc@5 82.8
Epoch: [9][91/704]	Time 0.122	Data 0.002	Loss 6.87	Acc@1 56.2	Acc@5 92.2
Epoch: [9][101/704]	Time 0.122	Data 0.002	Loss 8.87	Acc@1 48.4	Acc@5 79.7
Epoch: [9][111/704]	Time 0.121	Data 0.002	Loss 7.58	Acc@1 54.7	Acc@5 76.6
Epoch: [9][121/704]	Time 0.121	Data 0.002	Loss 6.88	Acc@1 57.8	Acc@5 82.8
Epoch: [9][131/704]	Time 0.121	Data 0.002	Loss 9.11	Acc@1 45.3	Acc@5 79.7
Epoch: [9][141/704]	Time 0.121	Data 0.001	Loss 9.05	Acc@1 40.6	Acc@5 79.7
Epoch: [9][151/704]	Time 0.121	Data 0.001	Loss 8.85	Acc@1 43.8	Acc@5 76.6
Epoch: [9][161/704]	Time 0.121	Data 0.001	Loss 6.92	Acc@1 57.8	Acc@5 87.5
Epoch: [9][171/704]	Time 0.121	Data 0.001	Loss 9.08	Acc@1 43.8	Acc@5 73.4
Epoch: [9][181/704]	Time 0.121	Data 0.001	Loss 7.70	Acc@1 50.0	Acc@5 89.1
Epoch: [9][191/704]	Time 0.120	Data 0.001	Loss 8.11	Acc@1 46.9	Acc@5 81.2
Epoch: [9][201/704]	Time 0.121	Data 0.001	Loss 9.14	Acc@1 48.4	Acc@5 73.4
Epoch: [9][211/704]	Time 0.120	Data 0.001	Loss 7.22	Acc@1 53.1	Acc@5 85.9
Epoch: [9][221/704]	Time 0.120	Data 0.001	Loss 7.75	Acc@1 43.8	Acc@5 78.1
Epoch: [9][231/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 57.8	Acc@5 89.1
Epoch: [9][241/704]	Time 0.120	Data 0.001	Loss 7.50	Acc@1 48.4	Acc@5 84.4
Epoch: [9][251/704]	Time 0.120	Data 0.001	Loss 8.13	Acc@1 53.1	Acc@5 79.7
Epoch: [9][261/704]	Time 0.120	Data 0.001	Loss 7.36	Acc@1 50.0	Acc@5 85.9
Epoch: [9][271/704]	Time 0.120	Data 0.001	Loss 9.50	Acc@1 42.2	Acc@5 75.0
Epoch: [9][281/704]	Time 0.120	Data 0.001	Loss 7.75	Acc@1 46.9	Acc@5 84.4
Epoch: [9][291/704]	Time 0.120	Data 0.001	Loss 8.62	Acc@1 46.9	Acc@5 78.1
Epoch: [9][301/704]	Time 0.120	Data 0.001	Loss 7.30	Acc@1 48.4	Acc@5 87.5
Epoch: [9][311/704]	Time 0.120	Data 0.001	Loss 8.00	Acc@1 45.3	Acc@5 82.8
Epoch: [9][321/704]	Time 0.120	Data 0.001	Loss 7.48	Acc@1 56.2	Acc@5 81.2
Epoch: [9][331/704]	Time 0.120	Data 0.001	Loss 8.61	Acc@1 48.4	Acc@5 81.2
Epoch: [9][341/704]	Time 0.120	Data 0.001	Loss 8.08	Acc@1 46.9	Acc@5 75.0
Epoch: [9][351/704]	Time 0.120	Data 0.001	Loss 8.70	Acc@1 48.4	Acc@5 78.1
Epoch: [9][361/704]	Time 0.120	Data 0.001	Loss 9.88	Acc@1 35.9	Acc@5 67.2
Epoch: [9][371/704]	Time 0.120	Data 0.001	Loss 8.17	Acc@1 53.1	Acc@5 85.9
Epoch: [9][381/704]	Time 0.120	Data 0.001	Loss 7.40	Acc@1 51.6	Acc@5 87.5
Epoch: [9][391/704]	Time 0.120	Data 0.001	Loss 7.53	Acc@1 54.7	Acc@5 79.7
Epoch: [9][401/704]	Time 0.120	Data 0.001	Loss 6.85	Acc@1 53.1	Acc@5 84.4
Epoch: [9][411/704]	Time 0.120	Data 0.001	Loss 8.55	Acc@1 46.9	Acc@5 76.6
Epoch: [9][421/704]	Time 0.120	Data 0.001	Loss 8.15	Acc@1 51.6	Acc@5 76.6
Epoch: [9][431/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 54.7	Acc@5 89.1
Epoch: [9][441/704]	Time 0.120	Data 0.001	Loss 9.07	Acc@1 43.8	Acc@5 70.3
Epoch: [9][451/704]	Time 0.120	Data 0.001	Loss 8.19	Acc@1 50.0	Acc@5 81.2
Epoch: [9][461/704]	Time 0.120	Data 0.001	Loss 7.93	Acc@1 53.1	Acc@5 76.6
Epoch: [9][471/704]	Time 0.120	Data 0.001	Loss 9.77	Acc@1 46.9	Acc@5 70.3
Epoch: [9][481/704]	Time 0.120	Data 0.001	Loss 7.80	Acc@1 46.9	Acc@5 82.8
Epoch: [9][491/704]	Time 0.120	Data 0.001	Loss 7.24	Acc@1 50.0	Acc@5 82.8
Epoch: [9][501/704]	Time 0.120	Data 0.001	Loss 7.76	Acc@1 51.6	Acc@5 85.9
Epoch: [9][511/704]	Time 0.120	Data 0.001	Loss 7.01	Acc@1 56.2	Acc@5 87.5
Epoch: [9][521/704]	Time 0.120	Data 0.001	Loss 7.57	Acc@1 54.7	Acc@5 89.1
Epoch: [9][531/704]	Time 0.120	Data 0.001	Loss 8.67	Acc@1 43.8	Acc@5 79.7
Epoch: [9][541/704]	Time 0.120	Data 0.001	Loss 8.08	Acc@1 51.6	Acc@5 82.8
Epoch: [9][551/704]	Time 0.120	Data 0.001	Loss 8.47	Acc@1 43.8	Acc@5 82.8
Epoch: [9][561/704]	Time 0.120	Data 0.001	Loss 6.61	Acc@1 54.7	Acc@5 85.9
Epoch: [9][571/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 46.9	Acc@5 84.4
Epoch: [9][581/704]	Time 0.120	Data 0.001	Loss 7.39	Acc@1 51.6	Acc@5 89.1
Epoch: [9][591/704]	Time 0.120	Data 0.001	Loss 9.03	Acc@1 45.3	Acc@5 76.6
Epoch: [9][601/704]	Time 0.120	Data 0.001	Loss 7.69	Acc@1 48.4	Acc@5 78.1
Epoch: [9][611/704]	Time 0.120	Data 0.001	Loss 8.58	Acc@1 40.6	Acc@5 81.2
Epoch: [9][621/704]	Time 0.120	Data 0.001	Loss 7.08	Acc@1 56.2	Acc@5 84.4
Epoch: [9][631/704]	Time 0.120	Data 0.001	Loss 7.92	Acc@1 43.8	Acc@5 84.4
Epoch: [9][641/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 51.6	Acc@5 89.1
Epoch: [9][651/704]	Time 0.120	Data 0.001	Loss 7.44	Acc@1 59.4	Acc@5 84.4
Epoch: [9][661/704]	Time 0.120	Data 0.001	Loss 7.45	Acc@1 56.2	Acc@5 79.7
Epoch: [9][671/704]	Time 0.120	Data 0.001	Loss 8.13	Acc@1 53.1	Acc@5 79.7
Epoch: [9][681/704]	Time 0.120	Data 0.001	Loss 6.42	Acc@1 56.2	Acc@5 89.1
Epoch: [9][691/704]	Time 0.120	Data 0.001	Loss 7.94	Acc@1 48.4	Acc@5 84.4
Epoch: [9][701/704]	Time 0.120	Data 0.001	Loss 7.44	Acc@1 50.0	Acc@5 85.9
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 9.2614	Acc@1 42.1875	Acc@5 75.0000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.7135	Acc@1 53.1250	Acc@5 81.2500
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 8.8610	Acc@1 31.2500	Acc@5 75.0000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 10.5426	Acc@1 39.0625	Acc@5 64.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.8643	Acc@1 48.4375	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.5136	Acc@1 48.4375	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 9.0030	Acc@1 51.5625	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.7859	Acc@1 54.6875	Acc@5 87.5000
 * prec@1 36.720 prec@5 68.840
 * prec@1 42.460 prec@5 74.480
 * prec@1 46.020 prec@5 77.780
 * prec@1 45.640 prec@5 77.660
New best validation last_bloc_accuracy 45.64
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_009.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_009.pth.tar'
Epoch: [10][1/704]	Time 0.297	Data 0.131	Loss 7.81	Acc@1 50.0	Acc@5 92.2
Epoch: [10][11/704]	Time 0.135	Data 0.012	Loss 7.53	Acc@1 45.3	Acc@5 79.7
Epoch: [10][21/704]	Time 0.128	Data 0.006	Loss 6.87	Acc@1 51.6	Acc@5 84.4
Epoch: [10][31/704]	Time 0.125	Data 0.004	Loss 8.17	Acc@1 48.4	Acc@5 76.6
Epoch: [10][41/704]	Time 0.123	Data 0.003	Loss 7.87	Acc@1 50.0	Acc@5 81.2
Epoch: [10][51/704]	Time 0.123	Data 0.003	Loss 8.18	Acc@1 45.3	Acc@5 79.7
Epoch: [10][61/704]	Time 0.122	Data 0.002	Loss 9.00	Acc@1 40.6	Acc@5 78.1
Epoch: [10][71/704]	Time 0.122	Data 0.002	Loss 8.50	Acc@1 51.6	Acc@5 78.1
Epoch: [10][81/704]	Time 0.121	Data 0.002	Loss 7.73	Acc@1 45.3	Acc@5 81.2
Epoch: [10][91/704]	Time 0.121	Data 0.002	Loss 7.54	Acc@1 50.0	Acc@5 82.8
Epoch: [10][101/704]	Time 0.121	Data 0.002	Loss 7.60	Acc@1 53.1	Acc@5 81.2
Epoch: [10][111/704]	Time 0.121	Data 0.001	Loss 7.26	Acc@1 54.7	Acc@5 79.7
Epoch: [10][121/704]	Time 0.121	Data 0.001	Loss 8.46	Acc@1 43.8	Acc@5 87.5
Epoch: [10][131/704]	Time 0.121	Data 0.001	Loss 8.28	Acc@1 46.9	Acc@5 78.1
Epoch: [10][141/704]	Time 0.121	Data 0.001	Loss 7.33	Acc@1 45.3	Acc@5 87.5
Epoch: [10][151/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 59.4	Acc@5 89.1
Epoch: [10][161/704]	Time 0.120	Data 0.001	Loss 8.72	Acc@1 56.2	Acc@5 79.7
Epoch: [10][171/704]	Time 0.120	Data 0.001	Loss 8.00	Acc@1 43.8	Acc@5 84.4
Epoch: [10][181/704]	Time 0.120	Data 0.001	Loss 6.99	Acc@1 54.7	Acc@5 87.5
Epoch: [10][191/704]	Time 0.120	Data 0.001	Loss 9.29	Acc@1 45.3	Acc@5 75.0
Epoch: [10][201/704]	Time 0.120	Data 0.001	Loss 7.02	Acc@1 54.7	Acc@5 87.5
Epoch: [10][211/704]	Time 0.120	Data 0.001	Loss 6.64	Acc@1 59.4	Acc@5 87.5
Epoch: [10][221/704]	Time 0.120	Data 0.001	Loss 7.54	Acc@1 50.0	Acc@5 78.1
Epoch: [10][231/704]	Time 0.120	Data 0.001	Loss 6.55	Acc@1 50.0	Acc@5 85.9
Epoch: [10][241/704]	Time 0.120	Data 0.001	Loss 6.85	Acc@1 57.8	Acc@5 89.1
Epoch: [10][251/704]	Time 0.120	Data 0.001	Loss 9.13	Acc@1 46.9	Acc@5 71.9
Epoch: [10][261/704]	Time 0.120	Data 0.001	Loss 8.11	Acc@1 46.9	Acc@5 81.2
Epoch: [10][271/704]	Time 0.120	Data 0.001	Loss 8.17	Acc@1 45.3	Acc@5 76.6
Epoch: [10][281/704]	Time 0.120	Data 0.001	Loss 7.29	Acc@1 51.6	Acc@5 87.5
Epoch: [10][291/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 57.8	Acc@5 81.2
Epoch: [10][301/704]	Time 0.120	Data 0.001	Loss 7.48	Acc@1 53.1	Acc@5 78.1
Epoch: [10][311/704]	Time 0.120	Data 0.001	Loss 7.81	Acc@1 56.2	Acc@5 85.9
Epoch: [10][321/704]	Time 0.120	Data 0.001	Loss 7.13	Acc@1 54.7	Acc@5 82.8
Epoch: [10][331/704]	Time 0.120	Data 0.001	Loss 7.62	Acc@1 54.7	Acc@5 79.7
Epoch: [10][341/704]	Time 0.120	Data 0.001	Loss 7.34	Acc@1 50.0	Acc@5 78.1
Epoch: [10][351/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 59.4	Acc@5 82.8
Epoch: [10][361/704]	Time 0.120	Data 0.001	Loss 7.76	Acc@1 51.6	Acc@5 85.9
Epoch: [10][371/704]	Time 0.120	Data 0.001	Loss 7.52	Acc@1 45.3	Acc@5 85.9
Epoch: [10][381/704]	Time 0.120	Data 0.001	Loss 7.55	Acc@1 50.0	Acc@5 78.1
Epoch: [10][391/704]	Time 0.120	Data 0.001	Loss 7.17	Acc@1 54.7	Acc@5 89.1
Epoch: [10][401/704]	Time 0.120	Data 0.001	Loss 8.60	Acc@1 42.2	Acc@5 85.9
Epoch: [10][411/704]	Time 0.120	Data 0.001	Loss 7.92	Acc@1 48.4	Acc@5 78.1
Epoch: [10][421/704]	Time 0.120	Data 0.001	Loss 6.69	Acc@1 56.2	Acc@5 87.5
Epoch: [10][431/704]	Time 0.120	Data 0.001	Loss 7.07	Acc@1 57.8	Acc@5 78.1
Epoch: [10][441/704]	Time 0.120	Data 0.001	Loss 7.19	Acc@1 53.1	Acc@5 84.4
Epoch: [10][451/704]	Time 0.120	Data 0.001	Loss 7.55	Acc@1 50.0	Acc@5 78.1
Epoch: [10][461/704]	Time 0.120	Data 0.001	Loss 7.52	Acc@1 50.0	Acc@5 87.5
Epoch: [10][471/704]	Time 0.120	Data 0.001	Loss 6.86	Acc@1 53.1	Acc@5 82.8
Epoch: [10][481/704]	Time 0.120	Data 0.001	Loss 7.04	Acc@1 56.2	Acc@5 84.4
Epoch: [10][491/704]	Time 0.120	Data 0.001	Loss 8.36	Acc@1 45.3	Acc@5 79.7
Epoch: [10][501/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 67.2	Acc@5 90.6
Epoch: [10][511/704]	Time 0.120	Data 0.001	Loss 7.91	Acc@1 51.6	Acc@5 76.6
Epoch: [10][521/704]	Time 0.120	Data 0.001	Loss 7.23	Acc@1 48.4	Acc@5 87.5
Epoch: [10][531/704]	Time 0.120	Data 0.001	Loss 8.24	Acc@1 48.4	Acc@5 85.9
Epoch: [10][541/704]	Time 0.120	Data 0.001	Loss 7.56	Acc@1 51.6	Acc@5 84.4
Epoch: [10][551/704]	Time 0.120	Data 0.001	Loss 7.42	Acc@1 60.9	Acc@5 84.4
Epoch: [10][561/704]	Time 0.120	Data 0.001	Loss 7.33	Acc@1 64.1	Acc@5 84.4
Epoch: [10][571/704]	Time 0.120	Data 0.001	Loss 8.59	Acc@1 46.9	Acc@5 79.7
Epoch: [10][581/704]	Time 0.120	Data 0.001	Loss 8.06	Acc@1 46.9	Acc@5 78.1
Epoch: [10][591/704]	Time 0.120	Data 0.001	Loss 8.18	Acc@1 45.3	Acc@5 82.8
Epoch: [10][601/704]	Time 0.120	Data 0.001	Loss 7.13	Acc@1 56.2	Acc@5 84.4
Epoch: [10][611/704]	Time 0.120	Data 0.001	Loss 7.29	Acc@1 48.4	Acc@5 85.9
Epoch: [10][621/704]	Time 0.120	Data 0.001	Loss 8.45	Acc@1 50.0	Acc@5 71.9
Epoch: [10][631/704]	Time 0.120	Data 0.001	Loss 8.14	Acc@1 45.3	Acc@5 75.0
Epoch: [10][641/704]	Time 0.120	Data 0.001	Loss 8.17	Acc@1 45.3	Acc@5 81.2
Epoch: [10][651/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 62.5	Acc@5 89.1
Epoch: [10][661/704]	Time 0.120	Data 0.000	Loss 8.64	Acc@1 40.6	Acc@5 70.3
Epoch: [10][671/704]	Time 0.120	Data 0.000	Loss 6.62	Acc@1 64.1	Acc@5 85.9
Epoch: [10][681/704]	Time 0.120	Data 0.000	Loss 6.66	Acc@1 59.4	Acc@5 85.9
Epoch: [10][691/704]	Time 0.120	Data 0.000	Loss 5.82	Acc@1 62.5	Acc@5 92.2
Epoch: [10][701/704]	Time 0.120	Data 0.000	Loss 7.54	Acc@1 46.9	Acc@5 84.4
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 8.9371	Acc@1 43.7500	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 9.3608	Acc@1 46.8750	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 9.3828	Acc@1 43.7500	Acc@5 71.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 10.2364	Acc@1 42.1875	Acc@5 71.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.6607	Acc@1 51.5625	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.1311	Acc@1 48.4375	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.0748	Acc@1 51.5625	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.8218	Acc@1 53.1250	Acc@5 76.5625
 * prec@1 38.520 prec@5 70.380
 * prec@1 44.680 prec@5 76.060
 * prec@1 47.120 prec@5 79.220
 * prec@1 48.940 prec@5 79.540
New best validation last_bloc_accuracy 48.94
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_010.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_010.pth.tar'
Epoch: [11][1/704]	Time 0.296	Data 0.130	Loss 5.74	Acc@1 70.3	Acc@5 89.1
Epoch: [11][11/704]	Time 0.135	Data 0.012	Loss 7.98	Acc@1 48.4	Acc@5 78.1
Epoch: [11][21/704]	Time 0.128	Data 0.007	Loss 7.26	Acc@1 51.6	Acc@5 82.8
Epoch: [11][31/704]	Time 0.125	Data 0.005	Loss 7.31	Acc@1 60.9	Acc@5 81.2
Epoch: [11][41/704]	Time 0.125	Data 0.003	Loss 7.17	Acc@1 65.6	Acc@5 81.2
Epoch: [11][51/704]	Time 0.124	Data 0.003	Loss 7.45	Acc@1 56.2	Acc@5 85.9
Epoch: [11][61/704]	Time 0.123	Data 0.002	Loss 6.51	Acc@1 51.6	Acc@5 84.4
Epoch: [11][71/704]	Time 0.122	Data 0.002	Loss 8.50	Acc@1 42.2	Acc@5 73.4
Epoch: [11][81/704]	Time 0.122	Data 0.002	Loss 8.82	Acc@1 45.3	Acc@5 79.7
Epoch: [11][91/704]	Time 0.122	Data 0.002	Loss 6.66	Acc@1 59.4	Acc@5 85.9
Epoch: [11][101/704]	Time 0.121	Data 0.002	Loss 6.99	Acc@1 54.7	Acc@5 87.5
Epoch: [11][111/704]	Time 0.121	Data 0.001	Loss 8.36	Acc@1 43.8	Acc@5 79.7
Epoch: [11][121/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 64.1	Acc@5 84.4
Epoch: [11][131/704]	Time 0.121	Data 0.001	Loss 6.63	Acc@1 65.6	Acc@5 90.6
Epoch: [11][141/704]	Time 0.121	Data 0.001	Loss 7.66	Acc@1 53.1	Acc@5 78.1
Epoch: [11][151/704]	Time 0.121	Data 0.001	Loss 6.74	Acc@1 56.2	Acc@5 84.4
Epoch: [11][161/704]	Time 0.120	Data 0.001	Loss 7.26	Acc@1 57.8	Acc@5 81.2
Epoch: [11][171/704]	Time 0.120	Data 0.001	Loss 8.57	Acc@1 43.8	Acc@5 78.1
Epoch: [11][181/704]	Time 0.120	Data 0.001	Loss 9.13	Acc@1 42.2	Acc@5 65.6
Epoch: [11][191/704]	Time 0.120	Data 0.001	Loss 9.18	Acc@1 39.1	Acc@5 68.8
Epoch: [11][201/704]	Time 0.120	Data 0.001	Loss 6.82	Acc@1 56.2	Acc@5 82.8
Epoch: [11][211/704]	Time 0.120	Data 0.001	Loss 8.45	Acc@1 43.8	Acc@5 85.9
Epoch: [11][221/704]	Time 0.120	Data 0.001	Loss 7.73	Acc@1 46.9	Acc@5 87.5
Epoch: [11][231/704]	Time 0.120	Data 0.001	Loss 9.83	Acc@1 34.4	Acc@5 75.0
Epoch: [11][241/704]	Time 0.120	Data 0.001	Loss 6.77	Acc@1 53.1	Acc@5 85.9
Epoch: [11][251/704]	Time 0.120	Data 0.001	Loss 8.73	Acc@1 48.4	Acc@5 81.2
Epoch: [11][261/704]	Time 0.120	Data 0.001	Loss 9.23	Acc@1 35.9	Acc@5 71.9
Epoch: [11][271/704]	Time 0.120	Data 0.001	Loss 7.31	Acc@1 50.0	Acc@5 82.8
Epoch: [11][281/704]	Time 0.120	Data 0.001	Loss 7.90	Acc@1 56.2	Acc@5 84.4
Epoch: [11][291/704]	Time 0.120	Data 0.001	Loss 7.82	Acc@1 53.1	Acc@5 81.2
Epoch: [11][301/704]	Time 0.120	Data 0.001	Loss 8.32	Acc@1 54.7	Acc@5 75.0
Epoch: [11][311/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 53.1	Acc@5 84.4
Epoch: [11][321/704]	Time 0.120	Data 0.001	Loss 6.67	Acc@1 59.4	Acc@5 85.9
Epoch: [11][331/704]	Time 0.120	Data 0.001	Loss 8.12	Acc@1 46.9	Acc@5 78.1
Epoch: [11][341/704]	Time 0.120	Data 0.001	Loss 6.73	Acc@1 54.7	Acc@5 85.9
Epoch: [11][351/704]	Time 0.120	Data 0.001	Loss 7.00	Acc@1 53.1	Acc@5 85.9
Epoch: [11][361/704]	Time 0.120	Data 0.001	Loss 6.06	Acc@1 54.7	Acc@5 84.4
Epoch: [11][371/704]	Time 0.120	Data 0.001	Loss 7.60	Acc@1 54.7	Acc@5 79.7
Epoch: [11][381/704]	Time 0.120	Data 0.001	Loss 8.63	Acc@1 50.0	Acc@5 70.3
Epoch: [11][391/704]	Time 0.120	Data 0.001	Loss 8.46	Acc@1 45.3	Acc@5 75.0
Epoch: [11][401/704]	Time 0.120	Data 0.001	Loss 7.01	Acc@1 50.0	Acc@5 87.5
Epoch: [11][411/704]	Time 0.120	Data 0.001	Loss 8.12	Acc@1 54.7	Acc@5 78.1
Epoch: [11][421/704]	Time 0.120	Data 0.001	Loss 7.42	Acc@1 53.1	Acc@5 82.8
Epoch: [11][431/704]	Time 0.120	Data 0.001	Loss 7.33	Acc@1 53.1	Acc@5 87.5
Epoch: [11][441/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 53.1	Acc@5 93.8
Epoch: [11][451/704]	Time 0.120	Data 0.001	Loss 7.22	Acc@1 62.5	Acc@5 84.4
Epoch: [11][461/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 59.4	Acc@5 84.4
Epoch: [11][471/704]	Time 0.120	Data 0.001	Loss 7.58	Acc@1 56.2	Acc@5 81.2
Epoch: [11][481/704]	Time 0.120	Data 0.001	Loss 8.57	Acc@1 42.2	Acc@5 70.3
Epoch: [11][491/704]	Time 0.120	Data 0.001	Loss 6.95	Acc@1 54.7	Acc@5 87.5
Epoch: [11][501/704]	Time 0.120	Data 0.001	Loss 7.43	Acc@1 48.4	Acc@5 84.4
Epoch: [11][511/704]	Time 0.120	Data 0.001	Loss 7.22	Acc@1 46.9	Acc@5 79.7
Epoch: [11][521/704]	Time 0.120	Data 0.001	Loss 7.05	Acc@1 60.9	Acc@5 82.8
Epoch: [11][531/704]	Time 0.120	Data 0.001	Loss 8.69	Acc@1 42.2	Acc@5 82.8
Epoch: [11][541/704]	Time 0.120	Data 0.001	Loss 8.28	Acc@1 51.6	Acc@5 75.0
Epoch: [11][551/704]	Time 0.119	Data 0.001	Loss 6.05	Acc@1 65.6	Acc@5 90.6
Epoch: [11][561/704]	Time 0.120	Data 0.001	Loss 7.19	Acc@1 50.0	Acc@5 81.2
Epoch: [11][571/704]	Time 0.120	Data 0.000	Loss 7.43	Acc@1 50.0	Acc@5 79.7
Epoch: [11][581/704]	Time 0.120	Data 0.000	Loss 7.43	Acc@1 51.6	Acc@5 79.7
Epoch: [11][591/704]	Time 0.120	Data 0.000	Loss 7.75	Acc@1 57.8	Acc@5 79.7
Epoch: [11][601/704]	Time 0.120	Data 0.000	Loss 7.96	Acc@1 56.2	Acc@5 81.2
Epoch: [11][611/704]	Time 0.120	Data 0.000	Loss 6.99	Acc@1 51.6	Acc@5 84.4
Epoch: [11][621/704]	Time 0.119	Data 0.000	Loss 7.78	Acc@1 54.7	Acc@5 87.5
Epoch: [11][631/704]	Time 0.119	Data 0.000	Loss 9.03	Acc@1 40.6	Acc@5 73.4
Epoch: [11][641/704]	Time 0.119	Data 0.000	Loss 7.48	Acc@1 60.9	Acc@5 84.4
Epoch: [11][651/704]	Time 0.119	Data 0.000	Loss 6.91	Acc@1 54.7	Acc@5 85.9
Epoch: [11][661/704]	Time 0.119	Data 0.000	Loss 6.14	Acc@1 64.1	Acc@5 90.6
Epoch: [11][671/704]	Time 0.119	Data 0.000	Loss 7.63	Acc@1 50.0	Acc@5 84.4
Epoch: [11][681/704]	Time 0.119	Data 0.000	Loss 7.09	Acc@1 56.2	Acc@5 85.9
Epoch: [11][691/704]	Time 0.119	Data 0.000	Loss 8.14	Acc@1 50.0	Acc@5 76.6
Epoch: [11][701/704]	Time 0.119	Data 0.000	Loss 6.87	Acc@1 53.1	Acc@5 87.5
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 8.1843	Acc@1 51.5625	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 8.8630	Acc@1 39.0625	Acc@5 75.0000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.2563	Acc@1 48.4375	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 10.5213	Acc@1 31.2500	Acc@5 70.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.3362	Acc@1 48.4375	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7603	Acc@1 50.0000	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.8519	Acc@1 46.8750	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.9960	Acc@1 43.7500	Acc@5 82.8125
 * prec@1 37.020 prec@5 68.300
 * prec@1 43.480 prec@5 75.400
 * prec@1 46.540 prec@5 78.080
 * prec@1 45.720 prec@5 77.600
Current best validation last_bloc_accuracy 48.94
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_011.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_011.pth.tar'
Epoch: [12][1/704]	Time 0.326	Data 0.161	Loss 5.68	Acc@1 62.5	Acc@5 90.6
Epoch: [12][11/704]	Time 0.138	Data 0.015	Loss 5.49	Acc@1 57.8	Acc@5 90.6
Epoch: [12][21/704]	Time 0.129	Data 0.008	Loss 6.52	Acc@1 54.7	Acc@5 89.1
Epoch: [12][31/704]	Time 0.126	Data 0.005	Loss 6.77	Acc@1 59.4	Acc@5 90.6
Epoch: [12][41/704]	Time 0.125	Data 0.004	Loss 5.86	Acc@1 62.5	Acc@5 93.8
Epoch: [12][51/704]	Time 0.124	Data 0.003	Loss 6.47	Acc@1 56.2	Acc@5 87.5
Epoch: [12][61/704]	Time 0.123	Data 0.003	Loss 7.55	Acc@1 54.7	Acc@5 84.4
Epoch: [12][71/704]	Time 0.122	Data 0.003	Loss 7.34	Acc@1 60.9	Acc@5 79.7
Epoch: [12][81/704]	Time 0.122	Data 0.002	Loss 8.41	Acc@1 48.4	Acc@5 81.2
Epoch: [12][91/704]	Time 0.122	Data 0.002	Loss 7.08	Acc@1 51.6	Acc@5 81.2
Epoch: [12][101/704]	Time 0.121	Data 0.002	Loss 7.08	Acc@1 46.9	Acc@5 89.1
Epoch: [12][111/704]	Time 0.121	Data 0.002	Loss 8.18	Acc@1 43.8	Acc@5 79.7
Epoch: [12][121/704]	Time 0.121	Data 0.002	Loss 8.91	Acc@1 42.2	Acc@5 76.6
Epoch: [12][131/704]	Time 0.121	Data 0.002	Loss 6.81	Acc@1 54.7	Acc@5 89.1
Epoch: [12][141/704]	Time 0.121	Data 0.001	Loss 7.01	Acc@1 62.5	Acc@5 85.9
Epoch: [12][151/704]	Time 0.121	Data 0.001	Loss 7.07	Acc@1 56.2	Acc@5 82.8
Epoch: [12][161/704]	Time 0.121	Data 0.001	Loss 8.82	Acc@1 53.1	Acc@5 81.2
Epoch: [12][171/704]	Time 0.121	Data 0.001	Loss 7.99	Acc@1 53.1	Acc@5 82.8
Epoch: [12][181/704]	Time 0.121	Data 0.001	Loss 8.02	Acc@1 54.7	Acc@5 79.7
Epoch: [12][191/704]	Time 0.121	Data 0.001	Loss 8.31	Acc@1 53.1	Acc@5 84.4
Epoch: [12][201/704]	Time 0.121	Data 0.001	Loss 7.09	Acc@1 57.8	Acc@5 84.4
Epoch: [12][211/704]	Time 0.121	Data 0.001	Loss 7.54	Acc@1 54.7	Acc@5 84.4
Epoch: [12][221/704]	Time 0.121	Data 0.001	Loss 6.58	Acc@1 59.4	Acc@5 81.2
Epoch: [12][231/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 64.1	Acc@5 85.9
Epoch: [12][241/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 60.9	Acc@5 89.1
Epoch: [12][251/704]	Time 0.121	Data 0.001	Loss 7.67	Acc@1 51.6	Acc@5 81.2
Epoch: [12][261/704]	Time 0.121	Data 0.001	Loss 7.52	Acc@1 54.7	Acc@5 81.2
Epoch: [12][271/704]	Time 0.121	Data 0.001	Loss 8.37	Acc@1 39.1	Acc@5 87.5
Epoch: [12][281/704]	Time 0.121	Data 0.001	Loss 8.63	Acc@1 43.8	Acc@5 73.4
Epoch: [12][291/704]	Time 0.121	Data 0.001	Loss 7.39	Acc@1 56.2	Acc@5 81.2
Epoch: [12][301/704]	Time 0.121	Data 0.001	Loss 6.82	Acc@1 50.0	Acc@5 84.4
Epoch: [12][311/704]	Time 0.121	Data 0.001	Loss 8.58	Acc@1 45.3	Acc@5 71.9
Epoch: [12][321/704]	Time 0.121	Data 0.001	Loss 7.96	Acc@1 46.9	Acc@5 81.2
Epoch: [12][331/704]	Time 0.120	Data 0.001	Loss 7.70	Acc@1 50.0	Acc@5 84.4
Epoch: [12][341/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 64.1	Acc@5 84.4
Epoch: [12][351/704]	Time 0.120	Data 0.001	Loss 6.28	Acc@1 54.7	Acc@5 87.5
Epoch: [12][361/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 53.1	Acc@5 81.2
Epoch: [12][371/704]	Time 0.120	Data 0.001	Loss 6.71	Acc@1 59.4	Acc@5 90.6
Epoch: [12][381/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 46.9	Acc@5 85.9
Epoch: [12][391/704]	Time 0.120	Data 0.001	Loss 7.15	Acc@1 56.2	Acc@5 85.9
Epoch: [12][401/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 56.2	Acc@5 76.6
Epoch: [12][411/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 53.1	Acc@5 85.9
Epoch: [12][421/704]	Time 0.120	Data 0.001	Loss 7.36	Acc@1 56.2	Acc@5 82.8
Epoch: [12][431/704]	Time 0.120	Data 0.001	Loss 8.16	Acc@1 50.0	Acc@5 84.4
Epoch: [12][441/704]	Time 0.120	Data 0.001	Loss 6.59	Acc@1 60.9	Acc@5 84.4
Epoch: [12][451/704]	Time 0.120	Data 0.001	Loss 7.07	Acc@1 50.0	Acc@5 87.5
Epoch: [12][461/704]	Time 0.120	Data 0.001	Loss 6.53	Acc@1 56.2	Acc@5 87.5
Epoch: [12][471/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 60.9	Acc@5 87.5
Epoch: [12][481/704]	Time 0.120	Data 0.001	Loss 7.43	Acc@1 54.7	Acc@5 87.5
Epoch: [12][491/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 51.6	Acc@5 85.9
Epoch: [12][501/704]	Time 0.120	Data 0.001	Loss 8.78	Acc@1 43.8	Acc@5 78.1
Epoch: [12][511/704]	Time 0.120	Data 0.001	Loss 6.72	Acc@1 54.7	Acc@5 89.1
Epoch: [12][521/704]	Time 0.120	Data 0.001	Loss 8.25	Acc@1 48.4	Acc@5 76.6
Epoch: [12][531/704]	Time 0.120	Data 0.001	Loss 7.97	Acc@1 51.6	Acc@5 84.4
Epoch: [12][541/704]	Time 0.120	Data 0.001	Loss 7.44	Acc@1 54.7	Acc@5 82.8
Epoch: [12][551/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 56.2	Acc@5 81.2
Epoch: [12][561/704]	Time 0.120	Data 0.001	Loss 6.73	Acc@1 60.9	Acc@5 85.9
Epoch: [12][571/704]	Time 0.120	Data 0.001	Loss 7.40	Acc@1 56.2	Acc@5 85.9
Epoch: [12][581/704]	Time 0.120	Data 0.001	Loss 7.63	Acc@1 46.9	Acc@5 78.1
Epoch: [12][591/704]	Time 0.120	Data 0.001	Loss 6.99	Acc@1 53.1	Acc@5 82.8
Epoch: [12][601/704]	Time 0.120	Data 0.001	Loss 7.00	Acc@1 54.7	Acc@5 89.1
Epoch: [12][611/704]	Time 0.120	Data 0.001	Loss 7.33	Acc@1 51.6	Acc@5 85.9
Epoch: [12][621/704]	Time 0.120	Data 0.001	Loss 7.92	Acc@1 51.6	Acc@5 81.2
Epoch: [12][631/704]	Time 0.120	Data 0.001	Loss 7.04	Acc@1 51.6	Acc@5 84.4
Epoch: [12][641/704]	Time 0.120	Data 0.001	Loss 8.77	Acc@1 35.9	Acc@5 82.8
Epoch: [12][651/704]	Time 0.120	Data 0.001	Loss 7.58	Acc@1 56.2	Acc@5 79.7
Epoch: [12][661/704]	Time 0.120	Data 0.001	Loss 7.11	Acc@1 48.4	Acc@5 87.5
Epoch: [12][671/704]	Time 0.120	Data 0.001	Loss 8.52	Acc@1 56.2	Acc@5 81.2
Epoch: [12][681/704]	Time 0.120	Data 0.001	Loss 7.63	Acc@1 56.2	Acc@5 82.8
Epoch: [12][691/704]	Time 0.120	Data 0.001	Loss 7.73	Acc@1 50.0	Acc@5 81.2
Epoch: [12][701/704]	Time 0.120	Data 0.001	Loss 6.47	Acc@1 54.7	Acc@5 87.5
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 8.0745	Acc@1 39.0625	Acc@5 79.6875
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 8.2623	Acc@1 56.2500	Acc@5 73.4375
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 8.8329	Acc@1 37.5000	Acc@5 70.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.4677	Acc@1 51.5625	Acc@5 73.4375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.4797	Acc@1 53.1250	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 9.2452	Acc@1 39.0625	Acc@5 73.4375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7932	Acc@1 56.2500	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.9580	Acc@1 56.2500	Acc@5 82.8125
 * prec@1 38.600 prec@5 70.160
 * prec@1 44.880 prec@5 75.980
 * prec@1 47.600 prec@5 78.460
 * prec@1 48.560 prec@5 78.960
Current best validation last_bloc_accuracy 48.94
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_012.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_012.pth.tar'
Epoch: [13][1/704]	Time 0.292	Data 0.127	Loss 6.85	Acc@1 56.2	Acc@5 79.7
Epoch: [13][11/704]	Time 0.135	Data 0.012	Loss 6.76	Acc@1 50.0	Acc@5 89.1
Epoch: [13][21/704]	Time 0.128	Data 0.006	Loss 8.07	Acc@1 39.1	Acc@5 73.4
Epoch: [13][31/704]	Time 0.125	Data 0.004	Loss 8.45	Acc@1 46.9	Acc@5 82.8
Epoch: [13][41/704]	Time 0.123	Data 0.003	Loss 6.50	Acc@1 56.2	Acc@5 84.4
Epoch: [13][51/704]	Time 0.123	Data 0.003	Loss 8.18	Acc@1 54.7	Acc@5 73.4
Epoch: [13][61/704]	Time 0.122	Data 0.002	Loss 8.43	Acc@1 46.9	Acc@5 71.9
Epoch: [13][71/704]	Time 0.122	Data 0.002	Loss 7.27	Acc@1 43.8	Acc@5 79.7
Epoch: [13][81/704]	Time 0.121	Data 0.002	Loss 7.58	Acc@1 48.4	Acc@5 87.5
Epoch: [13][91/704]	Time 0.121	Data 0.002	Loss 7.18	Acc@1 51.6	Acc@5 82.8
Epoch: [13][101/704]	Time 0.121	Data 0.002	Loss 6.90	Acc@1 48.4	Acc@5 84.4
Epoch: [13][111/704]	Time 0.121	Data 0.001	Loss 7.38	Acc@1 51.6	Acc@5 84.4
Epoch: [13][121/704]	Time 0.121	Data 0.001	Loss 7.97	Acc@1 45.3	Acc@5 81.2
Epoch: [13][131/704]	Time 0.121	Data 0.001	Loss 7.12	Acc@1 51.6	Acc@5 82.8
Epoch: [13][141/704]	Time 0.121	Data 0.001	Loss 7.00	Acc@1 56.2	Acc@5 90.6
Epoch: [13][151/704]	Time 0.121	Data 0.001	Loss 7.96	Acc@1 43.8	Acc@5 78.1
Epoch: [13][161/704]	Time 0.121	Data 0.001	Loss 8.33	Acc@1 46.9	Acc@5 78.1
Epoch: [13][171/704]	Time 0.121	Data 0.001	Loss 7.89	Acc@1 54.7	Acc@5 82.8
Epoch: [13][181/704]	Time 0.120	Data 0.001	Loss 8.58	Acc@1 54.7	Acc@5 71.9
Epoch: [13][191/704]	Time 0.120	Data 0.001	Loss 7.72	Acc@1 56.2	Acc@5 89.1
Epoch: [13][201/704]	Time 0.120	Data 0.001	Loss 7.08	Acc@1 46.9	Acc@5 89.1
Epoch: [13][211/704]	Time 0.120	Data 0.001	Loss 6.91	Acc@1 51.6	Acc@5 85.9
Epoch: [13][221/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 53.1	Acc@5 89.1
Epoch: [13][231/704]	Time 0.120	Data 0.001	Loss 7.31	Acc@1 60.9	Acc@5 84.4
Epoch: [13][241/704]	Time 0.120	Data 0.001	Loss 7.36	Acc@1 51.6	Acc@5 82.8
Epoch: [13][251/704]	Time 0.120	Data 0.001	Loss 6.51	Acc@1 60.9	Acc@5 92.2
Epoch: [13][261/704]	Time 0.120	Data 0.001	Loss 6.92	Acc@1 56.2	Acc@5 82.8
Epoch: [13][271/704]	Time 0.120	Data 0.001	Loss 6.35	Acc@1 59.4	Acc@5 87.5
Epoch: [13][281/704]	Time 0.120	Data 0.001	Loss 7.37	Acc@1 53.1	Acc@5 89.1
Epoch: [13][291/704]	Time 0.120	Data 0.001	Loss 6.88	Acc@1 60.9	Acc@5 84.4
Epoch: [13][301/704]	Time 0.120	Data 0.001	Loss 6.92	Acc@1 57.8	Acc@5 87.5
Epoch: [13][311/704]	Time 0.120	Data 0.001	Loss 7.01	Acc@1 53.1	Acc@5 82.8
Epoch: [13][321/704]	Time 0.120	Data 0.001	Loss 6.14	Acc@1 64.1	Acc@5 87.5
Epoch: [13][331/704]	Time 0.120	Data 0.001	Loss 7.48	Acc@1 59.4	Acc@5 82.8
Epoch: [13][341/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 54.7	Acc@5 84.4
Epoch: [13][351/704]	Time 0.120	Data 0.001	Loss 6.57	Acc@1 57.8	Acc@5 89.1
Epoch: [13][361/704]	Time 0.120	Data 0.001	Loss 7.95	Acc@1 51.6	Acc@5 87.5
Epoch: [13][371/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 57.8	Acc@5 90.6
Epoch: [13][381/704]	Time 0.120	Data 0.001	Loss 6.52	Acc@1 62.5	Acc@5 87.5
Epoch: [13][391/704]	Time 0.120	Data 0.001	Loss 6.39	Acc@1 51.6	Acc@5 92.2
Epoch: [13][401/704]	Time 0.120	Data 0.001	Loss 6.74	Acc@1 59.4	Acc@5 84.4
Epoch: [13][411/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 54.7	Acc@5 87.5
Epoch: [13][421/704]	Time 0.120	Data 0.001	Loss 6.35	Acc@1 62.5	Acc@5 82.8
Epoch: [13][431/704]	Time 0.120	Data 0.001	Loss 8.89	Acc@1 45.3	Acc@5 79.7
Epoch: [13][441/704]	Time 0.120	Data 0.001	Loss 7.73	Acc@1 54.7	Acc@5 78.1
Epoch: [13][451/704]	Time 0.120	Data 0.001	Loss 7.75	Acc@1 50.0	Acc@5 87.5
Epoch: [13][461/704]	Time 0.120	Data 0.001	Loss 7.66	Acc@1 50.0	Acc@5 81.2
Epoch: [13][471/704]	Time 0.120	Data 0.001	Loss 6.18	Acc@1 60.9	Acc@5 84.4
Epoch: [13][481/704]	Time 0.120	Data 0.001	Loss 8.04	Acc@1 50.0	Acc@5 81.2
Epoch: [13][491/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 68.8	Acc@5 93.8
Epoch: [13][501/704]	Time 0.120	Data 0.001	Loss 6.21	Acc@1 59.4	Acc@5 85.9
Epoch: [13][511/704]	Time 0.120	Data 0.001	Loss 8.11	Acc@1 46.9	Acc@5 75.0
Epoch: [13][521/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 67.2	Acc@5 89.1
Epoch: [13][531/704]	Time 0.120	Data 0.001	Loss 6.04	Acc@1 64.1	Acc@5 85.9
Epoch: [13][541/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 54.7	Acc@5 87.5
Epoch: [13][551/704]	Time 0.120	Data 0.001	Loss 6.26	Acc@1 51.6	Acc@5 87.5
Epoch: [13][561/704]	Time 0.120	Data 0.001	Loss 7.75	Acc@1 51.6	Acc@5 76.6
Epoch: [13][571/704]	Time 0.120	Data 0.001	Loss 8.19	Acc@1 48.4	Acc@5 76.6
Epoch: [13][581/704]	Time 0.120	Data 0.000	Loss 7.18	Acc@1 48.4	Acc@5 84.4
Epoch: [13][591/704]	Time 0.120	Data 0.000	Loss 6.91	Acc@1 65.6	Acc@5 85.9
Epoch: [13][601/704]	Time 0.120	Data 0.000	Loss 6.87	Acc@1 51.6	Acc@5 87.5
Epoch: [13][611/704]	Time 0.120	Data 0.000	Loss 8.38	Acc@1 53.1	Acc@5 81.2
Epoch: [13][621/704]	Time 0.120	Data 0.000	Loss 8.47	Acc@1 46.9	Acc@5 76.6
Epoch: [13][631/704]	Time 0.120	Data 0.000	Loss 7.08	Acc@1 54.7	Acc@5 82.8
Epoch: [13][641/704]	Time 0.120	Data 0.000	Loss 6.60	Acc@1 57.8	Acc@5 84.4
Epoch: [13][651/704]	Time 0.120	Data 0.000	Loss 7.01	Acc@1 51.6	Acc@5 85.9
Epoch: [13][661/704]	Time 0.120	Data 0.000	Loss 6.38	Acc@1 68.8	Acc@5 87.5
Epoch: [13][671/704]	Time 0.120	Data 0.000	Loss 9.30	Acc@1 37.5	Acc@5 75.0
Epoch: [13][681/704]	Time 0.120	Data 0.000	Loss 6.41	Acc@1 65.6	Acc@5 87.5
Epoch: [13][691/704]	Time 0.120	Data 0.000	Loss 6.23	Acc@1 68.8	Acc@5 82.8
Epoch: [13][701/704]	Time 0.120	Data 0.000	Loss 7.92	Acc@1 50.0	Acc@5 78.1
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 8.7287	Acc@1 45.3125	Acc@5 73.4375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 9.1378	Acc@1 45.3125	Acc@5 73.4375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2942	Acc@1 48.4375	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3392	Acc@1 53.1250	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.9678	Acc@1 54.6875	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.6996	Acc@1 56.2500	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6156	Acc@1 46.8750	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 9.9872	Acc@1 32.8125	Acc@5 70.3125
 * prec@1 39.680 prec@5 71.660
 * prec@1 45.160 prec@5 76.700
 * prec@1 47.800 prec@5 80.000
 * prec@1 49.060 prec@5 79.740
New best validation last_bloc_accuracy 49.06
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_013.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_013.pth.tar'
Epoch: [14][1/704]	Time 0.297	Data 0.131	Loss 7.52	Acc@1 51.6	Acc@5 75.0
Epoch: [14][11/704]	Time 0.136	Data 0.012	Loss 7.83	Acc@1 48.4	Acc@5 81.2
Epoch: [14][21/704]	Time 0.128	Data 0.007	Loss 7.22	Acc@1 60.9	Acc@5 87.5
Epoch: [14][31/704]	Time 0.125	Data 0.005	Loss 6.81	Acc@1 51.6	Acc@5 87.5
Epoch: [14][41/704]	Time 0.124	Data 0.003	Loss 7.80	Acc@1 48.4	Acc@5 85.9
Epoch: [14][51/704]	Time 0.124	Data 0.003	Loss 7.87	Acc@1 59.4	Acc@5 79.7
Epoch: [14][61/704]	Time 0.123	Data 0.002	Loss 6.18	Acc@1 64.1	Acc@5 81.2
Epoch: [14][71/704]	Time 0.123	Data 0.002	Loss 7.83	Acc@1 46.9	Acc@5 85.9
Epoch: [14][81/704]	Time 0.122	Data 0.002	Loss 7.52	Acc@1 48.4	Acc@5 82.8
Epoch: [14][91/704]	Time 0.122	Data 0.002	Loss 7.55	Acc@1 59.4	Acc@5 81.2
Epoch: [14][101/704]	Time 0.122	Data 0.002	Loss 6.49	Acc@1 57.8	Acc@5 90.6
Epoch: [14][111/704]	Time 0.122	Data 0.001	Loss 6.24	Acc@1 59.4	Acc@5 82.8
Epoch: [14][121/704]	Time 0.122	Data 0.001	Loss 6.45	Acc@1 57.8	Acc@5 87.5
Epoch: [14][131/704]	Time 0.121	Data 0.001	Loss 7.24	Acc@1 56.2	Acc@5 81.2
Epoch: [14][141/704]	Time 0.121	Data 0.001	Loss 8.14	Acc@1 51.6	Acc@5 81.2
Epoch: [14][151/704]	Time 0.121	Data 0.001	Loss 7.32	Acc@1 53.1	Acc@5 84.4
Epoch: [14][161/704]	Time 0.121	Data 0.001	Loss 7.60	Acc@1 51.6	Acc@5 79.7
Epoch: [14][171/704]	Time 0.121	Data 0.001	Loss 7.94	Acc@1 42.2	Acc@5 82.8
Epoch: [14][181/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 62.5	Acc@5 89.1
Epoch: [14][191/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 59.4	Acc@5 90.6
Epoch: [14][201/704]	Time 0.121	Data 0.001	Loss 6.63	Acc@1 70.3	Acc@5 85.9
Epoch: [14][211/704]	Time 0.121	Data 0.001	Loss 8.37	Acc@1 51.6	Acc@5 82.8
Epoch: [14][221/704]	Time 0.121	Data 0.001	Loss 7.74	Acc@1 45.3	Acc@5 76.6
Epoch: [14][231/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 59.4	Acc@5 89.1
Epoch: [14][241/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 65.6	Acc@5 90.6
Epoch: [14][251/704]	Time 0.121	Data 0.001	Loss 6.86	Acc@1 60.9	Acc@5 85.9
Epoch: [14][261/704]	Time 0.120	Data 0.001	Loss 6.24	Acc@1 59.4	Acc@5 92.2
Epoch: [14][271/704]	Time 0.120	Data 0.001	Loss 7.45	Acc@1 45.3	Acc@5 79.7
Epoch: [14][281/704]	Time 0.120	Data 0.001	Loss 7.70	Acc@1 45.3	Acc@5 82.8
Epoch: [14][291/704]	Time 0.120	Data 0.001	Loss 7.68	Acc@1 53.1	Acc@5 84.4
Epoch: [14][301/704]	Time 0.120	Data 0.001	Loss 7.32	Acc@1 50.0	Acc@5 84.4
Epoch: [14][311/704]	Time 0.120	Data 0.001	Loss 6.86	Acc@1 53.1	Acc@5 84.4
Epoch: [14][321/704]	Time 0.120	Data 0.001	Loss 6.81	Acc@1 59.4	Acc@5 85.9
Epoch: [14][331/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 65.6	Acc@5 90.6
Epoch: [14][341/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 60.9	Acc@5 81.2
Epoch: [14][351/704]	Time 0.120	Data 0.001	Loss 7.52	Acc@1 54.7	Acc@5 85.9
Epoch: [14][361/704]	Time 0.120	Data 0.001	Loss 7.22	Acc@1 50.0	Acc@5 85.9
Epoch: [14][371/704]	Time 0.120	Data 0.001	Loss 8.00	Acc@1 43.8	Acc@5 76.6
Epoch: [14][381/704]	Time 0.120	Data 0.001	Loss 7.05	Acc@1 62.5	Acc@5 84.4
Epoch: [14][391/704]	Time 0.120	Data 0.001	Loss 7.47	Acc@1 53.1	Acc@5 87.5
Epoch: [14][401/704]	Time 0.120	Data 0.001	Loss 8.28	Acc@1 46.9	Acc@5 79.7
Epoch: [14][411/704]	Time 0.120	Data 0.001	Loss 6.53	Acc@1 56.2	Acc@5 89.1
Epoch: [14][421/704]	Time 0.120	Data 0.001	Loss 7.04	Acc@1 53.1	Acc@5 81.2
Epoch: [14][431/704]	Time 0.120	Data 0.001	Loss 6.80	Acc@1 57.8	Acc@5 89.1
Epoch: [14][441/704]	Time 0.120	Data 0.001	Loss 7.35	Acc@1 51.6	Acc@5 81.2
Epoch: [14][451/704]	Time 0.120	Data 0.001	Loss 7.05	Acc@1 57.8	Acc@5 84.4
Epoch: [14][461/704]	Time 0.120	Data 0.001	Loss 7.91	Acc@1 56.2	Acc@5 78.1
Epoch: [14][471/704]	Time 0.120	Data 0.001	Loss 6.64	Acc@1 64.1	Acc@5 87.5
Epoch: [14][481/704]	Time 0.120	Data 0.001	Loss 6.46	Acc@1 62.5	Acc@5 90.6
Epoch: [14][491/704]	Time 0.120	Data 0.001	Loss 6.71	Acc@1 64.1	Acc@5 84.4
Epoch: [14][501/704]	Time 0.120	Data 0.001	Loss 7.30	Acc@1 54.7	Acc@5 84.4
Epoch: [14][511/704]	Time 0.120	Data 0.001	Loss 7.00	Acc@1 50.0	Acc@5 85.9
Epoch: [14][521/704]	Time 0.120	Data 0.001	Loss 7.14	Acc@1 51.6	Acc@5 84.4
Epoch: [14][531/704]	Time 0.120	Data 0.001	Loss 7.77	Acc@1 53.1	Acc@5 81.2
Epoch: [14][541/704]	Time 0.120	Data 0.001	Loss 7.17	Acc@1 50.0	Acc@5 85.9
Epoch: [14][551/704]	Time 0.120	Data 0.001	Loss 7.27	Acc@1 57.8	Acc@5 85.9
Epoch: [14][561/704]	Time 0.120	Data 0.000	Loss 6.14	Acc@1 62.5	Acc@5 89.1
Epoch: [14][571/704]	Time 0.120	Data 0.000	Loss 7.48	Acc@1 48.4	Acc@5 85.9
Epoch: [14][581/704]	Time 0.120	Data 0.000	Loss 6.83	Acc@1 60.9	Acc@5 81.2
Epoch: [14][591/704]	Time 0.120	Data 0.000	Loss 7.19	Acc@1 60.9	Acc@5 84.4
Epoch: [14][601/704]	Time 0.120	Data 0.000	Loss 7.02	Acc@1 53.1	Acc@5 85.9
Epoch: [14][611/704]	Time 0.120	Data 0.000	Loss 7.96	Acc@1 59.4	Acc@5 84.4
Epoch: [14][621/704]	Time 0.120	Data 0.000	Loss 6.38	Acc@1 64.1	Acc@5 85.9
Epoch: [14][631/704]	Time 0.120	Data 0.000	Loss 6.65	Acc@1 53.1	Acc@5 89.1
Epoch: [14][641/704]	Time 0.120	Data 0.000	Loss 4.91	Acc@1 67.2	Acc@5 87.5
Epoch: [14][651/704]	Time 0.120	Data 0.000	Loss 5.48	Acc@1 64.1	Acc@5 95.3
Epoch: [14][661/704]	Time 0.120	Data 0.000	Loss 7.08	Acc@1 54.7	Acc@5 87.5
Epoch: [14][671/704]	Time 0.120	Data 0.000	Loss 7.09	Acc@1 54.7	Acc@5 78.1
Epoch: [14][681/704]	Time 0.120	Data 0.000	Loss 6.57	Acc@1 65.6	Acc@5 90.6
Epoch: [14][691/704]	Time 0.120	Data 0.000	Loss 7.15	Acc@1 57.8	Acc@5 79.7
Epoch: [14][701/704]	Time 0.120	Data 0.000	Loss 7.03	Acc@1 56.2	Acc@5 81.2
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.8373	Acc@1 46.8750	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 9.6108	Acc@1 43.7500	Acc@5 76.5625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.3787	Acc@1 54.6875	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3360	Acc@1 43.7500	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.5419	Acc@1 43.7500	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7930	Acc@1 50.0000	Acc@5 78.1250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6380	Acc@1 40.6250	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 8.4414	Acc@1 50.0000	Acc@5 76.5625
 * prec@1 39.660 prec@5 71.840
 * prec@1 45.560 prec@5 76.280
 * prec@1 48.620 prec@5 80.260
 * prec@1 49.340 prec@5 81.000
New best validation last_bloc_accuracy 49.34
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_014.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_014.pth.tar'
Epoch: [15][1/704]	Time 0.326	Data 0.161	Loss 8.34	Acc@1 51.6	Acc@5 78.1
Epoch: [15][11/704]	Time 0.138	Data 0.015	Loss 8.52	Acc@1 51.6	Acc@5 78.1
Epoch: [15][21/704]	Time 0.129	Data 0.008	Loss 5.92	Acc@1 54.7	Acc@5 84.4
Epoch: [15][31/704]	Time 0.126	Data 0.006	Loss 7.36	Acc@1 51.6	Acc@5 81.2
Epoch: [15][41/704]	Time 0.124	Data 0.004	Loss 7.95	Acc@1 53.1	Acc@5 79.7
Epoch: [15][51/704]	Time 0.123	Data 0.003	Loss 6.75	Acc@1 51.6	Acc@5 90.6
Epoch: [15][61/704]	Time 0.123	Data 0.003	Loss 6.41	Acc@1 56.2	Acc@5 81.2
Epoch: [15][71/704]	Time 0.122	Data 0.003	Loss 6.59	Acc@1 51.6	Acc@5 89.1
Epoch: [15][81/704]	Time 0.122	Data 0.002	Loss 6.84	Acc@1 62.5	Acc@5 84.4
Epoch: [15][91/704]	Time 0.122	Data 0.002	Loss 6.16	Acc@1 60.9	Acc@5 87.5
Epoch: [15][101/704]	Time 0.121	Data 0.002	Loss 5.53	Acc@1 64.1	Acc@5 90.6
Epoch: [15][111/704]	Time 0.121	Data 0.002	Loss 7.28	Acc@1 56.2	Acc@5 84.4
Epoch: [15][121/704]	Time 0.121	Data 0.002	Loss 6.64	Acc@1 51.6	Acc@5 87.5
Epoch: [15][131/704]	Time 0.121	Data 0.002	Loss 7.39	Acc@1 56.2	Acc@5 79.7
Epoch: [15][141/704]	Time 0.121	Data 0.001	Loss 7.57	Acc@1 57.8	Acc@5 84.4
Epoch: [15][151/704]	Time 0.121	Data 0.001	Loss 8.20	Acc@1 56.2	Acc@5 76.6
Epoch: [15][161/704]	Time 0.120	Data 0.001	Loss 6.06	Acc@1 62.5	Acc@5 89.1
Epoch: [15][171/704]	Time 0.120	Data 0.001	Loss 6.20	Acc@1 62.5	Acc@5 90.6
Epoch: [15][181/704]	Time 0.120	Data 0.001	Loss 7.80	Acc@1 50.0	Acc@5 84.4
Epoch: [15][191/704]	Time 0.120	Data 0.001	Loss 6.33	Acc@1 60.9	Acc@5 90.6
Epoch: [15][201/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 56.2	Acc@5 85.9
Epoch: [15][211/704]	Time 0.120	Data 0.001	Loss 8.84	Acc@1 40.6	Acc@5 79.7
Epoch: [15][221/704]	Time 0.120	Data 0.001	Loss 6.92	Acc@1 56.2	Acc@5 85.9
Epoch: [15][231/704]	Time 0.120	Data 0.001	Loss 7.51	Acc@1 56.2	Acc@5 79.7
Epoch: [15][241/704]	Time 0.120	Data 0.001	Loss 7.92	Acc@1 54.7	Acc@5 79.7
Epoch: [15][251/704]	Time 0.120	Data 0.001	Loss 7.20	Acc@1 50.0	Acc@5 85.9
Epoch: [15][261/704]	Time 0.120	Data 0.001	Loss 7.64	Acc@1 50.0	Acc@5 81.2
Epoch: [15][271/704]	Time 0.120	Data 0.001	Loss 6.60	Acc@1 64.1	Acc@5 90.6
Epoch: [15][281/704]	Time 0.120	Data 0.001	Loss 6.65	Acc@1 57.8	Acc@5 81.2
Epoch: [15][291/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 57.8	Acc@5 89.1
Epoch: [15][301/704]	Time 0.120	Data 0.001	Loss 8.22	Acc@1 50.0	Acc@5 81.2
Epoch: [15][311/704]	Time 0.120	Data 0.001	Loss 6.87	Acc@1 53.1	Acc@5 84.4
Epoch: [15][321/704]	Time 0.120	Data 0.001	Loss 6.52	Acc@1 59.4	Acc@5 84.4
Epoch: [15][331/704]	Time 0.120	Data 0.001	Loss 7.94	Acc@1 48.4	Acc@5 87.5
Epoch: [15][341/704]	Time 0.120	Data 0.001	Loss 8.49	Acc@1 45.3	Acc@5 79.7
Epoch: [15][351/704]	Time 0.120	Data 0.001	Loss 7.36	Acc@1 54.7	Acc@5 82.8
Epoch: [15][361/704]	Time 0.120	Data 0.001	Loss 7.35	Acc@1 50.0	Acc@5 81.2
Epoch: [15][371/704]	Time 0.120	Data 0.001	Loss 6.67	Acc@1 51.6	Acc@5 90.6
Epoch: [15][381/704]	Time 0.120	Data 0.001	Loss 6.80	Acc@1 64.1	Acc@5 84.4
Epoch: [15][391/704]	Time 0.120	Data 0.001	Loss 7.07	Acc@1 62.5	Acc@5 82.8
Epoch: [15][401/704]	Time 0.120	Data 0.001	Loss 7.18	Acc@1 48.4	Acc@5 87.5
Epoch: [15][411/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 62.5	Acc@5 89.1
Epoch: [15][421/704]	Time 0.120	Data 0.001	Loss 6.04	Acc@1 56.2	Acc@5 93.8
Epoch: [15][431/704]	Time 0.120	Data 0.001	Loss 7.61	Acc@1 50.0	Acc@5 87.5
Epoch: [15][441/704]	Time 0.120	Data 0.001	Loss 7.55	Acc@1 51.6	Acc@5 79.7
Epoch: [15][451/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 54.7	Acc@5 82.8
Epoch: [15][461/704]	Time 0.120	Data 0.001	Loss 6.86	Acc@1 54.7	Acc@5 84.4
Epoch: [15][471/704]	Time 0.120	Data 0.001	Loss 6.74	Acc@1 59.4	Acc@5 87.5
Epoch: [15][481/704]	Time 0.120	Data 0.001	Loss 6.75	Acc@1 51.6	Acc@5 87.5
Epoch: [15][491/704]	Time 0.120	Data 0.001	Loss 6.78	Acc@1 60.9	Acc@5 87.5
Epoch: [15][501/704]	Time 0.120	Data 0.001	Loss 6.39	Acc@1 60.9	Acc@5 90.6
Epoch: [15][511/704]	Time 0.120	Data 0.001	Loss 6.19	Acc@1 56.2	Acc@5 90.6
Epoch: [15][521/704]	Time 0.120	Data 0.001	Loss 6.72	Acc@1 62.5	Acc@5 82.8
Epoch: [15][531/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 50.0	Acc@5 87.5
Epoch: [15][541/704]	Time 0.120	Data 0.001	Loss 8.77	Acc@1 43.8	Acc@5 78.1
Epoch: [15][551/704]	Time 0.120	Data 0.001	Loss 7.19	Acc@1 53.1	Acc@5 90.6
Epoch: [15][561/704]	Time 0.120	Data 0.001	Loss 7.17	Acc@1 51.6	Acc@5 81.2
Epoch: [15][571/704]	Time 0.120	Data 0.001	Loss 8.46	Acc@1 48.4	Acc@5 76.6
Epoch: [15][581/704]	Time 0.119	Data 0.001	Loss 7.03	Acc@1 62.5	Acc@5 85.9
Epoch: [15][591/704]	Time 0.119	Data 0.001	Loss 7.91	Acc@1 48.4	Acc@5 84.4
Epoch: [15][601/704]	Time 0.119	Data 0.001	Loss 7.19	Acc@1 46.9	Acc@5 87.5
Epoch: [15][611/704]	Time 0.119	Data 0.001	Loss 8.71	Acc@1 57.8	Acc@5 81.2
Epoch: [15][621/704]	Time 0.119	Data 0.001	Loss 5.99	Acc@1 62.5	Acc@5 89.1
Epoch: [15][631/704]	Time 0.119	Data 0.001	Loss 6.86	Acc@1 57.8	Acc@5 85.9
Epoch: [15][641/704]	Time 0.119	Data 0.001	Loss 7.34	Acc@1 57.8	Acc@5 82.8
Epoch: [15][651/704]	Time 0.119	Data 0.001	Loss 6.26	Acc@1 57.8	Acc@5 90.6
Epoch: [15][661/704]	Time 0.119	Data 0.001	Loss 5.93	Acc@1 56.2	Acc@5 90.6
Epoch: [15][671/704]	Time 0.119	Data 0.001	Loss 8.29	Acc@1 45.3	Acc@5 84.4
Epoch: [15][681/704]	Time 0.119	Data 0.001	Loss 6.20	Acc@1 67.2	Acc@5 90.6
Epoch: [15][691/704]	Time 0.119	Data 0.001	Loss 7.87	Acc@1 53.1	Acc@5 82.8
Epoch: [15][701/704]	Time 0.119	Data 0.001	Loss 6.07	Acc@1 57.8	Acc@5 92.2
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 9.0149	Acc@1 39.0625	Acc@5 73.4375
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 8.4701	Acc@1 45.3125	Acc@5 75.0000
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 8.1728	Acc@1 45.3125	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 10.1736	Acc@1 42.1875	Acc@5 71.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9834	Acc@1 59.3750	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 9.4274	Acc@1 43.7500	Acc@5 67.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.9774	Acc@1 35.9375	Acc@5 73.4375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.5400	Acc@1 67.1875	Acc@5 89.0625
 * prec@1 38.720 prec@5 69.840
 * prec@1 44.680 prec@5 76.460
 * prec@1 47.400 prec@5 78.440
 * prec@1 49.180 prec@5 79.380
Current best validation last_bloc_accuracy 49.34
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_015.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_015.pth.tar'
Epoch: [16][1/704]	Time 0.326	Data 0.160	Loss 5.92	Acc@1 57.8	Acc@5 85.9
Epoch: [16][11/704]	Time 0.138	Data 0.015	Loss 7.34	Acc@1 45.3	Acc@5 84.4
Epoch: [16][21/704]	Time 0.129	Data 0.008	Loss 6.36	Acc@1 60.9	Acc@5 90.6
Epoch: [16][31/704]	Time 0.126	Data 0.005	Loss 7.18	Acc@1 50.0	Acc@5 81.2
Epoch: [16][41/704]	Time 0.124	Data 0.004	Loss 6.80	Acc@1 57.8	Acc@5 85.9
Epoch: [16][51/704]	Time 0.123	Data 0.003	Loss 6.37	Acc@1 64.1	Acc@5 87.5
Epoch: [16][61/704]	Time 0.123	Data 0.003	Loss 6.13	Acc@1 54.7	Acc@5 89.1
Epoch: [16][71/704]	Time 0.122	Data 0.003	Loss 6.16	Acc@1 67.2	Acc@5 90.6
Epoch: [16][81/704]	Time 0.122	Data 0.002	Loss 6.60	Acc@1 56.2	Acc@5 84.4
Epoch: [16][91/704]	Time 0.122	Data 0.002	Loss 5.76	Acc@1 75.0	Acc@5 89.1
Epoch: [16][101/704]	Time 0.121	Data 0.002	Loss 8.46	Acc@1 45.3	Acc@5 78.1
Epoch: [16][111/704]	Time 0.121	Data 0.002	Loss 7.49	Acc@1 50.0	Acc@5 81.2
Epoch: [16][121/704]	Time 0.121	Data 0.002	Loss 7.44	Acc@1 56.2	Acc@5 81.2
Epoch: [16][131/704]	Time 0.121	Data 0.002	Loss 6.59	Acc@1 64.1	Acc@5 84.4
Epoch: [16][141/704]	Time 0.121	Data 0.001	Loss 6.51	Acc@1 59.4	Acc@5 85.9
Epoch: [16][151/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 65.6	Acc@5 90.6
Epoch: [16][161/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 59.4	Acc@5 90.6
Epoch: [16][171/704]	Time 0.121	Data 0.001	Loss 7.81	Acc@1 50.0	Acc@5 84.4
Epoch: [16][181/704]	Time 0.121	Data 0.001	Loss 7.04	Acc@1 50.0	Acc@5 84.4
Epoch: [16][191/704]	Time 0.121	Data 0.001	Loss 7.48	Acc@1 57.8	Acc@5 79.7
Epoch: [16][201/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 57.8	Acc@5 85.9
Epoch: [16][211/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 57.8	Acc@5 89.1
Epoch: [16][221/704]	Time 0.120	Data 0.001	Loss 6.91	Acc@1 59.4	Acc@5 84.4
Epoch: [16][231/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 64.1	Acc@5 84.4
Epoch: [16][241/704]	Time 0.120	Data 0.001	Loss 6.12	Acc@1 59.4	Acc@5 89.1
Epoch: [16][251/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 62.5	Acc@5 90.6
Epoch: [16][261/704]	Time 0.120	Data 0.001	Loss 7.02	Acc@1 56.2	Acc@5 89.1
Epoch: [16][271/704]	Time 0.120	Data 0.001	Loss 5.05	Acc@1 67.2	Acc@5 93.8
Epoch: [16][281/704]	Time 0.120	Data 0.001	Loss 7.38	Acc@1 57.8	Acc@5 84.4
Epoch: [16][291/704]	Time 0.120	Data 0.001	Loss 8.11	Acc@1 56.2	Acc@5 78.1
Epoch: [16][301/704]	Time 0.120	Data 0.001	Loss 7.88	Acc@1 53.1	Acc@5 82.8
Epoch: [16][311/704]	Time 0.120	Data 0.001	Loss 7.50	Acc@1 51.6	Acc@5 85.9
Epoch: [16][321/704]	Time 0.120	Data 0.001	Loss 7.49	Acc@1 45.3	Acc@5 81.2
Epoch: [16][331/704]	Time 0.120	Data 0.001	Loss 6.99	Acc@1 46.9	Acc@5 89.1
Epoch: [16][341/704]	Time 0.120	Data 0.001	Loss 6.20	Acc@1 62.5	Acc@5 89.1
Epoch: [16][351/704]	Time 0.120	Data 0.001	Loss 7.60	Acc@1 53.1	Acc@5 79.7
Epoch: [16][361/704]	Time 0.120	Data 0.001	Loss 8.57	Acc@1 43.8	Acc@5 79.7
Epoch: [16][371/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 54.7	Acc@5 87.5
Epoch: [16][381/704]	Time 0.120	Data 0.001	Loss 7.54	Acc@1 51.6	Acc@5 84.4
Epoch: [16][391/704]	Time 0.120	Data 0.001	Loss 6.68	Acc@1 60.9	Acc@5 84.4
Epoch: [16][401/704]	Time 0.120	Data 0.001	Loss 7.18	Acc@1 56.2	Acc@5 81.2
Epoch: [16][411/704]	Time 0.120	Data 0.001	Loss 6.97	Acc@1 56.2	Acc@5 89.1
Epoch: [16][421/704]	Time 0.120	Data 0.001	Loss 7.17	Acc@1 54.7	Acc@5 85.9
Epoch: [16][431/704]	Time 0.120	Data 0.001	Loss 6.34	Acc@1 56.2	Acc@5 95.3
Epoch: [16][441/704]	Time 0.120	Data 0.001	Loss 6.71	Acc@1 56.2	Acc@5 84.4
Epoch: [16][451/704]	Time 0.120	Data 0.001	Loss 6.97	Acc@1 62.5	Acc@5 87.5
Epoch: [16][461/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 56.2	Acc@5 78.1
Epoch: [16][471/704]	Time 0.120	Data 0.001	Loss 6.23	Acc@1 62.5	Acc@5 84.4
Epoch: [16][481/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 56.2	Acc@5 90.6
Epoch: [16][491/704]	Time 0.120	Data 0.001	Loss 8.17	Acc@1 48.4	Acc@5 78.1
Epoch: [16][501/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 60.9	Acc@5 85.9
Epoch: [16][511/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 51.6	Acc@5 90.6
Epoch: [16][521/704]	Time 0.120	Data 0.001	Loss 6.91	Acc@1 53.1	Acc@5 84.4
Epoch: [16][531/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 64.1	Acc@5 92.2
Epoch: [16][541/704]	Time 0.120	Data 0.001	Loss 7.21	Acc@1 48.4	Acc@5 82.8
Epoch: [16][551/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 53.1	Acc@5 89.1
Epoch: [16][561/704]	Time 0.120	Data 0.001	Loss 6.89	Acc@1 54.7	Acc@5 84.4
Epoch: [16][571/704]	Time 0.120	Data 0.001	Loss 7.59	Acc@1 53.1	Acc@5 84.4
Epoch: [16][581/704]	Time 0.120	Data 0.001	Loss 8.87	Acc@1 35.9	Acc@5 73.4
Epoch: [16][591/704]	Time 0.120	Data 0.001	Loss 7.88	Acc@1 51.6	Acc@5 84.4
Epoch: [16][601/704]	Time 0.120	Data 0.001	Loss 7.00	Acc@1 53.1	Acc@5 81.2
Epoch: [16][611/704]	Time 0.120	Data 0.001	Loss 7.20	Acc@1 54.7	Acc@5 82.8
Epoch: [16][621/704]	Time 0.120	Data 0.001	Loss 6.81	Acc@1 59.4	Acc@5 84.4
Epoch: [16][631/704]	Time 0.120	Data 0.001	Loss 7.45	Acc@1 42.2	Acc@5 76.6
Epoch: [16][641/704]	Time 0.120	Data 0.001	Loss 8.13	Acc@1 46.9	Acc@5 82.8
Epoch: [16][651/704]	Time 0.120	Data 0.001	Loss 6.27	Acc@1 62.5	Acc@5 85.9
Epoch: [16][661/704]	Time 0.120	Data 0.001	Loss 7.47	Acc@1 46.9	Acc@5 85.9
Epoch: [16][671/704]	Time 0.120	Data 0.001	Loss 5.70	Acc@1 62.5	Acc@5 92.2
Epoch: [16][681/704]	Time 0.120	Data 0.001	Loss 7.26	Acc@1 51.6	Acc@5 82.8
Epoch: [16][691/704]	Time 0.120	Data 0.001	Loss 5.91	Acc@1 51.6	Acc@5 92.2
Epoch: [16][701/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 68.8	Acc@5 92.2
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 7.5784	Acc@1 54.6875	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.1731	Acc@1 48.4375	Acc@5 79.6875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6305	Acc@1 54.6875	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.2530	Acc@1 59.3750	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.1660	Acc@1 46.8750	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.4573	Acc@1 59.3750	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.1118	Acc@1 50.0000	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 9.6498	Acc@1 40.6250	Acc@5 75.0000
 * prec@1 40.380 prec@5 71.840
 * prec@1 45.180 prec@5 76.760
 * prec@1 49.200 prec@5 80.540
 * prec@1 50.300 prec@5 80.660
New best validation last_bloc_accuracy 50.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_016.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_016.pth.tar'
Epoch: [17][1/704]	Time 0.296	Data 0.130	Loss 6.13	Acc@1 62.5	Acc@5 87.5
Epoch: [17][11/704]	Time 0.135	Data 0.012	Loss 7.69	Acc@1 54.7	Acc@5 81.2
Epoch: [17][21/704]	Time 0.128	Data 0.006	Loss 7.41	Acc@1 51.6	Acc@5 79.7
Epoch: [17][31/704]	Time 0.125	Data 0.004	Loss 7.44	Acc@1 54.7	Acc@5 81.2
Epoch: [17][41/704]	Time 0.123	Data 0.003	Loss 7.23	Acc@1 56.2	Acc@5 79.7
Epoch: [17][51/704]	Time 0.123	Data 0.003	Loss 6.72	Acc@1 59.4	Acc@5 85.9
Epoch: [17][61/704]	Time 0.122	Data 0.002	Loss 6.84	Acc@1 59.4	Acc@5 87.5
Epoch: [17][71/704]	Time 0.122	Data 0.002	Loss 6.94	Acc@1 62.5	Acc@5 89.1
Epoch: [17][81/704]	Time 0.122	Data 0.002	Loss 6.20	Acc@1 60.9	Acc@5 84.4
Epoch: [17][91/704]	Time 0.122	Data 0.002	Loss 6.32	Acc@1 57.8	Acc@5 90.6
Epoch: [17][101/704]	Time 0.121	Data 0.002	Loss 6.26	Acc@1 60.9	Acc@5 89.1
Epoch: [17][111/704]	Time 0.121	Data 0.001	Loss 6.84	Acc@1 59.4	Acc@5 84.4
Epoch: [17][121/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 53.1	Acc@5 89.1
Epoch: [17][131/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 60.9	Acc@5 90.6
Epoch: [17][141/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 65.6	Acc@5 89.1
Epoch: [17][151/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 59.4	Acc@5 95.3
Epoch: [17][161/704]	Time 0.121	Data 0.001	Loss 6.41	Acc@1 57.8	Acc@5 89.1
Epoch: [17][171/704]	Time 0.120	Data 0.001	Loss 6.27	Acc@1 62.5	Acc@5 87.5
Epoch: [17][181/704]	Time 0.120	Data 0.001	Loss 6.78	Acc@1 59.4	Acc@5 81.2
Epoch: [17][191/704]	Time 0.120	Data 0.001	Loss 7.22	Acc@1 48.4	Acc@5 84.4
Epoch: [17][201/704]	Time 0.120	Data 0.001	Loss 7.61	Acc@1 54.7	Acc@5 81.2
Epoch: [17][211/704]	Time 0.120	Data 0.001	Loss 7.46	Acc@1 48.4	Acc@5 89.1
Epoch: [17][221/704]	Time 0.120	Data 0.001	Loss 7.63	Acc@1 50.0	Acc@5 76.6
Epoch: [17][231/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 59.4	Acc@5 90.6
Epoch: [17][241/704]	Time 0.120	Data 0.001	Loss 6.14	Acc@1 60.9	Acc@5 87.5
Epoch: [17][251/704]	Time 0.120	Data 0.001	Loss 7.71	Acc@1 46.9	Acc@5 82.8
Epoch: [17][261/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 42.2	Acc@5 87.5
Epoch: [17][271/704]	Time 0.120	Data 0.001	Loss 7.35	Acc@1 57.8	Acc@5 81.2
Epoch: [17][281/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 60.9	Acc@5 84.4
Epoch: [17][291/704]	Time 0.120	Data 0.001	Loss 6.16	Acc@1 57.8	Acc@5 84.4
Epoch: [17][301/704]	Time 0.120	Data 0.001	Loss 5.68	Acc@1 64.1	Acc@5 90.6
Epoch: [17][311/704]	Time 0.120	Data 0.001	Loss 6.00	Acc@1 71.9	Acc@5 95.3
Epoch: [17][321/704]	Time 0.120	Data 0.001	Loss 7.85	Acc@1 43.8	Acc@5 78.1
Epoch: [17][331/704]	Time 0.120	Data 0.001	Loss 6.63	Acc@1 62.5	Acc@5 87.5
Epoch: [17][341/704]	Time 0.120	Data 0.001	Loss 5.88	Acc@1 54.7	Acc@5 95.3
Epoch: [17][351/704]	Time 0.120	Data 0.001	Loss 7.85	Acc@1 56.2	Acc@5 79.7
Epoch: [17][361/704]	Time 0.120	Data 0.001	Loss 6.33	Acc@1 56.2	Acc@5 90.6
Epoch: [17][371/704]	Time 0.120	Data 0.001	Loss 6.25	Acc@1 60.9	Acc@5 87.5
Epoch: [17][381/704]	Time 0.120	Data 0.001	Loss 6.89	Acc@1 57.8	Acc@5 85.9
Epoch: [17][391/704]	Time 0.120	Data 0.001	Loss 6.33	Acc@1 60.9	Acc@5 81.2
Epoch: [17][401/704]	Time 0.120	Data 0.001	Loss 7.32	Acc@1 64.1	Acc@5 90.6
Epoch: [17][411/704]	Time 0.120	Data 0.001	Loss 6.68	Acc@1 56.2	Acc@5 87.5
Epoch: [17][421/704]	Time 0.120	Data 0.001	Loss 6.42	Acc@1 59.4	Acc@5 90.6
Epoch: [17][431/704]	Time 0.120	Data 0.001	Loss 4.54	Acc@1 71.9	Acc@5 96.9
Epoch: [17][441/704]	Time 0.120	Data 0.001	Loss 6.84	Acc@1 57.8	Acc@5 87.5
Epoch: [17][451/704]	Time 0.120	Data 0.001	Loss 6.52	Acc@1 57.8	Acc@5 90.6
Epoch: [17][461/704]	Time 0.120	Data 0.001	Loss 7.67	Acc@1 53.1	Acc@5 81.2
Epoch: [17][471/704]	Time 0.120	Data 0.001	Loss 6.83	Acc@1 60.9	Acc@5 82.8
Epoch: [17][481/704]	Time 0.120	Data 0.001	Loss 7.61	Acc@1 54.7	Acc@5 84.4
Epoch: [17][491/704]	Time 0.120	Data 0.001	Loss 6.76	Acc@1 62.5	Acc@5 90.6
Epoch: [17][501/704]	Time 0.120	Data 0.001	Loss 7.12	Acc@1 53.1	Acc@5 89.1
Epoch: [17][511/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 62.5	Acc@5 90.6
Epoch: [17][521/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 62.5	Acc@5 89.1
Epoch: [17][531/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 67.2	Acc@5 85.9
Epoch: [17][541/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 62.5	Acc@5 87.5
Epoch: [17][551/704]	Time 0.120	Data 0.001	Loss 7.36	Acc@1 46.9	Acc@5 84.4
Epoch: [17][561/704]	Time 0.120	Data 0.001	Loss 6.71	Acc@1 60.9	Acc@5 85.9
Epoch: [17][571/704]	Time 0.120	Data 0.000	Loss 6.81	Acc@1 62.5	Acc@5 81.2
Epoch: [17][581/704]	Time 0.119	Data 0.000	Loss 5.79	Acc@1 62.5	Acc@5 85.9
Epoch: [17][591/704]	Time 0.120	Data 0.000	Loss 7.55	Acc@1 48.4	Acc@5 79.7
Epoch: [17][601/704]	Time 0.120	Data 0.000	Loss 6.62	Acc@1 62.5	Acc@5 84.4
Epoch: [17][611/704]	Time 0.120	Data 0.000	Loss 7.57	Acc@1 42.2	Acc@5 85.9
Epoch: [17][621/704]	Time 0.120	Data 0.000	Loss 5.91	Acc@1 67.2	Acc@5 85.9
Epoch: [17][631/704]	Time 0.120	Data 0.000	Loss 6.23	Acc@1 56.2	Acc@5 93.8
Epoch: [17][641/704]	Time 0.120	Data 0.000	Loss 6.42	Acc@1 50.0	Acc@5 90.6
Epoch: [17][651/704]	Time 0.119	Data 0.000	Loss 6.81	Acc@1 57.8	Acc@5 76.6
Epoch: [17][661/704]	Time 0.119	Data 0.000	Loss 6.67	Acc@1 60.9	Acc@5 89.1
Epoch: [17][671/704]	Time 0.119	Data 0.000	Loss 7.13	Acc@1 59.4	Acc@5 84.4
Epoch: [17][681/704]	Time 0.119	Data 0.000	Loss 7.67	Acc@1 56.2	Acc@5 84.4
Epoch: [17][691/704]	Time 0.119	Data 0.000	Loss 7.29	Acc@1 64.1	Acc@5 82.8
Epoch: [17][701/704]	Time 0.119	Data 0.000	Loss 10.08	Acc@1 46.9	Acc@5 70.3
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 8.8303	Acc@1 50.0000	Acc@5 75.0000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.4668	Acc@1 50.0000	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0818	Acc@1 56.2500	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0208	Acc@1 51.5625	Acc@5 75.0000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.5561	Acc@1 53.1250	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.1119	Acc@1 57.8125	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.5369	Acc@1 59.3750	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7727	Acc@1 60.9375	Acc@5 82.8125
 * prec@1 40.220 prec@5 72.760
 * prec@1 46.720 prec@5 78.120
 * prec@1 49.760 prec@5 80.420
 * prec@1 49.440 prec@5 80.780
Current best validation last_bloc_accuracy 50.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_017.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_017.pth.tar'
Epoch: [18][1/704]	Time 0.327	Data 0.161	Loss 6.44	Acc@1 59.4	Acc@5 87.5
Epoch: [18][11/704]	Time 0.140	Data 0.015	Loss 5.71	Acc@1 62.5	Acc@5 93.8
Epoch: [18][21/704]	Time 0.130	Data 0.008	Loss 6.91	Acc@1 53.1	Acc@5 84.4
Epoch: [18][31/704]	Time 0.127	Data 0.005	Loss 5.93	Acc@1 67.2	Acc@5 87.5
Epoch: [18][41/704]	Time 0.125	Data 0.004	Loss 6.70	Acc@1 54.7	Acc@5 85.9
Epoch: [18][51/704]	Time 0.124	Data 0.003	Loss 5.80	Acc@1 56.2	Acc@5 89.1
Epoch: [18][61/704]	Time 0.123	Data 0.003	Loss 7.55	Acc@1 46.9	Acc@5 82.8
Epoch: [18][71/704]	Time 0.123	Data 0.003	Loss 7.26	Acc@1 54.7	Acc@5 82.8
Epoch: [18][81/704]	Time 0.122	Data 0.002	Loss 6.98	Acc@1 56.2	Acc@5 82.8
Epoch: [18][91/704]	Time 0.122	Data 0.002	Loss 6.64	Acc@1 57.8	Acc@5 84.4
Epoch: [18][101/704]	Time 0.122	Data 0.002	Loss 5.67	Acc@1 67.2	Acc@5 89.1
Epoch: [18][111/704]	Time 0.122	Data 0.002	Loss 7.92	Acc@1 51.6	Acc@5 79.7
Epoch: [18][121/704]	Time 0.121	Data 0.002	Loss 6.11	Acc@1 60.9	Acc@5 85.9
Epoch: [18][131/704]	Time 0.121	Data 0.002	Loss 6.73	Acc@1 59.4	Acc@5 87.5
Epoch: [18][141/704]	Time 0.121	Data 0.001	Loss 6.69	Acc@1 62.5	Acc@5 81.2
Epoch: [18][151/704]	Time 0.121	Data 0.001	Loss 8.86	Acc@1 42.2	Acc@5 79.7
Epoch: [18][161/704]	Time 0.121	Data 0.001	Loss 6.98	Acc@1 53.1	Acc@5 78.1
Epoch: [18][171/704]	Time 0.121	Data 0.001	Loss 6.67	Acc@1 56.2	Acc@5 82.8
Epoch: [18][181/704]	Time 0.121	Data 0.001	Loss 7.99	Acc@1 43.8	Acc@5 76.6
Epoch: [18][191/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 89.1
Epoch: [18][201/704]	Time 0.121	Data 0.001	Loss 6.35	Acc@1 57.8	Acc@5 82.8
Epoch: [18][211/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 57.8	Acc@5 90.6
Epoch: [18][221/704]	Time 0.120	Data 0.001	Loss 7.08	Acc@1 54.7	Acc@5 84.4
Epoch: [18][231/704]	Time 0.120	Data 0.001	Loss 7.24	Acc@1 57.8	Acc@5 84.4
Epoch: [18][241/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 57.8	Acc@5 89.1
Epoch: [18][251/704]	Time 0.120	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 92.2
Epoch: [18][261/704]	Time 0.120	Data 0.001	Loss 7.50	Acc@1 56.2	Acc@5 87.5
Epoch: [18][271/704]	Time 0.120	Data 0.001	Loss 6.58	Acc@1 59.4	Acc@5 92.2
Epoch: [18][281/704]	Time 0.120	Data 0.001	Loss 7.38	Acc@1 57.8	Acc@5 84.4
Epoch: [18][291/704]	Time 0.120	Data 0.001	Loss 6.99	Acc@1 57.8	Acc@5 85.9
Epoch: [18][301/704]	Time 0.120	Data 0.001	Loss 6.53	Acc@1 60.9	Acc@5 85.9
Epoch: [18][311/704]	Time 0.120	Data 0.001	Loss 6.03	Acc@1 59.4	Acc@5 93.8
Epoch: [18][321/704]	Time 0.120	Data 0.001	Loss 6.46	Acc@1 60.9	Acc@5 84.4
Epoch: [18][331/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 70.3	Acc@5 92.2
Epoch: [18][341/704]	Time 0.120	Data 0.001	Loss 7.64	Acc@1 51.6	Acc@5 82.8
Epoch: [18][351/704]	Time 0.120	Data 0.001	Loss 6.84	Acc@1 56.2	Acc@5 89.1
Epoch: [18][361/704]	Time 0.120	Data 0.001	Loss 6.93	Acc@1 57.8	Acc@5 87.5
Epoch: [18][371/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 57.8	Acc@5 95.3
Epoch: [18][381/704]	Time 0.120	Data 0.001	Loss 8.39	Acc@1 43.8	Acc@5 73.4
Epoch: [18][391/704]	Time 0.120	Data 0.001	Loss 6.28	Acc@1 59.4	Acc@5 89.1
Epoch: [18][401/704]	Time 0.120	Data 0.001	Loss 7.61	Acc@1 56.2	Acc@5 81.2
Epoch: [18][411/704]	Time 0.120	Data 0.001	Loss 7.09	Acc@1 43.8	Acc@5 85.9
Epoch: [18][421/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 60.9	Acc@5 84.4
Epoch: [18][431/704]	Time 0.120	Data 0.001	Loss 7.41	Acc@1 43.8	Acc@5 85.9
Epoch: [18][441/704]	Time 0.120	Data 0.001	Loss 6.59	Acc@1 64.1	Acc@5 84.4
Epoch: [18][451/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 67.2	Acc@5 90.6
Epoch: [18][461/704]	Time 0.120	Data 0.001	Loss 6.17	Acc@1 56.2	Acc@5 90.6
Epoch: [18][471/704]	Time 0.120	Data 0.001	Loss 7.35	Acc@1 54.7	Acc@5 89.1
Epoch: [18][481/704]	Time 0.120	Data 0.001	Loss 6.00	Acc@1 64.1	Acc@5 84.4
Epoch: [18][491/704]	Time 0.120	Data 0.001	Loss 7.26	Acc@1 46.9	Acc@5 84.4
Epoch: [18][501/704]	Time 0.120	Data 0.001	Loss 6.57	Acc@1 50.0	Acc@5 84.4
Epoch: [18][511/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 53.1	Acc@5 84.4
Epoch: [18][521/704]	Time 0.120	Data 0.001	Loss 8.13	Acc@1 43.8	Acc@5 79.7
Epoch: [18][531/704]	Time 0.120	Data 0.001	Loss 7.37	Acc@1 51.6	Acc@5 82.8
Epoch: [18][541/704]	Time 0.120	Data 0.001	Loss 7.37	Acc@1 53.1	Acc@5 82.8
Epoch: [18][551/704]	Time 0.120	Data 0.001	Loss 7.59	Acc@1 53.1	Acc@5 84.4
Epoch: [18][561/704]	Time 0.120	Data 0.001	Loss 8.79	Acc@1 45.3	Acc@5 82.8
Epoch: [18][571/704]	Time 0.120	Data 0.001	Loss 6.80	Acc@1 53.1	Acc@5 84.4
Epoch: [18][581/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 59.4	Acc@5 93.8
Epoch: [18][591/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 53.1	Acc@5 90.6
Epoch: [18][601/704]	Time 0.120	Data 0.001	Loss 6.09	Acc@1 59.4	Acc@5 90.6
Epoch: [18][611/704]	Time 0.120	Data 0.001	Loss 7.97	Acc@1 48.4	Acc@5 78.1
Epoch: [18][621/704]	Time 0.120	Data 0.001	Loss 7.24	Acc@1 56.2	Acc@5 81.2
Epoch: [18][631/704]	Time 0.120	Data 0.001	Loss 7.61	Acc@1 53.1	Acc@5 82.8
Epoch: [18][641/704]	Time 0.120	Data 0.001	Loss 6.77	Acc@1 56.2	Acc@5 84.4
Epoch: [18][651/704]	Time 0.120	Data 0.001	Loss 7.06	Acc@1 54.7	Acc@5 84.4
Epoch: [18][661/704]	Time 0.120	Data 0.001	Loss 6.98	Acc@1 53.1	Acc@5 84.4
Epoch: [18][671/704]	Time 0.120	Data 0.001	Loss 6.23	Acc@1 56.2	Acc@5 85.9
Epoch: [18][681/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 65.6	Acc@5 87.5
Epoch: [18][691/704]	Time 0.120	Data 0.001	Loss 6.12	Acc@1 57.8	Acc@5 90.6
Epoch: [18][701/704]	Time 0.120	Data 0.001	Loss 6.55	Acc@1 57.8	Acc@5 87.5
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.6996	Acc@1 64.0625	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.3542	Acc@1 48.4375	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.9318	Acc@1 37.5000	Acc@5 78.1250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.6743	Acc@1 37.5000	Acc@5 79.6875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9866	Acc@1 56.2500	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.0242	Acc@1 57.8125	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.8010	Acc@1 40.6250	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 9.1808	Acc@1 46.8750	Acc@5 75.0000
 * prec@1 41.540 prec@5 73.120
 * prec@1 45.240 prec@5 77.100
 * prec@1 47.880 prec@5 79.300
 * prec@1 49.600 prec@5 81.160
Current best validation last_bloc_accuracy 50.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_018.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_018.pth.tar'
Epoch: [19][1/704]	Time 0.326	Data 0.161	Loss 6.51	Acc@1 54.7	Acc@5 89.1
Epoch: [19][11/704]	Time 0.138	Data 0.015	Loss 7.69	Acc@1 45.3	Acc@5 84.4
Epoch: [19][21/704]	Time 0.129	Data 0.008	Loss 7.17	Acc@1 54.7	Acc@5 89.1
Epoch: [19][31/704]	Time 0.126	Data 0.006	Loss 7.56	Acc@1 53.1	Acc@5 90.6
Epoch: [19][41/704]	Time 0.124	Data 0.004	Loss 6.06	Acc@1 62.5	Acc@5 92.2
Epoch: [19][51/704]	Time 0.123	Data 0.004	Loss 6.39	Acc@1 57.8	Acc@5 84.4
Epoch: [19][61/704]	Time 0.123	Data 0.003	Loss 8.42	Acc@1 45.3	Acc@5 82.8
Epoch: [19][71/704]	Time 0.122	Data 0.003	Loss 7.69	Acc@1 48.4	Acc@5 79.7
Epoch: [19][81/704]	Time 0.122	Data 0.002	Loss 6.12	Acc@1 60.9	Acc@5 90.6
Epoch: [19][91/704]	Time 0.121	Data 0.002	Loss 6.24	Acc@1 53.1	Acc@5 89.1
Epoch: [19][101/704]	Time 0.121	Data 0.002	Loss 5.79	Acc@1 67.2	Acc@5 90.6
Epoch: [19][111/704]	Time 0.121	Data 0.002	Loss 7.45	Acc@1 51.6	Acc@5 79.7
Epoch: [19][121/704]	Time 0.121	Data 0.002	Loss 5.08	Acc@1 68.8	Acc@5 96.9
Epoch: [19][131/704]	Time 0.121	Data 0.002	Loss 8.55	Acc@1 43.8	Acc@5 79.7
Epoch: [19][141/704]	Time 0.121	Data 0.002	Loss 7.42	Acc@1 60.9	Acc@5 84.4
Epoch: [19][151/704]	Time 0.120	Data 0.001	Loss 7.39	Acc@1 59.4	Acc@5 79.7
Epoch: [19][161/704]	Time 0.120	Data 0.001	Loss 6.78	Acc@1 64.1	Acc@5 84.4
Epoch: [19][171/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 57.8	Acc@5 85.9
Epoch: [19][181/704]	Time 0.120	Data 0.001	Loss 7.88	Acc@1 53.1	Acc@5 82.8
Epoch: [19][191/704]	Time 0.120	Data 0.001	Loss 5.89	Acc@1 60.9	Acc@5 87.5
Epoch: [19][201/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 67.2	Acc@5 89.1
Epoch: [19][211/704]	Time 0.120	Data 0.001	Loss 6.61	Acc@1 64.1	Acc@5 93.8
Epoch: [19][221/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 65.6	Acc@5 89.1
Epoch: [19][231/704]	Time 0.120	Data 0.001	Loss 6.85	Acc@1 64.1	Acc@5 81.2
Epoch: [19][241/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 67.2	Acc@5 95.3
Epoch: [19][251/704]	Time 0.120	Data 0.001	Loss 7.49	Acc@1 54.7	Acc@5 89.1
Epoch: [19][261/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 60.9	Acc@5 90.6
Epoch: [19][271/704]	Time 0.120	Data 0.001	Loss 5.73	Acc@1 57.8	Acc@5 93.8
Epoch: [19][281/704]	Time 0.120	Data 0.001	Loss 8.20	Acc@1 51.6	Acc@5 78.1
Epoch: [19][291/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 73.4	Acc@5 93.8
Epoch: [19][301/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 56.2	Acc@5 87.5
Epoch: [19][311/704]	Time 0.120	Data 0.001	Loss 6.11	Acc@1 64.1	Acc@5 85.9
Epoch: [19][321/704]	Time 0.120	Data 0.001	Loss 6.88	Acc@1 59.4	Acc@5 82.8
Epoch: [19][331/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 53.1	Acc@5 85.9
Epoch: [19][341/704]	Time 0.120	Data 0.001	Loss 7.16	Acc@1 51.6	Acc@5 79.7
Epoch: [19][351/704]	Time 0.120	Data 0.001	Loss 7.04	Acc@1 57.8	Acc@5 84.4
Epoch: [19][361/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 62.5	Acc@5 82.8
Epoch: [19][371/704]	Time 0.120	Data 0.001	Loss 6.86	Acc@1 68.8	Acc@5 82.8
Epoch: [19][381/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 62.5	Acc@5 87.5
Epoch: [19][391/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 54.7	Acc@5 92.2
Epoch: [19][401/704]	Time 0.120	Data 0.001	Loss 6.37	Acc@1 62.5	Acc@5 82.8
Epoch: [19][411/704]	Time 0.120	Data 0.001	Loss 7.68	Acc@1 50.0	Acc@5 84.4
Epoch: [19][421/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 59.4	Acc@5 84.4
Epoch: [19][431/704]	Time 0.120	Data 0.001	Loss 7.21	Acc@1 53.1	Acc@5 85.9
Epoch: [19][441/704]	Time 0.120	Data 0.001	Loss 6.86	Acc@1 54.7	Acc@5 79.7
Epoch: [19][451/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 68.8	Acc@5 92.2
Epoch: [19][461/704]	Time 0.120	Data 0.001	Loss 6.69	Acc@1 53.1	Acc@5 85.9
Epoch: [19][471/704]	Time 0.120	Data 0.001	Loss 5.63	Acc@1 67.2	Acc@5 92.2
Epoch: [19][481/704]	Time 0.120	Data 0.001	Loss 7.42	Acc@1 60.9	Acc@5 79.7
Epoch: [19][491/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 60.9	Acc@5 92.2
Epoch: [19][501/704]	Time 0.120	Data 0.001	Loss 7.00	Acc@1 60.9	Acc@5 87.5
Epoch: [19][511/704]	Time 0.120	Data 0.001	Loss 6.77	Acc@1 60.9	Acc@5 92.2
Epoch: [19][521/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 70.3	Acc@5 93.8
Epoch: [19][531/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 57.8	Acc@5 82.8
Epoch: [19][541/704]	Time 0.120	Data 0.001	Loss 7.84	Acc@1 56.2	Acc@5 82.8
Epoch: [19][551/704]	Time 0.120	Data 0.001	Loss 7.49	Acc@1 56.2	Acc@5 84.4
Epoch: [19][561/704]	Time 0.120	Data 0.001	Loss 6.82	Acc@1 62.5	Acc@5 82.8
Epoch: [19][571/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 57.8	Acc@5 90.6
Epoch: [19][581/704]	Time 0.120	Data 0.001	Loss 7.77	Acc@1 50.0	Acc@5 81.2
Epoch: [19][591/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 57.8	Acc@5 81.2
Epoch: [19][601/704]	Time 0.120	Data 0.001	Loss 6.97	Acc@1 60.9	Acc@5 84.4
Epoch: [19][611/704]	Time 0.120	Data 0.001	Loss 6.91	Acc@1 57.8	Acc@5 87.5
Epoch: [19][621/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 57.8	Acc@5 84.4
Epoch: [19][631/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 65.6	Acc@5 85.9
Epoch: [19][641/704]	Time 0.120	Data 0.001	Loss 6.41	Acc@1 60.9	Acc@5 84.4
Epoch: [19][651/704]	Time 0.120	Data 0.001	Loss 7.36	Acc@1 56.2	Acc@5 81.2
Epoch: [19][661/704]	Time 0.120	Data 0.001	Loss 7.46	Acc@1 53.1	Acc@5 81.2
Epoch: [19][671/704]	Time 0.120	Data 0.001	Loss 7.00	Acc@1 46.9	Acc@5 92.2
Epoch: [19][681/704]	Time 0.120	Data 0.001	Loss 6.83	Acc@1 51.6	Acc@5 85.9
Epoch: [19][691/704]	Time 0.120	Data 0.001	Loss 7.84	Acc@1 51.6	Acc@5 79.7
Epoch: [19][701/704]	Time 0.119	Data 0.001	Loss 6.37	Acc@1 59.4	Acc@5 85.9
Epoch: [1/79]	Time 0.127	Data 0.113	Loss 7.9633	Acc@1 45.3125	Acc@5 78.1250
Epoch: [11/79]	Time 0.027	Data 0.014	Loss 8.7220	Acc@1 54.6875	Acc@5 79.6875
Epoch: [21/79]	Time 0.022	Data 0.009	Loss 8.1963	Acc@1 50.0000	Acc@5 79.6875
Epoch: [31/79]	Time 0.020	Data 0.008	Loss 8.3493	Acc@1 51.5625	Acc@5 78.1250
Epoch: [41/79]	Time 0.019	Data 0.007	Loss 7.0565	Acc@1 56.2500	Acc@5 87.5000
Epoch: [51/79]	Time 0.019	Data 0.006	Loss 8.0160	Acc@1 43.7500	Acc@5 78.1250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.7538	Acc@1 54.6875	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 7.1912	Acc@1 59.3750	Acc@5 85.9375
 * prec@1 40.880 prec@5 72.920
 * prec@1 46.660 prec@5 78.640
 * prec@1 49.220 prec@5 80.180
 * prec@1 50.040 prec@5 81.300
Current best validation last_bloc_accuracy 50.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_019.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_019.pth.tar'
Epoch: [20][1/704]	Time 0.295	Data 0.129	Loss 5.43	Acc@1 65.6	Acc@5 92.2
Epoch: [20][11/704]	Time 0.135	Data 0.012	Loss 5.86	Acc@1 64.1	Acc@5 93.8
Epoch: [20][21/704]	Time 0.127	Data 0.006	Loss 6.97	Acc@1 51.6	Acc@5 82.8
Epoch: [20][31/704]	Time 0.125	Data 0.004	Loss 6.64	Acc@1 59.4	Acc@5 89.1
Epoch: [20][41/704]	Time 0.123	Data 0.003	Loss 6.60	Acc@1 57.8	Acc@5 81.2
Epoch: [20][51/704]	Time 0.122	Data 0.003	Loss 6.94	Acc@1 57.8	Acc@5 85.9
Epoch: [20][61/704]	Time 0.122	Data 0.002	Loss 7.24	Acc@1 46.9	Acc@5 81.2
Epoch: [20][71/704]	Time 0.121	Data 0.002	Loss 5.44	Acc@1 64.1	Acc@5 90.6
Epoch: [20][81/704]	Time 0.121	Data 0.002	Loss 6.63	Acc@1 65.6	Acc@5 90.6
Epoch: [20][91/704]	Time 0.121	Data 0.002	Loss 7.29	Acc@1 59.4	Acc@5 81.2
Epoch: [20][101/704]	Time 0.121	Data 0.002	Loss 6.80	Acc@1 62.5	Acc@5 85.9
Epoch: [20][111/704]	Time 0.121	Data 0.001	Loss 6.70	Acc@1 56.2	Acc@5 84.4
Epoch: [20][121/704]	Time 0.121	Data 0.001	Loss 7.24	Acc@1 60.9	Acc@5 85.9
Epoch: [20][131/704]	Time 0.121	Data 0.001	Loss 6.56	Acc@1 65.6	Acc@5 87.5
Epoch: [20][141/704]	Time 0.121	Data 0.001	Loss 7.98	Acc@1 45.3	Acc@5 81.2
Epoch: [20][151/704]	Time 0.121	Data 0.001	Loss 7.38	Acc@1 60.9	Acc@5 90.6
Epoch: [20][161/704]	Time 0.120	Data 0.001	Loss 7.76	Acc@1 48.4	Acc@5 81.2
Epoch: [20][171/704]	Time 0.120	Data 0.001	Loss 7.15	Acc@1 56.2	Acc@5 85.9
Epoch: [20][181/704]	Time 0.120	Data 0.001	Loss 5.91	Acc@1 56.2	Acc@5 89.1
Epoch: [20][191/704]	Time 0.120	Data 0.001	Loss 6.61	Acc@1 62.5	Acc@5 87.5
Epoch: [20][201/704]	Time 0.120	Data 0.001	Loss 6.72	Acc@1 48.4	Acc@5 87.5
Epoch: [20][211/704]	Time 0.120	Data 0.001	Loss 7.23	Acc@1 53.1	Acc@5 84.4
Epoch: [20][221/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 62.5	Acc@5 90.6
Epoch: [20][231/704]	Time 0.120	Data 0.001	Loss 6.19	Acc@1 64.1	Acc@5 87.5
Epoch: [20][241/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 64.1	Acc@5 87.5
Epoch: [20][251/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 56.2	Acc@5 85.9
Epoch: [20][261/704]	Time 0.120	Data 0.001	Loss 5.91	Acc@1 70.3	Acc@5 92.2
Epoch: [20][271/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 51.6	Acc@5 84.4
Epoch: [20][281/704]	Time 0.120	Data 0.001	Loss 6.84	Acc@1 60.9	Acc@5 90.6
Epoch: [20][291/704]	Time 0.120	Data 0.001	Loss 6.41	Acc@1 51.6	Acc@5 87.5
Epoch: [20][301/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 59.4	Acc@5 92.2
Epoch: [20][311/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 70.3	Acc@5 90.6
Epoch: [20][321/704]	Time 0.120	Data 0.001	Loss 5.89	Acc@1 68.8	Acc@5 90.6
Epoch: [20][331/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 57.8	Acc@5 84.4
Epoch: [20][341/704]	Time 0.120	Data 0.001	Loss 6.74	Acc@1 68.8	Acc@5 87.5
Epoch: [20][351/704]	Time 0.120	Data 0.001	Loss 7.65	Acc@1 46.9	Acc@5 78.1
Epoch: [20][361/704]	Time 0.120	Data 0.001	Loss 6.77	Acc@1 60.9	Acc@5 85.9
Epoch: [20][371/704]	Time 0.120	Data 0.001	Loss 6.98	Acc@1 60.9	Acc@5 82.8
Epoch: [20][381/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 64.1	Acc@5 89.1
Epoch: [20][391/704]	Time 0.120	Data 0.001	Loss 7.17	Acc@1 53.1	Acc@5 82.8
Epoch: [20][401/704]	Time 0.120	Data 0.001	Loss 6.81	Acc@1 59.4	Acc@5 82.8
Epoch: [20][411/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 65.6	Acc@5 90.6
Epoch: [20][421/704]	Time 0.120	Data 0.001	Loss 6.76	Acc@1 62.5	Acc@5 85.9
Epoch: [20][431/704]	Time 0.120	Data 0.001	Loss 8.65	Acc@1 46.9	Acc@5 78.1
Epoch: [20][441/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 60.9	Acc@5 89.1
Epoch: [20][451/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 93.8
Epoch: [20][461/704]	Time 0.120	Data 0.001	Loss 6.59	Acc@1 56.2	Acc@5 90.6
Epoch: [20][471/704]	Time 0.120	Data 0.001	Loss 8.61	Acc@1 42.2	Acc@5 78.1
Epoch: [20][481/704]	Time 0.120	Data 0.001	Loss 7.57	Acc@1 50.0	Acc@5 84.4
Epoch: [20][491/704]	Time 0.120	Data 0.001	Loss 5.10	Acc@1 67.2	Acc@5 92.2
Epoch: [20][501/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 64.1	Acc@5 93.8
Epoch: [20][511/704]	Time 0.120	Data 0.001	Loss 5.05	Acc@1 65.6	Acc@5 92.2
Epoch: [20][521/704]	Time 0.120	Data 0.001	Loss 6.64	Acc@1 51.6	Acc@5 84.4
Epoch: [20][531/704]	Time 0.120	Data 0.001	Loss 6.51	Acc@1 62.5	Acc@5 89.1
Epoch: [20][541/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 67.2	Acc@5 84.4
Epoch: [20][551/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 51.6	Acc@5 84.4
Epoch: [20][561/704]	Time 0.120	Data 0.001	Loss 4.82	Acc@1 65.6	Acc@5 96.9
Epoch: [20][571/704]	Time 0.119	Data 0.001	Loss 5.14	Acc@1 65.6	Acc@5 93.8
Epoch: [20][581/704]	Time 0.119	Data 0.001	Loss 6.41	Acc@1 57.8	Acc@5 92.2
Epoch: [20][591/704]	Time 0.119	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 85.9
Epoch: [20][601/704]	Time 0.119	Data 0.001	Loss 7.41	Acc@1 53.1	Acc@5 81.2
Epoch: [20][611/704]	Time 0.119	Data 0.001	Loss 7.83	Acc@1 56.2	Acc@5 84.4
Epoch: [20][621/704]	Time 0.119	Data 0.001	Loss 6.72	Acc@1 60.9	Acc@5 87.5
Epoch: [20][631/704]	Time 0.120	Data 0.001	Loss 7.19	Acc@1 51.6	Acc@5 81.2
Epoch: [20][641/704]	Time 0.120	Data 0.001	Loss 6.99	Acc@1 51.6	Acc@5 87.5
Epoch: [20][651/704]	Time 0.120	Data 0.001	Loss 8.42	Acc@1 48.4	Acc@5 78.1
Epoch: [20][661/704]	Time 0.119	Data 0.001	Loss 7.90	Acc@1 57.8	Acc@5 82.8
Epoch: [20][671/704]	Time 0.119	Data 0.001	Loss 6.27	Acc@1 59.4	Acc@5 90.6
Epoch: [20][681/704]	Time 0.119	Data 0.001	Loss 6.96	Acc@1 56.2	Acc@5 84.4
Epoch: [20][691/704]	Time 0.119	Data 0.001	Loss 6.36	Acc@1 59.4	Acc@5 90.6
Epoch: [20][701/704]	Time 0.119	Data 0.001	Loss 6.22	Acc@1 64.1	Acc@5 89.1
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 8.9637	Acc@1 42.1875	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.3976	Acc@1 42.1875	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.5650	Acc@1 43.7500	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.2888	Acc@1 43.7500	Acc@5 76.5625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.2670	Acc@1 54.6875	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.0961	Acc@1 48.4375	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.8056	Acc@1 62.5000	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.2078	Acc@1 48.4375	Acc@5 75.0000
 * prec@1 40.960 prec@5 73.100
 * prec@1 46.460 prec@5 77.340
 * prec@1 50.760 prec@5 80.980
 * prec@1 50.960 prec@5 81.780
New best validation last_bloc_accuracy 50.96
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_020.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_020.pth.tar'
Epoch: [21][1/704]	Time 0.297	Data 0.131	Loss 6.62	Acc@1 60.9	Acc@5 84.4
Epoch: [21][11/704]	Time 0.135	Data 0.012	Loss 6.27	Acc@1 53.1	Acc@5 92.2
Epoch: [21][21/704]	Time 0.128	Data 0.007	Loss 7.44	Acc@1 56.2	Acc@5 82.8
Epoch: [21][31/704]	Time 0.125	Data 0.004	Loss 6.92	Acc@1 57.8	Acc@5 89.1
Epoch: [21][41/704]	Time 0.124	Data 0.003	Loss 6.68	Acc@1 62.5	Acc@5 87.5
Epoch: [21][51/704]	Time 0.123	Data 0.003	Loss 7.10	Acc@1 59.4	Acc@5 84.4
Epoch: [21][61/704]	Time 0.123	Data 0.002	Loss 5.95	Acc@1 62.5	Acc@5 87.5
Epoch: [21][71/704]	Time 0.122	Data 0.002	Loss 7.53	Acc@1 53.1	Acc@5 87.5
Epoch: [21][81/704]	Time 0.122	Data 0.002	Loss 5.98	Acc@1 60.9	Acc@5 90.6
Epoch: [21][91/704]	Time 0.121	Data 0.002	Loss 5.55	Acc@1 59.4	Acc@5 90.6
Epoch: [21][101/704]	Time 0.121	Data 0.002	Loss 5.68	Acc@1 62.5	Acc@5 89.1
Epoch: [21][111/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 59.4	Acc@5 87.5
Epoch: [21][121/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 59.4	Acc@5 92.2
Epoch: [21][131/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 60.9	Acc@5 89.1
Epoch: [21][141/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 57.8	Acc@5 84.4
Epoch: [21][151/704]	Time 0.121	Data 0.001	Loss 6.24	Acc@1 56.2	Acc@5 89.1
Epoch: [21][161/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 64.1	Acc@5 89.1
Epoch: [21][171/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 51.6	Acc@5 84.4
Epoch: [21][181/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 62.5	Acc@5 85.9
Epoch: [21][191/704]	Time 0.120	Data 0.001	Loss 6.64	Acc@1 59.4	Acc@5 87.5
Epoch: [21][201/704]	Time 0.120	Data 0.001	Loss 7.55	Acc@1 57.8	Acc@5 78.1
Epoch: [21][211/704]	Time 0.120	Data 0.001	Loss 6.32	Acc@1 57.8	Acc@5 93.8
Epoch: [21][221/704]	Time 0.120	Data 0.001	Loss 6.33	Acc@1 67.2	Acc@5 85.9
Epoch: [21][231/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 59.4	Acc@5 84.4
Epoch: [21][241/704]	Time 0.120	Data 0.001	Loss 6.16	Acc@1 57.8	Acc@5 85.9
Epoch: [21][251/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 60.9	Acc@5 90.6
Epoch: [21][261/704]	Time 0.120	Data 0.001	Loss 6.69	Acc@1 54.7	Acc@5 84.4
Epoch: [21][271/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 70.3	Acc@5 89.1
Epoch: [21][281/704]	Time 0.120	Data 0.001	Loss 6.98	Acc@1 56.2	Acc@5 90.6
Epoch: [21][291/704]	Time 0.120	Data 0.001	Loss 6.82	Acc@1 60.9	Acc@5 84.4
Epoch: [21][301/704]	Time 0.120	Data 0.001	Loss 6.67	Acc@1 67.2	Acc@5 87.5
Epoch: [21][311/704]	Time 0.120	Data 0.001	Loss 6.18	Acc@1 59.4	Acc@5 92.2
Epoch: [21][321/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 64.1	Acc@5 89.1
Epoch: [21][331/704]	Time 0.120	Data 0.001	Loss 5.70	Acc@1 60.9	Acc@5 90.6
Epoch: [21][341/704]	Time 0.120	Data 0.001	Loss 7.89	Acc@1 48.4	Acc@5 78.1
Epoch: [21][351/704]	Time 0.120	Data 0.001	Loss 6.76	Acc@1 57.8	Acc@5 87.5
Epoch: [21][361/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 70.3	Acc@5 84.4
Epoch: [21][371/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 68.8	Acc@5 89.1
Epoch: [21][381/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 62.5	Acc@5 93.8
Epoch: [21][391/704]	Time 0.120	Data 0.001	Loss 6.19	Acc@1 54.7	Acc@5 89.1
Epoch: [21][401/704]	Time 0.120	Data 0.001	Loss 7.35	Acc@1 53.1	Acc@5 85.9
Epoch: [21][411/704]	Time 0.120	Data 0.001	Loss 7.24	Acc@1 46.9	Acc@5 87.5
Epoch: [21][421/704]	Time 0.120	Data 0.001	Loss 4.87	Acc@1 68.8	Acc@5 90.6
Epoch: [21][431/704]	Time 0.120	Data 0.001	Loss 6.03	Acc@1 62.5	Acc@5 93.8
Epoch: [21][441/704]	Time 0.120	Data 0.001	Loss 6.85	Acc@1 60.9	Acc@5 82.8
Epoch: [21][451/704]	Time 0.120	Data 0.001	Loss 8.03	Acc@1 57.8	Acc@5 85.9
Epoch: [21][461/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 59.4	Acc@5 90.6
Epoch: [21][471/704]	Time 0.120	Data 0.001	Loss 6.61	Acc@1 56.2	Acc@5 87.5
Epoch: [21][481/704]	Time 0.120	Data 0.001	Loss 7.04	Acc@1 53.1	Acc@5 87.5
Epoch: [21][491/704]	Time 0.120	Data 0.001	Loss 7.42	Acc@1 54.7	Acc@5 82.8
Epoch: [21][501/704]	Time 0.120	Data 0.001	Loss 6.89	Acc@1 62.5	Acc@5 82.8
Epoch: [21][511/704]	Time 0.120	Data 0.001	Loss 6.53	Acc@1 59.4	Acc@5 84.4
Epoch: [21][521/704]	Time 0.120	Data 0.001	Loss 7.11	Acc@1 57.8	Acc@5 78.1
Epoch: [21][531/704]	Time 0.119	Data 0.001	Loss 7.43	Acc@1 60.9	Acc@5 79.7
Epoch: [21][541/704]	Time 0.119	Data 0.001	Loss 6.55	Acc@1 56.2	Acc@5 92.2
Epoch: [21][551/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 56.2	Acc@5 84.4
Epoch: [21][561/704]	Time 0.120	Data 0.001	Loss 6.76	Acc@1 59.4	Acc@5 89.1
Epoch: [21][571/704]	Time 0.120	Data 0.001	Loss 6.91	Acc@1 60.9	Acc@5 85.9
Epoch: [21][581/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 70.3	Acc@5 89.1
Epoch: [21][591/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 95.3
Epoch: [21][601/704]	Time 0.119	Data 0.001	Loss 5.98	Acc@1 62.5	Acc@5 82.8
Epoch: [21][611/704]	Time 0.119	Data 0.001	Loss 6.12	Acc@1 65.6	Acc@5 85.9
Epoch: [21][621/704]	Time 0.119	Data 0.001	Loss 6.94	Acc@1 59.4	Acc@5 82.8
Epoch: [21][631/704]	Time 0.119	Data 0.001	Loss 6.18	Acc@1 57.8	Acc@5 90.6
Epoch: [21][641/704]	Time 0.119	Data 0.001	Loss 7.16	Acc@1 43.8	Acc@5 90.6
Epoch: [21][651/704]	Time 0.119	Data 0.001	Loss 6.47	Acc@1 57.8	Acc@5 85.9
Epoch: [21][661/704]	Time 0.119	Data 0.001	Loss 7.20	Acc@1 57.8	Acc@5 84.4
Epoch: [21][671/704]	Time 0.119	Data 0.001	Loss 6.76	Acc@1 59.4	Acc@5 85.9
Epoch: [21][681/704]	Time 0.119	Data 0.001	Loss 7.28	Acc@1 43.8	Acc@5 82.8
Epoch: [21][691/704]	Time 0.119	Data 0.001	Loss 6.11	Acc@1 51.6	Acc@5 92.2
Epoch: [21][701/704]	Time 0.119	Data 0.001	Loss 5.71	Acc@1 65.6	Acc@5 90.6
Epoch: [1/79]	Time 0.099	Data 0.084	Loss 8.1696	Acc@1 42.1875	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0348	Acc@1 51.5625	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.8690	Acc@1 46.8750	Acc@5 76.5625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.7677	Acc@1 48.4375	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.0335	Acc@1 57.8125	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.2295	Acc@1 48.4375	Acc@5 78.1250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 9.4630	Acc@1 50.0000	Acc@5 78.1250
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 8.1134	Acc@1 46.8750	Acc@5 85.9375
 * prec@1 42.300 prec@5 74.200
 * prec@1 46.840 prec@5 78.220
 * prec@1 50.000 prec@5 80.940
 * prec@1 50.500 prec@5 81.560
Current best validation last_bloc_accuracy 50.96
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_021.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_021.pth.tar'
Epoch: [22][1/704]	Time 0.327	Data 0.161	Loss 6.39	Acc@1 56.2	Acc@5 87.5
Epoch: [22][11/704]	Time 0.138	Data 0.015	Loss 6.86	Acc@1 56.2	Acc@5 87.5
Epoch: [22][21/704]	Time 0.129	Data 0.008	Loss 7.11	Acc@1 59.4	Acc@5 81.2
Epoch: [22][31/704]	Time 0.126	Data 0.005	Loss 5.84	Acc@1 53.1	Acc@5 93.8
Epoch: [22][41/704]	Time 0.124	Data 0.004	Loss 6.41	Acc@1 60.9	Acc@5 93.8
Epoch: [22][51/704]	Time 0.123	Data 0.003	Loss 6.90	Acc@1 59.4	Acc@5 87.5
Epoch: [22][61/704]	Time 0.123	Data 0.003	Loss 6.05	Acc@1 59.4	Acc@5 92.2
Epoch: [22][71/704]	Time 0.122	Data 0.003	Loss 5.60	Acc@1 62.5	Acc@5 90.6
Epoch: [22][81/704]	Time 0.122	Data 0.002	Loss 5.81	Acc@1 68.8	Acc@5 90.6
Epoch: [22][91/704]	Time 0.122	Data 0.002	Loss 5.43	Acc@1 60.9	Acc@5 93.8
Epoch: [22][101/704]	Time 0.121	Data 0.002	Loss 6.32	Acc@1 60.9	Acc@5 89.1
Epoch: [22][111/704]	Time 0.121	Data 0.002	Loss 7.13	Acc@1 51.6	Acc@5 82.8
Epoch: [22][121/704]	Time 0.121	Data 0.002	Loss 6.21	Acc@1 60.9	Acc@5 87.5
Epoch: [22][131/704]	Time 0.121	Data 0.002	Loss 6.50	Acc@1 65.6	Acc@5 89.1
Epoch: [22][141/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 59.4	Acc@5 92.2
Epoch: [22][151/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 68.8	Acc@5 85.9
Epoch: [22][161/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 67.2	Acc@5 90.6
Epoch: [22][171/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 60.9	Acc@5 89.1
Epoch: [22][181/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 67.2	Acc@5 90.6
Epoch: [22][191/704]	Time 0.121	Data 0.001	Loss 7.87	Acc@1 59.4	Acc@5 85.9
Epoch: [22][201/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 65.6	Acc@5 93.8
Epoch: [22][211/704]	Time 0.121	Data 0.001	Loss 6.58	Acc@1 57.8	Acc@5 89.1
Epoch: [22][221/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 67.2	Acc@5 93.8
Epoch: [22][231/704]	Time 0.121	Data 0.001	Loss 6.66	Acc@1 51.6	Acc@5 84.4
Epoch: [22][241/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 70.3	Acc@5 92.2
Epoch: [22][251/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 65.6	Acc@5 82.8
Epoch: [22][261/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 67.2	Acc@5 92.2
Epoch: [22][271/704]	Time 0.120	Data 0.001	Loss 6.41	Acc@1 65.6	Acc@5 89.1
Epoch: [22][281/704]	Time 0.120	Data 0.001	Loss 6.87	Acc@1 64.1	Acc@5 89.1
Epoch: [22][291/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 59.4	Acc@5 90.6
Epoch: [22][301/704]	Time 0.120	Data 0.001	Loss 7.04	Acc@1 60.9	Acc@5 87.5
Epoch: [22][311/704]	Time 0.120	Data 0.001	Loss 6.85	Acc@1 57.8	Acc@5 82.8
Epoch: [22][321/704]	Time 0.120	Data 0.001	Loss 5.97	Acc@1 67.2	Acc@5 90.6
Epoch: [22][331/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 70.3	Acc@5 92.2
Epoch: [22][341/704]	Time 0.120	Data 0.001	Loss 5.68	Acc@1 64.1	Acc@5 89.1
Epoch: [22][351/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 59.4	Acc@5 89.1
Epoch: [22][361/704]	Time 0.120	Data 0.001	Loss 6.51	Acc@1 54.7	Acc@5 79.7
Epoch: [22][371/704]	Time 0.120	Data 0.001	Loss 6.72	Acc@1 64.1	Acc@5 85.9
Epoch: [22][381/704]	Time 0.120	Data 0.001	Loss 7.27	Acc@1 51.6	Acc@5 90.6
Epoch: [22][391/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 65.6	Acc@5 89.1
Epoch: [22][401/704]	Time 0.120	Data 0.001	Loss 7.41	Acc@1 59.4	Acc@5 87.5
Epoch: [22][411/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 59.4	Acc@5 90.6
Epoch: [22][421/704]	Time 0.120	Data 0.001	Loss 8.36	Acc@1 56.2	Acc@5 82.8
Epoch: [22][431/704]	Time 0.120	Data 0.001	Loss 6.99	Acc@1 53.1	Acc@5 82.8
Epoch: [22][441/704]	Time 0.120	Data 0.001	Loss 6.74	Acc@1 60.9	Acc@5 84.4
Epoch: [22][451/704]	Time 0.120	Data 0.001	Loss 7.70	Acc@1 50.0	Acc@5 81.2
Epoch: [22][461/704]	Time 0.120	Data 0.001	Loss 6.69	Acc@1 56.2	Acc@5 81.2
Epoch: [22][471/704]	Time 0.120	Data 0.001	Loss 6.88	Acc@1 62.5	Acc@5 87.5
Epoch: [22][481/704]	Time 0.120	Data 0.001	Loss 6.63	Acc@1 54.7	Acc@5 85.9
Epoch: [22][491/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 62.5	Acc@5 92.2
Epoch: [22][501/704]	Time 0.120	Data 0.001	Loss 6.82	Acc@1 60.9	Acc@5 82.8
Epoch: [22][511/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 53.1	Acc@5 92.2
Epoch: [22][521/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 68.8	Acc@5 82.8
Epoch: [22][531/704]	Time 0.120	Data 0.001	Loss 6.26	Acc@1 59.4	Acc@5 85.9
Epoch: [22][541/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 54.7	Acc@5 85.9
Epoch: [22][551/704]	Time 0.120	Data 0.001	Loss 7.02	Acc@1 51.6	Acc@5 87.5
Epoch: [22][561/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 68.8	Acc@5 89.1
Epoch: [22][571/704]	Time 0.120	Data 0.001	Loss 6.77	Acc@1 57.8	Acc@5 81.2
Epoch: [22][581/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 53.1	Acc@5 82.8
Epoch: [22][591/704]	Time 0.120	Data 0.001	Loss 7.49	Acc@1 54.7	Acc@5 82.8
Epoch: [22][601/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 56.2	Acc@5 93.8
Epoch: [22][611/704]	Time 0.120	Data 0.001	Loss 6.46	Acc@1 54.7	Acc@5 93.8
Epoch: [22][621/704]	Time 0.120	Data 0.001	Loss 7.08	Acc@1 54.7	Acc@5 82.8
Epoch: [22][631/704]	Time 0.120	Data 0.001	Loss 6.74	Acc@1 57.8	Acc@5 84.4
Epoch: [22][641/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 56.2	Acc@5 92.2
Epoch: [22][651/704]	Time 0.120	Data 0.001	Loss 8.26	Acc@1 48.4	Acc@5 76.6
Epoch: [22][661/704]	Time 0.120	Data 0.001	Loss 7.11	Acc@1 60.9	Acc@5 81.2
Epoch: [22][671/704]	Time 0.120	Data 0.001	Loss 5.57	Acc@1 65.6	Acc@5 90.6
Epoch: [22][681/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 64.1	Acc@5 85.9
Epoch: [22][691/704]	Time 0.120	Data 0.001	Loss 5.48	Acc@1 65.6	Acc@5 89.1
Epoch: [22][701/704]	Time 0.120	Data 0.001	Loss 6.39	Acc@1 59.4	Acc@5 87.5
Epoch: [1/79]	Time 0.128	Data 0.114	Loss 6.0192	Acc@1 57.8125	Acc@5 87.5000
Epoch: [11/79]	Time 0.027	Data 0.014	Loss 7.2028	Acc@1 57.8125	Acc@5 87.5000
Epoch: [21/79]	Time 0.022	Data 0.010	Loss 8.0853	Acc@1 53.1250	Acc@5 79.6875
Epoch: [31/79]	Time 0.020	Data 0.008	Loss 6.2446	Acc@1 54.6875	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.007	Loss 9.3089	Acc@1 43.7500	Acc@5 78.1250
Epoch: [51/79]	Time 0.019	Data 0.007	Loss 8.1046	Acc@1 50.0000	Acc@5 76.5625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4733	Acc@1 57.8125	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 7.3985	Acc@1 57.8125	Acc@5 85.9375
 * prec@1 44.020 prec@5 75.100
 * prec@1 47.720 prec@5 78.800
 * prec@1 51.720 prec@5 81.920
 * prec@1 52.460 prec@5 82.440
New best validation last_bloc_accuracy 52.46
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_022.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_022.pth.tar'
Epoch: [23][1/704]	Time 0.297	Data 0.130	Loss 5.27	Acc@1 65.6	Acc@5 95.3
Epoch: [23][11/704]	Time 0.136	Data 0.012	Loss 7.71	Acc@1 50.0	Acc@5 81.2
Epoch: [23][21/704]	Time 0.128	Data 0.007	Loss 5.39	Acc@1 67.2	Acc@5 85.9
Epoch: [23][31/704]	Time 0.125	Data 0.005	Loss 6.20	Acc@1 64.1	Acc@5 85.9
Epoch: [23][41/704]	Time 0.124	Data 0.003	Loss 6.45	Acc@1 53.1	Acc@5 87.5
Epoch: [23][51/704]	Time 0.123	Data 0.003	Loss 5.15	Acc@1 68.8	Acc@5 90.6
Epoch: [23][61/704]	Time 0.122	Data 0.002	Loss 6.82	Acc@1 56.2	Acc@5 85.9
Epoch: [23][71/704]	Time 0.122	Data 0.002	Loss 4.85	Acc@1 71.9	Acc@5 95.3
Epoch: [23][81/704]	Time 0.121	Data 0.002	Loss 6.34	Acc@1 65.6	Acc@5 90.6
Epoch: [23][91/704]	Time 0.121	Data 0.002	Loss 5.29	Acc@1 70.3	Acc@5 96.9
Epoch: [23][101/704]	Time 0.121	Data 0.002	Loss 7.07	Acc@1 59.4	Acc@5 87.5
Epoch: [23][111/704]	Time 0.121	Data 0.002	Loss 6.17	Acc@1 60.9	Acc@5 87.5
Epoch: [23][121/704]	Time 0.121	Data 0.001	Loss 6.97	Acc@1 48.4	Acc@5 89.1
Epoch: [23][131/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 60.9	Acc@5 90.6
Epoch: [23][141/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 68.8	Acc@5 95.3
Epoch: [23][151/704]	Time 0.121	Data 0.001	Loss 6.60	Acc@1 54.7	Acc@5 90.6
Epoch: [23][161/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 59.4	Acc@5 90.6
Epoch: [23][171/704]	Time 0.121	Data 0.001	Loss 7.47	Acc@1 48.4	Acc@5 87.5
Epoch: [23][181/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 60.9	Acc@5 93.8
Epoch: [23][191/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 62.5	Acc@5 87.5
Epoch: [23][201/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 54.7	Acc@5 90.6
Epoch: [23][211/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 68.8	Acc@5 90.6
Epoch: [23][221/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 51.6	Acc@5 84.4
Epoch: [23][231/704]	Time 0.121	Data 0.001	Loss 8.43	Acc@1 46.9	Acc@5 79.7
Epoch: [23][241/704]	Time 0.121	Data 0.001	Loss 6.90	Acc@1 64.1	Acc@5 89.1
Epoch: [23][251/704]	Time 0.120	Data 0.001	Loss 6.45	Acc@1 54.7	Acc@5 89.1
Epoch: [23][261/704]	Time 0.120	Data 0.001	Loss 5.89	Acc@1 62.5	Acc@5 89.1
Epoch: [23][271/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 54.7	Acc@5 87.5
Epoch: [23][281/704]	Time 0.120	Data 0.001	Loss 7.78	Acc@1 50.0	Acc@5 84.4
Epoch: [23][291/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 53.1	Acc@5 84.4
Epoch: [23][301/704]	Time 0.120	Data 0.001	Loss 5.65	Acc@1 67.2	Acc@5 90.6
Epoch: [23][311/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 59.4	Acc@5 89.1
Epoch: [23][321/704]	Time 0.120	Data 0.001	Loss 7.32	Acc@1 59.4	Acc@5 90.6
Epoch: [23][331/704]	Time 0.120	Data 0.001	Loss 6.33	Acc@1 54.7	Acc@5 93.8
Epoch: [23][341/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 54.7	Acc@5 92.2
Epoch: [23][351/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 56.2	Acc@5 89.1
Epoch: [23][361/704]	Time 0.120	Data 0.001	Loss 4.98	Acc@1 76.6	Acc@5 95.3
Epoch: [23][371/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 60.9	Acc@5 87.5
Epoch: [23][381/704]	Time 0.120	Data 0.001	Loss 7.34	Acc@1 50.0	Acc@5 81.2
Epoch: [23][391/704]	Time 0.120	Data 0.001	Loss 7.02	Acc@1 57.8	Acc@5 85.9
Epoch: [23][401/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 62.5	Acc@5 89.1
Epoch: [23][411/704]	Time 0.120	Data 0.001	Loss 7.02	Acc@1 59.4	Acc@5 90.6
Epoch: [23][421/704]	Time 0.120	Data 0.001	Loss 7.85	Acc@1 54.7	Acc@5 81.2
Epoch: [23][431/704]	Time 0.120	Data 0.001	Loss 6.85	Acc@1 53.1	Acc@5 90.6
Epoch: [23][441/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 67.2	Acc@5 87.5
Epoch: [23][451/704]	Time 0.120	Data 0.001	Loss 6.44	Acc@1 62.5	Acc@5 90.6
Epoch: [23][461/704]	Time 0.120	Data 0.001	Loss 7.20	Acc@1 53.1	Acc@5 87.5
Epoch: [23][471/704]	Time 0.120	Data 0.001	Loss 6.41	Acc@1 59.4	Acc@5 90.6
Epoch: [23][481/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 65.6	Acc@5 90.6
Epoch: [23][491/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 59.4	Acc@5 87.5
Epoch: [23][501/704]	Time 0.120	Data 0.001	Loss 7.52	Acc@1 45.3	Acc@5 81.2
Epoch: [23][511/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 60.9	Acc@5 90.6
Epoch: [23][521/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 64.1	Acc@5 93.8
Epoch: [23][531/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 56.2	Acc@5 84.4
Epoch: [23][541/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 46.9	Acc@5 89.1
Epoch: [23][551/704]	Time 0.120	Data 0.001	Loss 6.34	Acc@1 54.7	Acc@5 87.5
Epoch: [23][561/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 60.9	Acc@5 85.9
Epoch: [23][571/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 51.6	Acc@5 89.1
Epoch: [23][581/704]	Time 0.120	Data 0.001	Loss 7.71	Acc@1 43.8	Acc@5 82.8
Epoch: [23][591/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 71.9	Acc@5 87.5
Epoch: [23][601/704]	Time 0.120	Data 0.001	Loss 6.04	Acc@1 57.8	Acc@5 87.5
Epoch: [23][611/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 65.6	Acc@5 90.6
Epoch: [23][621/704]	Time 0.120	Data 0.001	Loss 6.82	Acc@1 50.0	Acc@5 82.8
Epoch: [23][631/704]	Time 0.120	Data 0.001	Loss 6.19	Acc@1 53.1	Acc@5 89.1
Epoch: [23][641/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 59.4	Acc@5 96.9
Epoch: [23][651/704]	Time 0.120	Data 0.001	Loss 7.82	Acc@1 48.4	Acc@5 84.4
Epoch: [23][661/704]	Time 0.120	Data 0.001	Loss 6.65	Acc@1 56.2	Acc@5 85.9
Epoch: [23][671/704]	Time 0.120	Data 0.001	Loss 8.21	Acc@1 45.3	Acc@5 81.2
Epoch: [23][681/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 59.4	Acc@5 92.2
Epoch: [23][691/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 59.4	Acc@5 85.9
Epoch: [23][701/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 51.6	Acc@5 85.9
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.4017	Acc@1 46.8750	Acc@5 78.1250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.9266	Acc@1 48.4375	Acc@5 79.6875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.4971	Acc@1 45.3125	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6050	Acc@1 60.9375	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.9434	Acc@1 50.0000	Acc@5 75.0000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.9165	Acc@1 51.5625	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4740	Acc@1 51.5625	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.6024	Acc@1 50.0000	Acc@5 84.3750
 * prec@1 44.600 prec@5 75.280
 * prec@1 48.640 prec@5 79.320
 * prec@1 52.240 prec@5 82.160
 * prec@1 52.520 prec@5 82.760
New best validation last_bloc_accuracy 52.52
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_023.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_023.pth.tar'
Epoch: [24][1/704]	Time 0.297	Data 0.130	Loss 5.96	Acc@1 64.1	Acc@5 96.9
Epoch: [24][11/704]	Time 0.136	Data 0.012	Loss 6.32	Acc@1 62.5	Acc@5 92.2
Epoch: [24][21/704]	Time 0.128	Data 0.007	Loss 6.13	Acc@1 60.9	Acc@5 90.6
Epoch: [24][31/704]	Time 0.125	Data 0.005	Loss 6.44	Acc@1 56.2	Acc@5 79.7
Epoch: [24][41/704]	Time 0.125	Data 0.004	Loss 6.61	Acc@1 65.6	Acc@5 90.6
Epoch: [24][51/704]	Time 0.124	Data 0.003	Loss 5.47	Acc@1 67.2	Acc@5 93.8
Epoch: [24][61/704]	Time 0.123	Data 0.003	Loss 7.23	Acc@1 57.8	Acc@5 81.2
Epoch: [24][71/704]	Time 0.123	Data 0.002	Loss 4.91	Acc@1 71.9	Acc@5 95.3
Epoch: [24][81/704]	Time 0.122	Data 0.002	Loss 6.78	Acc@1 62.5	Acc@5 87.5
Epoch: [24][91/704]	Time 0.122	Data 0.002	Loss 6.61	Acc@1 60.9	Acc@5 87.5
Epoch: [24][101/704]	Time 0.122	Data 0.002	Loss 7.04	Acc@1 51.6	Acc@5 87.5
Epoch: [24][111/704]	Time 0.122	Data 0.002	Loss 5.90	Acc@1 62.5	Acc@5 84.4
Epoch: [24][121/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 64.1	Acc@5 93.8
Epoch: [24][131/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 59.4	Acc@5 90.6
Epoch: [24][141/704]	Time 0.121	Data 0.001	Loss 7.29	Acc@1 62.5	Acc@5 79.7
Epoch: [24][151/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 67.2	Acc@5 87.5
Epoch: [24][161/704]	Time 0.121	Data 0.001	Loss 6.92	Acc@1 60.9	Acc@5 82.8
Epoch: [24][171/704]	Time 0.121	Data 0.001	Loss 7.68	Acc@1 60.9	Acc@5 82.8
Epoch: [24][181/704]	Time 0.121	Data 0.001	Loss 6.64	Acc@1 51.6	Acc@5 89.1
Epoch: [24][191/704]	Time 0.121	Data 0.001	Loss 6.75	Acc@1 57.8	Acc@5 82.8
Epoch: [24][201/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 65.6	Acc@5 93.8
Epoch: [24][211/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 62.5	Acc@5 92.2
Epoch: [24][221/704]	Time 0.121	Data 0.001	Loss 7.02	Acc@1 57.8	Acc@5 82.8
Epoch: [24][231/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 62.5	Acc@5 92.2
Epoch: [24][241/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 71.9	Acc@5 89.1
Epoch: [24][251/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 59.4	Acc@5 87.5
Epoch: [24][261/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 75.0	Acc@5 95.3
Epoch: [24][271/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 64.1	Acc@5 93.8
Epoch: [24][281/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 65.6	Acc@5 89.1
Epoch: [24][291/704]	Time 0.120	Data 0.001	Loss 7.29	Acc@1 57.8	Acc@5 84.4
Epoch: [24][301/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 57.8	Acc@5 89.1
Epoch: [24][311/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 64.1	Acc@5 85.9
Epoch: [24][321/704]	Time 0.120	Data 0.001	Loss 6.72	Acc@1 59.4	Acc@5 85.9
Epoch: [24][331/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 64.1	Acc@5 90.6
Epoch: [24][341/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 59.4	Acc@5 90.6
Epoch: [24][351/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 64.1	Acc@5 90.6
Epoch: [24][361/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 60.9	Acc@5 85.9
Epoch: [24][371/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 57.8	Acc@5 89.1
Epoch: [24][381/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 56.2	Acc@5 93.8
Epoch: [24][391/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 64.1	Acc@5 89.1
Epoch: [24][401/704]	Time 0.120	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 90.6
Epoch: [24][411/704]	Time 0.120	Data 0.001	Loss 6.60	Acc@1 59.4	Acc@5 90.6
Epoch: [24][421/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 48.4	Acc@5 85.9
Epoch: [24][431/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 93.8
Epoch: [24][441/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 70.3	Acc@5 92.2
Epoch: [24][451/704]	Time 0.120	Data 0.001	Loss 6.70	Acc@1 62.5	Acc@5 84.4
Epoch: [24][461/704]	Time 0.120	Data 0.001	Loss 6.25	Acc@1 67.2	Acc@5 81.2
Epoch: [24][471/704]	Time 0.120	Data 0.001	Loss 6.14	Acc@1 64.1	Acc@5 85.9
Epoch: [24][481/704]	Time 0.120	Data 0.001	Loss 6.77	Acc@1 54.7	Acc@5 84.4
Epoch: [24][491/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 60.9	Acc@5 85.9
Epoch: [24][501/704]	Time 0.120	Data 0.001	Loss 6.63	Acc@1 64.1	Acc@5 87.5
Epoch: [24][511/704]	Time 0.120	Data 0.001	Loss 7.05	Acc@1 54.7	Acc@5 87.5
Epoch: [24][521/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 64.1	Acc@5 95.3
Epoch: [24][531/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 92.2
Epoch: [24][541/704]	Time 0.120	Data 0.001	Loss 6.36	Acc@1 57.8	Acc@5 89.1
Epoch: [24][551/704]	Time 0.120	Data 0.001	Loss 6.81	Acc@1 60.9	Acc@5 85.9
Epoch: [24][561/704]	Time 0.120	Data 0.001	Loss 6.87	Acc@1 59.4	Acc@5 81.2
Epoch: [24][571/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 67.2	Acc@5 92.2
Epoch: [24][581/704]	Time 0.120	Data 0.001	Loss 6.69	Acc@1 54.7	Acc@5 84.4
Epoch: [24][591/704]	Time 0.120	Data 0.001	Loss 6.03	Acc@1 65.6	Acc@5 89.1
Epoch: [24][601/704]	Time 0.120	Data 0.001	Loss 6.09	Acc@1 60.9	Acc@5 89.1
Epoch: [24][611/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 70.3	Acc@5 85.9
Epoch: [24][621/704]	Time 0.120	Data 0.001	Loss 6.52	Acc@1 59.4	Acc@5 92.2
Epoch: [24][631/704]	Time 0.120	Data 0.001	Loss 7.08	Acc@1 51.6	Acc@5 87.5
Epoch: [24][641/704]	Time 0.120	Data 0.001	Loss 7.57	Acc@1 56.2	Acc@5 81.2
Epoch: [24][651/704]	Time 0.120	Data 0.001	Loss 7.36	Acc@1 54.7	Acc@5 81.2
Epoch: [24][661/704]	Time 0.120	Data 0.001	Loss 6.88	Acc@1 57.8	Acc@5 85.9
Epoch: [24][671/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 62.5	Acc@5 89.1
Epoch: [24][681/704]	Time 0.120	Data 0.001	Loss 5.39	Acc@1 70.3	Acc@5 92.2
Epoch: [24][691/704]	Time 0.120	Data 0.001	Loss 6.87	Acc@1 53.1	Acc@5 87.5
Epoch: [24][701/704]	Time 0.120	Data 0.001	Loss 6.61	Acc@1 53.1	Acc@5 92.2
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 8.2435	Acc@1 46.8750	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.0564	Acc@1 50.0000	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.9463	Acc@1 50.0000	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 9.2156	Acc@1 45.3125	Acc@5 75.0000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3186	Acc@1 48.4375	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 9.3107	Acc@1 42.1875	Acc@5 76.5625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.8609	Acc@1 51.5625	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.9655	Acc@1 50.0000	Acc@5 84.3750
 * prec@1 42.800 prec@5 74.160
 * prec@1 48.580 prec@5 79.800
 * prec@1 51.500 prec@5 81.680
 * prec@1 53.160 prec@5 83.020
New best validation last_bloc_accuracy 53.16
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_024.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_024.pth.tar'
Epoch: [25][1/704]	Time 0.327	Data 0.161	Loss 5.36	Acc@1 68.8	Acc@5 89.1
Epoch: [25][11/704]	Time 0.139	Data 0.015	Loss 6.30	Acc@1 64.1	Acc@5 90.6
Epoch: [25][21/704]	Time 0.130	Data 0.008	Loss 5.69	Acc@1 64.1	Acc@5 89.1
Epoch: [25][31/704]	Time 0.126	Data 0.006	Loss 5.96	Acc@1 68.8	Acc@5 92.2
Epoch: [25][41/704]	Time 0.125	Data 0.004	Loss 5.05	Acc@1 65.6	Acc@5 89.1
Epoch: [25][51/704]	Time 0.124	Data 0.004	Loss 5.51	Acc@1 68.8	Acc@5 96.9
Epoch: [25][61/704]	Time 0.123	Data 0.003	Loss 4.92	Acc@1 78.1	Acc@5 92.2
Epoch: [25][71/704]	Time 0.123	Data 0.003	Loss 5.36	Acc@1 62.5	Acc@5 90.6
Epoch: [25][81/704]	Time 0.122	Data 0.002	Loss 5.59	Acc@1 71.9	Acc@5 89.1
Epoch: [25][91/704]	Time 0.122	Data 0.002	Loss 5.94	Acc@1 51.6	Acc@5 89.1
Epoch: [25][101/704]	Time 0.122	Data 0.002	Loss 6.11	Acc@1 54.7	Acc@5 85.9
Epoch: [25][111/704]	Time 0.122	Data 0.002	Loss 7.30	Acc@1 57.8	Acc@5 87.5
Epoch: [25][121/704]	Time 0.121	Data 0.002	Loss 5.66	Acc@1 71.9	Acc@5 93.8
Epoch: [25][131/704]	Time 0.121	Data 0.002	Loss 6.22	Acc@1 60.9	Acc@5 89.1
Epoch: [25][141/704]	Time 0.121	Data 0.002	Loss 6.29	Acc@1 60.9	Acc@5 89.1
Epoch: [25][151/704]	Time 0.121	Data 0.001	Loss 7.49	Acc@1 57.8	Acc@5 82.8
Epoch: [25][161/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 59.4	Acc@5 90.6
Epoch: [25][171/704]	Time 0.121	Data 0.001	Loss 6.37	Acc@1 56.2	Acc@5 89.1
Epoch: [25][181/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 60.9	Acc@5 87.5
Epoch: [25][191/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 57.8	Acc@5 90.6
Epoch: [25][201/704]	Time 0.121	Data 0.001	Loss 6.57	Acc@1 57.8	Acc@5 85.9
Epoch: [25][211/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 59.4	Acc@5 87.5
Epoch: [25][221/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 62.5	Acc@5 87.5
Epoch: [25][231/704]	Time 0.121	Data 0.001	Loss 6.83	Acc@1 60.9	Acc@5 87.5
Epoch: [25][241/704]	Time 0.121	Data 0.001	Loss 6.81	Acc@1 60.9	Acc@5 84.4
Epoch: [25][251/704]	Time 0.121	Data 0.001	Loss 6.75	Acc@1 65.6	Acc@5 78.1
Epoch: [25][261/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 89.1
Epoch: [25][271/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 57.8	Acc@5 89.1
Epoch: [25][281/704]	Time 0.121	Data 0.001	Loss 6.65	Acc@1 54.7	Acc@5 89.1
Epoch: [25][291/704]	Time 0.121	Data 0.001	Loss 6.91	Acc@1 60.9	Acc@5 92.2
Epoch: [25][301/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 57.8	Acc@5 90.6
Epoch: [25][311/704]	Time 0.120	Data 0.001	Loss 7.94	Acc@1 46.9	Acc@5 82.8
Epoch: [25][321/704]	Time 0.120	Data 0.001	Loss 5.70	Acc@1 60.9	Acc@5 92.2
Epoch: [25][331/704]	Time 0.120	Data 0.001	Loss 7.48	Acc@1 46.9	Acc@5 89.1
Epoch: [25][341/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 70.3	Acc@5 90.6
Epoch: [25][351/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 60.9	Acc@5 84.4
Epoch: [25][361/704]	Time 0.120	Data 0.001	Loss 4.97	Acc@1 70.3	Acc@5 96.9
Epoch: [25][371/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 64.1	Acc@5 87.5
Epoch: [25][381/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 64.1	Acc@5 90.6
Epoch: [25][391/704]	Time 0.120	Data 0.001	Loss 7.53	Acc@1 60.9	Acc@5 84.4
Epoch: [25][401/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 62.5	Acc@5 90.6
Epoch: [25][411/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 59.4	Acc@5 93.8
Epoch: [25][421/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 53.1	Acc@5 78.1
Epoch: [25][431/704]	Time 0.120	Data 0.001	Loss 7.78	Acc@1 54.7	Acc@5 79.7
Epoch: [25][441/704]	Time 0.120	Data 0.001	Loss 6.29	Acc@1 59.4	Acc@5 90.6
Epoch: [25][451/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 70.3	Acc@5 92.2
Epoch: [25][461/704]	Time 0.120	Data 0.001	Loss 7.44	Acc@1 60.9	Acc@5 82.8
Epoch: [25][471/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 60.9	Acc@5 90.6
Epoch: [25][481/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 60.9	Acc@5 89.1
Epoch: [25][491/704]	Time 0.120	Data 0.001	Loss 6.05	Acc@1 59.4	Acc@5 89.1
Epoch: [25][501/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 70.3	Acc@5 87.5
Epoch: [25][511/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 90.6
Epoch: [25][521/704]	Time 0.120	Data 0.001	Loss 6.67	Acc@1 59.4	Acc@5 89.1
Epoch: [25][531/704]	Time 0.120	Data 0.001	Loss 6.41	Acc@1 60.9	Acc@5 85.9
Epoch: [25][541/704]	Time 0.120	Data 0.001	Loss 7.97	Acc@1 51.6	Acc@5 81.2
Epoch: [25][551/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 60.9	Acc@5 90.6
Epoch: [25][561/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 60.9	Acc@5 87.5
Epoch: [25][571/704]	Time 0.120	Data 0.001	Loss 6.79	Acc@1 57.8	Acc@5 81.2
Epoch: [25][581/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 57.8	Acc@5 82.8
Epoch: [25][591/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 62.5	Acc@5 90.6
Epoch: [25][601/704]	Time 0.120	Data 0.001	Loss 7.26	Acc@1 57.8	Acc@5 87.5
Epoch: [25][611/704]	Time 0.120	Data 0.001	Loss 6.84	Acc@1 51.6	Acc@5 87.5
Epoch: [25][621/704]	Time 0.120	Data 0.001	Loss 5.59	Acc@1 64.1	Acc@5 92.2
Epoch: [25][631/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 60.9	Acc@5 84.4
Epoch: [25][641/704]	Time 0.120	Data 0.001	Loss 4.95	Acc@1 64.1	Acc@5 90.6
Epoch: [25][651/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 93.8
Epoch: [25][661/704]	Time 0.120	Data 0.001	Loss 6.93	Acc@1 60.9	Acc@5 87.5
Epoch: [25][671/704]	Time 0.120	Data 0.001	Loss 6.32	Acc@1 57.8	Acc@5 85.9
Epoch: [25][681/704]	Time 0.120	Data 0.001	Loss 6.47	Acc@1 57.8	Acc@5 85.9
Epoch: [25][691/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 60.9	Acc@5 84.4
Epoch: [25][701/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 56.2	Acc@5 90.6
Epoch: [1/79]	Time 0.099	Data 0.085	Loss 7.9257	Acc@1 51.5625	Acc@5 78.1250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.7109	Acc@1 57.8125	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.1554	Acc@1 56.2500	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.6208	Acc@1 54.6875	Acc@5 76.5625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.2603	Acc@1 48.4375	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2287	Acc@1 48.4375	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.4146	Acc@1 45.3125	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 9.2296	Acc@1 50.0000	Acc@5 75.0000
 * prec@1 43.500 prec@5 74.160
 * prec@1 47.300 prec@5 78.020
 * prec@1 51.740 prec@5 81.720
 * prec@1 53.200 prec@5 82.080
New best validation last_bloc_accuracy 53.2
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_025.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_025.pth.tar'
Epoch: [26][1/704]	Time 0.331	Data 0.165	Loss 5.51	Acc@1 59.4	Acc@5 85.9
Epoch: [26][11/704]	Time 0.139	Data 0.015	Loss 6.47	Acc@1 56.2	Acc@5 85.9
Epoch: [26][21/704]	Time 0.129	Data 0.008	Loss 5.17	Acc@1 65.6	Acc@5 95.3
Epoch: [26][31/704]	Time 0.126	Data 0.006	Loss 6.81	Acc@1 62.5	Acc@5 87.5
Epoch: [26][41/704]	Time 0.125	Data 0.004	Loss 4.37	Acc@1 76.6	Acc@5 95.3
Epoch: [26][51/704]	Time 0.124	Data 0.004	Loss 5.58	Acc@1 68.8	Acc@5 95.3
Epoch: [26][61/704]	Time 0.123	Data 0.003	Loss 4.83	Acc@1 62.5	Acc@5 93.8
Epoch: [26][71/704]	Time 0.123	Data 0.003	Loss 6.03	Acc@1 53.1	Acc@5 93.8
Epoch: [26][81/704]	Time 0.123	Data 0.002	Loss 6.52	Acc@1 64.1	Acc@5 87.5
Epoch: [26][91/704]	Time 0.122	Data 0.002	Loss 5.41	Acc@1 64.1	Acc@5 92.2
Epoch: [26][101/704]	Time 0.122	Data 0.002	Loss 5.99	Acc@1 62.5	Acc@5 92.2
Epoch: [26][111/704]	Time 0.122	Data 0.002	Loss 8.58	Acc@1 50.0	Acc@5 79.7
Epoch: [26][121/704]	Time 0.122	Data 0.002	Loss 7.02	Acc@1 50.0	Acc@5 85.9
Epoch: [26][131/704]	Time 0.122	Data 0.002	Loss 7.28	Acc@1 62.5	Acc@5 85.9
Epoch: [26][141/704]	Time 0.122	Data 0.002	Loss 5.36	Acc@1 68.8	Acc@5 92.2
Epoch: [26][151/704]	Time 0.122	Data 0.002	Loss 5.82	Acc@1 71.9	Acc@5 85.9
Epoch: [26][161/704]	Time 0.122	Data 0.001	Loss 7.37	Acc@1 56.2	Acc@5 87.5
Epoch: [26][171/704]	Time 0.121	Data 0.001	Loss 6.67	Acc@1 60.9	Acc@5 89.1
Epoch: [26][181/704]	Time 0.121	Data 0.001	Loss 6.26	Acc@1 57.8	Acc@5 90.6
Epoch: [26][191/704]	Time 0.121	Data 0.001	Loss 6.69	Acc@1 64.1	Acc@5 89.1
Epoch: [26][201/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 57.8	Acc@5 87.5
Epoch: [26][211/704]	Time 0.121	Data 0.001	Loss 6.87	Acc@1 56.2	Acc@5 84.4
Epoch: [26][221/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 51.6	Acc@5 89.1
Epoch: [26][231/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 57.8	Acc@5 82.8
Epoch: [26][241/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 62.5	Acc@5 85.9
Epoch: [26][251/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 71.9	Acc@5 92.2
Epoch: [26][261/704]	Time 0.121	Data 0.001	Loss 7.01	Acc@1 57.8	Acc@5 87.5
Epoch: [26][271/704]	Time 0.121	Data 0.001	Loss 8.21	Acc@1 48.4	Acc@5 87.5
Epoch: [26][281/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 60.9	Acc@5 90.6
Epoch: [26][291/704]	Time 0.121	Data 0.001	Loss 7.04	Acc@1 51.6	Acc@5 87.5
Epoch: [26][301/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 56.2	Acc@5 87.5
Epoch: [26][311/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 70.3	Acc@5 85.9
Epoch: [26][321/704]	Time 0.121	Data 0.001	Loss 6.73	Acc@1 59.4	Acc@5 84.4
Epoch: [26][331/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 59.4	Acc@5 87.5
Epoch: [26][341/704]	Time 0.121	Data 0.001	Loss 7.67	Acc@1 59.4	Acc@5 87.5
Epoch: [26][351/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 64.1	Acc@5 92.2
Epoch: [26][361/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 65.6	Acc@5 89.1
Epoch: [26][371/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 51.6	Acc@5 82.8
Epoch: [26][381/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 59.4	Acc@5 93.8
Epoch: [26][391/704]	Time 0.121	Data 0.001	Loss 7.25	Acc@1 56.2	Acc@5 79.7
Epoch: [26][401/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 54.7	Acc@5 85.9
Epoch: [26][411/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 64.1	Acc@5 89.1
Epoch: [26][421/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 64.1	Acc@5 90.6
Epoch: [26][431/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 54.7	Acc@5 87.5
Epoch: [26][441/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 59.4	Acc@5 92.2
Epoch: [26][451/704]	Time 0.121	Data 0.001	Loss 8.33	Acc@1 51.6	Acc@5 81.2
Epoch: [26][461/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 60.9	Acc@5 89.1
Epoch: [26][471/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 68.8	Acc@5 90.6
Epoch: [26][481/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 57.8	Acc@5 92.2
Epoch: [26][491/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 62.5	Acc@5 92.2
Epoch: [26][501/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 65.6	Acc@5 92.2
Epoch: [26][511/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 57.8	Acc@5 89.1
Epoch: [26][521/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 59.4	Acc@5 92.2
Epoch: [26][531/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 65.6	Acc@5 87.5
Epoch: [26][541/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 68.8	Acc@5 90.6
Epoch: [26][551/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 60.9	Acc@5 87.5
Epoch: [26][561/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 56.2	Acc@5 90.6
Epoch: [26][571/704]	Time 0.121	Data 0.001	Loss 6.35	Acc@1 62.5	Acc@5 89.1
Epoch: [26][581/704]	Time 0.121	Data 0.001	Loss 6.84	Acc@1 57.8	Acc@5 89.1
Epoch: [26][591/704]	Time 0.121	Data 0.001	Loss 6.94	Acc@1 50.0	Acc@5 87.5
Epoch: [26][601/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 57.8	Acc@5 82.8
Epoch: [26][611/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 57.8	Acc@5 92.2
Epoch: [26][621/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 68.8	Acc@5 90.6
Epoch: [26][631/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 65.6	Acc@5 85.9
Epoch: [26][641/704]	Time 0.121	Data 0.001	Loss 7.35	Acc@1 57.8	Acc@5 85.9
Epoch: [26][651/704]	Time 0.121	Data 0.001	Loss 6.48	Acc@1 64.1	Acc@5 81.2
Epoch: [26][661/704]	Time 0.121	Data 0.001	Loss 6.18	Acc@1 68.8	Acc@5 90.6
Epoch: [26][671/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 96.9
Epoch: [26][681/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 73.4	Acc@5 95.3
Epoch: [26][691/704]	Time 0.121	Data 0.001	Loss 6.89	Acc@1 59.4	Acc@5 85.9
Epoch: [26][701/704]	Time 0.121	Data 0.001	Loss 7.51	Acc@1 56.2	Acc@5 85.9
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 7.4978	Acc@1 54.6875	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 9.4454	Acc@1 50.0000	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.1141	Acc@1 53.1250	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.8749	Acc@1 62.5000	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4042	Acc@1 51.5625	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2169	Acc@1 59.3750	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.2329	Acc@1 53.1250	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.5619	Acc@1 57.8125	Acc@5 90.6250
 * prec@1 43.280 prec@5 75.540
 * prec@1 47.920 prec@5 79.400
 * prec@1 52.680 prec@5 82.700
 * prec@1 52.800 prec@5 82.680
Current best validation last_bloc_accuracy 53.2
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_026.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_026.pth.tar'
Epoch: [27][1/704]	Time 0.299	Data 0.131	Loss 5.02	Acc@1 67.2	Acc@5 93.8
Epoch: [27][11/704]	Time 0.137	Data 0.012	Loss 6.26	Acc@1 51.6	Acc@5 79.7
Epoch: [27][21/704]	Time 0.129	Data 0.007	Loss 5.33	Acc@1 64.1	Acc@5 90.6
Epoch: [27][31/704]	Time 0.126	Data 0.005	Loss 4.91	Acc@1 65.6	Acc@5 93.8
Epoch: [27][41/704]	Time 0.125	Data 0.004	Loss 6.30	Acc@1 59.4	Acc@5 87.5
Epoch: [27][51/704]	Time 0.124	Data 0.003	Loss 5.37	Acc@1 67.2	Acc@5 95.3
Epoch: [27][61/704]	Time 0.124	Data 0.003	Loss 5.81	Acc@1 65.6	Acc@5 90.6
Epoch: [27][71/704]	Time 0.123	Data 0.002	Loss 6.32	Acc@1 60.9	Acc@5 82.8
Epoch: [27][81/704]	Time 0.123	Data 0.002	Loss 5.51	Acc@1 62.5	Acc@5 87.5
Epoch: [27][91/704]	Time 0.123	Data 0.002	Loss 7.73	Acc@1 42.2	Acc@5 79.7
Epoch: [27][101/704]	Time 0.123	Data 0.002	Loss 5.74	Acc@1 68.8	Acc@5 90.6
Epoch: [27][111/704]	Time 0.122	Data 0.002	Loss 5.95	Acc@1 57.8	Acc@5 87.5
Epoch: [27][121/704]	Time 0.122	Data 0.001	Loss 5.89	Acc@1 68.8	Acc@5 92.2
Epoch: [27][131/704]	Time 0.122	Data 0.001	Loss 4.82	Acc@1 70.3	Acc@5 96.9
Epoch: [27][141/704]	Time 0.122	Data 0.001	Loss 6.23	Acc@1 60.9	Acc@5 85.9
Epoch: [27][151/704]	Time 0.122	Data 0.001	Loss 6.06	Acc@1 62.5	Acc@5 92.2
Epoch: [27][161/704]	Time 0.122	Data 0.001	Loss 5.80	Acc@1 67.2	Acc@5 87.5
Epoch: [27][171/704]	Time 0.122	Data 0.001	Loss 6.50	Acc@1 57.8	Acc@5 87.5
Epoch: [27][181/704]	Time 0.122	Data 0.001	Loss 6.27	Acc@1 62.5	Acc@5 92.2
Epoch: [27][191/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 68.8	Acc@5 92.2
Epoch: [27][201/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 53.1	Acc@5 90.6
Epoch: [27][211/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 59.4	Acc@5 90.6
Epoch: [27][221/704]	Time 0.121	Data 0.001	Loss 6.77	Acc@1 56.2	Acc@5 84.4
Epoch: [27][231/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 57.8	Acc@5 93.8
Epoch: [27][241/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 71.9	Acc@5 87.5
Epoch: [27][251/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 62.5	Acc@5 92.2
Epoch: [27][261/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 87.5
Epoch: [27][271/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 64.1	Acc@5 87.5
Epoch: [27][281/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 73.4	Acc@5 93.8
Epoch: [27][291/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 62.5	Acc@5 92.2
Epoch: [27][301/704]	Time 0.121	Data 0.001	Loss 6.66	Acc@1 68.8	Acc@5 85.9
Epoch: [27][311/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 62.5	Acc@5 95.3
Epoch: [27][321/704]	Time 0.121	Data 0.001	Loss 7.07	Acc@1 53.1	Acc@5 89.1
Epoch: [27][331/704]	Time 0.121	Data 0.001	Loss 7.31	Acc@1 57.8	Acc@5 89.1
Epoch: [27][341/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 68.8	Acc@5 87.5
Epoch: [27][351/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 71.9	Acc@5 95.3
Epoch: [27][361/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 62.5	Acc@5 93.8
Epoch: [27][371/704]	Time 0.121	Data 0.001	Loss 6.37	Acc@1 54.7	Acc@5 90.6
Epoch: [27][381/704]	Time 0.121	Data 0.001	Loss 7.41	Acc@1 59.4	Acc@5 84.4
Epoch: [27][391/704]	Time 0.121	Data 0.001	Loss 7.40	Acc@1 56.2	Acc@5 89.1
Epoch: [27][401/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 51.6	Acc@5 93.8
Epoch: [27][411/704]	Time 0.121	Data 0.001	Loss 6.69	Acc@1 59.4	Acc@5 92.2
Epoch: [27][421/704]	Time 0.121	Data 0.001	Loss 7.04	Acc@1 56.2	Acc@5 82.8
Epoch: [27][431/704]	Time 0.121	Data 0.001	Loss 6.94	Acc@1 51.6	Acc@5 90.6
Epoch: [27][441/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 60.9	Acc@5 93.8
Epoch: [27][451/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 64.1	Acc@5 89.1
Epoch: [27][461/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 62.5	Acc@5 93.8
Epoch: [27][471/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 65.6	Acc@5 92.2
Epoch: [27][481/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 62.5	Acc@5 92.2
Epoch: [27][491/704]	Time 0.121	Data 0.001	Loss 7.56	Acc@1 46.9	Acc@5 84.4
Epoch: [27][501/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 54.7	Acc@5 92.2
Epoch: [27][511/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 67.2	Acc@5 90.6
Epoch: [27][521/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 65.6	Acc@5 96.9
Epoch: [27][531/704]	Time 0.121	Data 0.001	Loss 7.12	Acc@1 62.5	Acc@5 84.4
Epoch: [27][541/704]	Time 0.121	Data 0.001	Loss 7.18	Acc@1 51.6	Acc@5 84.4
Epoch: [27][551/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 65.6	Acc@5 92.2
Epoch: [27][561/704]	Time 0.121	Data 0.001	Loss 7.19	Acc@1 54.7	Acc@5 87.5
Epoch: [27][571/704]	Time 0.121	Data 0.001	Loss 7.67	Acc@1 46.9	Acc@5 82.8
Epoch: [27][581/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 56.2	Acc@5 89.1
Epoch: [27][591/704]	Time 0.121	Data 0.001	Loss 6.35	Acc@1 64.1	Acc@5 89.1
Epoch: [27][601/704]	Time 0.121	Data 0.001	Loss 8.37	Acc@1 50.0	Acc@5 73.4
Epoch: [27][611/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 57.8	Acc@5 95.3
Epoch: [27][621/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 56.2	Acc@5 89.1
Epoch: [27][631/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 67.2	Acc@5 85.9
Epoch: [27][641/704]	Time 0.121	Data 0.001	Loss 6.24	Acc@1 68.8	Acc@5 92.2
Epoch: [27][651/704]	Time 0.121	Data 0.001	Loss 6.68	Acc@1 59.4	Acc@5 85.9
Epoch: [27][661/704]	Time 0.121	Data 0.001	Loss 7.10	Acc@1 56.2	Acc@5 84.4
Epoch: [27][671/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 57.8	Acc@5 82.8
Epoch: [27][681/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 64.1	Acc@5 93.8
Epoch: [27][691/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 59.4	Acc@5 89.1
Epoch: [27][701/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 50.0	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 8.6349	Acc@1 45.3125	Acc@5 75.0000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.2328	Acc@1 51.5625	Acc@5 79.6875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0820	Acc@1 46.8750	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.9483	Acc@1 70.3125	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4247	Acc@1 48.4375	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7944	Acc@1 45.3125	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.2593	Acc@1 51.5625	Acc@5 79.6875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.6129	Acc@1 54.6875	Acc@5 79.6875
 * prec@1 43.440 prec@5 74.980
 * prec@1 48.860 prec@5 79.100
 * prec@1 49.520 prec@5 79.580
 * prec@1 49.680 prec@5 80.140
Current best validation last_bloc_accuracy 53.2
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_027.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_027.pth.tar'
Epoch: [28][1/704]	Time 0.331	Data 0.164	Loss 6.32	Acc@1 54.7	Acc@5 90.6
Epoch: [28][11/704]	Time 0.140	Data 0.015	Loss 7.44	Acc@1 46.9	Acc@5 82.8
Epoch: [28][21/704]	Time 0.131	Data 0.008	Loss 5.77	Acc@1 68.8	Acc@5 93.8
Epoch: [28][31/704]	Time 0.127	Data 0.006	Loss 5.71	Acc@1 57.8	Acc@5 87.5
Epoch: [28][41/704]	Time 0.126	Data 0.004	Loss 5.59	Acc@1 65.6	Acc@5 90.6
Epoch: [28][51/704]	Time 0.125	Data 0.003	Loss 4.33	Acc@1 65.6	Acc@5 95.3
Epoch: [28][61/704]	Time 0.124	Data 0.003	Loss 7.30	Acc@1 59.4	Acc@5 84.4
Epoch: [28][71/704]	Time 0.123	Data 0.003	Loss 6.75	Acc@1 59.4	Acc@5 85.9
Epoch: [28][81/704]	Time 0.123	Data 0.002	Loss 6.63	Acc@1 62.5	Acc@5 85.9
Epoch: [28][91/704]	Time 0.123	Data 0.002	Loss 6.21	Acc@1 59.4	Acc@5 92.2
Epoch: [28][101/704]	Time 0.123	Data 0.002	Loss 6.15	Acc@1 59.4	Acc@5 90.6
Epoch: [28][111/704]	Time 0.122	Data 0.002	Loss 5.89	Acc@1 64.1	Acc@5 93.8
Epoch: [28][121/704]	Time 0.122	Data 0.002	Loss 5.94	Acc@1 59.4	Acc@5 89.1
Epoch: [28][131/704]	Time 0.122	Data 0.002	Loss 5.65	Acc@1 62.5	Acc@5 93.8
Epoch: [28][141/704]	Time 0.122	Data 0.001	Loss 5.87	Acc@1 68.8	Acc@5 89.1
Epoch: [28][151/704]	Time 0.122	Data 0.001	Loss 5.33	Acc@1 70.3	Acc@5 93.8
Epoch: [28][161/704]	Time 0.122	Data 0.001	Loss 4.53	Acc@1 65.6	Acc@5 93.8
Epoch: [28][171/704]	Time 0.122	Data 0.001	Loss 5.82	Acc@1 56.2	Acc@5 89.1
Epoch: [28][181/704]	Time 0.122	Data 0.001	Loss 6.79	Acc@1 62.5	Acc@5 90.6
Epoch: [28][191/704]	Time 0.122	Data 0.001	Loss 7.48	Acc@1 42.2	Acc@5 90.6
Epoch: [28][201/704]	Time 0.122	Data 0.001	Loss 7.01	Acc@1 57.8	Acc@5 84.4
Epoch: [28][211/704]	Time 0.121	Data 0.001	Loss 6.93	Acc@1 53.1	Acc@5 85.9
Epoch: [28][221/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 57.8	Acc@5 92.2
Epoch: [28][231/704]	Time 0.121	Data 0.001	Loss 7.33	Acc@1 48.4	Acc@5 82.8
Epoch: [28][241/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 64.1	Acc@5 89.1
Epoch: [28][251/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 65.6	Acc@5 93.8
Epoch: [28][261/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 70.3	Acc@5 98.4
Epoch: [28][271/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 68.8	Acc@5 93.8
Epoch: [28][281/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 62.5	Acc@5 90.6
Epoch: [28][291/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 65.6	Acc@5 87.5
Epoch: [28][301/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 60.9	Acc@5 89.1
Epoch: [28][311/704]	Time 0.121	Data 0.001	Loss 6.76	Acc@1 56.2	Acc@5 87.5
Epoch: [28][321/704]	Time 0.121	Data 0.001	Loss 8.09	Acc@1 46.9	Acc@5 81.2
Epoch: [28][331/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 60.9	Acc@5 90.6
Epoch: [28][341/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 57.8	Acc@5 87.5
Epoch: [28][351/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 64.1	Acc@5 92.2
Epoch: [28][361/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 60.9	Acc@5 90.6
Epoch: [28][371/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 62.5	Acc@5 85.9
Epoch: [28][381/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 68.8	Acc@5 89.1
Epoch: [28][391/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 62.5	Acc@5 87.5
Epoch: [28][401/704]	Time 0.121	Data 0.001	Loss 6.28	Acc@1 56.2	Acc@5 87.5
Epoch: [28][411/704]	Time 0.121	Data 0.001	Loss 7.51	Acc@1 53.1	Acc@5 84.4
Epoch: [28][421/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 60.9	Acc@5 92.2
Epoch: [28][431/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 65.6	Acc@5 89.1
Epoch: [28][441/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 59.4	Acc@5 89.1
Epoch: [28][451/704]	Time 0.121	Data 0.001	Loss 6.78	Acc@1 57.8	Acc@5 84.4
Epoch: [28][461/704]	Time 0.121	Data 0.001	Loss 7.26	Acc@1 53.1	Acc@5 87.5
Epoch: [28][471/704]	Time 0.121	Data 0.001	Loss 6.92	Acc@1 59.4	Acc@5 87.5
Epoch: [28][481/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 51.6	Acc@5 84.4
Epoch: [28][491/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 53.1	Acc@5 87.5
Epoch: [28][501/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 54.7	Acc@5 85.9
Epoch: [28][511/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 71.9	Acc@5 90.6
Epoch: [28][521/704]	Time 0.121	Data 0.001	Loss 7.47	Acc@1 57.8	Acc@5 81.2
Epoch: [28][531/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 75.0	Acc@5 96.9
Epoch: [28][541/704]	Time 0.121	Data 0.001	Loss 7.06	Acc@1 57.8	Acc@5 89.1
Epoch: [28][551/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 67.2	Acc@5 92.2
Epoch: [28][561/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 53.1	Acc@5 85.9
Epoch: [28][571/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 68.8	Acc@5 92.2
Epoch: [28][581/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 62.5	Acc@5 89.1
Epoch: [28][591/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 62.5	Acc@5 89.1
Epoch: [28][601/704]	Time 0.121	Data 0.001	Loss 7.14	Acc@1 51.6	Acc@5 87.5
Epoch: [28][611/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 64.1	Acc@5 89.1
Epoch: [28][621/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 56.2	Acc@5 85.9
Epoch: [28][631/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 71.9	Acc@5 90.6
Epoch: [28][641/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 67.2	Acc@5 92.2
Epoch: [28][651/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 53.1	Acc@5 82.8
Epoch: [28][661/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 89.1
Epoch: [28][671/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 67.2	Acc@5 89.1
Epoch: [28][681/704]	Time 0.121	Data 0.001	Loss 6.70	Acc@1 59.4	Acc@5 81.2
Epoch: [28][691/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 71.9	Acc@5 92.2
Epoch: [28][701/704]	Time 0.121	Data 0.001	Loss 6.73	Acc@1 56.2	Acc@5 85.9
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.9157	Acc@1 54.6875	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.0808	Acc@1 70.3125	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0703	Acc@1 53.1250	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.1503	Acc@1 53.1250	Acc@5 76.5625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 9.1407	Acc@1 42.1875	Acc@5 73.4375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.9873	Acc@1 46.8750	Acc@5 76.5625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 8.4075	Acc@1 48.4375	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.3871	Acc@1 53.1250	Acc@5 79.6875
 * prec@1 42.900 prec@5 74.700
 * prec@1 48.200 prec@5 79.400
 * prec@1 51.180 prec@5 81.860
 * prec@1 53.840 prec@5 83.200
New best validation last_bloc_accuracy 53.84
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_028.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_028.pth.tar'
Epoch: [29][1/704]	Time 0.331	Data 0.164	Loss 5.75	Acc@1 56.2	Acc@5 92.2
Epoch: [29][11/704]	Time 0.140	Data 0.015	Loss 6.46	Acc@1 60.9	Acc@5 81.2
Epoch: [29][21/704]	Time 0.130	Data 0.008	Loss 6.38	Acc@1 53.1	Acc@5 84.4
Epoch: [29][31/704]	Time 0.127	Data 0.006	Loss 7.02	Acc@1 51.6	Acc@5 84.4
Epoch: [29][41/704]	Time 0.126	Data 0.004	Loss 6.41	Acc@1 64.1	Acc@5 84.4
Epoch: [29][51/704]	Time 0.124	Data 0.004	Loss 5.05	Acc@1 71.9	Acc@5 92.2
Epoch: [29][61/704]	Time 0.124	Data 0.003	Loss 6.44	Acc@1 60.9	Acc@5 92.2
Epoch: [29][71/704]	Time 0.123	Data 0.003	Loss 5.89	Acc@1 57.8	Acc@5 90.6
Epoch: [29][81/704]	Time 0.123	Data 0.002	Loss 8.06	Acc@1 43.8	Acc@5 79.7
Epoch: [29][91/704]	Time 0.123	Data 0.002	Loss 5.79	Acc@1 67.2	Acc@5 92.2
Epoch: [29][101/704]	Time 0.122	Data 0.002	Loss 6.06	Acc@1 64.1	Acc@5 90.6
Epoch: [29][111/704]	Time 0.122	Data 0.002	Loss 6.28	Acc@1 67.2	Acc@5 90.6
Epoch: [29][121/704]	Time 0.122	Data 0.002	Loss 5.67	Acc@1 70.3	Acc@5 90.6
Epoch: [29][131/704]	Time 0.122	Data 0.002	Loss 5.56	Acc@1 70.3	Acc@5 87.5
Epoch: [29][141/704]	Time 0.122	Data 0.002	Loss 5.16	Acc@1 73.4	Acc@5 89.1
Epoch: [29][151/704]	Time 0.122	Data 0.001	Loss 5.72	Acc@1 57.8	Acc@5 95.3
Epoch: [29][161/704]	Time 0.122	Data 0.001	Loss 6.78	Acc@1 60.9	Acc@5 87.5
Epoch: [29][171/704]	Time 0.122	Data 0.001	Loss 6.05	Acc@1 57.8	Acc@5 85.9
Epoch: [29][181/704]	Time 0.122	Data 0.001	Loss 6.65	Acc@1 54.7	Acc@5 84.4
Epoch: [29][191/704]	Time 0.122	Data 0.001	Loss 7.32	Acc@1 53.1	Acc@5 89.1
Epoch: [29][201/704]	Time 0.122	Data 0.001	Loss 6.99	Acc@1 56.2	Acc@5 90.6
Epoch: [29][211/704]	Time 0.122	Data 0.001	Loss 5.18	Acc@1 64.1	Acc@5 90.6
Epoch: [29][221/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 64.1	Acc@5 84.4
Epoch: [29][231/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 68.8	Acc@5 87.5
Epoch: [29][241/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 59.4	Acc@5 87.5
Epoch: [29][251/704]	Time 0.121	Data 0.001	Loss 7.78	Acc@1 53.1	Acc@5 82.8
Epoch: [29][261/704]	Time 0.121	Data 0.001	Loss 6.86	Acc@1 57.8	Acc@5 79.7
Epoch: [29][271/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 65.6	Acc@5 85.9
Epoch: [29][281/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 62.5	Acc@5 87.5
Epoch: [29][291/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 60.9	Acc@5 90.6
Epoch: [29][301/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 70.3	Acc@5 95.3
Epoch: [29][311/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 65.6	Acc@5 84.4
Epoch: [29][321/704]	Time 0.121	Data 0.001	Loss 7.25	Acc@1 50.0	Acc@5 84.4
Epoch: [29][331/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 64.1	Acc@5 90.6
Epoch: [29][341/704]	Time 0.121	Data 0.001	Loss 6.77	Acc@1 54.7	Acc@5 89.1
Epoch: [29][351/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 62.5	Acc@5 87.5
Epoch: [29][361/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 62.5	Acc@5 85.9
Epoch: [29][371/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 46.9	Acc@5 85.9
Epoch: [29][381/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 60.9	Acc@5 87.5
Epoch: [29][391/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 71.9	Acc@5 93.8
Epoch: [29][401/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 60.9	Acc@5 92.2
Epoch: [29][411/704]	Time 0.121	Data 0.001	Loss 7.71	Acc@1 51.6	Acc@5 84.4
Epoch: [29][421/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 70.3	Acc@5 92.2
Epoch: [29][431/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 65.6	Acc@5 92.2
Epoch: [29][441/704]	Time 0.121	Data 0.001	Loss 6.37	Acc@1 60.9	Acc@5 90.6
Epoch: [29][451/704]	Time 0.121	Data 0.001	Loss 7.57	Acc@1 56.2	Acc@5 82.8
Epoch: [29][461/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 65.6	Acc@5 87.5
Epoch: [29][471/704]	Time 0.121	Data 0.001	Loss 6.43	Acc@1 53.1	Acc@5 81.2
Epoch: [29][481/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 67.2	Acc@5 95.3
Epoch: [29][491/704]	Time 0.121	Data 0.001	Loss 8.09	Acc@1 42.2	Acc@5 82.8
Epoch: [29][501/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 57.8	Acc@5 85.9
Epoch: [29][511/704]	Time 0.121	Data 0.001	Loss 6.18	Acc@1 57.8	Acc@5 90.6
Epoch: [29][521/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 57.8	Acc@5 90.6
Epoch: [29][531/704]	Time 0.121	Data 0.001	Loss 7.25	Acc@1 54.7	Acc@5 82.8
Epoch: [29][541/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 59.4	Acc@5 90.6
Epoch: [29][551/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 60.9	Acc@5 89.1
Epoch: [29][561/704]	Time 0.121	Data 0.001	Loss 6.90	Acc@1 60.9	Acc@5 85.9
Epoch: [29][571/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 62.5	Acc@5 90.6
Epoch: [29][581/704]	Time 0.121	Data 0.001	Loss 6.83	Acc@1 56.2	Acc@5 87.5
Epoch: [29][591/704]	Time 0.121	Data 0.001	Loss 6.87	Acc@1 59.4	Acc@5 84.4
Epoch: [29][601/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 70.3	Acc@5 90.6
Epoch: [29][611/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 90.6
Epoch: [29][621/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 65.6	Acc@5 90.6
Epoch: [29][631/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 62.5	Acc@5 89.1
Epoch: [29][641/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 59.4	Acc@5 90.6
Epoch: [29][651/704]	Time 0.121	Data 0.001	Loss 6.87	Acc@1 59.4	Acc@5 85.9
Epoch: [29][661/704]	Time 0.121	Data 0.001	Loss 6.48	Acc@1 50.0	Acc@5 89.1
Epoch: [29][671/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 57.8	Acc@5 90.6
Epoch: [29][681/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 64.1	Acc@5 85.9
Epoch: [29][691/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 56.2	Acc@5 90.6
Epoch: [29][701/704]	Time 0.121	Data 0.001	Loss 7.71	Acc@1 53.1	Acc@5 81.2
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 9.1783	Acc@1 39.0625	Acc@5 78.1250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7019	Acc@1 54.6875	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2642	Acc@1 53.1250	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6759	Acc@1 48.4375	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.2802	Acc@1 56.2500	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.5292	Acc@1 67.1875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4823	Acc@1 57.8125	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.3398	Acc@1 54.6875	Acc@5 84.3750
 * prec@1 44.440 prec@5 75.280
 * prec@1 48.320 prec@5 79.980
 * prec@1 52.720 prec@5 82.520
 * prec@1 53.380 prec@5 82.840
Current best validation last_bloc_accuracy 53.84
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_029.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_029.pth.tar'
Epoch: [30][1/704]	Time 0.298	Data 0.131	Loss 5.93	Acc@1 64.1	Acc@5 93.8
Epoch: [30][11/704]	Time 0.137	Data 0.012	Loss 5.20	Acc@1 62.5	Acc@5 95.3
Epoch: [30][21/704]	Time 0.129	Data 0.007	Loss 6.15	Acc@1 64.1	Acc@5 90.6
Epoch: [30][31/704]	Time 0.126	Data 0.005	Loss 5.92	Acc@1 60.9	Acc@5 87.5
Epoch: [30][41/704]	Time 0.125	Data 0.004	Loss 6.21	Acc@1 65.6	Acc@5 85.9
Epoch: [30][51/704]	Time 0.124	Data 0.003	Loss 6.66	Acc@1 53.1	Acc@5 90.6
Epoch: [30][61/704]	Time 0.123	Data 0.002	Loss 5.35	Acc@1 60.9	Acc@5 90.6
Epoch: [30][71/704]	Time 0.123	Data 0.002	Loss 6.17	Acc@1 62.5	Acc@5 92.2
Epoch: [30][81/704]	Time 0.123	Data 0.002	Loss 5.60	Acc@1 62.5	Acc@5 92.2
Epoch: [30][91/704]	Time 0.123	Data 0.002	Loss 6.52	Acc@1 57.8	Acc@5 87.5
Epoch: [30][101/704]	Time 0.123	Data 0.002	Loss 5.35	Acc@1 71.9	Acc@5 92.2
Epoch: [30][111/704]	Time 0.122	Data 0.002	Loss 7.46	Acc@1 53.1	Acc@5 85.9
Epoch: [30][121/704]	Time 0.122	Data 0.001	Loss 7.28	Acc@1 48.4	Acc@5 82.8
Epoch: [30][131/704]	Time 0.122	Data 0.001	Loss 6.98	Acc@1 60.9	Acc@5 84.4
Epoch: [30][141/704]	Time 0.122	Data 0.001	Loss 5.36	Acc@1 65.6	Acc@5 90.6
Epoch: [30][151/704]	Time 0.122	Data 0.001	Loss 4.51	Acc@1 71.9	Acc@5 95.3
Epoch: [30][161/704]	Time 0.122	Data 0.001	Loss 6.92	Acc@1 50.0	Acc@5 85.9
Epoch: [30][171/704]	Time 0.122	Data 0.001	Loss 5.72	Acc@1 62.5	Acc@5 87.5
Epoch: [30][181/704]	Time 0.122	Data 0.001	Loss 5.61	Acc@1 67.2	Acc@5 92.2
Epoch: [30][191/704]	Time 0.122	Data 0.001	Loss 6.30	Acc@1 60.9	Acc@5 95.3
Epoch: [30][201/704]	Time 0.122	Data 0.001	Loss 7.01	Acc@1 59.4	Acc@5 87.5
Epoch: [30][211/704]	Time 0.122	Data 0.001	Loss 4.90	Acc@1 57.8	Acc@5 93.8
Epoch: [30][221/704]	Time 0.122	Data 0.001	Loss 5.42	Acc@1 59.4	Acc@5 89.1
Epoch: [30][231/704]	Time 0.121	Data 0.001	Loss 6.79	Acc@1 60.9	Acc@5 84.4
Epoch: [30][241/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 92.2
Epoch: [30][251/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 62.5	Acc@5 87.5
Epoch: [30][261/704]	Time 0.121	Data 0.001	Loss 6.78	Acc@1 59.4	Acc@5 85.9
Epoch: [30][271/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 67.2	Acc@5 93.8
Epoch: [30][281/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 65.6	Acc@5 90.6
Epoch: [30][291/704]	Time 0.121	Data 0.001	Loss 7.37	Acc@1 56.2	Acc@5 85.9
Epoch: [30][301/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 68.8	Acc@5 93.8
Epoch: [30][311/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 57.8	Acc@5 89.1
Epoch: [30][321/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 59.4	Acc@5 89.1
Epoch: [30][331/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 60.9	Acc@5 92.2
Epoch: [30][341/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 67.2	Acc@5 90.6
Epoch: [30][351/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 71.9	Acc@5 95.3
Epoch: [30][361/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 65.6	Acc@5 93.8
Epoch: [30][371/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 71.9	Acc@5 85.9
Epoch: [30][381/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 60.9	Acc@5 89.1
Epoch: [30][391/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 64.1	Acc@5 90.6
Epoch: [30][401/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 90.6
Epoch: [30][411/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 70.3	Acc@5 90.6
Epoch: [30][421/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 67.2	Acc@5 89.1
Epoch: [30][431/704]	Time 0.121	Data 0.001	Loss 6.93	Acc@1 60.9	Acc@5 87.5
Epoch: [30][441/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 64.1	Acc@5 90.6
Epoch: [30][451/704]	Time 0.121	Data 0.001	Loss 7.01	Acc@1 56.2	Acc@5 89.1
Epoch: [30][461/704]	Time 0.121	Data 0.001	Loss 6.99	Acc@1 54.7	Acc@5 85.9
Epoch: [30][471/704]	Time 0.121	Data 0.001	Loss 6.28	Acc@1 57.8	Acc@5 82.8
Epoch: [30][481/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 60.9	Acc@5 93.8
Epoch: [30][491/704]	Time 0.121	Data 0.001	Loss 6.73	Acc@1 53.1	Acc@5 85.9
Epoch: [30][501/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 65.6	Acc@5 85.9
Epoch: [30][511/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 64.1	Acc@5 95.3
Epoch: [30][521/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 68.8	Acc@5 92.2
Epoch: [30][531/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 68.8	Acc@5 92.2
Epoch: [30][541/704]	Time 0.121	Data 0.001	Loss 6.93	Acc@1 56.2	Acc@5 82.8
Epoch: [30][551/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 70.3	Acc@5 85.9
Epoch: [30][561/704]	Time 0.121	Data 0.001	Loss 6.91	Acc@1 54.7	Acc@5 85.9
Epoch: [30][571/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 59.4	Acc@5 85.9
Epoch: [30][581/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 59.4	Acc@5 87.5
Epoch: [30][591/704]	Time 0.121	Data 0.001	Loss 6.71	Acc@1 54.7	Acc@5 89.1
Epoch: [30][601/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 65.6	Acc@5 90.6
Epoch: [30][611/704]	Time 0.121	Data 0.001	Loss 6.75	Acc@1 62.5	Acc@5 87.5
Epoch: [30][621/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 93.8
Epoch: [30][631/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 62.5	Acc@5 85.9
Epoch: [30][641/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 68.8	Acc@5 89.1
Epoch: [30][651/704]	Time 0.121	Data 0.001	Loss 6.75	Acc@1 57.8	Acc@5 87.5
Epoch: [30][661/704]	Time 0.121	Data 0.001	Loss 6.55	Acc@1 56.2	Acc@5 90.6
Epoch: [30][671/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 68.8	Acc@5 89.1
Epoch: [30][681/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 59.4	Acc@5 81.2
Epoch: [30][691/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 60.9	Acc@5 87.5
Epoch: [30][701/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 64.1	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.9478	Acc@1 48.4375	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.6182	Acc@1 62.5000	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.0596	Acc@1 50.0000	Acc@5 76.5625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.1886	Acc@1 43.7500	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7858	Acc@1 62.5000	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 9.0580	Acc@1 43.7500	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.0295	Acc@1 56.2500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9476	Acc@1 60.9375	Acc@5 92.1875
 * prec@1 43.340 prec@5 74.380
 * prec@1 48.740 prec@5 78.960
 * prec@1 52.700 prec@5 83.420
 * prec@1 55.040 prec@5 83.660
New best validation last_bloc_accuracy 55.04
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_030.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_030.pth.tar'
Epoch: [31][1/704]	Time 0.300	Data 0.132	Loss 4.88	Acc@1 70.3	Acc@5 89.1
Epoch: [31][11/704]	Time 0.141	Data 0.012	Loss 6.01	Acc@1 60.9	Acc@5 90.6
Epoch: [31][21/704]	Time 0.131	Data 0.007	Loss 6.68	Acc@1 57.8	Acc@5 85.9
Epoch: [31][31/704]	Time 0.128	Data 0.005	Loss 6.24	Acc@1 54.7	Acc@5 79.7
Epoch: [31][41/704]	Time 0.126	Data 0.004	Loss 5.94	Acc@1 57.8	Acc@5 92.2
Epoch: [31][51/704]	Time 0.125	Data 0.003	Loss 5.83	Acc@1 67.2	Acc@5 92.2
Epoch: [31][61/704]	Time 0.124	Data 0.003	Loss 7.74	Acc@1 54.7	Acc@5 84.4
Epoch: [31][71/704]	Time 0.124	Data 0.002	Loss 6.28	Acc@1 57.8	Acc@5 85.9
Epoch: [31][81/704]	Time 0.123	Data 0.002	Loss 5.14	Acc@1 67.2	Acc@5 95.3
Epoch: [31][91/704]	Time 0.123	Data 0.002	Loss 5.98	Acc@1 67.2	Acc@5 90.6
Epoch: [31][101/704]	Time 0.123	Data 0.002	Loss 5.99	Acc@1 57.8	Acc@5 85.9
Epoch: [31][111/704]	Time 0.123	Data 0.002	Loss 5.65	Acc@1 59.4	Acc@5 89.1
Epoch: [31][121/704]	Time 0.122	Data 0.001	Loss 5.28	Acc@1 73.4	Acc@5 96.9
Epoch: [31][131/704]	Time 0.122	Data 0.001	Loss 6.25	Acc@1 59.4	Acc@5 85.9
Epoch: [31][141/704]	Time 0.122	Data 0.001	Loss 6.70	Acc@1 62.5	Acc@5 87.5
Epoch: [31][151/704]	Time 0.122	Data 0.001	Loss 5.44	Acc@1 73.4	Acc@5 89.1
Epoch: [31][161/704]	Time 0.122	Data 0.001	Loss 6.01	Acc@1 67.2	Acc@5 90.6
Epoch: [31][171/704]	Time 0.122	Data 0.001	Loss 6.73	Acc@1 57.8	Acc@5 90.6
Epoch: [31][181/704]	Time 0.122	Data 0.001	Loss 5.78	Acc@1 60.9	Acc@5 90.6
Epoch: [31][191/704]	Time 0.122	Data 0.001	Loss 5.60	Acc@1 67.2	Acc@5 89.1
Epoch: [31][201/704]	Time 0.122	Data 0.001	Loss 6.10	Acc@1 64.1	Acc@5 89.1
Epoch: [31][211/704]	Time 0.122	Data 0.001	Loss 6.02	Acc@1 64.1	Acc@5 89.1
Epoch: [31][221/704]	Time 0.122	Data 0.001	Loss 5.23	Acc@1 65.6	Acc@5 96.9
Epoch: [31][231/704]	Time 0.122	Data 0.001	Loss 5.46	Acc@1 68.8	Acc@5 93.8
Epoch: [31][241/704]	Time 0.122	Data 0.001	Loss 7.09	Acc@1 53.1	Acc@5 89.1
Epoch: [31][251/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 53.1	Acc@5 84.4
Epoch: [31][261/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 62.5	Acc@5 89.1
Epoch: [31][271/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 59.4	Acc@5 89.1
Epoch: [31][281/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 57.8	Acc@5 96.9
Epoch: [31][291/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 68.8	Acc@5 95.3
Epoch: [31][301/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 68.8	Acc@5 90.6
Epoch: [31][311/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 70.3	Acc@5 93.8
Epoch: [31][321/704]	Time 0.121	Data 0.001	Loss 6.73	Acc@1 60.9	Acc@5 90.6
Epoch: [31][331/704]	Time 0.121	Data 0.001	Loss 6.54	Acc@1 48.4	Acc@5 90.6
Epoch: [31][341/704]	Time 0.121	Data 0.001	Loss 6.26	Acc@1 62.5	Acc@5 90.6
Epoch: [31][351/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 60.9	Acc@5 85.9
Epoch: [31][361/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 60.9	Acc@5 84.4
Epoch: [31][371/704]	Time 0.121	Data 0.001	Loss 6.98	Acc@1 54.7	Acc@5 90.6
Epoch: [31][381/704]	Time 0.121	Data 0.001	Loss 6.59	Acc@1 56.2	Acc@5 87.5
Epoch: [31][391/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 64.1	Acc@5 89.1
Epoch: [31][401/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 65.6	Acc@5 89.1
Epoch: [31][411/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 60.9	Acc@5 84.4
Epoch: [31][421/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 53.1	Acc@5 84.4
Epoch: [31][431/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 67.2	Acc@5 89.1
Epoch: [31][441/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 68.8	Acc@5 85.9
Epoch: [31][451/704]	Time 0.121	Data 0.001	Loss 7.57	Acc@1 57.8	Acc@5 78.1
Epoch: [31][461/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 65.6	Acc@5 90.6
Epoch: [31][471/704]	Time 0.121	Data 0.001	Loss 6.57	Acc@1 54.7	Acc@5 85.9
Epoch: [31][481/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 64.1	Acc@5 90.6
Epoch: [31][491/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 60.9	Acc@5 92.2
Epoch: [31][501/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 62.5	Acc@5 89.1
Epoch: [31][511/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 56.2	Acc@5 89.1
Epoch: [31][521/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 67.2	Acc@5 96.9
Epoch: [31][531/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 64.1	Acc@5 95.3
Epoch: [31][541/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 64.1	Acc@5 93.8
Epoch: [31][551/704]	Time 0.121	Data 0.001	Loss 6.54	Acc@1 56.2	Acc@5 87.5
Epoch: [31][561/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 84.4
Epoch: [31][571/704]	Time 0.121	Data 0.001	Loss 7.18	Acc@1 54.7	Acc@5 85.9
Epoch: [31][581/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 56.2	Acc@5 85.9
Epoch: [31][591/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 57.8	Acc@5 90.6
Epoch: [31][601/704]	Time 0.121	Data 0.001	Loss 6.86	Acc@1 56.2	Acc@5 85.9
Epoch: [31][611/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 78.1	Acc@5 90.6
Epoch: [31][621/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 73.4	Acc@5 89.1
Epoch: [31][631/704]	Time 0.121	Data 0.001	Loss 6.86	Acc@1 48.4	Acc@5 92.2
Epoch: [31][641/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 64.1	Acc@5 85.9
Epoch: [31][651/704]	Time 0.121	Data 0.001	Loss 8.06	Acc@1 64.1	Acc@5 82.8
Epoch: [31][661/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 62.5	Acc@5 92.2
Epoch: [31][671/704]	Time 0.121	Data 0.001	Loss 6.68	Acc@1 59.4	Acc@5 89.1
Epoch: [31][681/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 67.2	Acc@5 84.4
Epoch: [31][691/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 90.6
Epoch: [31][701/704]	Time 0.121	Data 0.001	Loss 7.36	Acc@1 46.9	Acc@5 78.1
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.6897	Acc@1 53.1250	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.9349	Acc@1 50.0000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.7792	Acc@1 54.6875	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 9.7260	Acc@1 42.1875	Acc@5 78.1250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 9.3720	Acc@1 35.9375	Acc@5 76.5625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.8583	Acc@1 60.9375	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.1675	Acc@1 48.4375	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.6718	Acc@1 54.6875	Acc@5 79.6875
 * prec@1 45.100 prec@5 76.520
 * prec@1 50.320 prec@5 80.760
 * prec@1 53.140 prec@5 83.160
 * prec@1 53.660 prec@5 83.820
Current best validation last_bloc_accuracy 55.04
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_031.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_031.pth.tar'
Epoch: [32][1/704]	Time 0.330	Data 0.163	Loss 5.87	Acc@1 68.8	Acc@5 90.6
Epoch: [32][11/704]	Time 0.139	Data 0.015	Loss 6.30	Acc@1 62.5	Acc@5 95.3
Epoch: [32][21/704]	Time 0.130	Data 0.008	Loss 5.07	Acc@1 67.2	Acc@5 93.8
Epoch: [32][31/704]	Time 0.127	Data 0.006	Loss 5.84	Acc@1 68.8	Acc@5 90.6
Epoch: [32][41/704]	Time 0.125	Data 0.004	Loss 4.95	Acc@1 67.2	Acc@5 89.1
Epoch: [32][51/704]	Time 0.124	Data 0.004	Loss 6.12	Acc@1 57.8	Acc@5 84.4
Epoch: [32][61/704]	Time 0.124	Data 0.003	Loss 5.09	Acc@1 71.9	Acc@5 90.6
Epoch: [32][71/704]	Time 0.123	Data 0.003	Loss 5.95	Acc@1 62.5	Acc@5 87.5
Epoch: [32][81/704]	Time 0.123	Data 0.002	Loss 6.95	Acc@1 54.7	Acc@5 89.1
Epoch: [32][91/704]	Time 0.123	Data 0.002	Loss 6.72	Acc@1 62.5	Acc@5 85.9
Epoch: [32][101/704]	Time 0.122	Data 0.002	Loss 5.00	Acc@1 70.3	Acc@5 95.3
Epoch: [32][111/704]	Time 0.122	Data 0.002	Loss 5.61	Acc@1 64.1	Acc@5 93.8
Epoch: [32][121/704]	Time 0.122	Data 0.002	Loss 7.64	Acc@1 59.4	Acc@5 82.8
Epoch: [32][131/704]	Time 0.122	Data 0.002	Loss 6.43	Acc@1 65.6	Acc@5 84.4
Epoch: [32][141/704]	Time 0.122	Data 0.001	Loss 6.26	Acc@1 64.1	Acc@5 87.5
Epoch: [32][151/704]	Time 0.122	Data 0.001	Loss 5.51	Acc@1 62.5	Acc@5 85.9
Epoch: [32][161/704]	Time 0.122	Data 0.001	Loss 3.69	Acc@1 75.0	Acc@5 98.4
Epoch: [32][171/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 65.6	Acc@5 85.9
Epoch: [32][181/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 93.8
Epoch: [32][191/704]	Time 0.121	Data 0.001	Loss 7.07	Acc@1 53.1	Acc@5 85.9
Epoch: [32][201/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 62.5	Acc@5 89.1
Epoch: [32][211/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 68.8	Acc@5 87.5
Epoch: [32][221/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 60.9	Acc@5 92.2
Epoch: [32][231/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 65.6	Acc@5 90.6
Epoch: [32][241/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 64.1	Acc@5 90.6
Epoch: [32][251/704]	Time 0.121	Data 0.001	Loss 6.97	Acc@1 64.1	Acc@5 90.6
Epoch: [32][261/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 56.2	Acc@5 90.6
Epoch: [32][271/704]	Time 0.121	Data 0.001	Loss 7.22	Acc@1 56.2	Acc@5 82.8
Epoch: [32][281/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 71.9	Acc@5 92.2
Epoch: [32][291/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 64.1	Acc@5 87.5
Epoch: [32][301/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 70.3	Acc@5 92.2
Epoch: [32][311/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 57.8	Acc@5 87.5
Epoch: [32][321/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 60.9	Acc@5 90.6
Epoch: [32][331/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 60.9	Acc@5 89.1
Epoch: [32][341/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 67.2	Acc@5 90.6
Epoch: [32][351/704]	Time 0.121	Data 0.001	Loss 7.44	Acc@1 48.4	Acc@5 82.8
Epoch: [32][361/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 62.5	Acc@5 90.6
Epoch: [32][371/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 75.0	Acc@5 90.6
Epoch: [32][381/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 67.2	Acc@5 95.3
Epoch: [32][391/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 62.5	Acc@5 82.8
Epoch: [32][401/704]	Time 0.121	Data 0.001	Loss 6.60	Acc@1 56.2	Acc@5 89.1
Epoch: [32][411/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 56.2	Acc@5 89.1
Epoch: [32][421/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 65.6	Acc@5 89.1
Epoch: [32][431/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 68.8	Acc@5 89.1
Epoch: [32][441/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 60.9	Acc@5 92.2
Epoch: [32][451/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 71.9	Acc@5 89.1
Epoch: [32][461/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 51.6	Acc@5 90.6
Epoch: [32][471/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 64.1	Acc@5 89.1
Epoch: [32][481/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 62.5	Acc@5 90.6
Epoch: [32][491/704]	Time 0.121	Data 0.001	Loss 6.66	Acc@1 54.7	Acc@5 87.5
Epoch: [32][501/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 62.5	Acc@5 89.1
Epoch: [32][511/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 57.8	Acc@5 92.2
Epoch: [32][521/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 62.5	Acc@5 95.3
Epoch: [32][531/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 56.2	Acc@5 85.9
Epoch: [32][541/704]	Time 0.121	Data 0.001	Loss 7.50	Acc@1 56.2	Acc@5 84.4
Epoch: [32][551/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 54.7	Acc@5 89.1
Epoch: [32][561/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 67.2	Acc@5 93.8
Epoch: [32][571/704]	Time 0.121	Data 0.001	Loss 6.57	Acc@1 57.8	Acc@5 84.4
Epoch: [32][581/704]	Time 0.121	Data 0.001	Loss 7.16	Acc@1 60.9	Acc@5 81.2
Epoch: [32][591/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 60.9	Acc@5 89.1
Epoch: [32][601/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 62.5	Acc@5 87.5
Epoch: [32][611/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 54.7	Acc@5 82.8
Epoch: [32][621/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 59.4	Acc@5 92.2
Epoch: [32][631/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 56.2	Acc@5 92.2
Epoch: [32][641/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 71.9	Acc@5 89.1
Epoch: [32][651/704]	Time 0.121	Data 0.001	Loss 6.42	Acc@1 67.2	Acc@5 89.1
Epoch: [32][661/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 54.7	Acc@5 89.1
Epoch: [32][671/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 68.8	Acc@5 87.5
Epoch: [32][681/704]	Time 0.121	Data 0.001	Loss 6.65	Acc@1 62.5	Acc@5 87.5
Epoch: [32][691/704]	Time 0.121	Data 0.001	Loss 6.68	Acc@1 53.1	Acc@5 82.8
Epoch: [32][701/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 62.5	Acc@5 85.9
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.9662	Acc@1 43.7500	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0621	Acc@1 48.4375	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.7058	Acc@1 43.7500	Acc@5 78.1250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.4645	Acc@1 48.4375	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.8741	Acc@1 46.8750	Acc@5 75.0000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.5256	Acc@1 53.1250	Acc@5 76.5625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.9218	Acc@1 46.8750	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 9.3286	Acc@1 50.0000	Acc@5 76.5625
 * prec@1 43.660 prec@5 74.840
 * prec@1 47.880 prec@5 79.300
 * prec@1 51.180 prec@5 82.280
 * prec@1 51.720 prec@5 82.400
Current best validation last_bloc_accuracy 55.04
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_032.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_032.pth.tar'
Epoch: [33][1/704]	Time 0.298	Data 0.132	Loss 7.64	Acc@1 42.2	Acc@5 81.2
Epoch: [33][11/704]	Time 0.136	Data 0.012	Loss 6.30	Acc@1 56.2	Acc@5 89.1
Epoch: [33][21/704]	Time 0.128	Data 0.007	Loss 5.67	Acc@1 71.9	Acc@5 92.2
Epoch: [33][31/704]	Time 0.125	Data 0.005	Loss 6.01	Acc@1 65.6	Acc@5 90.6
Epoch: [33][41/704]	Time 0.124	Data 0.004	Loss 6.08	Acc@1 60.9	Acc@5 90.6
Epoch: [33][51/704]	Time 0.123	Data 0.003	Loss 4.74	Acc@1 76.6	Acc@5 90.6
Epoch: [33][61/704]	Time 0.122	Data 0.002	Loss 4.28	Acc@1 79.7	Acc@5 95.3
Epoch: [33][71/704]	Time 0.122	Data 0.002	Loss 6.75	Acc@1 57.8	Acc@5 85.9
Epoch: [33][81/704]	Time 0.122	Data 0.002	Loss 5.97	Acc@1 67.2	Acc@5 90.6
Epoch: [33][91/704]	Time 0.121	Data 0.002	Loss 6.39	Acc@1 57.8	Acc@5 89.1
Epoch: [33][101/704]	Time 0.121	Data 0.002	Loss 5.31	Acc@1 68.8	Acc@5 92.2
Epoch: [33][111/704]	Time 0.121	Data 0.002	Loss 5.64	Acc@1 67.2	Acc@5 93.8
Epoch: [33][121/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 60.9	Acc@5 92.2
Epoch: [33][131/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 56.2	Acc@5 90.6
Epoch: [33][141/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 65.6	Acc@5 90.6
Epoch: [33][151/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 90.6
Epoch: [33][161/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 70.3	Acc@5 93.8
Epoch: [33][171/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 78.1	Acc@5 95.3
Epoch: [33][181/704]	Time 0.121	Data 0.001	Loss 7.47	Acc@1 51.6	Acc@5 85.9
Epoch: [33][191/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 65.6	Acc@5 95.3
Epoch: [33][201/704]	Time 0.121	Data 0.001	Loss 6.18	Acc@1 57.8	Acc@5 90.6
Epoch: [33][211/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 68.8	Acc@5 84.4
Epoch: [33][221/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 67.2	Acc@5 87.5
Epoch: [33][231/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 57.8	Acc@5 87.5
Epoch: [33][241/704]	Time 0.120	Data 0.001	Loss 6.33	Acc@1 54.7	Acc@5 79.7
Epoch: [33][251/704]	Time 0.120	Data 0.001	Loss 6.80	Acc@1 59.4	Acc@5 85.9
Epoch: [33][261/704]	Time 0.120	Data 0.001	Loss 4.79	Acc@1 57.8	Acc@5 92.2
Epoch: [33][271/704]	Time 0.120	Data 0.001	Loss 6.05	Acc@1 62.5	Acc@5 89.1
Epoch: [33][281/704]	Time 0.120	Data 0.001	Loss 8.16	Acc@1 53.1	Acc@5 84.4
Epoch: [33][291/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 62.5	Acc@5 92.2
Epoch: [33][301/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 68.8	Acc@5 87.5
Epoch: [33][311/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 64.1	Acc@5 85.9
Epoch: [33][321/704]	Time 0.120	Data 0.001	Loss 6.42	Acc@1 57.8	Acc@5 89.1
Epoch: [33][331/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 57.8	Acc@5 90.6
Epoch: [33][341/704]	Time 0.120	Data 0.001	Loss 6.01	Acc@1 57.8	Acc@5 89.1
Epoch: [33][351/704]	Time 0.120	Data 0.001	Loss 6.81	Acc@1 62.5	Acc@5 89.1
Epoch: [33][361/704]	Time 0.120	Data 0.001	Loss 6.17	Acc@1 60.9	Acc@5 87.5
Epoch: [33][371/704]	Time 0.120	Data 0.001	Loss 4.58	Acc@1 67.2	Acc@5 95.3
Epoch: [33][381/704]	Time 0.120	Data 0.001	Loss 7.14	Acc@1 56.2	Acc@5 89.1
Epoch: [33][391/704]	Time 0.120	Data 0.001	Loss 6.26	Acc@1 64.1	Acc@5 89.1
Epoch: [33][401/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 53.1	Acc@5 84.4
Epoch: [33][411/704]	Time 0.120	Data 0.001	Loss 6.29	Acc@1 59.4	Acc@5 90.6
Epoch: [33][421/704]	Time 0.120	Data 0.001	Loss 6.46	Acc@1 48.4	Acc@5 87.5
Epoch: [33][431/704]	Time 0.120	Data 0.001	Loss 6.23	Acc@1 68.8	Acc@5 87.5
Epoch: [33][441/704]	Time 0.120	Data 0.001	Loss 6.95	Acc@1 54.7	Acc@5 89.1
Epoch: [33][451/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 62.5	Acc@5 90.6
Epoch: [33][461/704]	Time 0.120	Data 0.001	Loss 6.53	Acc@1 60.9	Acc@5 84.4
Epoch: [33][471/704]	Time 0.120	Data 0.001	Loss 5.03	Acc@1 60.9	Acc@5 92.2
Epoch: [33][481/704]	Time 0.120	Data 0.001	Loss 7.39	Acc@1 60.9	Acc@5 87.5
Epoch: [33][491/704]	Time 0.120	Data 0.001	Loss 7.22	Acc@1 60.9	Acc@5 84.4
Epoch: [33][501/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 68.8	Acc@5 93.8
Epoch: [33][511/704]	Time 0.120	Data 0.001	Loss 6.11	Acc@1 54.7	Acc@5 90.6
Epoch: [33][521/704]	Time 0.120	Data 0.001	Loss 6.53	Acc@1 62.5	Acc@5 87.5
Epoch: [33][531/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 68.8	Acc@5 87.5
Epoch: [33][541/704]	Time 0.120	Data 0.001	Loss 6.90	Acc@1 62.5	Acc@5 85.9
Epoch: [33][551/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 56.2	Acc@5 79.7
Epoch: [33][561/704]	Time 0.120	Data 0.001	Loss 7.37	Acc@1 53.1	Acc@5 85.9
Epoch: [33][571/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 60.9	Acc@5 93.8
Epoch: [33][581/704]	Time 0.120	Data 0.001	Loss 6.15	Acc@1 59.4	Acc@5 90.6
Epoch: [33][591/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 59.4	Acc@5 90.6
Epoch: [33][601/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 68.8	Acc@5 89.1
Epoch: [33][611/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 62.5	Acc@5 85.9
Epoch: [33][621/704]	Time 0.120	Data 0.001	Loss 7.29	Acc@1 50.0	Acc@5 89.1
Epoch: [33][631/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 67.2	Acc@5 90.6
Epoch: [33][641/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 64.1	Acc@5 89.1
Epoch: [33][651/704]	Time 0.120	Data 0.001	Loss 4.79	Acc@1 70.3	Acc@5 90.6
Epoch: [33][661/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 62.5	Acc@5 96.9
Epoch: [33][671/704]	Time 0.120	Data 0.001	Loss 6.27	Acc@1 62.5	Acc@5 92.2
Epoch: [33][681/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 57.8	Acc@5 87.5
Epoch: [33][691/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 64.1	Acc@5 95.3
Epoch: [33][701/704]	Time 0.120	Data 0.001	Loss 7.60	Acc@1 51.6	Acc@5 84.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.5115	Acc@1 51.5625	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.5437	Acc@1 56.2500	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7336	Acc@1 59.3750	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0754	Acc@1 48.4375	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7398	Acc@1 54.6875	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.5684	Acc@1 51.5625	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.2729	Acc@1 54.6875	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.3610	Acc@1 54.6875	Acc@5 78.1250
 * prec@1 45.180 prec@5 77.260
 * prec@1 49.540 prec@5 80.380
 * prec@1 52.720 prec@5 83.000
 * prec@1 54.800 prec@5 84.620
Current best validation last_bloc_accuracy 55.04
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_033.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_033.pth.tar'
Epoch: [34][1/704]	Time 0.296	Data 0.129	Loss 4.72	Acc@1 60.9	Acc@5 92.2
Epoch: [34][11/704]	Time 0.136	Data 0.012	Loss 6.77	Acc@1 57.8	Acc@5 89.1
Epoch: [34][21/704]	Time 0.129	Data 0.006	Loss 5.49	Acc@1 62.5	Acc@5 92.2
Epoch: [34][31/704]	Time 0.126	Data 0.004	Loss 4.63	Acc@1 64.1	Acc@5 92.2
Epoch: [34][41/704]	Time 0.125	Data 0.003	Loss 5.54	Acc@1 62.5	Acc@5 89.1
Epoch: [34][51/704]	Time 0.124	Data 0.003	Loss 5.16	Acc@1 67.2	Acc@5 90.6
Epoch: [34][61/704]	Time 0.124	Data 0.002	Loss 5.99	Acc@1 57.8	Acc@5 93.8
Epoch: [34][71/704]	Time 0.123	Data 0.002	Loss 5.27	Acc@1 65.6	Acc@5 93.8
Epoch: [34][81/704]	Time 0.123	Data 0.002	Loss 5.10	Acc@1 64.1	Acc@5 92.2
Epoch: [34][91/704]	Time 0.123	Data 0.002	Loss 6.15	Acc@1 59.4	Acc@5 95.3
Epoch: [34][101/704]	Time 0.122	Data 0.002	Loss 6.09	Acc@1 60.9	Acc@5 92.2
Epoch: [34][111/704]	Time 0.122	Data 0.001	Loss 5.39	Acc@1 57.8	Acc@5 89.1
Epoch: [34][121/704]	Time 0.122	Data 0.001	Loss 6.11	Acc@1 64.1	Acc@5 92.2
Epoch: [34][131/704]	Time 0.122	Data 0.001	Loss 6.68	Acc@1 51.6	Acc@5 92.2
Epoch: [34][141/704]	Time 0.122	Data 0.001	Loss 6.51	Acc@1 62.5	Acc@5 87.5
Epoch: [34][151/704]	Time 0.122	Data 0.001	Loss 5.94	Acc@1 60.9	Acc@5 90.6
Epoch: [34][161/704]	Time 0.122	Data 0.001	Loss 5.35	Acc@1 67.2	Acc@5 84.4
Epoch: [34][171/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 64.1	Acc@5 92.2
Epoch: [34][181/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 75.0	Acc@5 93.8
Epoch: [34][191/704]	Time 0.121	Data 0.001	Loss 6.50	Acc@1 51.6	Acc@5 89.1
Epoch: [34][201/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 68.8	Acc@5 92.2
Epoch: [34][211/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 64.1	Acc@5 89.1
Epoch: [34][221/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 68.8	Acc@5 92.2
Epoch: [34][231/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 57.8	Acc@5 82.8
Epoch: [34][241/704]	Time 0.121	Data 0.001	Loss 7.27	Acc@1 62.5	Acc@5 85.9
Epoch: [34][251/704]	Time 0.121	Data 0.001	Loss 6.41	Acc@1 64.1	Acc@5 89.1
Epoch: [34][261/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 64.1	Acc@5 92.2
Epoch: [34][271/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 75.0	Acc@5 93.8
Epoch: [34][281/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 64.1	Acc@5 85.9
Epoch: [34][291/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 64.1	Acc@5 93.8
Epoch: [34][301/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 67.2	Acc@5 93.8
Epoch: [34][311/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 76.6	Acc@5 95.3
Epoch: [34][321/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 65.6	Acc@5 87.5
Epoch: [34][331/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 93.8
Epoch: [34][341/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 60.9	Acc@5 87.5
Epoch: [34][351/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 56.2	Acc@5 95.3
Epoch: [34][361/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 64.1	Acc@5 92.2
Epoch: [34][371/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 65.6	Acc@5 90.6
Epoch: [34][381/704]	Time 0.120	Data 0.001	Loss 6.89	Acc@1 59.4	Acc@5 82.8
Epoch: [34][391/704]	Time 0.120	Data 0.001	Loss 6.27	Acc@1 62.5	Acc@5 96.9
Epoch: [34][401/704]	Time 0.120	Data 0.001	Loss 5.57	Acc@1 59.4	Acc@5 87.5
Epoch: [34][411/704]	Time 0.120	Data 0.001	Loss 4.96	Acc@1 70.3	Acc@5 93.8
Epoch: [34][421/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 90.6
Epoch: [34][431/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 62.5	Acc@5 90.6
Epoch: [34][441/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 70.3	Acc@5 87.5
Epoch: [34][451/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 70.3	Acc@5 87.5
Epoch: [34][461/704]	Time 0.120	Data 0.001	Loss 6.37	Acc@1 54.7	Acc@5 95.3
Epoch: [34][471/704]	Time 0.120	Data 0.001	Loss 4.77	Acc@1 65.6	Acc@5 92.2
Epoch: [34][481/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 68.8	Acc@5 85.9
Epoch: [34][491/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 67.2	Acc@5 92.2
Epoch: [34][501/704]	Time 0.120	Data 0.001	Loss 5.76	Acc@1 60.9	Acc@5 93.8
Epoch: [34][511/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 76.6	Acc@5 90.6
Epoch: [34][521/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 67.2	Acc@5 90.6
Epoch: [34][531/704]	Time 0.120	Data 0.001	Loss 6.27	Acc@1 60.9	Acc@5 96.9
Epoch: [34][541/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 60.9	Acc@5 82.8
Epoch: [34][551/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 62.5	Acc@5 89.1
Epoch: [34][561/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 53.1	Acc@5 92.2
Epoch: [34][571/704]	Time 0.120	Data 0.001	Loss 5.46	Acc@1 65.6	Acc@5 92.2
Epoch: [34][581/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 62.5	Acc@5 90.6
Epoch: [34][591/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 64.1	Acc@5 87.5
Epoch: [34][601/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 62.5	Acc@5 85.9
Epoch: [34][611/704]	Time 0.120	Data 0.001	Loss 5.91	Acc@1 64.1	Acc@5 89.1
Epoch: [34][621/704]	Time 0.120	Data 0.001	Loss 4.63	Acc@1 75.0	Acc@5 93.8
Epoch: [34][631/704]	Time 0.120	Data 0.001	Loss 4.82	Acc@1 73.4	Acc@5 89.1
Epoch: [34][641/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 56.2	Acc@5 90.6
Epoch: [34][651/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 60.9	Acc@5 87.5
Epoch: [34][661/704]	Time 0.120	Data 0.001	Loss 6.29	Acc@1 50.0	Acc@5 93.8
Epoch: [34][671/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 68.8	Acc@5 89.1
Epoch: [34][681/704]	Time 0.120	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 93.8
Epoch: [34][691/704]	Time 0.120	Data 0.001	Loss 5.46	Acc@1 62.5	Acc@5 90.6
Epoch: [34][701/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 59.4	Acc@5 87.5
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.2267	Acc@1 50.0000	Acc@5 79.6875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.0383	Acc@1 62.5000	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.7208	Acc@1 53.1250	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.4124	Acc@1 60.9375	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6425	Acc@1 64.0625	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.3727	Acc@1 51.5625	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.5907	Acc@1 51.5625	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.0113	Acc@1 56.2500	Acc@5 78.1250
 * prec@1 45.180 prec@5 76.940
 * prec@1 50.020 prec@5 80.860
 * prec@1 54.580 prec@5 83.660
 * prec@1 55.260 prec@5 84.360
New best validation last_bloc_accuracy 55.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_034.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_034.pth.tar'
Epoch: [35][1/704]	Time 0.330	Data 0.164	Loss 6.39	Acc@1 62.5	Acc@5 93.8
Epoch: [35][11/704]	Time 0.139	Data 0.015	Loss 6.10	Acc@1 60.9	Acc@5 92.2
Epoch: [35][21/704]	Time 0.130	Data 0.008	Loss 5.09	Acc@1 71.9	Acc@5 90.6
Epoch: [35][31/704]	Time 0.126	Data 0.006	Loss 5.51	Acc@1 65.6	Acc@5 89.1
Epoch: [35][41/704]	Time 0.125	Data 0.004	Loss 5.62	Acc@1 70.3	Acc@5 93.8
Epoch: [35][51/704]	Time 0.124	Data 0.004	Loss 6.40	Acc@1 57.8	Acc@5 87.5
Epoch: [35][61/704]	Time 0.123	Data 0.003	Loss 5.46	Acc@1 64.1	Acc@5 92.2
Epoch: [35][71/704]	Time 0.123	Data 0.003	Loss 6.02	Acc@1 59.4	Acc@5 90.6
Epoch: [35][81/704]	Time 0.122	Data 0.002	Loss 5.90	Acc@1 64.1	Acc@5 92.2
Epoch: [35][91/704]	Time 0.122	Data 0.002	Loss 6.27	Acc@1 60.9	Acc@5 90.6
Epoch: [35][101/704]	Time 0.122	Data 0.002	Loss 5.13	Acc@1 65.6	Acc@5 90.6
Epoch: [35][111/704]	Time 0.122	Data 0.002	Loss 6.00	Acc@1 60.9	Acc@5 90.6
Epoch: [35][121/704]	Time 0.121	Data 0.002	Loss 6.22	Acc@1 56.2	Acc@5 95.3
Epoch: [35][131/704]	Time 0.121	Data 0.002	Loss 5.67	Acc@1 60.9	Acc@5 92.2
Epoch: [35][141/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 67.2	Acc@5 87.5
Epoch: [35][151/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 67.2	Acc@5 90.6
Epoch: [35][161/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 65.6	Acc@5 93.8
Epoch: [35][171/704]	Time 0.121	Data 0.001	Loss 6.48	Acc@1 65.6	Acc@5 81.2
Epoch: [35][181/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 67.2	Acc@5 81.2
Epoch: [35][191/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 70.3	Acc@5 90.6
Epoch: [35][201/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 57.8	Acc@5 90.6
Epoch: [35][211/704]	Time 0.120	Data 0.001	Loss 6.39	Acc@1 57.8	Acc@5 89.1
Epoch: [35][221/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 95.3
Epoch: [35][231/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 48.4	Acc@5 84.4
Epoch: [35][241/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 62.5	Acc@5 85.9
Epoch: [35][251/704]	Time 0.120	Data 0.001	Loss 6.95	Acc@1 65.6	Acc@5 79.7
Epoch: [35][261/704]	Time 0.120	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 92.2
Epoch: [35][271/704]	Time 0.120	Data 0.001	Loss 6.87	Acc@1 53.1	Acc@5 87.5
Epoch: [35][281/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 53.1	Acc@5 89.1
Epoch: [35][291/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 73.4	Acc@5 90.6
Epoch: [35][301/704]	Time 0.120	Data 0.001	Loss 4.38	Acc@1 71.9	Acc@5 95.3
Epoch: [35][311/704]	Time 0.120	Data 0.001	Loss 6.76	Acc@1 60.9	Acc@5 81.2
Epoch: [35][321/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 70.3	Acc@5 93.8
Epoch: [35][331/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 67.2	Acc@5 93.8
Epoch: [35][341/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 60.9	Acc@5 82.8
Epoch: [35][351/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 65.6	Acc@5 85.9
Epoch: [35][361/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 67.2	Acc@5 92.2
Epoch: [35][371/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 65.6	Acc@5 90.6
Epoch: [35][381/704]	Time 0.120	Data 0.001	Loss 6.47	Acc@1 56.2	Acc@5 85.9
Epoch: [35][391/704]	Time 0.120	Data 0.001	Loss 6.99	Acc@1 51.6	Acc@5 81.2
Epoch: [35][401/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 57.8	Acc@5 89.1
Epoch: [35][411/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 75.0	Acc@5 92.2
Epoch: [35][421/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 59.4	Acc@5 87.5
Epoch: [35][431/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 64.1	Acc@5 90.6
Epoch: [35][441/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 67.2	Acc@5 95.3
Epoch: [35][451/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 67.2	Acc@5 89.1
Epoch: [35][461/704]	Time 0.120	Data 0.001	Loss 6.03	Acc@1 57.8	Acc@5 93.8
Epoch: [35][471/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 64.1	Acc@5 92.2
Epoch: [35][481/704]	Time 0.120	Data 0.001	Loss 5.91	Acc@1 64.1	Acc@5 90.6
Epoch: [35][491/704]	Time 0.120	Data 0.001	Loss 6.33	Acc@1 60.9	Acc@5 90.6
Epoch: [35][501/704]	Time 0.120	Data 0.001	Loss 6.14	Acc@1 62.5	Acc@5 95.3
Epoch: [35][511/704]	Time 0.120	Data 0.001	Loss 7.00	Acc@1 59.4	Acc@5 87.5
Epoch: [35][521/704]	Time 0.120	Data 0.001	Loss 5.45	Acc@1 62.5	Acc@5 89.1
Epoch: [35][531/704]	Time 0.120	Data 0.001	Loss 5.09	Acc@1 68.8	Acc@5 93.8
Epoch: [35][541/704]	Time 0.120	Data 0.001	Loss 5.42	Acc@1 68.8	Acc@5 93.8
Epoch: [35][551/704]	Time 0.120	Data 0.001	Loss 6.76	Acc@1 57.8	Acc@5 90.6
Epoch: [35][561/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 57.8	Acc@5 89.1
Epoch: [35][571/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 62.5	Acc@5 92.2
Epoch: [35][581/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 89.1
Epoch: [35][591/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 78.1	Acc@5 92.2
Epoch: [35][601/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 64.1	Acc@5 82.8
Epoch: [35][611/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 56.2	Acc@5 87.5
Epoch: [35][621/704]	Time 0.120	Data 0.001	Loss 7.45	Acc@1 54.7	Acc@5 84.4
Epoch: [35][631/704]	Time 0.120	Data 0.001	Loss 6.36	Acc@1 57.8	Acc@5 87.5
Epoch: [35][641/704]	Time 0.120	Data 0.001	Loss 5.68	Acc@1 57.8	Acc@5 92.2
Epoch: [35][651/704]	Time 0.120	Data 0.001	Loss 6.99	Acc@1 50.0	Acc@5 89.1
Epoch: [35][661/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 70.3	Acc@5 95.3
Epoch: [35][671/704]	Time 0.120	Data 0.001	Loss 6.68	Acc@1 57.8	Acc@5 87.5
Epoch: [35][681/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 65.6	Acc@5 93.8
Epoch: [35][691/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 60.9	Acc@5 90.6
Epoch: [35][701/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 64.1	Acc@5 87.5
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.3904	Acc@1 53.1250	Acc@5 79.6875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.1497	Acc@1 48.4375	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6173	Acc@1 56.2500	Acc@5 78.1250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.3970	Acc@1 51.5625	Acc@5 76.5625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2396	Acc@1 59.3750	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.1139	Acc@1 50.0000	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7759	Acc@1 53.1250	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.0461	Acc@1 59.3750	Acc@5 89.0625
 * prec@1 44.260 prec@5 76.180
 * prec@1 50.120 prec@5 80.960
 * prec@1 53.500 prec@5 83.540
 * prec@1 55.140 prec@5 84.060
Current best validation last_bloc_accuracy 55.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_035.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_035.pth.tar'
Epoch: [36][1/704]	Time 0.326	Data 0.160	Loss 4.38	Acc@1 70.3	Acc@5 95.3
Epoch: [36][11/704]	Time 0.139	Data 0.015	Loss 5.62	Acc@1 56.2	Acc@5 90.6
Epoch: [36][21/704]	Time 0.129	Data 0.008	Loss 4.68	Acc@1 73.4	Acc@5 95.3
Epoch: [36][31/704]	Time 0.126	Data 0.005	Loss 6.50	Acc@1 54.7	Acc@5 84.4
Epoch: [36][41/704]	Time 0.125	Data 0.004	Loss 5.42	Acc@1 67.2	Acc@5 96.9
Epoch: [36][51/704]	Time 0.124	Data 0.003	Loss 4.50	Acc@1 70.3	Acc@5 93.8
Epoch: [36][61/704]	Time 0.123	Data 0.003	Loss 6.88	Acc@1 54.7	Acc@5 82.8
Epoch: [36][71/704]	Time 0.122	Data 0.003	Loss 5.56	Acc@1 67.2	Acc@5 90.6
Epoch: [36][81/704]	Time 0.122	Data 0.002	Loss 4.56	Acc@1 78.1	Acc@5 90.6
Epoch: [36][91/704]	Time 0.122	Data 0.002	Loss 5.22	Acc@1 71.9	Acc@5 93.8
Epoch: [36][101/704]	Time 0.122	Data 0.002	Loss 6.99	Acc@1 56.2	Acc@5 85.9
Epoch: [36][111/704]	Time 0.122	Data 0.002	Loss 5.13	Acc@1 68.8	Acc@5 93.8
Epoch: [36][121/704]	Time 0.121	Data 0.002	Loss 6.86	Acc@1 59.4	Acc@5 89.1
Epoch: [36][131/704]	Time 0.121	Data 0.002	Loss 5.67	Acc@1 65.6	Acc@5 92.2
Epoch: [36][141/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 64.1	Acc@5 81.2
Epoch: [36][151/704]	Time 0.121	Data 0.001	Loss 6.70	Acc@1 59.4	Acc@5 87.5
Epoch: [36][161/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 62.5	Acc@5 87.5
Epoch: [36][171/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 70.3	Acc@5 90.6
Epoch: [36][181/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 64.1	Acc@5 92.2
Epoch: [36][191/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 92.2
Epoch: [36][201/704]	Time 0.121	Data 0.001	Loss 6.51	Acc@1 60.9	Acc@5 84.4
Epoch: [36][211/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 57.8	Acc@5 90.6
Epoch: [36][221/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 60.9	Acc@5 92.2
Epoch: [36][231/704]	Time 0.121	Data 0.001	Loss 6.82	Acc@1 56.2	Acc@5 92.2
Epoch: [36][241/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 67.2	Acc@5 92.2
Epoch: [36][251/704]	Time 0.121	Data 0.001	Loss 6.72	Acc@1 60.9	Acc@5 89.1
Epoch: [36][261/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 56.2	Acc@5 90.6
Epoch: [36][271/704]	Time 0.120	Data 0.001	Loss 8.59	Acc@1 42.2	Acc@5 71.9
Epoch: [36][281/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 70.3	Acc@5 90.6
Epoch: [36][291/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 70.3	Acc@5 92.2
Epoch: [36][301/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 65.6	Acc@5 87.5
Epoch: [36][311/704]	Time 0.120	Data 0.001	Loss 5.80	Acc@1 68.8	Acc@5 89.1
Epoch: [36][321/704]	Time 0.120	Data 0.001	Loss 5.76	Acc@1 70.3	Acc@5 85.9
Epoch: [36][331/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 59.4	Acc@5 90.6
Epoch: [36][341/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 60.9	Acc@5 90.6
Epoch: [36][351/704]	Time 0.120	Data 0.001	Loss 6.83	Acc@1 43.8	Acc@5 87.5
Epoch: [36][361/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 65.6	Acc@5 95.3
Epoch: [36][371/704]	Time 0.120	Data 0.001	Loss 6.20	Acc@1 68.8	Acc@5 90.6
Epoch: [36][381/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 65.6	Acc@5 92.2
Epoch: [36][391/704]	Time 0.120	Data 0.001	Loss 6.25	Acc@1 64.1	Acc@5 87.5
Epoch: [36][401/704]	Time 0.120	Data 0.001	Loss 7.43	Acc@1 54.7	Acc@5 84.4
Epoch: [36][411/704]	Time 0.120	Data 0.001	Loss 4.60	Acc@1 70.3	Acc@5 93.8
Epoch: [36][421/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 64.1	Acc@5 85.9
Epoch: [36][431/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 60.9	Acc@5 89.1
Epoch: [36][441/704]	Time 0.120	Data 0.001	Loss 7.20	Acc@1 57.8	Acc@5 84.4
Epoch: [36][451/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 68.8	Acc@5 92.2
Epoch: [36][461/704]	Time 0.120	Data 0.001	Loss 8.11	Acc@1 46.9	Acc@5 76.6
Epoch: [36][471/704]	Time 0.120	Data 0.001	Loss 6.87	Acc@1 51.6	Acc@5 87.5
Epoch: [36][481/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 68.8	Acc@5 93.8
Epoch: [36][491/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 68.8	Acc@5 92.2
Epoch: [36][501/704]	Time 0.120	Data 0.001	Loss 6.18	Acc@1 65.6	Acc@5 90.6
Epoch: [36][511/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 73.4	Acc@5 95.3
Epoch: [36][521/704]	Time 0.120	Data 0.001	Loss 6.64	Acc@1 56.2	Acc@5 89.1
Epoch: [36][531/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 65.6	Acc@5 92.2
Epoch: [36][541/704]	Time 0.120	Data 0.001	Loss 4.94	Acc@1 71.9	Acc@5 96.9
Epoch: [36][551/704]	Time 0.120	Data 0.001	Loss 7.53	Acc@1 53.1	Acc@5 79.7
Epoch: [36][561/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 62.5	Acc@5 84.4
Epoch: [36][571/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 54.7	Acc@5 93.8
Epoch: [36][581/704]	Time 0.120	Data 0.001	Loss 6.73	Acc@1 54.7	Acc@5 79.7
Epoch: [36][591/704]	Time 0.120	Data 0.001	Loss 6.24	Acc@1 68.8	Acc@5 87.5
Epoch: [36][601/704]	Time 0.120	Data 0.001	Loss 5.80	Acc@1 67.2	Acc@5 89.1
Epoch: [36][611/704]	Time 0.120	Data 0.001	Loss 4.53	Acc@1 71.9	Acc@5 95.3
Epoch: [36][621/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 67.2	Acc@5 82.8
Epoch: [36][631/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 68.8	Acc@5 89.1
Epoch: [36][641/704]	Time 0.120	Data 0.001	Loss 4.55	Acc@1 75.0	Acc@5 95.3
Epoch: [36][651/704]	Time 0.120	Data 0.001	Loss 6.17	Acc@1 65.6	Acc@5 92.2
Epoch: [36][661/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 60.9	Acc@5 93.8
Epoch: [36][671/704]	Time 0.120	Data 0.001	Loss 6.71	Acc@1 51.6	Acc@5 90.6
Epoch: [36][681/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 59.4	Acc@5 85.9
Epoch: [36][691/704]	Time 0.120	Data 0.001	Loss 4.67	Acc@1 75.0	Acc@5 95.3
Epoch: [36][701/704]	Time 0.120	Data 0.001	Loss 4.39	Acc@1 71.9	Acc@5 95.3
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.0106	Acc@1 57.8125	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.8175	Acc@1 56.2500	Acc@5 76.5625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.9279	Acc@1 60.9375	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 9.0328	Acc@1 45.3125	Acc@5 78.1250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.8341	Acc@1 54.6875	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.5140	Acc@1 51.5625	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6858	Acc@1 56.2500	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.7451	Acc@1 54.6875	Acc@5 78.1250
 * prec@1 45.380 prec@5 76.520
 * prec@1 49.960 prec@5 81.580
 * prec@1 53.080 prec@5 82.740
 * prec@1 54.720 prec@5 84.400
Current best validation last_bloc_accuracy 55.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_036.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_036.pth.tar'
Epoch: [37][1/704]	Time 0.298	Data 0.131	Loss 5.49	Acc@1 67.2	Acc@5 90.6
Epoch: [37][11/704]	Time 0.137	Data 0.012	Loss 7.01	Acc@1 56.2	Acc@5 82.8
Epoch: [37][21/704]	Time 0.129	Data 0.006	Loss 5.54	Acc@1 62.5	Acc@5 98.4
Epoch: [37][31/704]	Time 0.126	Data 0.005	Loss 5.48	Acc@1 54.7	Acc@5 95.3
Epoch: [37][41/704]	Time 0.125	Data 0.003	Loss 4.43	Acc@1 73.4	Acc@5 90.6
Epoch: [37][51/704]	Time 0.124	Data 0.003	Loss 4.68	Acc@1 70.3	Acc@5 95.3
Epoch: [37][61/704]	Time 0.123	Data 0.002	Loss 5.61	Acc@1 67.2	Acc@5 87.5
Epoch: [37][71/704]	Time 0.123	Data 0.002	Loss 6.00	Acc@1 62.5	Acc@5 85.9
Epoch: [37][81/704]	Time 0.122	Data 0.002	Loss 5.31	Acc@1 68.8	Acc@5 92.2
Epoch: [37][91/704]	Time 0.123	Data 0.002	Loss 5.62	Acc@1 65.6	Acc@5 87.5
Epoch: [37][101/704]	Time 0.122	Data 0.002	Loss 4.43	Acc@1 81.2	Acc@5 95.3
Epoch: [37][111/704]	Time 0.122	Data 0.002	Loss 5.40	Acc@1 60.9	Acc@5 90.6
Epoch: [37][121/704]	Time 0.122	Data 0.001	Loss 5.64	Acc@1 60.9	Acc@5 92.2
Epoch: [37][131/704]	Time 0.122	Data 0.001	Loss 5.24	Acc@1 71.9	Acc@5 90.6
Epoch: [37][141/704]	Time 0.122	Data 0.001	Loss 5.78	Acc@1 62.5	Acc@5 93.8
Epoch: [37][151/704]	Time 0.122	Data 0.001	Loss 5.59	Acc@1 64.1	Acc@5 87.5
Epoch: [37][161/704]	Time 0.122	Data 0.001	Loss 6.05	Acc@1 64.1	Acc@5 89.1
Epoch: [37][171/704]	Time 0.122	Data 0.001	Loss 5.62	Acc@1 59.4	Acc@5 82.8
Epoch: [37][181/704]	Time 0.122	Data 0.001	Loss 5.84	Acc@1 60.9	Acc@5 89.1
Epoch: [37][191/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 67.2	Acc@5 89.1
Epoch: [37][201/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 62.5	Acc@5 93.8
Epoch: [37][211/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 56.2	Acc@5 85.9
Epoch: [37][221/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 62.5	Acc@5 87.5
Epoch: [37][231/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 62.5	Acc@5 87.5
Epoch: [37][241/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 62.5	Acc@5 92.2
Epoch: [37][251/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 62.5	Acc@5 92.2
Epoch: [37][261/704]	Time 0.121	Data 0.001	Loss 6.57	Acc@1 59.4	Acc@5 89.1
Epoch: [37][271/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 76.6	Acc@5 93.8
Epoch: [37][281/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 64.1	Acc@5 96.9
Epoch: [37][291/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 62.5	Acc@5 92.2
Epoch: [37][301/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 57.8	Acc@5 84.4
Epoch: [37][311/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 90.6
Epoch: [37][321/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 76.6	Acc@5 92.2
Epoch: [37][331/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 59.4	Acc@5 90.6
Epoch: [37][341/704]	Time 0.121	Data 0.001	Loss 6.72	Acc@1 59.4	Acc@5 89.1
Epoch: [37][351/704]	Time 0.121	Data 0.001	Loss 6.84	Acc@1 56.2	Acc@5 82.8
Epoch: [37][361/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 71.9	Acc@5 92.2
Epoch: [37][371/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 70.3	Acc@5 95.3
Epoch: [37][381/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 67.2	Acc@5 90.6
Epoch: [37][391/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 65.6	Acc@5 90.6
Epoch: [37][401/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 60.9	Acc@5 90.6
Epoch: [37][411/704]	Time 0.121	Data 0.001	Loss 7.50	Acc@1 54.7	Acc@5 82.8
Epoch: [37][421/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 68.8	Acc@5 92.2
Epoch: [37][431/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 62.5	Acc@5 89.1
Epoch: [37][441/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 62.5	Acc@5 89.1
Epoch: [37][451/704]	Time 0.121	Data 0.001	Loss 6.92	Acc@1 56.2	Acc@5 78.1
Epoch: [37][461/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 64.1	Acc@5 92.2
Epoch: [37][471/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 48.4	Acc@5 89.1
Epoch: [37][481/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 64.1	Acc@5 90.6
Epoch: [37][491/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 92.2
Epoch: [37][501/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 60.9	Acc@5 84.4
Epoch: [37][511/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 70.3	Acc@5 92.2
Epoch: [37][521/704]	Time 0.121	Data 0.001	Loss 6.62	Acc@1 56.2	Acc@5 90.6
Epoch: [37][531/704]	Time 0.121	Data 0.001	Loss 7.24	Acc@1 64.1	Acc@5 84.4
Epoch: [37][541/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 67.2	Acc@5 89.1
Epoch: [37][551/704]	Time 0.121	Data 0.001	Loss 6.96	Acc@1 57.8	Acc@5 82.8
Epoch: [37][561/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 90.6
Epoch: [37][571/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 62.5	Acc@5 90.6
Epoch: [37][581/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 65.6	Acc@5 89.1
Epoch: [37][591/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 64.1	Acc@5 87.5
Epoch: [37][601/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 67.2	Acc@5 90.6
Epoch: [37][611/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 62.5	Acc@5 90.6
Epoch: [37][621/704]	Time 0.121	Data 0.001	Loss 4.22	Acc@1 71.9	Acc@5 93.8
Epoch: [37][631/704]	Time 0.121	Data 0.001	Loss 7.23	Acc@1 57.8	Acc@5 85.9
Epoch: [37][641/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 67.2	Acc@5 90.6
Epoch: [37][651/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 67.2	Acc@5 96.9
Epoch: [37][661/704]	Time 0.121	Data 0.001	Loss 6.80	Acc@1 65.6	Acc@5 81.2
Epoch: [37][671/704]	Time 0.121	Data 0.001	Loss 6.71	Acc@1 60.9	Acc@5 92.2
Epoch: [37][681/704]	Time 0.121	Data 0.001	Loss 6.58	Acc@1 51.6	Acc@5 84.4
Epoch: [37][691/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 59.4	Acc@5 93.8
Epoch: [37][701/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 64.1	Acc@5 84.4
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 8.2238	Acc@1 51.5625	Acc@5 78.1250
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.2222	Acc@1 64.0625	Acc@5 84.3750
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 7.3057	Acc@1 53.1250	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.0241	Acc@1 51.5625	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.5066	Acc@1 46.8750	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6302	Acc@1 57.8125	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.5310	Acc@1 45.3125	Acc@5 79.6875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9621	Acc@1 54.6875	Acc@5 81.2500
 * prec@1 46.960 prec@5 77.000
 * prec@1 51.820 prec@5 82.360
 * prec@1 54.540 prec@5 84.180
 * prec@1 55.800 prec@5 85.060
New best validation last_bloc_accuracy 55.8
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_037.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_037.pth.tar'
Epoch: [38][1/704]	Time 0.300	Data 0.132	Loss 5.47	Acc@1 67.2	Acc@5 95.3
Epoch: [38][11/704]	Time 0.140	Data 0.012	Loss 5.26	Acc@1 65.6	Acc@5 92.2
Epoch: [38][21/704]	Time 0.131	Data 0.007	Loss 6.22	Acc@1 60.9	Acc@5 89.1
Epoch: [38][31/704]	Time 0.127	Data 0.005	Loss 5.66	Acc@1 59.4	Acc@5 93.8
Epoch: [38][41/704]	Time 0.126	Data 0.004	Loss 5.69	Acc@1 68.8	Acc@5 93.8
Epoch: [38][51/704]	Time 0.124	Data 0.003	Loss 5.89	Acc@1 65.6	Acc@5 89.1
Epoch: [38][61/704]	Time 0.124	Data 0.002	Loss 5.59	Acc@1 57.8	Acc@5 87.5
Epoch: [38][71/704]	Time 0.123	Data 0.002	Loss 5.47	Acc@1 62.5	Acc@5 89.1
Epoch: [38][81/704]	Time 0.123	Data 0.002	Loss 4.84	Acc@1 68.8	Acc@5 89.1
Epoch: [38][91/704]	Time 0.122	Data 0.002	Loss 5.23	Acc@1 70.3	Acc@5 93.8
Epoch: [38][101/704]	Time 0.122	Data 0.002	Loss 5.65	Acc@1 65.6	Acc@5 92.2
Epoch: [38][111/704]	Time 0.122	Data 0.002	Loss 7.04	Acc@1 60.9	Acc@5 79.7
Epoch: [38][121/704]	Time 0.122	Data 0.001	Loss 5.24	Acc@1 71.9	Acc@5 92.2
Epoch: [38][131/704]	Time 0.122	Data 0.001	Loss 5.59	Acc@1 64.1	Acc@5 84.4
Epoch: [38][141/704]	Time 0.122	Data 0.001	Loss 4.54	Acc@1 78.1	Acc@5 93.8
Epoch: [38][151/704]	Time 0.122	Data 0.001	Loss 6.11	Acc@1 62.5	Acc@5 93.8
Epoch: [38][161/704]	Time 0.122	Data 0.001	Loss 5.89	Acc@1 57.8	Acc@5 87.5
Epoch: [38][171/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 64.1	Acc@5 92.2
Epoch: [38][181/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 64.1	Acc@5 92.2
Epoch: [38][191/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 70.3	Acc@5 90.6
Epoch: [38][201/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 64.1	Acc@5 89.1
Epoch: [38][211/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 93.8
Epoch: [38][221/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 92.2
Epoch: [38][231/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 64.1	Acc@5 89.1
Epoch: [38][241/704]	Time 0.121	Data 0.001	Loss 7.29	Acc@1 62.5	Acc@5 78.1
Epoch: [38][251/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 70.3	Acc@5 93.8
Epoch: [38][261/704]	Time 0.121	Data 0.001	Loss 7.82	Acc@1 54.7	Acc@5 73.4
Epoch: [38][271/704]	Time 0.121	Data 0.001	Loss 7.09	Acc@1 54.7	Acc@5 85.9
Epoch: [38][281/704]	Time 0.121	Data 0.001	Loss 6.82	Acc@1 64.1	Acc@5 89.1
Epoch: [38][291/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 67.2	Acc@5 92.2
Epoch: [38][301/704]	Time 0.121	Data 0.001	Loss 6.26	Acc@1 71.9	Acc@5 92.2
Epoch: [38][311/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 68.8	Acc@5 89.1
Epoch: [38][321/704]	Time 0.121	Data 0.001	Loss 7.08	Acc@1 60.9	Acc@5 85.9
Epoch: [38][331/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 65.6	Acc@5 87.5
Epoch: [38][341/704]	Time 0.121	Data 0.001	Loss 6.57	Acc@1 64.1	Acc@5 84.4
Epoch: [38][351/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 65.6	Acc@5 90.6
Epoch: [38][361/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 57.8	Acc@5 92.2
Epoch: [38][371/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 65.6	Acc@5 84.4
Epoch: [38][381/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 93.8
Epoch: [38][391/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 71.9	Acc@5 92.2
Epoch: [38][401/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 57.8	Acc@5 87.5
Epoch: [38][411/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 64.1	Acc@5 90.6
Epoch: [38][421/704]	Time 0.121	Data 0.001	Loss 7.81	Acc@1 48.4	Acc@5 84.4
Epoch: [38][431/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 64.1	Acc@5 92.2
Epoch: [38][441/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 65.6	Acc@5 95.3
Epoch: [38][451/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 64.1	Acc@5 93.8
Epoch: [38][461/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 62.5	Acc@5 87.5
Epoch: [38][471/704]	Time 0.121	Data 0.001	Loss 6.89	Acc@1 73.4	Acc@5 87.5
Epoch: [38][481/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 56.2	Acc@5 89.1
Epoch: [38][491/704]	Time 0.121	Data 0.001	Loss 6.82	Acc@1 53.1	Acc@5 87.5
Epoch: [38][501/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 57.8	Acc@5 85.9
Epoch: [38][511/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 68.8	Acc@5 87.5
Epoch: [38][521/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 59.4	Acc@5 89.1
Epoch: [38][531/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 64.1	Acc@5 93.8
Epoch: [38][541/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 68.8	Acc@5 93.8
Epoch: [38][551/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 73.4	Acc@5 89.1
Epoch: [38][561/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 65.6	Acc@5 85.9
Epoch: [38][571/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 71.9	Acc@5 84.4
Epoch: [38][581/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 65.6	Acc@5 87.5
Epoch: [38][591/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 60.9	Acc@5 89.1
Epoch: [38][601/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 56.2	Acc@5 85.9
Epoch: [38][611/704]	Time 0.121	Data 0.001	Loss 7.46	Acc@1 56.2	Acc@5 81.2
Epoch: [38][621/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 46.9	Acc@5 87.5
Epoch: [38][631/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 62.5	Acc@5 95.3
Epoch: [38][641/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 62.5	Acc@5 92.2
Epoch: [38][651/704]	Time 0.120	Data 0.001	Loss 7.14	Acc@1 57.8	Acc@5 84.4
Epoch: [38][661/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 65.6	Acc@5 89.1
Epoch: [38][671/704]	Time 0.120	Data 0.001	Loss 6.67	Acc@1 57.8	Acc@5 87.5
Epoch: [38][681/704]	Time 0.120	Data 0.001	Loss 6.24	Acc@1 60.9	Acc@5 84.4
Epoch: [38][691/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 68.8	Acc@5 92.2
Epoch: [38][701/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 70.3	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.0887	Acc@1 46.8750	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.8156	Acc@1 51.5625	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.3881	Acc@1 48.4375	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.8930	Acc@1 57.8125	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.8396	Acc@1 53.1250	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.8720	Acc@1 56.2500	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.9412	Acc@1 48.4375	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.0957	Acc@1 62.5000	Acc@5 87.5000
 * prec@1 45.360 prec@5 77.360
 * prec@1 49.060 prec@5 80.640
 * prec@1 52.060 prec@5 82.700
 * prec@1 52.580 prec@5 82.900
Current best validation last_bloc_accuracy 55.8
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_038.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_038.pth.tar'
Epoch: [39][1/704]	Time 0.328	Data 0.162	Loss 5.53	Acc@1 68.8	Acc@5 92.2
Epoch: [39][11/704]	Time 0.139	Data 0.015	Loss 4.69	Acc@1 68.8	Acc@5 98.4
Epoch: [39][21/704]	Time 0.129	Data 0.008	Loss 5.09	Acc@1 65.6	Acc@5 95.3
Epoch: [39][31/704]	Time 0.126	Data 0.005	Loss 5.91	Acc@1 62.5	Acc@5 89.1
Epoch: [39][41/704]	Time 0.125	Data 0.004	Loss 4.97	Acc@1 68.8	Acc@5 95.3
Epoch: [39][51/704]	Time 0.124	Data 0.003	Loss 4.14	Acc@1 75.0	Acc@5 95.3
Epoch: [39][61/704]	Time 0.123	Data 0.003	Loss 7.40	Acc@1 53.1	Acc@5 87.5
Epoch: [39][71/704]	Time 0.122	Data 0.003	Loss 5.49	Acc@1 64.1	Acc@5 90.6
Epoch: [39][81/704]	Time 0.122	Data 0.002	Loss 6.08	Acc@1 59.4	Acc@5 89.1
Epoch: [39][91/704]	Time 0.122	Data 0.002	Loss 6.27	Acc@1 62.5	Acc@5 92.2
Epoch: [39][101/704]	Time 0.121	Data 0.002	Loss 6.19	Acc@1 67.2	Acc@5 93.8
Epoch: [39][111/704]	Time 0.121	Data 0.002	Loss 4.69	Acc@1 76.6	Acc@5 93.8
Epoch: [39][121/704]	Time 0.121	Data 0.002	Loss 6.12	Acc@1 67.2	Acc@5 89.1
Epoch: [39][131/704]	Time 0.121	Data 0.002	Loss 6.60	Acc@1 57.8	Acc@5 89.1
Epoch: [39][141/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 76.6	Acc@5 93.8
Epoch: [39][151/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 76.6	Acc@5 98.4
Epoch: [39][161/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 54.7	Acc@5 89.1
Epoch: [39][171/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 60.9	Acc@5 93.8
Epoch: [39][181/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 59.4	Acc@5 89.1
Epoch: [39][191/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 62.5	Acc@5 90.6
Epoch: [39][201/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 68.8	Acc@5 90.6
Epoch: [39][211/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 81.2	Acc@5 92.2
Epoch: [39][221/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 92.2
Epoch: [39][231/704]	Time 0.121	Data 0.001	Loss 6.58	Acc@1 57.8	Acc@5 92.2
Epoch: [39][241/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 71.9	Acc@5 93.8
Epoch: [39][251/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 59.4	Acc@5 90.6
Epoch: [39][261/704]	Time 0.120	Data 0.001	Loss 6.85	Acc@1 60.9	Acc@5 87.5
Epoch: [39][271/704]	Time 0.120	Data 0.001	Loss 6.35	Acc@1 67.2	Acc@5 85.9
Epoch: [39][281/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 60.9	Acc@5 93.8
Epoch: [39][291/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 62.5	Acc@5 95.3
Epoch: [39][301/704]	Time 0.120	Data 0.001	Loss 5.80	Acc@1 67.2	Acc@5 92.2
Epoch: [39][311/704]	Time 0.120	Data 0.001	Loss 5.43	Acc@1 64.1	Acc@5 93.8
Epoch: [39][321/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 64.1	Acc@5 93.8
Epoch: [39][331/704]	Time 0.120	Data 0.001	Loss 6.32	Acc@1 56.2	Acc@5 89.1
Epoch: [39][341/704]	Time 0.120	Data 0.001	Loss 6.04	Acc@1 60.9	Acc@5 85.9
Epoch: [39][351/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 67.2	Acc@5 90.6
Epoch: [39][361/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 60.9	Acc@5 87.5
Epoch: [39][371/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 68.8	Acc@5 90.6
Epoch: [39][381/704]	Time 0.120	Data 0.001	Loss 4.47	Acc@1 68.8	Acc@5 95.3
Epoch: [39][391/704]	Time 0.120	Data 0.001	Loss 5.01	Acc@1 67.2	Acc@5 93.8
Epoch: [39][401/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 65.6	Acc@5 89.1
Epoch: [39][411/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 65.6	Acc@5 92.2
Epoch: [39][421/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 65.6	Acc@5 93.8
Epoch: [39][431/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 71.9	Acc@5 90.6
Epoch: [39][441/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 56.2	Acc@5 89.1
Epoch: [39][451/704]	Time 0.120	Data 0.001	Loss 7.11	Acc@1 51.6	Acc@5 84.4
Epoch: [39][461/704]	Time 0.120	Data 0.001	Loss 5.89	Acc@1 64.1	Acc@5 90.6
Epoch: [39][471/704]	Time 0.120	Data 0.001	Loss 6.16	Acc@1 64.1	Acc@5 85.9
Epoch: [39][481/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 56.2	Acc@5 92.2
Epoch: [39][491/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 70.3	Acc@5 89.1
Epoch: [39][501/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 68.8	Acc@5 90.6
Epoch: [39][511/704]	Time 0.120	Data 0.001	Loss 5.02	Acc@1 68.8	Acc@5 92.2
Epoch: [39][521/704]	Time 0.120	Data 0.001	Loss 6.10	Acc@1 64.1	Acc@5 95.3
Epoch: [39][531/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 65.6	Acc@5 84.4
Epoch: [39][541/704]	Time 0.120	Data 0.001	Loss 6.20	Acc@1 64.1	Acc@5 92.2
Epoch: [39][551/704]	Time 0.120	Data 0.001	Loss 5.10	Acc@1 67.2	Acc@5 92.2
Epoch: [39][561/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 92.2
Epoch: [39][571/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 62.5	Acc@5 95.3
Epoch: [39][581/704]	Time 0.120	Data 0.001	Loss 7.42	Acc@1 46.9	Acc@5 84.4
Epoch: [39][591/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 90.6
Epoch: [39][601/704]	Time 0.120	Data 0.001	Loss 6.61	Acc@1 60.9	Acc@5 89.1
Epoch: [39][611/704]	Time 0.120	Data 0.001	Loss 5.65	Acc@1 67.2	Acc@5 95.3
Epoch: [39][621/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 68.8	Acc@5 90.6
Epoch: [39][631/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 62.5	Acc@5 87.5
Epoch: [39][641/704]	Time 0.120	Data 0.001	Loss 6.05	Acc@1 60.9	Acc@5 90.6
Epoch: [39][651/704]	Time 0.120	Data 0.001	Loss 6.15	Acc@1 68.8	Acc@5 92.2
Epoch: [39][661/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 64.1	Acc@5 96.9
Epoch: [39][671/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 68.8	Acc@5 89.1
Epoch: [39][681/704]	Time 0.120	Data 0.001	Loss 5.49	Acc@1 60.9	Acc@5 90.6
Epoch: [39][691/704]	Time 0.120	Data 0.001	Loss 4.17	Acc@1 79.7	Acc@5 95.3
Epoch: [39][701/704]	Time 0.120	Data 0.001	Loss 6.79	Acc@1 57.8	Acc@5 87.5
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 9.2104	Acc@1 43.7500	Acc@5 67.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.7371	Acc@1 51.5625	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 9.0585	Acc@1 46.8750	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.7302	Acc@1 57.8125	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.5572	Acc@1 53.1250	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9851	Acc@1 46.8750	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7917	Acc@1 53.1250	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.3100	Acc@1 62.5000	Acc@5 89.0625
 * prec@1 45.400 prec@5 76.000
 * prec@1 49.880 prec@5 81.020
 * prec@1 53.220 prec@5 82.620
 * prec@1 55.700 prec@5 84.620
Current best validation last_bloc_accuracy 55.8
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_039.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_039.pth.tar'
Epoch: [40][1/704]	Time 0.301	Data 0.133	Loss 6.71	Acc@1 54.7	Acc@5 87.5
Epoch: [40][11/704]	Time 0.137	Data 0.012	Loss 5.80	Acc@1 56.2	Acc@5 87.5
Epoch: [40][21/704]	Time 0.129	Data 0.007	Loss 5.52	Acc@1 70.3	Acc@5 89.1
Epoch: [40][31/704]	Time 0.126	Data 0.005	Loss 6.34	Acc@1 67.2	Acc@5 85.9
Epoch: [40][41/704]	Time 0.125	Data 0.004	Loss 5.84	Acc@1 62.5	Acc@5 90.6
Epoch: [40][51/704]	Time 0.124	Data 0.003	Loss 6.59	Acc@1 54.7	Acc@5 90.6
Epoch: [40][61/704]	Time 0.123	Data 0.003	Loss 6.98	Acc@1 54.7	Acc@5 89.1
Epoch: [40][71/704]	Time 0.123	Data 0.002	Loss 4.18	Acc@1 81.2	Acc@5 98.4
Epoch: [40][81/704]	Time 0.123	Data 0.002	Loss 5.76	Acc@1 57.8	Acc@5 90.6
Epoch: [40][91/704]	Time 0.122	Data 0.002	Loss 4.67	Acc@1 70.3	Acc@5 92.2
Epoch: [40][101/704]	Time 0.122	Data 0.002	Loss 6.69	Acc@1 53.1	Acc@5 84.4
Epoch: [40][111/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 68.8	Acc@5 89.1
Epoch: [40][121/704]	Time 0.122	Data 0.001	Loss 5.18	Acc@1 65.6	Acc@5 92.2
Epoch: [40][131/704]	Time 0.122	Data 0.001	Loss 6.33	Acc@1 62.5	Acc@5 89.1
Epoch: [40][141/704]	Time 0.122	Data 0.001	Loss 5.50	Acc@1 67.2	Acc@5 87.5
Epoch: [40][151/704]	Time 0.122	Data 0.001	Loss 5.46	Acc@1 62.5	Acc@5 93.8
Epoch: [40][161/704]	Time 0.122	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 90.6
Epoch: [40][171/704]	Time 0.122	Data 0.001	Loss 5.62	Acc@1 65.6	Acc@5 90.6
Epoch: [40][181/704]	Time 0.122	Data 0.001	Loss 5.58	Acc@1 62.5	Acc@5 93.8
Epoch: [40][191/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 70.3	Acc@5 95.3
Epoch: [40][201/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 71.9	Acc@5 95.3
Epoch: [40][211/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 67.2	Acc@5 95.3
Epoch: [40][221/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 68.8	Acc@5 90.6
Epoch: [40][231/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 65.6	Acc@5 90.6
Epoch: [40][241/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 68.8	Acc@5 90.6
Epoch: [40][251/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 68.8	Acc@5 90.6
Epoch: [40][261/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 65.6	Acc@5 84.4
Epoch: [40][271/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 64.1	Acc@5 89.1
Epoch: [40][281/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 57.8	Acc@5 85.9
Epoch: [40][291/704]	Time 0.121	Data 0.001	Loss 7.45	Acc@1 48.4	Acc@5 82.8
Epoch: [40][301/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 65.6	Acc@5 89.1
Epoch: [40][311/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 60.9	Acc@5 90.6
Epoch: [40][321/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 78.1	Acc@5 96.9
Epoch: [40][331/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 59.4	Acc@5 92.2
Epoch: [40][341/704]	Time 0.121	Data 0.001	Loss 6.73	Acc@1 59.4	Acc@5 82.8
Epoch: [40][351/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 60.9	Acc@5 85.9
Epoch: [40][361/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 54.7	Acc@5 92.2
Epoch: [40][371/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 60.9	Acc@5 93.8
Epoch: [40][381/704]	Time 0.121	Data 0.001	Loss 6.63	Acc@1 59.4	Acc@5 89.1
Epoch: [40][391/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 64.1	Acc@5 98.4
Epoch: [40][401/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 59.4	Acc@5 92.2
Epoch: [40][411/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 65.6	Acc@5 89.1
Epoch: [40][421/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 68.8	Acc@5 87.5
Epoch: [40][431/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 62.5	Acc@5 95.3
Epoch: [40][441/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 60.9	Acc@5 89.1
Epoch: [40][451/704]	Time 0.121	Data 0.001	Loss 6.80	Acc@1 56.2	Acc@5 89.1
Epoch: [40][461/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 59.4	Acc@5 87.5
Epoch: [40][471/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 68.8	Acc@5 92.2
Epoch: [40][481/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 73.4	Acc@5 96.9
Epoch: [40][491/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 73.4	Acc@5 93.8
Epoch: [40][501/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 68.8	Acc@5 87.5
Epoch: [40][511/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 65.6	Acc@5 92.2
Epoch: [40][521/704]	Time 0.121	Data 0.001	Loss 6.38	Acc@1 64.1	Acc@5 81.2
Epoch: [40][531/704]	Time 0.121	Data 0.001	Loss 7.34	Acc@1 53.1	Acc@5 84.4
Epoch: [40][541/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 59.4	Acc@5 96.9
Epoch: [40][551/704]	Time 0.121	Data 0.001	Loss 6.59	Acc@1 56.2	Acc@5 89.1
Epoch: [40][561/704]	Time 0.121	Data 0.001	Loss 7.49	Acc@1 62.5	Acc@5 82.8
Epoch: [40][571/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 59.4	Acc@5 89.1
Epoch: [40][581/704]	Time 0.121	Data 0.001	Loss 6.38	Acc@1 64.1	Acc@5 85.9
Epoch: [40][591/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 68.8	Acc@5 87.5
Epoch: [40][601/704]	Time 0.121	Data 0.001	Loss 7.01	Acc@1 60.9	Acc@5 85.9
Epoch: [40][611/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 60.9	Acc@5 81.2
Epoch: [40][621/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 64.1	Acc@5 89.1
Epoch: [40][631/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 56.2	Acc@5 92.2
Epoch: [40][641/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 59.4	Acc@5 93.8
Epoch: [40][651/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 70.3	Acc@5 90.6
Epoch: [40][661/704]	Time 0.121	Data 0.001	Loss 8.42	Acc@1 45.3	Acc@5 81.2
Epoch: [40][671/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 60.9	Acc@5 89.1
Epoch: [40][681/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 73.4	Acc@5 90.6
Epoch: [40][691/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 64.1	Acc@5 89.1
Epoch: [40][701/704]	Time 0.121	Data 0.001	Loss 6.60	Acc@1 54.7	Acc@5 90.6
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.1803	Acc@1 53.1250	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.9578	Acc@1 59.3750	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.7369	Acc@1 56.2500	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.9378	Acc@1 51.5625	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.1093	Acc@1 67.1875	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2495	Acc@1 50.0000	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 9.2746	Acc@1 45.3125	Acc@5 75.0000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.3843	Acc@1 53.1250	Acc@5 82.8125
 * prec@1 46.580 prec@5 77.040
 * prec@1 50.860 prec@5 81.400
 * prec@1 53.960 prec@5 83.700
 * prec@1 55.400 prec@5 84.540
Current best validation last_bloc_accuracy 55.8
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_040.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_040.pth.tar'
Epoch: [41][1/704]	Time 0.297	Data 0.130	Loss 5.83	Acc@1 64.1	Acc@5 87.5
Epoch: [41][11/704]	Time 0.136	Data 0.012	Loss 6.79	Acc@1 62.5	Acc@5 89.1
Epoch: [41][21/704]	Time 0.128	Data 0.006	Loss 6.04	Acc@1 53.1	Acc@5 93.8
Epoch: [41][31/704]	Time 0.125	Data 0.004	Loss 4.84	Acc@1 65.6	Acc@5 96.9
Epoch: [41][41/704]	Time 0.124	Data 0.003	Loss 5.63	Acc@1 68.8	Acc@5 89.1
Epoch: [41][51/704]	Time 0.123	Data 0.003	Loss 5.03	Acc@1 64.1	Acc@5 96.9
Epoch: [41][61/704]	Time 0.123	Data 0.002	Loss 5.15	Acc@1 64.1	Acc@5 90.6
Epoch: [41][71/704]	Time 0.123	Data 0.002	Loss 5.06	Acc@1 65.6	Acc@5 93.8
Epoch: [41][81/704]	Time 0.122	Data 0.002	Loss 6.60	Acc@1 60.9	Acc@5 84.4
Epoch: [41][91/704]	Time 0.122	Data 0.002	Loss 6.70	Acc@1 54.7	Acc@5 84.4
Epoch: [41][101/704]	Time 0.122	Data 0.002	Loss 6.07	Acc@1 54.7	Acc@5 85.9
Epoch: [41][111/704]	Time 0.122	Data 0.001	Loss 6.15	Acc@1 68.8	Acc@5 89.1
Epoch: [41][121/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 64.1	Acc@5 92.2
Epoch: [41][131/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 59.4	Acc@5 93.8
Epoch: [41][141/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 70.3	Acc@5 93.8
Epoch: [41][151/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 64.1	Acc@5 93.8
Epoch: [41][161/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 71.9	Acc@5 90.6
Epoch: [41][171/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 68.8	Acc@5 93.8
Epoch: [41][181/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 65.6	Acc@5 90.6
Epoch: [41][191/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 65.6	Acc@5 90.6
Epoch: [41][201/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 62.5	Acc@5 90.6
Epoch: [41][211/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 59.4	Acc@5 87.5
Epoch: [41][221/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 65.6	Acc@5 95.3
Epoch: [41][231/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 71.9	Acc@5 89.1
Epoch: [41][241/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 79.7	Acc@5 90.6
Epoch: [41][251/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 64.1	Acc@5 84.4
Epoch: [41][261/704]	Time 0.120	Data 0.001	Loss 5.63	Acc@1 56.2	Acc@5 89.1
Epoch: [41][271/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 70.3	Acc@5 95.3
Epoch: [41][281/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 60.9	Acc@5 92.2
Epoch: [41][291/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 64.1	Acc@5 89.1
Epoch: [41][301/704]	Time 0.120	Data 0.001	Loss 6.15	Acc@1 68.8	Acc@5 84.4
Epoch: [41][311/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 60.9	Acc@5 87.5
Epoch: [41][321/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 67.2	Acc@5 93.8
Epoch: [41][331/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 67.2	Acc@5 90.6
Epoch: [41][341/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 73.4	Acc@5 93.8
Epoch: [41][351/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 59.4	Acc@5 89.1
Epoch: [41][361/704]	Time 0.120	Data 0.001	Loss 4.46	Acc@1 71.9	Acc@5 93.8
Epoch: [41][371/704]	Time 0.120	Data 0.001	Loss 6.05	Acc@1 64.1	Acc@5 87.5
Epoch: [41][381/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 65.6	Acc@5 93.8
Epoch: [41][391/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 73.4	Acc@5 93.8
Epoch: [41][401/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 68.8	Acc@5 84.4
Epoch: [41][411/704]	Time 0.120	Data 0.001	Loss 6.10	Acc@1 68.8	Acc@5 87.5
Epoch: [41][421/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 59.4	Acc@5 87.5
Epoch: [41][431/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 56.2	Acc@5 93.8
Epoch: [41][441/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 60.9	Acc@5 84.4
Epoch: [41][451/704]	Time 0.120	Data 0.001	Loss 5.40	Acc@1 67.2	Acc@5 93.8
Epoch: [41][461/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 56.2	Acc@5 85.9
Epoch: [41][471/704]	Time 0.120	Data 0.001	Loss 4.67	Acc@1 70.3	Acc@5 96.9
Epoch: [41][481/704]	Time 0.120	Data 0.001	Loss 7.39	Acc@1 62.5	Acc@5 87.5
Epoch: [41][491/704]	Time 0.120	Data 0.001	Loss 4.44	Acc@1 82.8	Acc@5 93.8
Epoch: [41][501/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 65.6	Acc@5 85.9
Epoch: [41][511/704]	Time 0.120	Data 0.001	Loss 4.94	Acc@1 62.5	Acc@5 92.2
Epoch: [41][521/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 56.2	Acc@5 90.6
Epoch: [41][531/704]	Time 0.120	Data 0.001	Loss 6.89	Acc@1 65.6	Acc@5 90.6
Epoch: [41][541/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 67.2	Acc@5 89.1
Epoch: [41][551/704]	Time 0.120	Data 0.001	Loss 7.09	Acc@1 59.4	Acc@5 89.1
Epoch: [41][561/704]	Time 0.120	Data 0.001	Loss 6.65	Acc@1 59.4	Acc@5 82.8
Epoch: [41][571/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 60.9	Acc@5 92.2
Epoch: [41][581/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 60.9	Acc@5 89.1
Epoch: [41][591/704]	Time 0.120	Data 0.001	Loss 6.42	Acc@1 60.9	Acc@5 87.5
Epoch: [41][601/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 65.6	Acc@5 89.1
Epoch: [41][611/704]	Time 0.120	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 89.1
Epoch: [41][621/704]	Time 0.120	Data 0.001	Loss 4.77	Acc@1 73.4	Acc@5 92.2
Epoch: [41][631/704]	Time 0.120	Data 0.001	Loss 5.57	Acc@1 67.2	Acc@5 89.1
Epoch: [41][641/704]	Time 0.120	Data 0.001	Loss 4.48	Acc@1 68.8	Acc@5 95.3
Epoch: [41][651/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 93.8
Epoch: [41][661/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 64.1	Acc@5 92.2
Epoch: [41][671/704]	Time 0.120	Data 0.001	Loss 4.59	Acc@1 71.9	Acc@5 89.1
Epoch: [41][681/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 65.6	Acc@5 90.6
Epoch: [41][691/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 56.2	Acc@5 87.5
Epoch: [41][701/704]	Time 0.120	Data 0.001	Loss 5.02	Acc@1 68.8	Acc@5 87.5
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.0200	Acc@1 46.8750	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.1132	Acc@1 51.5625	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.7446	Acc@1 42.1875	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.4868	Acc@1 42.1875	Acc@5 78.1250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.1022	Acc@1 57.8125	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9084	Acc@1 57.8125	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.3651	Acc@1 43.7500	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.6977	Acc@1 56.2500	Acc@5 84.3750
 * prec@1 46.060 prec@5 77.440
 * prec@1 50.540 prec@5 81.260
 * prec@1 53.620 prec@5 82.980
 * prec@1 52.880 prec@5 82.880
Current best validation last_bloc_accuracy 55.8
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_041.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_041.pth.tar'
Epoch: [42][1/704]	Time 0.329	Data 0.163	Loss 5.64	Acc@1 65.6	Acc@5 87.5
Epoch: [42][11/704]	Time 0.139	Data 0.015	Loss 5.53	Acc@1 64.1	Acc@5 87.5
Epoch: [42][21/704]	Time 0.130	Data 0.008	Loss 5.59	Acc@1 59.4	Acc@5 95.3
Epoch: [42][31/704]	Time 0.126	Data 0.006	Loss 5.49	Acc@1 71.9	Acc@5 93.8
Epoch: [42][41/704]	Time 0.125	Data 0.004	Loss 4.98	Acc@1 62.5	Acc@5 93.8
Epoch: [42][51/704]	Time 0.124	Data 0.004	Loss 5.69	Acc@1 60.9	Acc@5 87.5
Epoch: [42][61/704]	Time 0.123	Data 0.003	Loss 5.09	Acc@1 71.9	Acc@5 93.8
Epoch: [42][71/704]	Time 0.123	Data 0.003	Loss 5.89	Acc@1 65.6	Acc@5 95.3
Epoch: [42][81/704]	Time 0.122	Data 0.002	Loss 5.42	Acc@1 67.2	Acc@5 95.3
Epoch: [42][91/704]	Time 0.122	Data 0.002	Loss 6.12	Acc@1 64.1	Acc@5 90.6
Epoch: [42][101/704]	Time 0.122	Data 0.002	Loss 6.19	Acc@1 68.8	Acc@5 92.2
Epoch: [42][111/704]	Time 0.121	Data 0.002	Loss 5.20	Acc@1 75.0	Acc@5 96.9
Epoch: [42][121/704]	Time 0.121	Data 0.002	Loss 5.69	Acc@1 62.5	Acc@5 89.1
Epoch: [42][131/704]	Time 0.121	Data 0.002	Loss 5.87	Acc@1 67.2	Acc@5 92.2
Epoch: [42][141/704]	Time 0.121	Data 0.002	Loss 6.72	Acc@1 59.4	Acc@5 92.2
Epoch: [42][151/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 56.2	Acc@5 82.8
Epoch: [42][161/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 67.2	Acc@5 92.2
Epoch: [42][171/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 67.2	Acc@5 93.8
Epoch: [42][181/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 75.0	Acc@5 90.6
Epoch: [42][191/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 89.1
Epoch: [42][201/704]	Time 0.121	Data 0.001	Loss 6.81	Acc@1 53.1	Acc@5 90.6
Epoch: [42][211/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 56.2	Acc@5 87.5
Epoch: [42][221/704]	Time 0.121	Data 0.001	Loss 7.15	Acc@1 57.8	Acc@5 79.7
Epoch: [42][231/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 90.6
Epoch: [42][241/704]	Time 0.120	Data 0.001	Loss 6.23	Acc@1 54.7	Acc@5 89.1
Epoch: [42][251/704]	Time 0.120	Data 0.001	Loss 4.70	Acc@1 65.6	Acc@5 92.2
Epoch: [42][261/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 62.5	Acc@5 93.8
Epoch: [42][271/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 62.5	Acc@5 90.6
Epoch: [42][281/704]	Time 0.120	Data 0.001	Loss 4.80	Acc@1 73.4	Acc@5 89.1
Epoch: [42][291/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 62.5	Acc@5 90.6
Epoch: [42][301/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 57.8	Acc@5 89.1
Epoch: [42][311/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 60.9	Acc@5 92.2
Epoch: [42][321/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 65.6	Acc@5 90.6
Epoch: [42][331/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 68.8	Acc@5 95.3
Epoch: [42][341/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 65.6	Acc@5 90.6
Epoch: [42][351/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 67.2	Acc@5 90.6
Epoch: [42][361/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 75.0	Acc@5 92.2
Epoch: [42][371/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 64.1	Acc@5 89.1
Epoch: [42][381/704]	Time 0.120	Data 0.001	Loss 6.47	Acc@1 56.2	Acc@5 89.1
Epoch: [42][391/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 93.8
Epoch: [42][401/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 65.6	Acc@5 93.8
Epoch: [42][411/704]	Time 0.120	Data 0.001	Loss 5.76	Acc@1 64.1	Acc@5 89.1
Epoch: [42][421/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 70.3	Acc@5 89.1
Epoch: [42][431/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 64.1	Acc@5 90.6
Epoch: [42][441/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 68.8	Acc@5 90.6
Epoch: [42][451/704]	Time 0.120	Data 0.001	Loss 5.40	Acc@1 75.0	Acc@5 89.1
Epoch: [42][461/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 89.1
Epoch: [42][471/704]	Time 0.120	Data 0.001	Loss 6.34	Acc@1 62.5	Acc@5 90.6
Epoch: [42][481/704]	Time 0.120	Data 0.001	Loss 7.00	Acc@1 48.4	Acc@5 90.6
Epoch: [42][491/704]	Time 0.120	Data 0.001	Loss 7.24	Acc@1 54.7	Acc@5 82.8
Epoch: [42][501/704]	Time 0.120	Data 0.001	Loss 5.41	Acc@1 70.3	Acc@5 89.1
Epoch: [42][511/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 57.8	Acc@5 89.1
Epoch: [42][521/704]	Time 0.120	Data 0.001	Loss 6.32	Acc@1 59.4	Acc@5 95.3
Epoch: [42][531/704]	Time 0.120	Data 0.001	Loss 6.27	Acc@1 67.2	Acc@5 90.6
Epoch: [42][541/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 68.8	Acc@5 90.6
Epoch: [42][551/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 62.5	Acc@5 89.1
Epoch: [42][561/704]	Time 0.120	Data 0.001	Loss 4.96	Acc@1 68.8	Acc@5 90.6
Epoch: [42][571/704]	Time 0.120	Data 0.001	Loss 5.70	Acc@1 65.6	Acc@5 89.1
Epoch: [42][581/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 70.3	Acc@5 90.6
Epoch: [42][591/704]	Time 0.120	Data 0.001	Loss 4.62	Acc@1 73.4	Acc@5 90.6
Epoch: [42][601/704]	Time 0.120	Data 0.001	Loss 6.39	Acc@1 60.9	Acc@5 90.6
Epoch: [42][611/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 70.3	Acc@5 95.3
Epoch: [42][621/704]	Time 0.120	Data 0.001	Loss 6.93	Acc@1 56.2	Acc@5 85.9
Epoch: [42][631/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 59.4	Acc@5 92.2
Epoch: [42][641/704]	Time 0.120	Data 0.001	Loss 4.73	Acc@1 67.2	Acc@5 93.8
Epoch: [42][651/704]	Time 0.120	Data 0.001	Loss 6.86	Acc@1 64.1	Acc@5 89.1
Epoch: [42][661/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 59.4	Acc@5 93.8
Epoch: [42][671/704]	Time 0.120	Data 0.001	Loss 6.05	Acc@1 59.4	Acc@5 90.6
Epoch: [42][681/704]	Time 0.120	Data 0.001	Loss 6.87	Acc@1 59.4	Acc@5 89.1
Epoch: [42][691/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 56.2	Acc@5 87.5
Epoch: [42][701/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 60.9	Acc@5 85.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.2926	Acc@1 54.6875	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.7432	Acc@1 62.5000	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.9753	Acc@1 59.3750	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9427	Acc@1 65.6250	Acc@5 79.6875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.0392	Acc@1 71.8750	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8187	Acc@1 60.9375	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.3123	Acc@1 53.1250	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.9517	Acc@1 50.0000	Acc@5 82.8125
 * prec@1 45.880 prec@5 77.680
 * prec@1 50.960 prec@5 81.460
 * prec@1 54.400 prec@5 84.160
 * prec@1 56.660 prec@5 84.900
New best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_042.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_042.pth.tar'
Epoch: [43][1/704]	Time 0.335	Data 0.169	Loss 4.95	Acc@1 68.8	Acc@5 92.2
Epoch: [43][11/704]	Time 0.140	Data 0.016	Loss 6.12	Acc@1 60.9	Acc@5 90.6
Epoch: [43][21/704]	Time 0.131	Data 0.008	Loss 5.24	Acc@1 65.6	Acc@5 93.8
Epoch: [43][31/704]	Time 0.127	Data 0.006	Loss 4.94	Acc@1 76.6	Acc@5 89.1
Epoch: [43][41/704]	Time 0.126	Data 0.004	Loss 5.35	Acc@1 62.5	Acc@5 85.9
Epoch: [43][51/704]	Time 0.125	Data 0.004	Loss 5.93	Acc@1 62.5	Acc@5 85.9
Epoch: [43][61/704]	Time 0.124	Data 0.003	Loss 6.10	Acc@1 64.1	Acc@5 84.4
Epoch: [43][71/704]	Time 0.123	Data 0.003	Loss 5.02	Acc@1 65.6	Acc@5 87.5
Epoch: [43][81/704]	Time 0.123	Data 0.002	Loss 5.66	Acc@1 60.9	Acc@5 90.6
Epoch: [43][91/704]	Time 0.123	Data 0.002	Loss 5.24	Acc@1 78.1	Acc@5 85.9
Epoch: [43][101/704]	Time 0.122	Data 0.002	Loss 5.73	Acc@1 64.1	Acc@5 93.8
Epoch: [43][111/704]	Time 0.122	Data 0.002	Loss 6.44	Acc@1 53.1	Acc@5 85.9
Epoch: [43][121/704]	Time 0.122	Data 0.002	Loss 5.62	Acc@1 60.9	Acc@5 89.1
Epoch: [43][131/704]	Time 0.122	Data 0.002	Loss 4.95	Acc@1 73.4	Acc@5 93.8
Epoch: [43][141/704]	Time 0.122	Data 0.002	Loss 5.84	Acc@1 64.1	Acc@5 92.2
Epoch: [43][151/704]	Time 0.122	Data 0.001	Loss 5.89	Acc@1 67.2	Acc@5 90.6
Epoch: [43][161/704]	Time 0.122	Data 0.001	Loss 5.05	Acc@1 64.1	Acc@5 92.2
Epoch: [43][171/704]	Time 0.122	Data 0.001	Loss 5.54	Acc@1 67.2	Acc@5 90.6
Epoch: [43][181/704]	Time 0.122	Data 0.001	Loss 4.64	Acc@1 75.0	Acc@5 95.3
Epoch: [43][191/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 68.8	Acc@5 87.5
Epoch: [43][201/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 62.5	Acc@5 89.1
Epoch: [43][211/704]	Time 0.121	Data 0.001	Loss 8.09	Acc@1 46.9	Acc@5 85.9
Epoch: [43][221/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 65.6	Acc@5 92.2
Epoch: [43][231/704]	Time 0.121	Data 0.001	Loss 6.89	Acc@1 60.9	Acc@5 85.9
Epoch: [43][241/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 68.8	Acc@5 93.8
Epoch: [43][251/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 65.6	Acc@5 87.5
Epoch: [43][261/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 62.5	Acc@5 89.1
Epoch: [43][271/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 65.6	Acc@5 90.6
Epoch: [43][281/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 92.2
Epoch: [43][291/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 67.2	Acc@5 93.8
Epoch: [43][301/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 59.4	Acc@5 87.5
Epoch: [43][311/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 73.4	Acc@5 90.6
Epoch: [43][321/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 71.9	Acc@5 92.2
Epoch: [43][331/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 60.9	Acc@5 89.1
Epoch: [43][341/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 70.3	Acc@5 87.5
Epoch: [43][351/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 68.8	Acc@5 90.6
Epoch: [43][361/704]	Time 0.121	Data 0.001	Loss 7.46	Acc@1 51.6	Acc@5 90.6
Epoch: [43][371/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 60.9	Acc@5 89.1
Epoch: [43][381/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 67.2	Acc@5 95.3
Epoch: [43][391/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 54.7	Acc@5 90.6
Epoch: [43][401/704]	Time 0.121	Data 0.001	Loss 6.90	Acc@1 54.7	Acc@5 85.9
Epoch: [43][411/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 65.6	Acc@5 92.2
Epoch: [43][421/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 64.1	Acc@5 95.3
Epoch: [43][431/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 64.1	Acc@5 93.8
Epoch: [43][441/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 64.1	Acc@5 95.3
Epoch: [43][451/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 68.8	Acc@5 89.1
Epoch: [43][461/704]	Time 0.121	Data 0.001	Loss 6.84	Acc@1 64.1	Acc@5 84.4
Epoch: [43][471/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 64.1	Acc@5 87.5
Epoch: [43][481/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 68.8	Acc@5 93.8
Epoch: [43][491/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 93.8
Epoch: [43][501/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 75.0	Acc@5 95.3
Epoch: [43][511/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 71.9	Acc@5 92.2
Epoch: [43][521/704]	Time 0.121	Data 0.001	Loss 6.78	Acc@1 64.1	Acc@5 81.2
Epoch: [43][531/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 64.1	Acc@5 90.6
Epoch: [43][541/704]	Time 0.121	Data 0.001	Loss 6.61	Acc@1 64.1	Acc@5 89.1
Epoch: [43][551/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 65.6	Acc@5 92.2
Epoch: [43][561/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 73.4	Acc@5 90.6
Epoch: [43][571/704]	Time 0.121	Data 0.001	Loss 6.63	Acc@1 50.0	Acc@5 84.4
Epoch: [43][581/704]	Time 0.121	Data 0.001	Loss 6.74	Acc@1 60.9	Acc@5 84.4
Epoch: [43][591/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 62.5	Acc@5 89.1
Epoch: [43][601/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 54.7	Acc@5 92.2
Epoch: [43][611/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 64.1	Acc@5 90.6
Epoch: [43][621/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 57.8	Acc@5 87.5
Epoch: [43][631/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 71.9	Acc@5 87.5
Epoch: [43][641/704]	Time 0.121	Data 0.001	Loss 6.77	Acc@1 57.8	Acc@5 78.1
Epoch: [43][651/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 60.9	Acc@5 89.1
Epoch: [43][661/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 68.8	Acc@5 92.2
Epoch: [43][671/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 67.2	Acc@5 89.1
Epoch: [43][681/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 57.8	Acc@5 93.8
Epoch: [43][691/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 62.5	Acc@5 89.1
Epoch: [43][701/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 75.0	Acc@5 93.8
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.4284	Acc@1 51.5625	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 8.3557	Acc@1 56.2500	Acc@5 85.9375
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 7.1112	Acc@1 59.3750	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6173	Acc@1 64.0625	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7517	Acc@1 56.2500	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2108	Acc@1 54.6875	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.3293	Acc@1 59.3750	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.5995	Acc@1 46.8750	Acc@5 75.0000
 * prec@1 44.900 prec@5 75.900
 * prec@1 50.320 prec@5 80.720
 * prec@1 53.600 prec@5 83.080
 * prec@1 55.280 prec@5 83.600
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_043.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_043.pth.tar'
Epoch: [44][1/704]	Time 0.297	Data 0.130	Loss 4.92	Acc@1 68.8	Acc@5 92.2
Epoch: [44][11/704]	Time 0.136	Data 0.012	Loss 6.35	Acc@1 57.8	Acc@5 87.5
Epoch: [44][21/704]	Time 0.128	Data 0.007	Loss 4.52	Acc@1 73.4	Acc@5 90.6
Epoch: [44][31/704]	Time 0.125	Data 0.005	Loss 6.25	Acc@1 62.5	Acc@5 89.1
Epoch: [44][41/704]	Time 0.124	Data 0.004	Loss 6.13	Acc@1 65.6	Acc@5 90.6
Epoch: [44][51/704]	Time 0.123	Data 0.003	Loss 5.49	Acc@1 65.6	Acc@5 90.6
Epoch: [44][61/704]	Time 0.122	Data 0.002	Loss 4.70	Acc@1 75.0	Acc@5 93.8
Epoch: [44][71/704]	Time 0.122	Data 0.002	Loss 5.44	Acc@1 70.3	Acc@5 82.8
Epoch: [44][81/704]	Time 0.122	Data 0.002	Loss 5.89	Acc@1 59.4	Acc@5 87.5
Epoch: [44][91/704]	Time 0.122	Data 0.002	Loss 6.63	Acc@1 50.0	Acc@5 87.5
Epoch: [44][101/704]	Time 0.122	Data 0.002	Loss 5.58	Acc@1 64.1	Acc@5 90.6
Epoch: [44][111/704]	Time 0.122	Data 0.002	Loss 5.19	Acc@1 71.9	Acc@5 92.2
Epoch: [44][121/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 65.6	Acc@5 95.3
Epoch: [44][131/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 70.3	Acc@5 89.1
Epoch: [44][141/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 65.6	Acc@5 90.6
Epoch: [44][151/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 59.4	Acc@5 85.9
Epoch: [44][161/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 87.5
Epoch: [44][171/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 64.1	Acc@5 89.1
Epoch: [44][181/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 87.5
Epoch: [44][191/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 68.8	Acc@5 89.1
Epoch: [44][201/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 60.9	Acc@5 89.1
Epoch: [44][211/704]	Time 0.121	Data 0.001	Loss 6.79	Acc@1 53.1	Acc@5 87.5
Epoch: [44][221/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 59.4	Acc@5 92.2
Epoch: [44][231/704]	Time 0.120	Data 0.001	Loss 4.37	Acc@1 67.2	Acc@5 95.3
Epoch: [44][241/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 57.8	Acc@5 89.1
Epoch: [44][251/704]	Time 0.120	Data 0.001	Loss 4.46	Acc@1 62.5	Acc@5 92.2
Epoch: [44][261/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 62.5	Acc@5 90.6
Epoch: [44][271/704]	Time 0.120	Data 0.001	Loss 6.74	Acc@1 60.9	Acc@5 81.2
Epoch: [44][281/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 62.5	Acc@5 89.1
Epoch: [44][291/704]	Time 0.120	Data 0.001	Loss 6.55	Acc@1 56.2	Acc@5 87.5
Epoch: [44][301/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 70.3	Acc@5 93.8
Epoch: [44][311/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 54.7	Acc@5 89.1
Epoch: [44][321/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 60.9	Acc@5 92.2
Epoch: [44][331/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 93.8
Epoch: [44][341/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 65.6	Acc@5 96.9
Epoch: [44][351/704]	Time 0.120	Data 0.001	Loss 6.55	Acc@1 60.9	Acc@5 82.8
Epoch: [44][361/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 75.0	Acc@5 96.9
Epoch: [44][371/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 65.6	Acc@5 96.9
Epoch: [44][381/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 62.5	Acc@5 87.5
Epoch: [44][391/704]	Time 0.120	Data 0.001	Loss 5.30	Acc@1 64.1	Acc@5 96.9
Epoch: [44][401/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 71.9	Acc@5 93.8
Epoch: [44][411/704]	Time 0.120	Data 0.001	Loss 6.71	Acc@1 54.7	Acc@5 92.2
Epoch: [44][421/704]	Time 0.120	Data 0.001	Loss 6.46	Acc@1 53.1	Acc@5 84.4
Epoch: [44][431/704]	Time 0.120	Data 0.001	Loss 6.44	Acc@1 64.1	Acc@5 85.9
Epoch: [44][441/704]	Time 0.120	Data 0.001	Loss 6.88	Acc@1 56.2	Acc@5 87.5
Epoch: [44][451/704]	Time 0.120	Data 0.001	Loss 6.36	Acc@1 62.5	Acc@5 87.5
Epoch: [44][461/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 67.2	Acc@5 89.1
Epoch: [44][471/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 68.8	Acc@5 87.5
Epoch: [44][481/704]	Time 0.120	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 93.8
Epoch: [44][491/704]	Time 0.120	Data 0.001	Loss 4.50	Acc@1 70.3	Acc@5 96.9
Epoch: [44][501/704]	Time 0.120	Data 0.001	Loss 6.63	Acc@1 53.1	Acc@5 87.5
Epoch: [44][511/704]	Time 0.120	Data 0.001	Loss 4.89	Acc@1 67.2	Acc@5 90.6
Epoch: [44][521/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 68.8	Acc@5 93.8
Epoch: [44][531/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 65.6	Acc@5 100.0
Epoch: [44][541/704]	Time 0.120	Data 0.001	Loss 6.15	Acc@1 56.2	Acc@5 87.5
Epoch: [44][551/704]	Time 0.120	Data 0.001	Loss 5.27	Acc@1 62.5	Acc@5 96.9
Epoch: [44][561/704]	Time 0.120	Data 0.001	Loss 4.99	Acc@1 65.6	Acc@5 93.8
Epoch: [44][571/704]	Time 0.120	Data 0.001	Loss 6.53	Acc@1 62.5	Acc@5 84.4
Epoch: [44][581/704]	Time 0.120	Data 0.001	Loss 6.67	Acc@1 57.8	Acc@5 82.8
Epoch: [44][591/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 64.1	Acc@5 95.3
Epoch: [44][601/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 54.7	Acc@5 89.1
Epoch: [44][611/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 68.8	Acc@5 92.2
Epoch: [44][621/704]	Time 0.120	Data 0.001	Loss 5.27	Acc@1 68.8	Acc@5 92.2
Epoch: [44][631/704]	Time 0.120	Data 0.001	Loss 6.37	Acc@1 62.5	Acc@5 89.1
Epoch: [44][641/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 60.9	Acc@5 93.8
Epoch: [44][651/704]	Time 0.120	Data 0.001	Loss 6.78	Acc@1 56.2	Acc@5 85.9
Epoch: [44][661/704]	Time 0.120	Data 0.001	Loss 5.57	Acc@1 65.6	Acc@5 93.8
Epoch: [44][671/704]	Time 0.120	Data 0.001	Loss 7.60	Acc@1 54.7	Acc@5 87.5
Epoch: [44][681/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 51.6	Acc@5 92.2
Epoch: [44][691/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 59.4	Acc@5 85.9
Epoch: [44][701/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 62.5	Acc@5 81.2
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 8.1111	Acc@1 46.8750	Acc@5 75.0000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.9302	Acc@1 43.7500	Acc@5 73.4375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.3043	Acc@1 45.3125	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9134	Acc@1 48.4375	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.0418	Acc@1 59.3750	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.4872	Acc@1 43.7500	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6722	Acc@1 50.0000	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.2545	Acc@1 56.2500	Acc@5 85.9375
 * prec@1 45.840 prec@5 76.540
 * prec@1 50.240 prec@5 80.200
 * prec@1 51.700 prec@5 81.280
 * prec@1 51.520 prec@5 81.700
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_044.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_044.pth.tar'
Epoch: [45][1/704]	Time 0.297	Data 0.129	Loss 3.85	Acc@1 78.1	Acc@5 98.4
Epoch: [45][11/704]	Time 0.140	Data 0.012	Loss 5.72	Acc@1 65.6	Acc@5 93.8
Epoch: [45][21/704]	Time 0.130	Data 0.007	Loss 6.47	Acc@1 59.4	Acc@5 90.6
Epoch: [45][31/704]	Time 0.127	Data 0.005	Loss 7.03	Acc@1 59.4	Acc@5 89.1
Epoch: [45][41/704]	Time 0.125	Data 0.004	Loss 4.75	Acc@1 73.4	Acc@5 95.3
Epoch: [45][51/704]	Time 0.124	Data 0.003	Loss 4.86	Acc@1 67.2	Acc@5 85.9
Epoch: [45][61/704]	Time 0.123	Data 0.002	Loss 5.32	Acc@1 65.6	Acc@5 95.3
Epoch: [45][71/704]	Time 0.123	Data 0.002	Loss 4.90	Acc@1 60.9	Acc@5 90.6
Epoch: [45][81/704]	Time 0.122	Data 0.002	Loss 5.61	Acc@1 64.1	Acc@5 95.3
Epoch: [45][91/704]	Time 0.122	Data 0.002	Loss 5.40	Acc@1 68.8	Acc@5 90.6
Epoch: [45][101/704]	Time 0.122	Data 0.002	Loss 4.98	Acc@1 62.5	Acc@5 93.8
Epoch: [45][111/704]	Time 0.122	Data 0.002	Loss 6.30	Acc@1 65.6	Acc@5 90.6
Epoch: [45][121/704]	Time 0.122	Data 0.001	Loss 5.38	Acc@1 65.6	Acc@5 92.2
Epoch: [45][131/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 70.3	Acc@5 95.3
Epoch: [45][141/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 67.2	Acc@5 92.2
Epoch: [45][151/704]	Time 0.121	Data 0.001	Loss 6.99	Acc@1 60.9	Acc@5 87.5
Epoch: [45][161/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 56.2	Acc@5 90.6
Epoch: [45][171/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 62.5	Acc@5 90.6
Epoch: [45][181/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 48.4	Acc@5 84.4
Epoch: [45][191/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 57.8	Acc@5 87.5
Epoch: [45][201/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 70.3	Acc@5 98.4
Epoch: [45][211/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 62.5	Acc@5 89.1
Epoch: [45][221/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 93.8
Epoch: [45][231/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 75.0	Acc@5 93.8
Epoch: [45][241/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 68.8	Acc@5 87.5
Epoch: [45][251/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 78.1	Acc@5 92.2
Epoch: [45][261/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 60.9	Acc@5 90.6
Epoch: [45][271/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 92.2
Epoch: [45][281/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 67.2	Acc@5 92.2
Epoch: [45][291/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 67.2	Acc@5 90.6
Epoch: [45][301/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 64.1	Acc@5 96.9
Epoch: [45][311/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 60.9	Acc@5 81.2
Epoch: [45][321/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 67.2	Acc@5 92.2
Epoch: [45][331/704]	Time 0.120	Data 0.001	Loss 6.36	Acc@1 62.5	Acc@5 87.5
Epoch: [45][341/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 71.9	Acc@5 89.1
Epoch: [45][351/704]	Time 0.120	Data 0.001	Loss 6.73	Acc@1 62.5	Acc@5 82.8
Epoch: [45][361/704]	Time 0.120	Data 0.001	Loss 4.42	Acc@1 70.3	Acc@5 95.3
Epoch: [45][371/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 71.9	Acc@5 84.4
Epoch: [45][381/704]	Time 0.120	Data 0.001	Loss 4.97	Acc@1 65.6	Acc@5 95.3
Epoch: [45][391/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 70.3	Acc@5 89.1
Epoch: [45][401/704]	Time 0.120	Data 0.001	Loss 6.23	Acc@1 59.4	Acc@5 89.1
Epoch: [45][411/704]	Time 0.120	Data 0.001	Loss 5.35	Acc@1 60.9	Acc@5 89.1
Epoch: [45][421/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 64.1	Acc@5 95.3
Epoch: [45][431/704]	Time 0.120	Data 0.001	Loss 4.70	Acc@1 71.9	Acc@5 89.1
Epoch: [45][441/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 57.8	Acc@5 84.4
Epoch: [45][451/704]	Time 0.120	Data 0.001	Loss 6.78	Acc@1 60.9	Acc@5 82.8
Epoch: [45][461/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 67.2	Acc@5 87.5
Epoch: [45][471/704]	Time 0.120	Data 0.001	Loss 4.93	Acc@1 71.9	Acc@5 90.6
Epoch: [45][481/704]	Time 0.120	Data 0.001	Loss 7.20	Acc@1 57.8	Acc@5 81.2
Epoch: [45][491/704]	Time 0.120	Data 0.001	Loss 6.68	Acc@1 57.8	Acc@5 82.8
Epoch: [45][501/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 68.8	Acc@5 92.2
Epoch: [45][511/704]	Time 0.120	Data 0.001	Loss 4.94	Acc@1 65.6	Acc@5 92.2
Epoch: [45][521/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 90.6
Epoch: [45][531/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 65.6	Acc@5 96.9
Epoch: [45][541/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 67.2	Acc@5 92.2
Epoch: [45][551/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 54.7	Acc@5 85.9
Epoch: [45][561/704]	Time 0.120	Data 0.001	Loss 6.28	Acc@1 67.2	Acc@5 84.4
Epoch: [45][571/704]	Time 0.120	Data 0.001	Loss 4.54	Acc@1 76.6	Acc@5 95.3
Epoch: [45][581/704]	Time 0.120	Data 0.001	Loss 8.18	Acc@1 46.9	Acc@5 84.4
Epoch: [45][591/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 67.2	Acc@5 87.5
Epoch: [45][601/704]	Time 0.120	Data 0.001	Loss 6.26	Acc@1 60.9	Acc@5 82.8
Epoch: [45][611/704]	Time 0.120	Data 0.001	Loss 4.93	Acc@1 71.9	Acc@5 93.8
Epoch: [45][621/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 65.6	Acc@5 92.2
Epoch: [45][631/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 67.2	Acc@5 92.2
Epoch: [45][641/704]	Time 0.120	Data 0.001	Loss 5.39	Acc@1 59.4	Acc@5 93.8
Epoch: [45][651/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 65.6	Acc@5 92.2
Epoch: [45][661/704]	Time 0.120	Data 0.001	Loss 3.78	Acc@1 76.6	Acc@5 95.3
Epoch: [45][671/704]	Time 0.120	Data 0.001	Loss 7.05	Acc@1 51.6	Acc@5 87.5
Epoch: [45][681/704]	Time 0.120	Data 0.001	Loss 4.72	Acc@1 73.4	Acc@5 90.6
Epoch: [45][691/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 56.2	Acc@5 92.2
Epoch: [45][701/704]	Time 0.120	Data 0.001	Loss 6.52	Acc@1 57.8	Acc@5 85.9
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.2713	Acc@1 57.8125	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.0802	Acc@1 57.8125	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.0396	Acc@1 62.5000	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.1924	Acc@1 67.1875	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2117	Acc@1 54.6875	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.1608	Acc@1 65.6250	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.3984	Acc@1 51.5625	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.0729	Acc@1 54.6875	Acc@5 78.1250
 * prec@1 46.120 prec@5 76.440
 * prec@1 51.360 prec@5 81.980
 * prec@1 54.820 prec@5 83.380
 * prec@1 56.400 prec@5 84.860
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_045.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_045.pth.tar'
Epoch: [46][1/704]	Time 0.330	Data 0.163	Loss 6.51	Acc@1 57.8	Acc@5 95.3
Epoch: [46][11/704]	Time 0.139	Data 0.015	Loss 7.39	Acc@1 59.4	Acc@5 89.1
Epoch: [46][21/704]	Time 0.130	Data 0.008	Loss 6.56	Acc@1 60.9	Acc@5 93.8
Epoch: [46][31/704]	Time 0.127	Data 0.006	Loss 6.01	Acc@1 64.1	Acc@5 89.1
Epoch: [46][41/704]	Time 0.126	Data 0.004	Loss 6.28	Acc@1 56.2	Acc@5 84.4
Epoch: [46][51/704]	Time 0.124	Data 0.003	Loss 5.76	Acc@1 67.2	Acc@5 90.6
Epoch: [46][61/704]	Time 0.124	Data 0.003	Loss 6.00	Acc@1 62.5	Acc@5 89.1
Epoch: [46][71/704]	Time 0.123	Data 0.003	Loss 5.18	Acc@1 62.5	Acc@5 95.3
Epoch: [46][81/704]	Time 0.123	Data 0.002	Loss 6.18	Acc@1 59.4	Acc@5 85.9
Epoch: [46][91/704]	Time 0.123	Data 0.002	Loss 6.26	Acc@1 62.5	Acc@5 85.9
Epoch: [46][101/704]	Time 0.122	Data 0.002	Loss 4.88	Acc@1 67.2	Acc@5 95.3
Epoch: [46][111/704]	Time 0.122	Data 0.002	Loss 5.53	Acc@1 60.9	Acc@5 95.3
Epoch: [46][121/704]	Time 0.122	Data 0.002	Loss 4.32	Acc@1 75.0	Acc@5 93.8
Epoch: [46][131/704]	Time 0.122	Data 0.002	Loss 5.16	Acc@1 71.9	Acc@5 95.3
Epoch: [46][141/704]	Time 0.122	Data 0.002	Loss 4.50	Acc@1 71.9	Acc@5 93.8
Epoch: [46][151/704]	Time 0.122	Data 0.001	Loss 5.78	Acc@1 67.2	Acc@5 92.2
Epoch: [46][161/704]	Time 0.122	Data 0.001	Loss 4.89	Acc@1 67.2	Acc@5 98.4
Epoch: [46][171/704]	Time 0.122	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 96.9
Epoch: [46][181/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 71.9	Acc@5 93.8
Epoch: [46][191/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 92.2
Epoch: [46][201/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 68.8	Acc@5 84.4
Epoch: [46][211/704]	Time 0.121	Data 0.001	Loss 6.24	Acc@1 60.9	Acc@5 89.1
Epoch: [46][221/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 64.1	Acc@5 92.2
Epoch: [46][231/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 67.2	Acc@5 90.6
Epoch: [46][241/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 68.8	Acc@5 96.9
Epoch: [46][251/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 67.2	Acc@5 92.2
Epoch: [46][261/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 62.5	Acc@5 93.8
Epoch: [46][271/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 59.4	Acc@5 92.2
Epoch: [46][281/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 93.8
Epoch: [46][291/704]	Time 0.121	Data 0.001	Loss 6.75	Acc@1 56.2	Acc@5 87.5
Epoch: [46][301/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 68.8	Acc@5 90.6
Epoch: [46][311/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 67.2	Acc@5 92.2
Epoch: [46][321/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 68.8	Acc@5 93.8
Epoch: [46][331/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 57.8	Acc@5 92.2
Epoch: [46][341/704]	Time 0.121	Data 0.001	Loss 6.48	Acc@1 59.4	Acc@5 82.8
Epoch: [46][351/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 70.3	Acc@5 95.3
Epoch: [46][361/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 56.2	Acc@5 95.3
Epoch: [46][371/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 67.2	Acc@5 93.8
Epoch: [46][381/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 50.0	Acc@5 92.2
Epoch: [46][391/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 67.2	Acc@5 93.8
Epoch: [46][401/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 67.2	Acc@5 96.9
Epoch: [46][411/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 67.2	Acc@5 90.6
Epoch: [46][421/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 62.5	Acc@5 90.6
Epoch: [46][431/704]	Time 0.121	Data 0.001	Loss 6.64	Acc@1 56.2	Acc@5 87.5
Epoch: [46][441/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 60.9	Acc@5 89.1
Epoch: [46][451/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 67.2	Acc@5 89.1
Epoch: [46][461/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 67.2	Acc@5 95.3
Epoch: [46][471/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 68.8	Acc@5 87.5
Epoch: [46][481/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 67.2	Acc@5 90.6
Epoch: [46][491/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 92.2
Epoch: [46][501/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 60.9	Acc@5 85.9
Epoch: [46][511/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 62.5	Acc@5 92.2
Epoch: [46][521/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 67.2	Acc@5 87.5
Epoch: [46][531/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 68.8	Acc@5 90.6
Epoch: [46][541/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 57.8	Acc@5 87.5
Epoch: [46][551/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 59.4	Acc@5 89.1
Epoch: [46][561/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 62.5	Acc@5 89.1
Epoch: [46][571/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 68.8	Acc@5 90.6
Epoch: [46][581/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 70.3	Acc@5 92.2
Epoch: [46][591/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 56.2	Acc@5 85.9
Epoch: [46][601/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 57.8	Acc@5 90.6
Epoch: [46][611/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 64.1	Acc@5 92.2
Epoch: [46][621/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 68.8	Acc@5 98.4
Epoch: [46][631/704]	Time 0.121	Data 0.001	Loss 6.91	Acc@1 59.4	Acc@5 89.1
Epoch: [46][641/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 68.8	Acc@5 93.8
Epoch: [46][651/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 60.9	Acc@5 90.6
Epoch: [46][661/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 71.9	Acc@5 89.1
Epoch: [46][671/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 75.0	Acc@5 93.8
Epoch: [46][681/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 59.4	Acc@5 82.8
Epoch: [46][691/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 67.2	Acc@5 92.2
Epoch: [46][701/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 65.6	Acc@5 92.2
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.1580	Acc@1 65.6250	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.8259	Acc@1 57.8125	Acc@5 75.0000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.3164	Acc@1 42.1875	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6172	Acc@1 59.3750	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4942	Acc@1 50.0000	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.3348	Acc@1 59.3750	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.7999	Acc@1 54.6875	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9191	Acc@1 56.2500	Acc@5 84.3750
 * prec@1 45.160 prec@5 76.360
 * prec@1 49.180 prec@5 79.740
 * prec@1 53.860 prec@5 83.360
 * prec@1 54.720 prec@5 84.000
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_046.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_046.pth.tar'
Epoch: [47][1/704]	Time 0.297	Data 0.131	Loss 4.63	Acc@1 73.4	Acc@5 95.3
Epoch: [47][11/704]	Time 0.136	Data 0.012	Loss 5.17	Acc@1 67.2	Acc@5 96.9
Epoch: [47][21/704]	Time 0.128	Data 0.007	Loss 6.07	Acc@1 68.8	Acc@5 92.2
Epoch: [47][31/704]	Time 0.125	Data 0.005	Loss 5.74	Acc@1 70.3	Acc@5 92.2
Epoch: [47][41/704]	Time 0.124	Data 0.004	Loss 6.83	Acc@1 56.2	Acc@5 92.2
Epoch: [47][51/704]	Time 0.123	Data 0.003	Loss 4.84	Acc@1 70.3	Acc@5 90.6
Epoch: [47][61/704]	Time 0.123	Data 0.002	Loss 4.41	Acc@1 70.3	Acc@5 92.2
Epoch: [47][71/704]	Time 0.122	Data 0.002	Loss 5.48	Acc@1 65.6	Acc@5 92.2
Epoch: [47][81/704]	Time 0.122	Data 0.002	Loss 5.60	Acc@1 68.8	Acc@5 87.5
Epoch: [47][91/704]	Time 0.122	Data 0.002	Loss 5.03	Acc@1 71.9	Acc@5 90.6
Epoch: [47][101/704]	Time 0.122	Data 0.002	Loss 5.47	Acc@1 62.5	Acc@5 85.9
Epoch: [47][111/704]	Time 0.121	Data 0.002	Loss 5.15	Acc@1 67.2	Acc@5 90.6
Epoch: [47][121/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 68.8	Acc@5 85.9
Epoch: [47][131/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 65.6	Acc@5 90.6
Epoch: [47][141/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 71.9	Acc@5 92.2
Epoch: [47][151/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 70.3	Acc@5 92.2
Epoch: [47][161/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 68.8	Acc@5 85.9
Epoch: [47][171/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 59.4	Acc@5 89.1
Epoch: [47][181/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 67.2	Acc@5 89.1
Epoch: [47][191/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 71.9	Acc@5 93.8
Epoch: [47][201/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 67.2	Acc@5 92.2
Epoch: [47][211/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 65.6	Acc@5 93.8
Epoch: [47][221/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 64.1	Acc@5 95.3
Epoch: [47][231/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 79.7	Acc@5 90.6
Epoch: [47][241/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 60.9	Acc@5 92.2
Epoch: [47][251/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 67.2	Acc@5 89.1
Epoch: [47][261/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 70.3	Acc@5 96.9
Epoch: [47][271/704]	Time 0.121	Data 0.001	Loss 6.95	Acc@1 56.2	Acc@5 89.1
Epoch: [47][281/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 67.2	Acc@5 84.4
Epoch: [47][291/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 65.6	Acc@5 93.8
Epoch: [47][301/704]	Time 0.120	Data 0.001	Loss 6.30	Acc@1 65.6	Acc@5 90.6
Epoch: [47][311/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 70.3	Acc@5 90.6
Epoch: [47][321/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 59.4	Acc@5 84.4
Epoch: [47][331/704]	Time 0.120	Data 0.001	Loss 4.34	Acc@1 70.3	Acc@5 93.8
Epoch: [47][341/704]	Time 0.120	Data 0.001	Loss 5.89	Acc@1 70.3	Acc@5 93.8
Epoch: [47][351/704]	Time 0.120	Data 0.001	Loss 5.63	Acc@1 68.8	Acc@5 93.8
Epoch: [47][361/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 59.4	Acc@5 87.5
Epoch: [47][371/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 57.8	Acc@5 89.1
Epoch: [47][381/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 62.5	Acc@5 96.9
Epoch: [47][391/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 60.9	Acc@5 85.9
Epoch: [47][401/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 60.9	Acc@5 90.6
Epoch: [47][411/704]	Time 0.120	Data 0.001	Loss 5.73	Acc@1 65.6	Acc@5 84.4
Epoch: [47][421/704]	Time 0.120	Data 0.001	Loss 6.23	Acc@1 65.6	Acc@5 90.6
Epoch: [47][431/704]	Time 0.120	Data 0.001	Loss 7.16	Acc@1 54.7	Acc@5 87.5
Epoch: [47][441/704]	Time 0.120	Data 0.001	Loss 4.61	Acc@1 71.9	Acc@5 95.3
Epoch: [47][451/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 71.9	Acc@5 92.2
Epoch: [47][461/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 62.5	Acc@5 89.1
Epoch: [47][471/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 60.9	Acc@5 92.2
Epoch: [47][481/704]	Time 0.120	Data 0.001	Loss 6.64	Acc@1 54.7	Acc@5 87.5
Epoch: [47][491/704]	Time 0.120	Data 0.001	Loss 7.06	Acc@1 54.7	Acc@5 89.1
Epoch: [47][501/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 71.9	Acc@5 87.5
Epoch: [47][511/704]	Time 0.120	Data 0.001	Loss 6.98	Acc@1 57.8	Acc@5 87.5
Epoch: [47][521/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 75.0	Acc@5 90.6
Epoch: [47][531/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 90.6
Epoch: [47][541/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 67.2	Acc@5 92.2
Epoch: [47][551/704]	Time 0.120	Data 0.001	Loss 5.65	Acc@1 65.6	Acc@5 90.6
Epoch: [47][561/704]	Time 0.120	Data 0.001	Loss 6.60	Acc@1 59.4	Acc@5 92.2
Epoch: [47][571/704]	Time 0.120	Data 0.001	Loss 6.39	Acc@1 60.9	Acc@5 84.4
Epoch: [47][581/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 67.2	Acc@5 89.1
Epoch: [47][591/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 70.3	Acc@5 93.8
Epoch: [47][601/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 71.9	Acc@5 89.1
Epoch: [47][611/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 62.5	Acc@5 93.8
Epoch: [47][621/704]	Time 0.120	Data 0.001	Loss 5.96	Acc@1 60.9	Acc@5 92.2
Epoch: [47][631/704]	Time 0.120	Data 0.001	Loss 6.00	Acc@1 57.8	Acc@5 89.1
Epoch: [47][641/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 73.4	Acc@5 89.1
Epoch: [47][651/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 60.9	Acc@5 89.1
Epoch: [47][661/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 71.9	Acc@5 90.6
Epoch: [47][671/704]	Time 0.120	Data 0.001	Loss 4.17	Acc@1 78.1	Acc@5 98.4
Epoch: [47][681/704]	Time 0.120	Data 0.001	Loss 5.80	Acc@1 70.3	Acc@5 90.6
Epoch: [47][691/704]	Time 0.120	Data 0.001	Loss 4.83	Acc@1 73.4	Acc@5 92.2
Epoch: [47][701/704]	Time 0.120	Data 0.001	Loss 5.48	Acc@1 70.3	Acc@5 89.1
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.8000	Acc@1 64.0625	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.7806	Acc@1 57.8125	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.8897	Acc@1 54.6875	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.2838	Acc@1 60.9375	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4972	Acc@1 54.6875	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9171	Acc@1 53.1250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.1535	Acc@1 56.2500	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1129	Acc@1 60.9375	Acc@5 89.0625
 * prec@1 45.620 prec@5 76.720
 * prec@1 51.180 prec@5 81.640
 * prec@1 54.380 prec@5 83.860
 * prec@1 55.440 prec@5 84.980
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_047.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_047.pth.tar'
Epoch: [48][1/704]	Time 0.297	Data 0.130	Loss 5.38	Acc@1 70.3	Acc@5 93.8
Epoch: [48][11/704]	Time 0.136	Data 0.012	Loss 4.62	Acc@1 65.6	Acc@5 92.2
Epoch: [48][21/704]	Time 0.128	Data 0.007	Loss 3.93	Acc@1 75.0	Acc@5 98.4
Epoch: [48][31/704]	Time 0.125	Data 0.005	Loss 6.23	Acc@1 62.5	Acc@5 89.1
Epoch: [48][41/704]	Time 0.124	Data 0.003	Loss 5.22	Acc@1 71.9	Acc@5 89.1
Epoch: [48][51/704]	Time 0.123	Data 0.003	Loss 5.58	Acc@1 67.2	Acc@5 85.9
Epoch: [48][61/704]	Time 0.123	Data 0.002	Loss 6.37	Acc@1 62.5	Acc@5 89.1
Epoch: [48][71/704]	Time 0.123	Data 0.002	Loss 5.23	Acc@1 64.1	Acc@5 92.2
Epoch: [48][81/704]	Time 0.122	Data 0.002	Loss 6.23	Acc@1 68.8	Acc@5 87.5
Epoch: [48][91/704]	Time 0.122	Data 0.002	Loss 5.06	Acc@1 76.6	Acc@5 93.8
Epoch: [48][101/704]	Time 0.122	Data 0.002	Loss 5.41	Acc@1 60.9	Acc@5 90.6
Epoch: [48][111/704]	Time 0.122	Data 0.001	Loss 5.64	Acc@1 67.2	Acc@5 93.8
Epoch: [48][121/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 65.6	Acc@5 84.4
Epoch: [48][131/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 62.5	Acc@5 90.6
Epoch: [48][141/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 65.6	Acc@5 92.2
Epoch: [48][151/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 67.2	Acc@5 93.8
Epoch: [48][161/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 76.6	Acc@5 95.3
Epoch: [48][171/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 73.4	Acc@5 93.8
Epoch: [48][181/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 71.9	Acc@5 93.8
Epoch: [48][191/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 67.2	Acc@5 92.2
Epoch: [48][201/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 62.5	Acc@5 92.2
Epoch: [48][211/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 65.6	Acc@5 93.8
Epoch: [48][221/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 68.8	Acc@5 100.0
Epoch: [48][231/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 62.5	Acc@5 90.6
Epoch: [48][241/704]	Time 0.120	Data 0.001	Loss 6.59	Acc@1 53.1	Acc@5 85.9
Epoch: [48][251/704]	Time 0.120	Data 0.001	Loss 6.42	Acc@1 59.4	Acc@5 89.1
Epoch: [48][261/704]	Time 0.120	Data 0.001	Loss 5.46	Acc@1 68.8	Acc@5 89.1
Epoch: [48][271/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 65.6	Acc@5 92.2
Epoch: [48][281/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 73.4	Acc@5 90.6
Epoch: [48][291/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 64.1	Acc@5 90.6
Epoch: [48][301/704]	Time 0.120	Data 0.001	Loss 4.58	Acc@1 70.3	Acc@5 92.2
Epoch: [48][311/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 95.3
Epoch: [48][321/704]	Time 0.120	Data 0.001	Loss 4.61	Acc@1 71.9	Acc@5 95.3
Epoch: [48][331/704]	Time 0.120	Data 0.001	Loss 4.54	Acc@1 73.4	Acc@5 93.8
Epoch: [48][341/704]	Time 0.120	Data 0.001	Loss 5.80	Acc@1 57.8	Acc@5 92.2
Epoch: [48][351/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 71.9	Acc@5 92.2
Epoch: [48][361/704]	Time 0.120	Data 0.001	Loss 5.27	Acc@1 67.2	Acc@5 90.6
Epoch: [48][371/704]	Time 0.120	Data 0.001	Loss 4.94	Acc@1 70.3	Acc@5 96.9
Epoch: [48][381/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 57.8	Acc@5 93.8
Epoch: [48][391/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 93.8
Epoch: [48][401/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 57.8	Acc@5 92.2
Epoch: [48][411/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 71.9	Acc@5 89.1
Epoch: [48][421/704]	Time 0.120	Data 0.001	Loss 5.97	Acc@1 65.6	Acc@5 93.8
Epoch: [48][431/704]	Time 0.120	Data 0.001	Loss 6.14	Acc@1 56.2	Acc@5 87.5
Epoch: [48][441/704]	Time 0.120	Data 0.001	Loss 4.94	Acc@1 67.2	Acc@5 93.8
Epoch: [48][451/704]	Time 0.120	Data 0.001	Loss 5.09	Acc@1 73.4	Acc@5 90.6
Epoch: [48][461/704]	Time 0.120	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 95.3
Epoch: [48][471/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 60.9	Acc@5 90.6
Epoch: [48][481/704]	Time 0.120	Data 0.001	Loss 4.81	Acc@1 70.3	Acc@5 95.3
Epoch: [48][491/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 92.2
Epoch: [48][501/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 60.9	Acc@5 90.6
Epoch: [48][511/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 60.9	Acc@5 90.6
Epoch: [48][521/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 73.4	Acc@5 95.3
Epoch: [48][531/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 57.8	Acc@5 87.5
Epoch: [48][541/704]	Time 0.120	Data 0.001	Loss 6.93	Acc@1 57.8	Acc@5 87.5
Epoch: [48][551/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 67.2	Acc@5 92.2
Epoch: [48][561/704]	Time 0.120	Data 0.001	Loss 4.60	Acc@1 67.2	Acc@5 95.3
Epoch: [48][571/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 62.5	Acc@5 92.2
Epoch: [48][581/704]	Time 0.120	Data 0.001	Loss 7.28	Acc@1 60.9	Acc@5 85.9
Epoch: [48][591/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 57.8	Acc@5 92.2
Epoch: [48][601/704]	Time 0.120	Data 0.001	Loss 6.76	Acc@1 60.9	Acc@5 81.2
Epoch: [48][611/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 68.8	Acc@5 93.8
Epoch: [48][621/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 59.4	Acc@5 87.5
Epoch: [48][631/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 68.8	Acc@5 92.2
Epoch: [48][641/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 64.1	Acc@5 84.4
Epoch: [48][651/704]	Time 0.120	Data 0.001	Loss 6.75	Acc@1 53.1	Acc@5 90.6
Epoch: [48][661/704]	Time 0.120	Data 0.001	Loss 4.72	Acc@1 68.8	Acc@5 93.8
Epoch: [48][671/704]	Time 0.120	Data 0.001	Loss 4.28	Acc@1 68.8	Acc@5 93.8
Epoch: [48][681/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 62.5	Acc@5 87.5
Epoch: [48][691/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 73.4	Acc@5 96.9
Epoch: [48][701/704]	Time 0.120	Data 0.001	Loss 6.21	Acc@1 60.9	Acc@5 85.9
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.1717	Acc@1 64.0625	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7666	Acc@1 56.2500	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.8694	Acc@1 57.8125	Acc@5 76.5625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.0990	Acc@1 54.6875	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3399	Acc@1 54.6875	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0045	Acc@1 70.3125	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4735	Acc@1 51.5625	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.2979	Acc@1 48.4375	Acc@5 76.5625
 * prec@1 47.040 prec@5 78.520
 * prec@1 50.760 prec@5 81.840
 * prec@1 52.980 prec@5 82.840
 * prec@1 54.440 prec@5 83.240
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_048.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_048.pth.tar'
Epoch: [49][1/704]	Time 0.329	Data 0.163	Loss 4.93	Acc@1 70.3	Acc@5 93.8
Epoch: [49][11/704]	Time 0.139	Data 0.015	Loss 6.84	Acc@1 56.2	Acc@5 87.5
Epoch: [49][21/704]	Time 0.130	Data 0.008	Loss 6.12	Acc@1 54.7	Acc@5 89.1
Epoch: [49][31/704]	Time 0.127	Data 0.006	Loss 4.81	Acc@1 76.6	Acc@5 92.2
Epoch: [49][41/704]	Time 0.125	Data 0.004	Loss 6.40	Acc@1 57.8	Acc@5 90.6
Epoch: [49][51/704]	Time 0.124	Data 0.003	Loss 4.76	Acc@1 76.6	Acc@5 100.0
Epoch: [49][61/704]	Time 0.123	Data 0.003	Loss 5.44	Acc@1 59.4	Acc@5 93.8
Epoch: [49][71/704]	Time 0.123	Data 0.003	Loss 5.15	Acc@1 70.3	Acc@5 90.6
Epoch: [49][81/704]	Time 0.122	Data 0.002	Loss 5.02	Acc@1 68.8	Acc@5 92.2
Epoch: [49][91/704]	Time 0.122	Data 0.002	Loss 4.95	Acc@1 70.3	Acc@5 92.2
Epoch: [49][101/704]	Time 0.122	Data 0.002	Loss 3.74	Acc@1 75.0	Acc@5 96.9
Epoch: [49][111/704]	Time 0.122	Data 0.002	Loss 6.18	Acc@1 64.1	Acc@5 87.5
Epoch: [49][121/704]	Time 0.121	Data 0.002	Loss 5.31	Acc@1 73.4	Acc@5 92.2
Epoch: [49][131/704]	Time 0.121	Data 0.002	Loss 4.28	Acc@1 70.3	Acc@5 92.2
Epoch: [49][141/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 89.1
Epoch: [49][151/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 71.9	Acc@5 93.8
Epoch: [49][161/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 60.9	Acc@5 84.4
Epoch: [49][171/704]	Time 0.121	Data 0.001	Loss 6.38	Acc@1 60.9	Acc@5 87.5
Epoch: [49][181/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 78.1	Acc@5 92.2
Epoch: [49][191/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 68.8	Acc@5 90.6
Epoch: [49][201/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 73.4	Acc@5 89.1
Epoch: [49][211/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 68.8	Acc@5 92.2
Epoch: [49][221/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 93.8
Epoch: [49][231/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 75.0	Acc@5 93.8
Epoch: [49][241/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 68.8	Acc@5 90.6
Epoch: [49][251/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 57.8	Acc@5 87.5
Epoch: [49][261/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 62.5	Acc@5 87.5
Epoch: [49][271/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 67.2	Acc@5 95.3
Epoch: [49][281/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 64.1	Acc@5 85.9
Epoch: [49][291/704]	Time 0.120	Data 0.001	Loss 6.95	Acc@1 67.2	Acc@5 87.5
Epoch: [49][301/704]	Time 0.120	Data 0.001	Loss 5.59	Acc@1 67.2	Acc@5 90.6
Epoch: [49][311/704]	Time 0.120	Data 0.001	Loss 4.81	Acc@1 70.3	Acc@5 89.1
Epoch: [49][321/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 73.4	Acc@5 90.6
Epoch: [49][331/704]	Time 0.120	Data 0.001	Loss 4.25	Acc@1 73.4	Acc@5 95.3
Epoch: [49][341/704]	Time 0.120	Data 0.001	Loss 5.80	Acc@1 62.5	Acc@5 92.2
Epoch: [49][351/704]	Time 0.120	Data 0.001	Loss 6.46	Acc@1 67.2	Acc@5 89.1
Epoch: [49][361/704]	Time 0.120	Data 0.001	Loss 4.97	Acc@1 65.6	Acc@5 93.8
Epoch: [49][371/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 68.8	Acc@5 87.5
Epoch: [49][381/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 64.1	Acc@5 90.6
Epoch: [49][391/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 62.5	Acc@5 95.3
Epoch: [49][401/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 65.6	Acc@5 85.9
Epoch: [49][411/704]	Time 0.120	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 95.3
Epoch: [49][421/704]	Time 0.120	Data 0.001	Loss 6.59	Acc@1 64.1	Acc@5 87.5
Epoch: [49][431/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 68.8	Acc@5 95.3
Epoch: [49][441/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 64.1	Acc@5 87.5
Epoch: [49][451/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 73.4	Acc@5 90.6
Epoch: [49][461/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 71.9	Acc@5 89.1
Epoch: [49][471/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 57.8	Acc@5 84.4
Epoch: [49][481/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 60.9	Acc@5 90.6
Epoch: [49][491/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 59.4	Acc@5 92.2
Epoch: [49][501/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 59.4	Acc@5 90.6
Epoch: [49][511/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 68.8	Acc@5 90.6
Epoch: [49][521/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 71.9	Acc@5 93.8
Epoch: [49][531/704]	Time 0.120	Data 0.001	Loss 6.26	Acc@1 56.2	Acc@5 84.4
Epoch: [49][541/704]	Time 0.120	Data 0.001	Loss 4.27	Acc@1 71.9	Acc@5 93.8
Epoch: [49][551/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 92.2
Epoch: [49][561/704]	Time 0.120	Data 0.001	Loss 4.99	Acc@1 64.1	Acc@5 90.6
Epoch: [49][571/704]	Time 0.120	Data 0.001	Loss 5.27	Acc@1 70.3	Acc@5 92.2
Epoch: [49][581/704]	Time 0.120	Data 0.001	Loss 6.67	Acc@1 54.7	Acc@5 84.4
Epoch: [49][591/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 60.9	Acc@5 81.2
Epoch: [49][601/704]	Time 0.120	Data 0.001	Loss 4.36	Acc@1 68.8	Acc@5 92.2
Epoch: [49][611/704]	Time 0.120	Data 0.001	Loss 4.88	Acc@1 70.3	Acc@5 92.2
Epoch: [49][621/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 64.1	Acc@5 95.3
Epoch: [49][631/704]	Time 0.120	Data 0.001	Loss 6.01	Acc@1 65.6	Acc@5 85.9
Epoch: [49][641/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 70.3	Acc@5 87.5
Epoch: [49][651/704]	Time 0.120	Data 0.001	Loss 5.91	Acc@1 64.1	Acc@5 89.1
Epoch: [49][661/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 68.8	Acc@5 92.2
Epoch: [49][671/704]	Time 0.120	Data 0.001	Loss 6.42	Acc@1 60.9	Acc@5 85.9
Epoch: [49][681/704]	Time 0.120	Data 0.001	Loss 6.58	Acc@1 62.5	Acc@5 89.1
Epoch: [49][691/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 64.1	Acc@5 90.6
Epoch: [49][701/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 56.2	Acc@5 87.5
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.0712	Acc@1 57.8125	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.5857	Acc@1 65.6250	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 9.1520	Acc@1 42.1875	Acc@5 75.0000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3855	Acc@1 67.1875	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.6163	Acc@1 51.5625	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7996	Acc@1 60.9375	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.5752	Acc@1 54.6875	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.0819	Acc@1 50.0000	Acc@5 87.5000
 * prec@1 43.240 prec@5 75.360
 * prec@1 49.580 prec@5 81.380
 * prec@1 53.980 prec@5 84.480
 * prec@1 55.820 prec@5 85.100
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_049.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_049.pth.tar'
Epoch: [50][1/704]	Time 0.335	Data 0.168	Loss 5.27	Acc@1 62.5	Acc@5 90.6
Epoch: [50][11/704]	Time 0.140	Data 0.016	Loss 7.12	Acc@1 65.6	Acc@5 85.9
Epoch: [50][21/704]	Time 0.131	Data 0.008	Loss 6.18	Acc@1 59.4	Acc@5 85.9
Epoch: [50][31/704]	Time 0.127	Data 0.006	Loss 6.65	Acc@1 59.4	Acc@5 87.5
Epoch: [50][41/704]	Time 0.126	Data 0.004	Loss 6.69	Acc@1 56.2	Acc@5 85.9
Epoch: [50][51/704]	Time 0.125	Data 0.004	Loss 5.10	Acc@1 78.1	Acc@5 89.1
Epoch: [50][61/704]	Time 0.124	Data 0.003	Loss 6.74	Acc@1 62.5	Acc@5 95.3
Epoch: [50][71/704]	Time 0.123	Data 0.003	Loss 6.49	Acc@1 59.4	Acc@5 89.1
Epoch: [50][81/704]	Time 0.123	Data 0.002	Loss 5.54	Acc@1 62.5	Acc@5 89.1
Epoch: [50][91/704]	Time 0.122	Data 0.002	Loss 5.01	Acc@1 60.9	Acc@5 90.6
Epoch: [50][101/704]	Time 0.122	Data 0.002	Loss 4.93	Acc@1 70.3	Acc@5 95.3
Epoch: [50][111/704]	Time 0.122	Data 0.002	Loss 6.24	Acc@1 64.1	Acc@5 87.5
Epoch: [50][121/704]	Time 0.122	Data 0.002	Loss 5.48	Acc@1 73.4	Acc@5 92.2
Epoch: [50][131/704]	Time 0.121	Data 0.002	Loss 6.01	Acc@1 60.9	Acc@5 87.5
Epoch: [50][141/704]	Time 0.121	Data 0.002	Loss 5.16	Acc@1 71.9	Acc@5 92.2
Epoch: [50][151/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 67.2	Acc@5 93.8
Epoch: [50][161/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 60.9	Acc@5 92.2
Epoch: [50][171/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 67.2	Acc@5 87.5
Epoch: [50][181/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 92.2
Epoch: [50][191/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 92.2
Epoch: [50][201/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 67.2	Acc@5 85.9
Epoch: [50][211/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 73.4	Acc@5 95.3
Epoch: [50][221/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 67.2	Acc@5 95.3
Epoch: [50][231/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 64.1	Acc@5 93.8
Epoch: [50][241/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 65.6	Acc@5 90.6
Epoch: [50][251/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 65.6	Acc@5 90.6
Epoch: [50][261/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 76.6	Acc@5 95.3
Epoch: [50][271/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 67.2	Acc@5 90.6
Epoch: [50][281/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 92.2
Epoch: [50][291/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 90.6
Epoch: [50][301/704]	Time 0.120	Data 0.001	Loss 4.81	Acc@1 65.6	Acc@5 95.3
Epoch: [50][311/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 70.3	Acc@5 89.1
Epoch: [50][321/704]	Time 0.120	Data 0.001	Loss 6.89	Acc@1 57.8	Acc@5 89.1
Epoch: [50][331/704]	Time 0.120	Data 0.001	Loss 5.05	Acc@1 71.9	Acc@5 98.4
Epoch: [50][341/704]	Time 0.120	Data 0.001	Loss 6.35	Acc@1 51.6	Acc@5 89.1
Epoch: [50][351/704]	Time 0.120	Data 0.001	Loss 5.01	Acc@1 64.1	Acc@5 95.3
Epoch: [50][361/704]	Time 0.120	Data 0.001	Loss 6.37	Acc@1 67.2	Acc@5 92.2
Epoch: [50][371/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 62.5	Acc@5 92.2
Epoch: [50][381/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 62.5	Acc@5 93.8
Epoch: [50][391/704]	Time 0.120	Data 0.001	Loss 6.22	Acc@1 56.2	Acc@5 87.5
Epoch: [50][401/704]	Time 0.120	Data 0.001	Loss 6.36	Acc@1 64.1	Acc@5 87.5
Epoch: [50][411/704]	Time 0.120	Data 0.001	Loss 5.46	Acc@1 56.2	Acc@5 90.6
Epoch: [50][421/704]	Time 0.120	Data 0.001	Loss 5.96	Acc@1 57.8	Acc@5 89.1
Epoch: [50][431/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 68.8	Acc@5 90.6
Epoch: [50][441/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 70.3	Acc@5 93.8
Epoch: [50][451/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 92.2
Epoch: [50][461/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 73.4	Acc@5 92.2
Epoch: [50][471/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 71.9	Acc@5 93.8
Epoch: [50][481/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 68.8	Acc@5 93.8
Epoch: [50][491/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 57.8	Acc@5 90.6
Epoch: [50][501/704]	Time 0.120	Data 0.001	Loss 5.35	Acc@1 68.8	Acc@5 93.8
Epoch: [50][511/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 70.3	Acc@5 87.5
Epoch: [50][521/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 65.6	Acc@5 93.8
Epoch: [50][531/704]	Time 0.120	Data 0.001	Loss 5.02	Acc@1 67.2	Acc@5 93.8
Epoch: [50][541/704]	Time 0.120	Data 0.001	Loss 5.02	Acc@1 71.9	Acc@5 89.1
Epoch: [50][551/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 71.9	Acc@5 89.1
Epoch: [50][561/704]	Time 0.120	Data 0.001	Loss 6.73	Acc@1 59.4	Acc@5 90.6
Epoch: [50][571/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 62.5	Acc@5 92.2
Epoch: [50][581/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 62.5	Acc@5 90.6
Epoch: [50][591/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 59.4	Acc@5 87.5
Epoch: [50][601/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 71.9	Acc@5 95.3
Epoch: [50][611/704]	Time 0.120	Data 0.001	Loss 6.35	Acc@1 59.4	Acc@5 89.1
Epoch: [50][621/704]	Time 0.120	Data 0.001	Loss 5.57	Acc@1 65.6	Acc@5 92.2
Epoch: [50][631/704]	Time 0.120	Data 0.001	Loss 6.80	Acc@1 51.6	Acc@5 82.8
Epoch: [50][641/704]	Time 0.120	Data 0.001	Loss 4.45	Acc@1 67.2	Acc@5 90.6
Epoch: [50][651/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 68.8	Acc@5 87.5
Epoch: [50][661/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 57.8	Acc@5 92.2
Epoch: [50][671/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 60.9	Acc@5 93.8
Epoch: [50][681/704]	Time 0.120	Data 0.001	Loss 5.48	Acc@1 68.8	Acc@5 92.2
Epoch: [50][691/704]	Time 0.120	Data 0.001	Loss 5.68	Acc@1 64.1	Acc@5 93.8
Epoch: [50][701/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 62.5	Acc@5 87.5
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 8.2128	Acc@1 51.5625	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 4.9907	Acc@1 73.4375	Acc@5 90.6250
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 5.9286	Acc@1 57.8125	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.5461	Acc@1 57.8125	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.8415	Acc@1 59.3750	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7242	Acc@1 45.3125	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4590	Acc@1 67.1875	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.3881	Acc@1 59.3750	Acc@5 84.3750
 * prec@1 46.820 prec@5 78.160
 * prec@1 49.900 prec@5 81.640
 * prec@1 55.660 prec@5 84.180
 * prec@1 55.720 prec@5 84.680
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_050.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_050.pth.tar'
Epoch: [51][1/704]	Time 0.299	Data 0.132	Loss 4.42	Acc@1 75.0	Acc@5 95.3
Epoch: [51][11/704]	Time 0.136	Data 0.012	Loss 5.14	Acc@1 67.2	Acc@5 89.1
Epoch: [51][21/704]	Time 0.128	Data 0.007	Loss 5.82	Acc@1 60.9	Acc@5 95.3
Epoch: [51][31/704]	Time 0.125	Data 0.005	Loss 6.00	Acc@1 53.1	Acc@5 87.5
Epoch: [51][41/704]	Time 0.124	Data 0.004	Loss 5.52	Acc@1 65.6	Acc@5 92.2
Epoch: [51][51/704]	Time 0.123	Data 0.003	Loss 5.51	Acc@1 59.4	Acc@5 90.6
Epoch: [51][61/704]	Time 0.123	Data 0.003	Loss 4.83	Acc@1 70.3	Acc@5 92.2
Epoch: [51][71/704]	Time 0.122	Data 0.002	Loss 5.24	Acc@1 62.5	Acc@5 87.5
Epoch: [51][81/704]	Time 0.122	Data 0.002	Loss 4.95	Acc@1 78.1	Acc@5 93.8
Epoch: [51][91/704]	Time 0.122	Data 0.002	Loss 5.98	Acc@1 51.6	Acc@5 95.3
Epoch: [51][101/704]	Time 0.122	Data 0.002	Loss 4.68	Acc@1 70.3	Acc@5 90.6
Epoch: [51][111/704]	Time 0.122	Data 0.002	Loss 4.10	Acc@1 82.8	Acc@5 98.4
Epoch: [51][121/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 90.6
Epoch: [51][131/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 60.9	Acc@5 85.9
Epoch: [51][141/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 68.8	Acc@5 89.1
Epoch: [51][151/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 67.2	Acc@5 90.6
Epoch: [51][161/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 67.2	Acc@5 93.8
Epoch: [51][171/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 67.2	Acc@5 90.6
Epoch: [51][181/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 60.9	Acc@5 92.2
Epoch: [51][191/704]	Time 0.121	Data 0.001	Loss 6.75	Acc@1 60.9	Acc@5 84.4
Epoch: [51][201/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 68.8	Acc@5 93.8
Epoch: [51][211/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 89.1
Epoch: [51][221/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 67.2	Acc@5 93.8
Epoch: [51][231/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 65.6	Acc@5 90.6
Epoch: [51][241/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 62.5	Acc@5 87.5
Epoch: [51][251/704]	Time 0.120	Data 0.001	Loss 7.70	Acc@1 56.2	Acc@5 84.4
Epoch: [51][261/704]	Time 0.120	Data 0.001	Loss 4.60	Acc@1 70.3	Acc@5 96.9
Epoch: [51][271/704]	Time 0.120	Data 0.001	Loss 5.35	Acc@1 67.2	Acc@5 96.9
Epoch: [51][281/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 70.3	Acc@5 93.8
Epoch: [51][291/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 64.1	Acc@5 93.8
Epoch: [51][301/704]	Time 0.120	Data 0.001	Loss 5.76	Acc@1 59.4	Acc@5 93.8
Epoch: [51][311/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 92.2
Epoch: [51][321/704]	Time 0.120	Data 0.001	Loss 6.16	Acc@1 60.9	Acc@5 89.1
Epoch: [51][331/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 68.8	Acc@5 92.2
Epoch: [51][341/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 65.6	Acc@5 96.9
Epoch: [51][351/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 59.4	Acc@5 87.5
Epoch: [51][361/704]	Time 0.120	Data 0.001	Loss 6.28	Acc@1 62.5	Acc@5 90.6
Epoch: [51][371/704]	Time 0.120	Data 0.001	Loss 4.98	Acc@1 68.8	Acc@5 90.6
Epoch: [51][381/704]	Time 0.120	Data 0.001	Loss 4.82	Acc@1 67.2	Acc@5 90.6
Epoch: [51][391/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 62.5	Acc@5 87.5
Epoch: [51][401/704]	Time 0.120	Data 0.001	Loss 4.87	Acc@1 60.9	Acc@5 96.9
Epoch: [51][411/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 62.5	Acc@5 89.1
Epoch: [51][421/704]	Time 0.120	Data 0.001	Loss 6.21	Acc@1 53.1	Acc@5 87.5
Epoch: [51][431/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 70.3	Acc@5 96.9
Epoch: [51][441/704]	Time 0.120	Data 0.001	Loss 4.74	Acc@1 67.2	Acc@5 95.3
Epoch: [51][451/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 93.8
Epoch: [51][461/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 67.2	Acc@5 87.5
Epoch: [51][471/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 78.1	Acc@5 93.8
Epoch: [51][481/704]	Time 0.120	Data 0.001	Loss 5.96	Acc@1 64.1	Acc@5 85.9
Epoch: [51][491/704]	Time 0.120	Data 0.001	Loss 5.97	Acc@1 67.2	Acc@5 90.6
Epoch: [51][501/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 59.4	Acc@5 92.2
Epoch: [51][511/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 54.7	Acc@5 90.6
Epoch: [51][521/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 57.8	Acc@5 87.5
Epoch: [51][531/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 64.1	Acc@5 95.3
Epoch: [51][541/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 62.5	Acc@5 87.5
Epoch: [51][551/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 93.8
Epoch: [51][561/704]	Time 0.120	Data 0.001	Loss 4.64	Acc@1 65.6	Acc@5 96.9
Epoch: [51][571/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 67.2	Acc@5 90.6
Epoch: [51][581/704]	Time 0.120	Data 0.001	Loss 4.49	Acc@1 79.7	Acc@5 98.4
Epoch: [51][591/704]	Time 0.120	Data 0.001	Loss 4.80	Acc@1 64.1	Acc@5 95.3
Epoch: [51][601/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 67.2	Acc@5 90.6
Epoch: [51][611/704]	Time 0.120	Data 0.001	Loss 6.12	Acc@1 68.8	Acc@5 85.9
Epoch: [51][621/704]	Time 0.120	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 92.2
Epoch: [51][631/704]	Time 0.120	Data 0.001	Loss 4.88	Acc@1 67.2	Acc@5 90.6
Epoch: [51][641/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 59.4	Acc@5 90.6
Epoch: [51][651/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 56.2	Acc@5 87.5
Epoch: [51][661/704]	Time 0.120	Data 0.001	Loss 4.22	Acc@1 67.2	Acc@5 96.9
Epoch: [51][671/704]	Time 0.120	Data 0.001	Loss 4.36	Acc@1 65.6	Acc@5 93.8
Epoch: [51][681/704]	Time 0.120	Data 0.001	Loss 5.30	Acc@1 71.9	Acc@5 92.2
Epoch: [51][691/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 90.6
Epoch: [51][701/704]	Time 0.120	Data 0.001	Loss 6.23	Acc@1 54.7	Acc@5 85.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.1427	Acc@1 62.5000	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.5897	Acc@1 53.1250	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.0241	Acc@1 57.8125	Acc@5 78.1250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.6132	Acc@1 56.2500	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.6550	Acc@1 45.3125	Acc@5 76.5625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.1452	Acc@1 62.5000	Acc@5 78.1250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.8487	Acc@1 48.4375	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3115	Acc@1 60.9375	Acc@5 89.0625
 * prec@1 46.100 prec@5 77.240
 * prec@1 50.400 prec@5 81.460
 * prec@1 54.620 prec@5 84.300
 * prec@1 56.360 prec@5 84.880
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_051.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_051.pth.tar'
Epoch: [52][1/704]	Time 0.300	Data 0.131	Loss 5.08	Acc@1 67.2	Acc@5 93.8
Epoch: [52][11/704]	Time 0.140	Data 0.012	Loss 6.58	Acc@1 54.7	Acc@5 93.8
Epoch: [52][21/704]	Time 0.130	Data 0.007	Loss 6.93	Acc@1 53.1	Acc@5 82.8
Epoch: [52][31/704]	Time 0.127	Data 0.005	Loss 5.54	Acc@1 64.1	Acc@5 90.6
Epoch: [52][41/704]	Time 0.125	Data 0.004	Loss 3.83	Acc@1 73.4	Acc@5 93.8
Epoch: [52][51/704]	Time 0.124	Data 0.003	Loss 5.18	Acc@1 67.2	Acc@5 95.3
Epoch: [52][61/704]	Time 0.124	Data 0.003	Loss 5.15	Acc@1 65.6	Acc@5 93.8
Epoch: [52][71/704]	Time 0.123	Data 0.002	Loss 4.38	Acc@1 73.4	Acc@5 95.3
Epoch: [52][81/704]	Time 0.123	Data 0.002	Loss 5.98	Acc@1 65.6	Acc@5 87.5
Epoch: [52][91/704]	Time 0.122	Data 0.002	Loss 5.92	Acc@1 59.4	Acc@5 89.1
Epoch: [52][101/704]	Time 0.122	Data 0.002	Loss 6.30	Acc@1 64.1	Acc@5 90.6
Epoch: [52][111/704]	Time 0.122	Data 0.002	Loss 4.97	Acc@1 78.1	Acc@5 95.3
Epoch: [52][121/704]	Time 0.122	Data 0.001	Loss 5.21	Acc@1 62.5	Acc@5 93.8
Epoch: [52][131/704]	Time 0.122	Data 0.001	Loss 5.35	Acc@1 57.8	Acc@5 89.1
Epoch: [52][141/704]	Time 0.122	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 92.2
Epoch: [52][151/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 75.0	Acc@5 90.6
Epoch: [52][161/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 76.6	Acc@5 98.4
Epoch: [52][171/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 59.4	Acc@5 89.1
Epoch: [52][181/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 76.6	Acc@5 85.9
Epoch: [52][191/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 67.2	Acc@5 95.3
Epoch: [52][201/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 67.2	Acc@5 92.2
Epoch: [52][211/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 64.1	Acc@5 93.8
Epoch: [52][221/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 64.1	Acc@5 90.6
Epoch: [52][231/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 68.8	Acc@5 93.8
Epoch: [52][241/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 68.8	Acc@5 90.6
Epoch: [52][251/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 62.5	Acc@5 95.3
Epoch: [52][261/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 67.2	Acc@5 92.2
Epoch: [52][271/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 62.5	Acc@5 89.1
Epoch: [52][281/704]	Time 0.121	Data 0.001	Loss 6.86	Acc@1 62.5	Acc@5 84.4
Epoch: [52][291/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 60.9	Acc@5 87.5
Epoch: [52][301/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 67.2	Acc@5 90.6
Epoch: [52][311/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 64.1	Acc@5 93.8
Epoch: [52][321/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 67.2	Acc@5 92.2
Epoch: [52][331/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 70.3	Acc@5 93.8
Epoch: [52][341/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 65.6	Acc@5 89.1
Epoch: [52][351/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 70.3	Acc@5 95.3
Epoch: [52][361/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 62.5	Acc@5 92.2
Epoch: [52][371/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 62.5	Acc@5 89.1
Epoch: [52][381/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 73.4	Acc@5 95.3
Epoch: [52][391/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 65.6	Acc@5 90.6
Epoch: [52][401/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 64.1	Acc@5 89.1
Epoch: [52][411/704]	Time 0.120	Data 0.001	Loss 4.36	Acc@1 70.3	Acc@5 98.4
Epoch: [52][421/704]	Time 0.120	Data 0.001	Loss 5.11	Acc@1 64.1	Acc@5 93.8
Epoch: [52][431/704]	Time 0.120	Data 0.001	Loss 5.76	Acc@1 70.3	Acc@5 89.1
Epoch: [52][441/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 70.3	Acc@5 89.1
Epoch: [52][451/704]	Time 0.120	Data 0.001	Loss 5.97	Acc@1 57.8	Acc@5 89.1
Epoch: [52][461/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 62.5	Acc@5 95.3
Epoch: [52][471/704]	Time 0.120	Data 0.001	Loss 6.89	Acc@1 48.4	Acc@5 87.5
Epoch: [52][481/704]	Time 0.120	Data 0.001	Loss 4.45	Acc@1 67.2	Acc@5 93.8
Epoch: [52][491/704]	Time 0.120	Data 0.001	Loss 6.68	Acc@1 62.5	Acc@5 84.4
Epoch: [52][501/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 59.4	Acc@5 92.2
Epoch: [52][511/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 64.1	Acc@5 95.3
Epoch: [52][521/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 64.1	Acc@5 95.3
Epoch: [52][531/704]	Time 0.120	Data 0.001	Loss 5.88	Acc@1 64.1	Acc@5 85.9
Epoch: [52][541/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 54.7	Acc@5 93.8
Epoch: [52][551/704]	Time 0.120	Data 0.001	Loss 3.96	Acc@1 76.6	Acc@5 93.8
Epoch: [52][561/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 64.1	Acc@5 93.8
Epoch: [52][571/704]	Time 0.120	Data 0.001	Loss 5.46	Acc@1 68.8	Acc@5 85.9
Epoch: [52][581/704]	Time 0.120	Data 0.001	Loss 4.48	Acc@1 70.3	Acc@5 95.3
Epoch: [52][591/704]	Time 0.120	Data 0.001	Loss 6.25	Acc@1 67.2	Acc@5 93.8
Epoch: [52][601/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 68.8	Acc@5 96.9
Epoch: [52][611/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 67.2	Acc@5 93.8
Epoch: [52][621/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 60.9	Acc@5 89.1
Epoch: [52][631/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 67.2	Acc@5 92.2
Epoch: [52][641/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 93.8
Epoch: [52][651/704]	Time 0.120	Data 0.001	Loss 5.35	Acc@1 54.7	Acc@5 92.2
Epoch: [52][661/704]	Time 0.120	Data 0.001	Loss 5.41	Acc@1 73.4	Acc@5 92.2
Epoch: [52][671/704]	Time 0.120	Data 0.001	Loss 4.50	Acc@1 73.4	Acc@5 90.6
Epoch: [52][681/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 64.1	Acc@5 92.2
Epoch: [52][691/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 64.1	Acc@5 93.8
Epoch: [52][701/704]	Time 0.120	Data 0.001	Loss 6.93	Acc@1 60.9	Acc@5 84.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.1963	Acc@1 60.9375	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.7383	Acc@1 45.3125	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6446	Acc@1 48.4375	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.1606	Acc@1 57.8125	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.9377	Acc@1 57.8125	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7208	Acc@1 51.5625	Acc@5 76.5625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.6233	Acc@1 60.9375	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1164	Acc@1 60.9375	Acc@5 85.9375
 * prec@1 46.160 prec@5 77.960
 * prec@1 50.260 prec@5 80.520
 * prec@1 53.720 prec@5 84.280
 * prec@1 55.080 prec@5 84.260
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_052.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_052.pth.tar'
Epoch: [53][1/704]	Time 0.332	Data 0.166	Loss 4.64	Acc@1 75.0	Acc@5 95.3
Epoch: [53][11/704]	Time 0.140	Data 0.015	Loss 5.83	Acc@1 54.7	Acc@5 85.9
Epoch: [53][21/704]	Time 0.130	Data 0.008	Loss 5.19	Acc@1 75.0	Acc@5 90.6
Epoch: [53][31/704]	Time 0.127	Data 0.006	Loss 6.03	Acc@1 60.9	Acc@5 92.2
Epoch: [53][41/704]	Time 0.125	Data 0.004	Loss 4.65	Acc@1 65.6	Acc@5 95.3
Epoch: [53][51/704]	Time 0.124	Data 0.004	Loss 4.16	Acc@1 78.1	Acc@5 95.3
Epoch: [53][61/704]	Time 0.123	Data 0.003	Loss 5.62	Acc@1 56.2	Acc@5 89.1
Epoch: [53][71/704]	Time 0.123	Data 0.003	Loss 6.02	Acc@1 68.8	Acc@5 87.5
Epoch: [53][81/704]	Time 0.123	Data 0.002	Loss 4.98	Acc@1 78.1	Acc@5 95.3
Epoch: [53][91/704]	Time 0.122	Data 0.002	Loss 4.93	Acc@1 65.6	Acc@5 93.8
Epoch: [53][101/704]	Time 0.122	Data 0.002	Loss 3.76	Acc@1 78.1	Acc@5 93.8
Epoch: [53][111/704]	Time 0.122	Data 0.002	Loss 4.13	Acc@1 76.6	Acc@5 93.8
Epoch: [53][121/704]	Time 0.122	Data 0.002	Loss 5.13	Acc@1 62.5	Acc@5 95.3
Epoch: [53][131/704]	Time 0.122	Data 0.002	Loss 5.08	Acc@1 70.3	Acc@5 87.5
Epoch: [53][141/704]	Time 0.121	Data 0.002	Loss 5.55	Acc@1 65.6	Acc@5 87.5
Epoch: [53][151/704]	Time 0.121	Data 0.002	Loss 4.54	Acc@1 68.8	Acc@5 98.4
Epoch: [53][161/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 68.8	Acc@5 95.3
Epoch: [53][171/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 65.6	Acc@5 90.6
Epoch: [53][181/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 59.4	Acc@5 90.6
Epoch: [53][191/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 73.4	Acc@5 95.3
Epoch: [53][201/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 60.9	Acc@5 92.2
Epoch: [53][211/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 79.7	Acc@5 90.6
Epoch: [53][221/704]	Time 0.121	Data 0.001	Loss 6.77	Acc@1 59.4	Acc@5 84.4
Epoch: [53][231/704]	Time 0.121	Data 0.001	Loss 6.73	Acc@1 60.9	Acc@5 81.2
Epoch: [53][241/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 56.2	Acc@5 89.1
Epoch: [53][251/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 68.8	Acc@5 92.2
Epoch: [53][261/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 62.5	Acc@5 92.2
Epoch: [53][271/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 70.3	Acc@5 90.6
Epoch: [53][281/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 71.9	Acc@5 93.8
Epoch: [53][291/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 67.2	Acc@5 93.8
Epoch: [53][301/704]	Time 0.121	Data 0.001	Loss 7.12	Acc@1 53.1	Acc@5 85.9
Epoch: [53][311/704]	Time 0.121	Data 0.001	Loss 6.43	Acc@1 57.8	Acc@5 90.6
Epoch: [53][321/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 73.4	Acc@5 89.1
Epoch: [53][331/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 71.9	Acc@5 87.5
Epoch: [53][341/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 62.5	Acc@5 93.8
Epoch: [53][351/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 59.4	Acc@5 95.3
Epoch: [53][361/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 68.8	Acc@5 90.6
Epoch: [53][371/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 62.5	Acc@5 90.6
Epoch: [53][381/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 68.8	Acc@5 95.3
Epoch: [53][391/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 93.8
Epoch: [53][401/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 71.9	Acc@5 93.8
Epoch: [53][411/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 64.1	Acc@5 90.6
Epoch: [53][421/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 70.3	Acc@5 89.1
Epoch: [53][431/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 71.9	Acc@5 87.5
Epoch: [53][441/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 70.3	Acc@5 93.8
Epoch: [53][451/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 62.5	Acc@5 89.1
Epoch: [53][461/704]	Time 0.120	Data 0.001	Loss 7.30	Acc@1 60.9	Acc@5 84.4
Epoch: [53][471/704]	Time 0.120	Data 0.001	Loss 6.19	Acc@1 56.2	Acc@5 87.5
Epoch: [53][481/704]	Time 0.120	Data 0.001	Loss 6.17	Acc@1 56.2	Acc@5 89.1
Epoch: [53][491/704]	Time 0.120	Data 0.001	Loss 6.55	Acc@1 62.5	Acc@5 87.5
Epoch: [53][501/704]	Time 0.120	Data 0.001	Loss 6.17	Acc@1 53.1	Acc@5 90.6
Epoch: [53][511/704]	Time 0.120	Data 0.001	Loss 6.01	Acc@1 60.9	Acc@5 87.5
Epoch: [53][521/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 62.5	Acc@5 85.9
Epoch: [53][531/704]	Time 0.120	Data 0.001	Loss 4.38	Acc@1 71.9	Acc@5 96.9
Epoch: [53][541/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 56.2	Acc@5 89.1
Epoch: [53][551/704]	Time 0.120	Data 0.001	Loss 6.76	Acc@1 56.2	Acc@5 93.8
Epoch: [53][561/704]	Time 0.120	Data 0.001	Loss 4.86	Acc@1 68.8	Acc@5 93.8
Epoch: [53][571/704]	Time 0.120	Data 0.001	Loss 4.87	Acc@1 76.6	Acc@5 92.2
Epoch: [53][581/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 70.3	Acc@5 90.6
Epoch: [53][591/704]	Time 0.120	Data 0.001	Loss 6.24	Acc@1 62.5	Acc@5 90.6
Epoch: [53][601/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 64.1	Acc@5 90.6
Epoch: [53][611/704]	Time 0.120	Data 0.001	Loss 5.06	Acc@1 73.4	Acc@5 93.8
Epoch: [53][621/704]	Time 0.120	Data 0.001	Loss 6.73	Acc@1 51.6	Acc@5 81.2
Epoch: [53][631/704]	Time 0.120	Data 0.001	Loss 4.18	Acc@1 81.2	Acc@5 95.3
Epoch: [53][641/704]	Time 0.120	Data 0.001	Loss 6.30	Acc@1 67.2	Acc@5 90.6
Epoch: [53][651/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 64.1	Acc@5 90.6
Epoch: [53][661/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 67.2	Acc@5 92.2
Epoch: [53][671/704]	Time 0.120	Data 0.001	Loss 4.51	Acc@1 67.2	Acc@5 95.3
Epoch: [53][681/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 62.5	Acc@5 90.6
Epoch: [53][691/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 67.2	Acc@5 93.8
Epoch: [53][701/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 67.2	Acc@5 93.8
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.7364	Acc@1 60.9375	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 8.8507	Acc@1 50.0000	Acc@5 76.5625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2977	Acc@1 48.4375	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.9218	Acc@1 51.5625	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3240	Acc@1 48.4375	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.0822	Acc@1 53.1250	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6625	Acc@1 51.5625	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.2209	Acc@1 56.2500	Acc@5 85.9375
 * prec@1 47.360 prec@5 78.180
 * prec@1 51.800 prec@5 82.100
 * prec@1 55.100 prec@5 84.680
 * prec@1 55.740 prec@5 84.420
Current best validation last_bloc_accuracy 56.66
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_053.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_053.pth.tar'
Epoch: [54][1/704]	Time 0.295	Data 0.128	Loss 4.86	Acc@1 73.4	Acc@5 89.1
Epoch: [54][11/704]	Time 0.136	Data 0.012	Loss 5.28	Acc@1 65.6	Acc@5 96.9
Epoch: [54][21/704]	Time 0.128	Data 0.006	Loss 6.39	Acc@1 64.1	Acc@5 90.6
Epoch: [54][31/704]	Time 0.126	Data 0.004	Loss 4.62	Acc@1 67.2	Acc@5 95.3
Epoch: [54][41/704]	Time 0.124	Data 0.003	Loss 5.15	Acc@1 65.6	Acc@5 92.2
Epoch: [54][51/704]	Time 0.123	Data 0.003	Loss 3.83	Acc@1 68.8	Acc@5 95.3
Epoch: [54][61/704]	Time 0.123	Data 0.002	Loss 4.13	Acc@1 76.6	Acc@5 100.0
Epoch: [54][71/704]	Time 0.122	Data 0.002	Loss 4.48	Acc@1 75.0	Acc@5 95.3
Epoch: [54][81/704]	Time 0.122	Data 0.002	Loss 4.61	Acc@1 68.8	Acc@5 90.6
Epoch: [54][91/704]	Time 0.122	Data 0.002	Loss 6.05	Acc@1 54.7	Acc@5 93.8
Epoch: [54][101/704]	Time 0.122	Data 0.002	Loss 4.36	Acc@1 76.6	Acc@5 96.9
Epoch: [54][111/704]	Time 0.121	Data 0.002	Loss 4.22	Acc@1 76.6	Acc@5 96.9
Epoch: [54][121/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 73.4	Acc@5 93.8
Epoch: [54][131/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 68.8	Acc@5 95.3
Epoch: [54][141/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 64.1	Acc@5 95.3
Epoch: [54][151/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 71.9	Acc@5 92.2
Epoch: [54][161/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 64.1	Acc@5 93.8
Epoch: [54][171/704]	Time 0.121	Data 0.001	Loss 6.58	Acc@1 62.5	Acc@5 90.6
Epoch: [54][181/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 65.6	Acc@5 92.2
Epoch: [54][191/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 64.1	Acc@5 89.1
Epoch: [54][201/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 73.4	Acc@5 93.8
Epoch: [54][211/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 64.1	Acc@5 95.3
Epoch: [54][221/704]	Time 0.121	Data 0.001	Loss 6.99	Acc@1 57.8	Acc@5 84.4
Epoch: [54][231/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 92.2
Epoch: [54][241/704]	Time 0.121	Data 0.001	Loss 6.61	Acc@1 64.1	Acc@5 85.9
Epoch: [54][251/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 64.1	Acc@5 89.1
Epoch: [54][261/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 68.8	Acc@5 89.1
Epoch: [54][271/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 95.3
Epoch: [54][281/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 85.9
Epoch: [54][291/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 67.2	Acc@5 93.8
Epoch: [54][301/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 62.5	Acc@5 89.1
Epoch: [54][311/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 68.8	Acc@5 93.8
Epoch: [54][321/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 65.6	Acc@5 93.8
Epoch: [54][331/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 62.5	Acc@5 81.2
Epoch: [54][341/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 70.3	Acc@5 87.5
Epoch: [54][351/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 64.1	Acc@5 95.3
Epoch: [54][361/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 59.4	Acc@5 93.8
Epoch: [54][371/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 65.6	Acc@5 90.6
Epoch: [54][381/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 62.5	Acc@5 93.8
Epoch: [54][391/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 59.4	Acc@5 89.1
Epoch: [54][401/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 70.3	Acc@5 95.3
Epoch: [54][411/704]	Time 0.121	Data 0.001	Loss 7.05	Acc@1 57.8	Acc@5 87.5
Epoch: [54][421/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 70.3	Acc@5 92.2
Epoch: [54][431/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 67.2	Acc@5 89.1
Epoch: [54][441/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 68.8	Acc@5 90.6
Epoch: [54][451/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 71.9	Acc@5 93.8
Epoch: [54][461/704]	Time 0.120	Data 0.001	Loss 6.24	Acc@1 54.7	Acc@5 90.6
Epoch: [54][471/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 65.6	Acc@5 89.1
Epoch: [54][481/704]	Time 0.120	Data 0.001	Loss 4.77	Acc@1 65.6	Acc@5 93.8
Epoch: [54][491/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 62.5	Acc@5 90.6
Epoch: [54][501/704]	Time 0.120	Data 0.001	Loss 6.56	Acc@1 57.8	Acc@5 85.9
Epoch: [54][511/704]	Time 0.120	Data 0.001	Loss 4.60	Acc@1 67.2	Acc@5 92.2
Epoch: [54][521/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 71.9	Acc@5 93.8
Epoch: [54][531/704]	Time 0.120	Data 0.001	Loss 4.98	Acc@1 70.3	Acc@5 90.6
Epoch: [54][541/704]	Time 0.120	Data 0.001	Loss 7.08	Acc@1 56.2	Acc@5 84.4
Epoch: [54][551/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 71.9	Acc@5 89.1
Epoch: [54][561/704]	Time 0.120	Data 0.001	Loss 4.39	Acc@1 79.7	Acc@5 96.9
Epoch: [54][571/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 89.1
Epoch: [54][581/704]	Time 0.120	Data 0.001	Loss 4.66	Acc@1 67.2	Acc@5 92.2
Epoch: [54][591/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 60.9	Acc@5 87.5
Epoch: [54][601/704]	Time 0.120	Data 0.001	Loss 6.47	Acc@1 54.7	Acc@5 90.6
Epoch: [54][611/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 68.8	Acc@5 92.2
Epoch: [54][621/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 70.3	Acc@5 93.8
Epoch: [54][631/704]	Time 0.120	Data 0.001	Loss 6.35	Acc@1 57.8	Acc@5 92.2
Epoch: [54][641/704]	Time 0.120	Data 0.001	Loss 4.42	Acc@1 76.6	Acc@5 96.9
Epoch: [54][651/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 65.6	Acc@5 95.3
Epoch: [54][661/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 65.6	Acc@5 90.6
Epoch: [54][671/704]	Time 0.120	Data 0.001	Loss 6.69	Acc@1 62.5	Acc@5 79.7
Epoch: [54][681/704]	Time 0.120	Data 0.001	Loss 4.58	Acc@1 73.4	Acc@5 90.6
Epoch: [54][691/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 57.8	Acc@5 89.1
Epoch: [54][701/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 67.2	Acc@5 90.6
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 7.4189	Acc@1 50.0000	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.6064	Acc@1 65.6250	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.1347	Acc@1 54.6875	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3403	Acc@1 60.9375	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4534	Acc@1 51.5625	Acc@5 76.5625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.1290	Acc@1 57.8125	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6806	Acc@1 68.7500	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2135	Acc@1 48.4375	Acc@5 89.0625
 * prec@1 46.640 prec@5 77.900
 * prec@1 51.140 prec@5 82.340
 * prec@1 55.600 prec@5 84.020
 * prec@1 56.840 prec@5 84.560
New best validation last_bloc_accuracy 56.84
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_054.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_054.pth.tar'
Epoch: [55][1/704]	Time 0.300	Data 0.132	Loss 5.98	Acc@1 67.2	Acc@5 92.2
Epoch: [55][11/704]	Time 0.136	Data 0.012	Loss 6.92	Acc@1 56.2	Acc@5 81.2
Epoch: [55][21/704]	Time 0.128	Data 0.007	Loss 5.37	Acc@1 64.1	Acc@5 93.8
Epoch: [55][31/704]	Time 0.126	Data 0.005	Loss 4.74	Acc@1 73.4	Acc@5 95.3
Epoch: [55][41/704]	Time 0.124	Data 0.004	Loss 5.48	Acc@1 68.8	Acc@5 92.2
Epoch: [55][51/704]	Time 0.123	Data 0.003	Loss 6.81	Acc@1 62.5	Acc@5 87.5
Epoch: [55][61/704]	Time 0.123	Data 0.003	Loss 5.03	Acc@1 65.6	Acc@5 90.6
Epoch: [55][71/704]	Time 0.123	Data 0.002	Loss 5.66	Acc@1 67.2	Acc@5 89.1
Epoch: [55][81/704]	Time 0.123	Data 0.002	Loss 7.65	Acc@1 53.1	Acc@5 90.6
Epoch: [55][91/704]	Time 0.122	Data 0.002	Loss 4.89	Acc@1 75.0	Acc@5 90.6
Epoch: [55][101/704]	Time 0.122	Data 0.002	Loss 4.27	Acc@1 75.0	Acc@5 93.8
Epoch: [55][111/704]	Time 0.122	Data 0.002	Loss 4.67	Acc@1 75.0	Acc@5 92.2
Epoch: [55][121/704]	Time 0.122	Data 0.001	Loss 4.82	Acc@1 70.3	Acc@5 92.2
Epoch: [55][131/704]	Time 0.122	Data 0.001	Loss 4.32	Acc@1 75.0	Acc@5 95.3
Epoch: [55][141/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 60.9	Acc@5 95.3
Epoch: [55][151/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 64.1	Acc@5 89.1
Epoch: [55][161/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 71.9	Acc@5 90.6
Epoch: [55][171/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 70.3	Acc@5 89.1
Epoch: [55][181/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 60.9	Acc@5 87.5
Epoch: [55][191/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 64.1	Acc@5 89.1
Epoch: [55][201/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 62.5	Acc@5 90.6
Epoch: [55][211/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 62.5	Acc@5 87.5
Epoch: [55][221/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 65.6	Acc@5 87.5
Epoch: [55][231/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 75.0	Acc@5 92.2
Epoch: [55][241/704]	Time 0.121	Data 0.001	Loss 7.49	Acc@1 57.8	Acc@5 84.4
Epoch: [55][251/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 71.9	Acc@5 87.5
Epoch: [55][261/704]	Time 0.121	Data 0.001	Loss 3.57	Acc@1 79.7	Acc@5 96.9
Epoch: [55][271/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 70.3	Acc@5 92.2
Epoch: [55][281/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 79.7	Acc@5 98.4
Epoch: [55][291/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 68.8	Acc@5 84.4
Epoch: [55][301/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 67.2	Acc@5 92.2
Epoch: [55][311/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 59.4	Acc@5 95.3
Epoch: [55][321/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 67.2	Acc@5 82.8
Epoch: [55][331/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 67.2	Acc@5 82.8
Epoch: [55][341/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 68.8	Acc@5 95.3
Epoch: [55][351/704]	Time 0.121	Data 0.001	Loss 6.62	Acc@1 64.1	Acc@5 85.9
Epoch: [55][361/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 56.2	Acc@5 85.9
Epoch: [55][371/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 62.5	Acc@5 87.5
Epoch: [55][381/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 93.8
Epoch: [55][391/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 95.3
Epoch: [55][401/704]	Time 0.120	Data 0.001	Loss 6.38	Acc@1 62.5	Acc@5 85.9
Epoch: [55][411/704]	Time 0.120	Data 0.001	Loss 4.35	Acc@1 70.3	Acc@5 92.2
Epoch: [55][421/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 64.1	Acc@5 85.9
Epoch: [55][431/704]	Time 0.120	Data 0.001	Loss 6.71	Acc@1 67.2	Acc@5 85.9
Epoch: [55][441/704]	Time 0.120	Data 0.001	Loss 5.63	Acc@1 60.9	Acc@5 90.6
Epoch: [55][451/704]	Time 0.120	Data 0.001	Loss 4.52	Acc@1 76.6	Acc@5 98.4
Epoch: [55][461/704]	Time 0.120	Data 0.001	Loss 4.58	Acc@1 73.4	Acc@5 96.9
Epoch: [55][471/704]	Time 0.120	Data 0.001	Loss 3.87	Acc@1 84.4	Acc@5 100.0
Epoch: [55][481/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 96.9
Epoch: [55][491/704]	Time 0.120	Data 0.001	Loss 6.06	Acc@1 59.4	Acc@5 90.6
Epoch: [55][501/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 70.3	Acc@5 96.9
Epoch: [55][511/704]	Time 0.120	Data 0.001	Loss 6.01	Acc@1 59.4	Acc@5 92.2
Epoch: [55][521/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 68.8	Acc@5 93.8
Epoch: [55][531/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 62.5	Acc@5 89.1
Epoch: [55][541/704]	Time 0.120	Data 0.001	Loss 4.64	Acc@1 73.4	Acc@5 93.8
Epoch: [55][551/704]	Time 0.120	Data 0.001	Loss 5.27	Acc@1 70.3	Acc@5 92.2
Epoch: [55][561/704]	Time 0.120	Data 0.001	Loss 5.59	Acc@1 70.3	Acc@5 93.8
Epoch: [55][571/704]	Time 0.120	Data 0.001	Loss 5.76	Acc@1 65.6	Acc@5 85.9
Epoch: [55][581/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 64.1	Acc@5 89.1
Epoch: [55][591/704]	Time 0.120	Data 0.001	Loss 5.63	Acc@1 65.6	Acc@5 90.6
Epoch: [55][601/704]	Time 0.120	Data 0.001	Loss 4.42	Acc@1 81.2	Acc@5 96.9
Epoch: [55][611/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 71.9	Acc@5 89.1
Epoch: [55][621/704]	Time 0.120	Data 0.001	Loss 6.05	Acc@1 60.9	Acc@5 87.5
Epoch: [55][631/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 75.0	Acc@5 92.2
Epoch: [55][641/704]	Time 0.120	Data 0.001	Loss 7.05	Acc@1 56.2	Acc@5 81.2
Epoch: [55][651/704]	Time 0.120	Data 0.001	Loss 6.17	Acc@1 54.7	Acc@5 92.2
Epoch: [55][661/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 67.2	Acc@5 93.8
Epoch: [55][671/704]	Time 0.120	Data 0.001	Loss 6.19	Acc@1 59.4	Acc@5 87.5
Epoch: [55][681/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 71.9	Acc@5 95.3
Epoch: [55][691/704]	Time 0.120	Data 0.001	Loss 6.64	Acc@1 65.6	Acc@5 89.1
Epoch: [55][701/704]	Time 0.120	Data 0.001	Loss 6.72	Acc@1 59.4	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.2631	Acc@1 62.5000	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.1978	Acc@1 62.5000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.3243	Acc@1 57.8125	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.8792	Acc@1 54.6875	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.8412	Acc@1 42.1875	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 9.9390	Acc@1 40.6250	Acc@5 76.5625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.0886	Acc@1 50.0000	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1986	Acc@1 62.5000	Acc@5 87.5000
 * prec@1 45.600 prec@5 77.060
 * prec@1 50.520 prec@5 80.740
 * prec@1 52.940 prec@5 83.680
 * prec@1 55.060 prec@5 84.380
Current best validation last_bloc_accuracy 56.84
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_055.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_055.pth.tar'
Epoch: [56][1/704]	Time 0.331	Data 0.165	Loss 5.39	Acc@1 65.6	Acc@5 90.6
Epoch: [56][11/704]	Time 0.139	Data 0.015	Loss 5.51	Acc@1 65.6	Acc@5 87.5
Epoch: [56][21/704]	Time 0.130	Data 0.008	Loss 4.74	Acc@1 75.0	Acc@5 93.8
Epoch: [56][31/704]	Time 0.127	Data 0.006	Loss 4.85	Acc@1 75.0	Acc@5 96.9
Epoch: [56][41/704]	Time 0.125	Data 0.004	Loss 6.64	Acc@1 64.1	Acc@5 87.5
Epoch: [56][51/704]	Time 0.124	Data 0.004	Loss 5.45	Acc@1 67.2	Acc@5 89.1
Epoch: [56][61/704]	Time 0.123	Data 0.003	Loss 5.67	Acc@1 68.8	Acc@5 89.1
Epoch: [56][71/704]	Time 0.123	Data 0.003	Loss 5.20	Acc@1 67.2	Acc@5 96.9
Epoch: [56][81/704]	Time 0.123	Data 0.003	Loss 5.69	Acc@1 62.5	Acc@5 93.8
Epoch: [56][91/704]	Time 0.122	Data 0.002	Loss 5.05	Acc@1 71.9	Acc@5 89.1
Epoch: [56][101/704]	Time 0.122	Data 0.002	Loss 4.84	Acc@1 71.9	Acc@5 92.2
Epoch: [56][111/704]	Time 0.122	Data 0.002	Loss 6.13	Acc@1 68.8	Acc@5 92.2
Epoch: [56][121/704]	Time 0.122	Data 0.002	Loss 4.73	Acc@1 76.6	Acc@5 98.4
Epoch: [56][131/704]	Time 0.122	Data 0.002	Loss 3.73	Acc@1 79.7	Acc@5 98.4
Epoch: [56][141/704]	Time 0.121	Data 0.002	Loss 4.02	Acc@1 76.6	Acc@5 95.3
Epoch: [56][151/704]	Time 0.121	Data 0.002	Loss 5.88	Acc@1 62.5	Acc@5 87.5
Epoch: [56][161/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 70.3	Acc@5 95.3
Epoch: [56][171/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 75.0	Acc@5 92.2
Epoch: [56][181/704]	Time 0.121	Data 0.001	Loss 6.57	Acc@1 64.1	Acc@5 87.5
Epoch: [56][191/704]	Time 0.121	Data 0.001	Loss 6.28	Acc@1 57.8	Acc@5 92.2
Epoch: [56][201/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 62.5	Acc@5 93.8
Epoch: [56][211/704]	Time 0.121	Data 0.001	Loss 6.54	Acc@1 59.4	Acc@5 89.1
Epoch: [56][221/704]	Time 0.121	Data 0.001	Loss 6.36	Acc@1 60.9	Acc@5 89.1
Epoch: [56][231/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 71.9	Acc@5 93.8
Epoch: [56][241/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 71.9	Acc@5 90.6
Epoch: [56][251/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 75.0	Acc@5 90.6
Epoch: [56][261/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 67.2	Acc@5 95.3
Epoch: [56][271/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 62.5	Acc@5 84.4
Epoch: [56][281/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 65.6	Acc@5 93.8
Epoch: [56][291/704]	Time 0.121	Data 0.001	Loss 7.06	Acc@1 56.2	Acc@5 84.4
Epoch: [56][301/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 59.4	Acc@5 89.1
Epoch: [56][311/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 73.4	Acc@5 98.4
Epoch: [56][321/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 70.3	Acc@5 89.1
Epoch: [56][331/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 67.2	Acc@5 98.4
Epoch: [56][341/704]	Time 0.121	Data 0.001	Loss 7.85	Acc@1 51.6	Acc@5 81.2
Epoch: [56][351/704]	Time 0.121	Data 0.001	Loss 7.21	Acc@1 59.4	Acc@5 84.4
Epoch: [56][361/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 53.1	Acc@5 87.5
Epoch: [56][371/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 65.6	Acc@5 85.9
Epoch: [56][381/704]	Time 0.121	Data 0.001	Loss 6.24	Acc@1 62.5	Acc@5 87.5
Epoch: [56][391/704]	Time 0.121	Data 0.001	Loss 7.15	Acc@1 56.2	Acc@5 87.5
Epoch: [56][401/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 70.3	Acc@5 92.2
Epoch: [56][411/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 68.8	Acc@5 93.8
Epoch: [56][421/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 75.0	Acc@5 95.3
Epoch: [56][431/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 75.0	Acc@5 90.6
Epoch: [56][441/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 68.8	Acc@5 90.6
Epoch: [56][451/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 92.2
Epoch: [56][461/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 64.1	Acc@5 89.1
Epoch: [56][471/704]	Time 0.121	Data 0.001	Loss 6.75	Acc@1 54.7	Acc@5 89.1
Epoch: [56][481/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 70.3	Acc@5 90.6
Epoch: [56][491/704]	Time 0.121	Data 0.001	Loss 6.57	Acc@1 59.4	Acc@5 87.5
Epoch: [56][501/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 60.9	Acc@5 85.9
Epoch: [56][511/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 54.7	Acc@5 92.2
Epoch: [56][521/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 68.8	Acc@5 92.2
Epoch: [56][531/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 65.6	Acc@5 85.9
Epoch: [56][541/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 70.3	Acc@5 90.6
Epoch: [56][551/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 64.1	Acc@5 92.2
Epoch: [56][561/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 62.5	Acc@5 90.6
Epoch: [56][571/704]	Time 0.120	Data 0.001	Loss 4.34	Acc@1 71.9	Acc@5 93.8
Epoch: [56][581/704]	Time 0.120	Data 0.001	Loss 5.01	Acc@1 68.8	Acc@5 90.6
Epoch: [56][591/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 67.2	Acc@5 96.9
Epoch: [56][601/704]	Time 0.120	Data 0.001	Loss 5.91	Acc@1 68.8	Acc@5 85.9
Epoch: [56][611/704]	Time 0.120	Data 0.001	Loss 4.96	Acc@1 65.6	Acc@5 89.1
Epoch: [56][621/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 64.1	Acc@5 89.1
Epoch: [56][631/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 67.2	Acc@5 90.6
Epoch: [56][641/704]	Time 0.120	Data 0.001	Loss 4.30	Acc@1 78.1	Acc@5 96.9
Epoch: [56][651/704]	Time 0.120	Data 0.001	Loss 7.98	Acc@1 51.6	Acc@5 84.4
Epoch: [56][661/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 65.6	Acc@5 89.1
Epoch: [56][671/704]	Time 0.120	Data 0.001	Loss 4.81	Acc@1 67.2	Acc@5 93.8
Epoch: [56][681/704]	Time 0.120	Data 0.001	Loss 6.47	Acc@1 57.8	Acc@5 85.9
Epoch: [56][691/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 56.2	Acc@5 90.6
Epoch: [56][701/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 90.6
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 7.8788	Acc@1 45.3125	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.7903	Acc@1 54.6875	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.5681	Acc@1 51.5625	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5879	Acc@1 64.0625	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.2142	Acc@1 62.5000	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.8913	Acc@1 62.5000	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6354	Acc@1 51.5625	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.4997	Acc@1 67.1875	Acc@5 85.9375
 * prec@1 45.560 prec@5 77.300
 * prec@1 49.720 prec@5 80.980
 * prec@1 54.160 prec@5 83.520
 * prec@1 55.280 prec@5 84.100
Current best validation last_bloc_accuracy 56.84
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_056.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_056.pth.tar'
Epoch: [57][1/704]	Time 0.333	Data 0.166	Loss 5.44	Acc@1 71.9	Acc@5 95.3
Epoch: [57][11/704]	Time 0.140	Data 0.015	Loss 5.67	Acc@1 65.6	Acc@5 89.1
Epoch: [57][21/704]	Time 0.130	Data 0.008	Loss 4.81	Acc@1 68.8	Acc@5 98.4
Epoch: [57][31/704]	Time 0.127	Data 0.006	Loss 5.55	Acc@1 67.2	Acc@5 90.6
Epoch: [57][41/704]	Time 0.125	Data 0.004	Loss 4.52	Acc@1 79.7	Acc@5 93.8
Epoch: [57][51/704]	Time 0.124	Data 0.004	Loss 5.10	Acc@1 70.3	Acc@5 92.2
Epoch: [57][61/704]	Time 0.123	Data 0.003	Loss 6.93	Acc@1 54.7	Acc@5 85.9
Epoch: [57][71/704]	Time 0.123	Data 0.003	Loss 4.47	Acc@1 78.1	Acc@5 93.8
Epoch: [57][81/704]	Time 0.123	Data 0.002	Loss 5.50	Acc@1 68.8	Acc@5 90.6
Epoch: [57][91/704]	Time 0.122	Data 0.002	Loss 4.86	Acc@1 67.2	Acc@5 90.6
Epoch: [57][101/704]	Time 0.122	Data 0.002	Loss 5.80	Acc@1 59.4	Acc@5 84.4
Epoch: [57][111/704]	Time 0.122	Data 0.002	Loss 5.17	Acc@1 68.8	Acc@5 90.6
Epoch: [57][121/704]	Time 0.122	Data 0.002	Loss 4.71	Acc@1 75.0	Acc@5 89.1
Epoch: [57][131/704]	Time 0.122	Data 0.002	Loss 5.42	Acc@1 70.3	Acc@5 92.2
Epoch: [57][141/704]	Time 0.121	Data 0.002	Loss 3.88	Acc@1 73.4	Acc@5 96.9
Epoch: [57][151/704]	Time 0.121	Data 0.002	Loss 6.61	Acc@1 46.9	Acc@5 90.6
Epoch: [57][161/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 71.9	Acc@5 90.6
Epoch: [57][171/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 92.2
Epoch: [57][181/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 64.1	Acc@5 87.5
Epoch: [57][191/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 60.9	Acc@5 90.6
Epoch: [57][201/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 75.0	Acc@5 92.2
Epoch: [57][211/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 59.4	Acc@5 89.1
Epoch: [57][221/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 59.4	Acc@5 93.8
Epoch: [57][231/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 59.4	Acc@5 89.1
Epoch: [57][241/704]	Time 0.121	Data 0.001	Loss 3.90	Acc@1 76.6	Acc@5 93.8
Epoch: [57][251/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 64.1	Acc@5 90.6
Epoch: [57][261/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 68.8	Acc@5 95.3
Epoch: [57][271/704]	Time 0.121	Data 0.001	Loss 6.28	Acc@1 64.1	Acc@5 89.1
Epoch: [57][281/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 90.6
Epoch: [57][291/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 62.5	Acc@5 85.9
Epoch: [57][301/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 68.8	Acc@5 90.6
Epoch: [57][311/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 68.8	Acc@5 95.3
Epoch: [57][321/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 65.6	Acc@5 92.2
Epoch: [57][331/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 68.8	Acc@5 93.8
Epoch: [57][341/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 65.6	Acc@5 93.8
Epoch: [57][351/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 62.5	Acc@5 89.1
Epoch: [57][361/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 54.7	Acc@5 95.3
Epoch: [57][371/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 68.8	Acc@5 92.2
Epoch: [57][381/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 76.6	Acc@5 92.2
Epoch: [57][391/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 60.9	Acc@5 89.1
Epoch: [57][401/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 76.6	Acc@5 92.2
Epoch: [57][411/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 59.4	Acc@5 92.2
Epoch: [57][421/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 73.4	Acc@5 96.9
Epoch: [57][431/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 65.6	Acc@5 89.1
Epoch: [57][441/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 64.1	Acc@5 89.1
Epoch: [57][451/704]	Time 0.120	Data 0.001	Loss 6.21	Acc@1 67.2	Acc@5 93.8
Epoch: [57][461/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 67.2	Acc@5 89.1
Epoch: [57][471/704]	Time 0.120	Data 0.001	Loss 4.89	Acc@1 68.8	Acc@5 93.8
Epoch: [57][481/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 65.6	Acc@5 89.1
Epoch: [57][491/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 64.1	Acc@5 92.2
Epoch: [57][501/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 64.1	Acc@5 89.1
Epoch: [57][511/704]	Time 0.120	Data 0.001	Loss 5.76	Acc@1 59.4	Acc@5 90.6
Epoch: [57][521/704]	Time 0.120	Data 0.001	Loss 4.86	Acc@1 73.4	Acc@5 92.2
Epoch: [57][531/704]	Time 0.120	Data 0.001	Loss 4.85	Acc@1 79.7	Acc@5 89.1
Epoch: [57][541/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 57.8	Acc@5 90.6
Epoch: [57][551/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 65.6	Acc@5 90.6
Epoch: [57][561/704]	Time 0.120	Data 0.001	Loss 4.59	Acc@1 73.4	Acc@5 92.2
Epoch: [57][571/704]	Time 0.120	Data 0.001	Loss 5.39	Acc@1 62.5	Acc@5 92.2
Epoch: [57][581/704]	Time 0.120	Data 0.001	Loss 5.11	Acc@1 68.8	Acc@5 90.6
Epoch: [57][591/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 59.4	Acc@5 87.5
Epoch: [57][601/704]	Time 0.120	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 90.6
Epoch: [57][611/704]	Time 0.120	Data 0.001	Loss 6.37	Acc@1 60.9	Acc@5 87.5
Epoch: [57][621/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 65.6	Acc@5 89.1
Epoch: [57][631/704]	Time 0.120	Data 0.001	Loss 5.96	Acc@1 60.9	Acc@5 85.9
Epoch: [57][641/704]	Time 0.120	Data 0.001	Loss 7.89	Acc@1 48.4	Acc@5 79.7
Epoch: [57][651/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 67.2	Acc@5 93.8
Epoch: [57][661/704]	Time 0.120	Data 0.001	Loss 7.67	Acc@1 46.9	Acc@5 87.5
Epoch: [57][671/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 57.8	Acc@5 95.3
Epoch: [57][681/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 67.2	Acc@5 90.6
Epoch: [57][691/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 90.6
Epoch: [57][701/704]	Time 0.120	Data 0.001	Loss 6.72	Acc@1 62.5	Acc@5 85.9
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 8.3012	Acc@1 43.7500	Acc@5 75.0000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.6618	Acc@1 50.0000	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8110	Acc@1 64.0625	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5192	Acc@1 54.6875	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.1353	Acc@1 54.6875	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9451	Acc@1 48.4375	Acc@5 76.5625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.8539	Acc@1 56.2500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.8564	Acc@1 48.4375	Acc@5 76.5625
 * prec@1 48.180 prec@5 78.560
 * prec@1 51.860 prec@5 82.540
 * prec@1 55.960 prec@5 85.200
 * prec@1 55.080 prec@5 84.800
Current best validation last_bloc_accuracy 56.84
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_057.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_057.pth.tar'
Epoch: [58][1/704]	Time 0.297	Data 0.130	Loss 6.41	Acc@1 54.7	Acc@5 85.9
Epoch: [58][11/704]	Time 0.136	Data 0.012	Loss 5.17	Acc@1 62.5	Acc@5 92.2
Epoch: [58][21/704]	Time 0.129	Data 0.007	Loss 5.14	Acc@1 60.9	Acc@5 92.2
Epoch: [58][31/704]	Time 0.126	Data 0.005	Loss 5.88	Acc@1 64.1	Acc@5 95.3
Epoch: [58][41/704]	Time 0.124	Data 0.004	Loss 7.00	Acc@1 59.4	Acc@5 84.4
Epoch: [58][51/704]	Time 0.123	Data 0.003	Loss 5.72	Acc@1 67.2	Acc@5 89.1
Epoch: [58][61/704]	Time 0.123	Data 0.003	Loss 4.40	Acc@1 68.8	Acc@5 95.3
Epoch: [58][71/704]	Time 0.123	Data 0.002	Loss 4.89	Acc@1 68.8	Acc@5 93.8
Epoch: [58][81/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 67.2	Acc@5 95.3
Epoch: [58][91/704]	Time 0.122	Data 0.002	Loss 5.67	Acc@1 57.8	Acc@5 92.2
Epoch: [58][101/704]	Time 0.122	Data 0.002	Loss 4.50	Acc@1 70.3	Acc@5 92.2
Epoch: [58][111/704]	Time 0.122	Data 0.002	Loss 5.57	Acc@1 67.2	Acc@5 87.5
Epoch: [58][121/704]	Time 0.122	Data 0.001	Loss 5.20	Acc@1 65.6	Acc@5 89.1
Epoch: [58][131/704]	Time 0.122	Data 0.001	Loss 3.75	Acc@1 76.6	Acc@5 96.9
Epoch: [58][141/704]	Time 0.122	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 92.2
Epoch: [58][151/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 68.8	Acc@5 95.3
Epoch: [58][161/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 64.1	Acc@5 93.8
Epoch: [58][171/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 68.8	Acc@5 95.3
Epoch: [58][181/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 59.4	Acc@5 85.9
Epoch: [58][191/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 93.8
Epoch: [58][201/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 73.4	Acc@5 100.0
Epoch: [58][211/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 67.2	Acc@5 92.2
Epoch: [58][221/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 68.8	Acc@5 93.8
Epoch: [58][231/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 68.8	Acc@5 93.8
Epoch: [58][241/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 62.5	Acc@5 95.3
Epoch: [58][251/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 68.8	Acc@5 92.2
Epoch: [58][261/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 65.6	Acc@5 96.9
Epoch: [58][271/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 90.6
Epoch: [58][281/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 57.8	Acc@5 89.1
Epoch: [58][291/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 95.3
Epoch: [58][301/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 62.5	Acc@5 93.8
Epoch: [58][311/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 53.1	Acc@5 90.6
Epoch: [58][321/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 87.5
Epoch: [58][331/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 50.0	Acc@5 89.1
Epoch: [58][341/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 68.8	Acc@5 92.2
Epoch: [58][351/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 93.8
Epoch: [58][361/704]	Time 0.120	Data 0.001	Loss 4.53	Acc@1 71.9	Acc@5 96.9
Epoch: [58][371/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 92.2
Epoch: [58][381/704]	Time 0.120	Data 0.001	Loss 7.14	Acc@1 50.0	Acc@5 82.8
Epoch: [58][391/704]	Time 0.120	Data 0.001	Loss 6.09	Acc@1 62.5	Acc@5 85.9
Epoch: [58][401/704]	Time 0.120	Data 0.001	Loss 4.20	Acc@1 71.9	Acc@5 95.3
Epoch: [58][411/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 68.8	Acc@5 89.1
Epoch: [58][421/704]	Time 0.120	Data 0.001	Loss 5.30	Acc@1 62.5	Acc@5 95.3
Epoch: [58][431/704]	Time 0.120	Data 0.001	Loss 6.70	Acc@1 62.5	Acc@5 89.1
Epoch: [58][441/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 57.8	Acc@5 85.9
Epoch: [58][451/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 68.8	Acc@5 90.6
Epoch: [58][461/704]	Time 0.120	Data 0.001	Loss 5.02	Acc@1 60.9	Acc@5 90.6
Epoch: [58][471/704]	Time 0.120	Data 0.001	Loss 6.00	Acc@1 50.0	Acc@5 95.3
Epoch: [58][481/704]	Time 0.120	Data 0.001	Loss 4.85	Acc@1 70.3	Acc@5 96.9
Epoch: [58][491/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 65.6	Acc@5 89.1
Epoch: [58][501/704]	Time 0.120	Data 0.001	Loss 6.66	Acc@1 62.5	Acc@5 90.6
Epoch: [58][511/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 70.3	Acc@5 95.3
Epoch: [58][521/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 59.4	Acc@5 87.5
Epoch: [58][531/704]	Time 0.120	Data 0.001	Loss 4.67	Acc@1 70.3	Acc@5 95.3
Epoch: [58][541/704]	Time 0.120	Data 0.001	Loss 6.39	Acc@1 64.1	Acc@5 89.1
Epoch: [58][551/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 64.1	Acc@5 90.6
Epoch: [58][561/704]	Time 0.120	Data 0.001	Loss 6.36	Acc@1 56.2	Acc@5 92.2
Epoch: [58][571/704]	Time 0.120	Data 0.001	Loss 4.86	Acc@1 73.4	Acc@5 96.9
Epoch: [58][581/704]	Time 0.120	Data 0.001	Loss 5.97	Acc@1 57.8	Acc@5 85.9
Epoch: [58][591/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 73.4	Acc@5 89.1
Epoch: [58][601/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 67.2	Acc@5 93.8
Epoch: [58][611/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 70.3	Acc@5 92.2
Epoch: [58][621/704]	Time 0.120	Data 0.001	Loss 4.83	Acc@1 71.9	Acc@5 92.2
Epoch: [58][631/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 64.1	Acc@5 93.8
Epoch: [58][641/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 64.1	Acc@5 93.8
Epoch: [58][651/704]	Time 0.120	Data 0.001	Loss 6.18	Acc@1 65.6	Acc@5 93.8
Epoch: [58][661/704]	Time 0.120	Data 0.001	Loss 7.16	Acc@1 57.8	Acc@5 89.1
Epoch: [58][671/704]	Time 0.120	Data 0.001	Loss 4.64	Acc@1 71.9	Acc@5 93.8
Epoch: [58][681/704]	Time 0.120	Data 0.001	Loss 4.17	Acc@1 76.6	Acc@5 96.9
Epoch: [58][691/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 93.8
Epoch: [58][701/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.5056	Acc@1 51.5625	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.6604	Acc@1 51.5625	Acc@5 82.8125
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 6.5003	Acc@1 62.5000	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.3702	Acc@1 50.0000	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.0124	Acc@1 59.3750	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.8611	Acc@1 54.6875	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.0882	Acc@1 56.2500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1816	Acc@1 59.3750	Acc@5 93.7500
 * prec@1 46.600 prec@5 78.360
 * prec@1 51.340 prec@5 81.440
 * prec@1 55.300 prec@5 84.100
 * prec@1 57.540 prec@5 85.340
New best validation last_bloc_accuracy 57.54
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_058.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_058.pth.tar'
Epoch: [59][1/704]	Time 0.299	Data 0.132	Loss 5.10	Acc@1 57.8	Acc@5 93.8
Epoch: [59][11/704]	Time 0.140	Data 0.012	Loss 5.77	Acc@1 64.1	Acc@5 92.2
Epoch: [59][21/704]	Time 0.130	Data 0.007	Loss 5.21	Acc@1 67.2	Acc@5 92.2
Epoch: [59][31/704]	Time 0.127	Data 0.005	Loss 4.43	Acc@1 67.2	Acc@5 93.8
Epoch: [59][41/704]	Time 0.125	Data 0.004	Loss 4.96	Acc@1 67.2	Acc@5 93.8
Epoch: [59][51/704]	Time 0.124	Data 0.003	Loss 5.00	Acc@1 71.9	Acc@5 92.2
Epoch: [59][61/704]	Time 0.123	Data 0.003	Loss 4.75	Acc@1 70.3	Acc@5 95.3
Epoch: [59][71/704]	Time 0.123	Data 0.002	Loss 4.69	Acc@1 68.8	Acc@5 90.6
Epoch: [59][81/704]	Time 0.122	Data 0.002	Loss 5.36	Acc@1 59.4	Acc@5 89.1
Epoch: [59][91/704]	Time 0.122	Data 0.002	Loss 5.88	Acc@1 65.6	Acc@5 93.8
Epoch: [59][101/704]	Time 0.122	Data 0.002	Loss 5.77	Acc@1 64.1	Acc@5 85.9
Epoch: [59][111/704]	Time 0.122	Data 0.002	Loss 6.41	Acc@1 62.5	Acc@5 90.6
Epoch: [59][121/704]	Time 0.121	Data 0.002	Loss 5.16	Acc@1 73.4	Acc@5 92.2
Epoch: [59][131/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 90.6
Epoch: [59][141/704]	Time 0.121	Data 0.001	Loss 6.79	Acc@1 57.8	Acc@5 87.5
Epoch: [59][151/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 62.5	Acc@5 89.1
Epoch: [59][161/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 68.8	Acc@5 92.2
Epoch: [59][171/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 67.2	Acc@5 90.6
Epoch: [59][181/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 64.1	Acc@5 93.8
Epoch: [59][191/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 64.1	Acc@5 92.2
Epoch: [59][201/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 62.5	Acc@5 84.4
Epoch: [59][211/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 70.3	Acc@5 95.3
Epoch: [59][221/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 62.5	Acc@5 81.2
Epoch: [59][231/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 68.8	Acc@5 81.2
Epoch: [59][241/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 75.0	Acc@5 92.2
Epoch: [59][251/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 73.4	Acc@5 95.3
Epoch: [59][261/704]	Time 0.120	Data 0.001	Loss 4.65	Acc@1 70.3	Acc@5 95.3
Epoch: [59][271/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 67.2	Acc@5 96.9
Epoch: [59][281/704]	Time 0.120	Data 0.001	Loss 5.11	Acc@1 70.3	Acc@5 92.2
Epoch: [59][291/704]	Time 0.120	Data 0.001	Loss 4.64	Acc@1 68.8	Acc@5 95.3
Epoch: [59][301/704]	Time 0.120	Data 0.001	Loss 6.51	Acc@1 62.5	Acc@5 84.4
Epoch: [59][311/704]	Time 0.120	Data 0.001	Loss 4.38	Acc@1 81.2	Acc@5 93.8
Epoch: [59][321/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 71.9	Acc@5 90.6
Epoch: [59][331/704]	Time 0.120	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 95.3
Epoch: [59][341/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 70.3	Acc@5 92.2
Epoch: [59][351/704]	Time 0.120	Data 0.001	Loss 4.87	Acc@1 67.2	Acc@5 92.2
Epoch: [59][361/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 65.6	Acc@5 90.6
Epoch: [59][371/704]	Time 0.120	Data 0.001	Loss 4.69	Acc@1 71.9	Acc@5 92.2
Epoch: [59][381/704]	Time 0.120	Data 0.001	Loss 4.93	Acc@1 71.9	Acc@5 95.3
Epoch: [59][391/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 62.5	Acc@5 93.8
Epoch: [59][401/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 67.2	Acc@5 89.1
Epoch: [59][411/704]	Time 0.120	Data 0.001	Loss 6.45	Acc@1 57.8	Acc@5 89.1
Epoch: [59][421/704]	Time 0.120	Data 0.001	Loss 6.41	Acc@1 60.9	Acc@5 85.9
Epoch: [59][431/704]	Time 0.120	Data 0.001	Loss 4.66	Acc@1 70.3	Acc@5 95.3
Epoch: [59][441/704]	Time 0.120	Data 0.001	Loss 4.93	Acc@1 68.8	Acc@5 92.2
Epoch: [59][451/704]	Time 0.120	Data 0.001	Loss 5.35	Acc@1 64.1	Acc@5 90.6
Epoch: [59][461/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 62.5	Acc@5 92.2
Epoch: [59][471/704]	Time 0.120	Data 0.001	Loss 6.17	Acc@1 60.9	Acc@5 87.5
Epoch: [59][481/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 62.5	Acc@5 93.8
Epoch: [59][491/704]	Time 0.120	Data 0.001	Loss 5.09	Acc@1 73.4	Acc@5 95.3
Epoch: [59][501/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 73.4	Acc@5 92.2
Epoch: [59][511/704]	Time 0.120	Data 0.001	Loss 4.73	Acc@1 71.9	Acc@5 96.9
Epoch: [59][521/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 62.5	Acc@5 92.2
Epoch: [59][531/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 71.9	Acc@5 93.8
Epoch: [59][541/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 73.4	Acc@5 93.8
Epoch: [59][551/704]	Time 0.120	Data 0.001	Loss 6.75	Acc@1 57.8	Acc@5 89.1
Epoch: [59][561/704]	Time 0.120	Data 0.001	Loss 6.18	Acc@1 67.2	Acc@5 85.9
Epoch: [59][571/704]	Time 0.120	Data 0.001	Loss 5.43	Acc@1 70.3	Acc@5 93.8
Epoch: [59][581/704]	Time 0.120	Data 0.001	Loss 6.63	Acc@1 67.2	Acc@5 89.1
Epoch: [59][591/704]	Time 0.120	Data 0.001	Loss 6.44	Acc@1 62.5	Acc@5 89.1
Epoch: [59][601/704]	Time 0.120	Data 0.001	Loss 6.16	Acc@1 65.6	Acc@5 89.1
Epoch: [59][611/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 89.1
Epoch: [59][621/704]	Time 0.120	Data 0.001	Loss 4.41	Acc@1 71.9	Acc@5 93.8
Epoch: [59][631/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 65.6	Acc@5 90.6
Epoch: [59][641/704]	Time 0.120	Data 0.001	Loss 6.16	Acc@1 56.2	Acc@5 90.6
Epoch: [59][651/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 62.5	Acc@5 92.2
Epoch: [59][661/704]	Time 0.120	Data 0.001	Loss 6.95	Acc@1 53.1	Acc@5 90.6
Epoch: [59][671/704]	Time 0.120	Data 0.001	Loss 4.57	Acc@1 70.3	Acc@5 90.6
Epoch: [59][681/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 62.5	Acc@5 93.8
Epoch: [59][691/704]	Time 0.120	Data 0.001	Loss 4.51	Acc@1 65.6	Acc@5 93.8
Epoch: [59][701/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.9507	Acc@1 53.1250	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.3256	Acc@1 48.4375	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8162	Acc@1 59.3750	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.1064	Acc@1 46.8750	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.7854	Acc@1 64.0625	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.5052	Acc@1 48.4375	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7455	Acc@1 62.5000	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9999	Acc@1 53.1250	Acc@5 84.3750
 * prec@1 48.660 prec@5 77.880
 * prec@1 52.100 prec@5 82.340
 * prec@1 55.180 prec@5 85.140
 * prec@1 55.380 prec@5 85.280
Current best validation last_bloc_accuracy 57.54
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_059.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_059.pth.tar'
Epoch: [60][1/704]	Time 0.330	Data 0.164	Loss 4.85	Acc@1 64.1	Acc@5 90.6
Epoch: [60][11/704]	Time 0.140	Data 0.015	Loss 5.99	Acc@1 65.6	Acc@5 90.6
Epoch: [60][21/704]	Time 0.130	Data 0.008	Loss 5.70	Acc@1 65.6	Acc@5 90.6
Epoch: [60][31/704]	Time 0.127	Data 0.006	Loss 4.39	Acc@1 73.4	Acc@5 93.8
Epoch: [60][41/704]	Time 0.125	Data 0.004	Loss 6.00	Acc@1 65.6	Acc@5 92.2
Epoch: [60][51/704]	Time 0.124	Data 0.004	Loss 6.01	Acc@1 64.1	Acc@5 90.6
Epoch: [60][61/704]	Time 0.124	Data 0.003	Loss 6.67	Acc@1 62.5	Acc@5 89.1
Epoch: [60][71/704]	Time 0.123	Data 0.003	Loss 6.29	Acc@1 62.5	Acc@5 90.6
Epoch: [60][81/704]	Time 0.123	Data 0.002	Loss 5.43	Acc@1 62.5	Acc@5 87.5
Epoch: [60][91/704]	Time 0.123	Data 0.002	Loss 5.09	Acc@1 62.5	Acc@5 89.1
Epoch: [60][101/704]	Time 0.122	Data 0.002	Loss 5.36	Acc@1 67.2	Acc@5 87.5
Epoch: [60][111/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 70.3	Acc@5 89.1
Epoch: [60][121/704]	Time 0.122	Data 0.002	Loss 5.44	Acc@1 67.2	Acc@5 95.3
Epoch: [60][131/704]	Time 0.122	Data 0.002	Loss 4.65	Acc@1 68.8	Acc@5 92.2
Epoch: [60][141/704]	Time 0.122	Data 0.002	Loss 4.65	Acc@1 75.0	Acc@5 92.2
Epoch: [60][151/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 68.8	Acc@5 89.1
Epoch: [60][161/704]	Time 0.121	Data 0.001	Loss 3.81	Acc@1 82.8	Acc@5 96.9
Epoch: [60][171/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 64.1	Acc@5 95.3
Epoch: [60][181/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 62.5	Acc@5 85.9
Epoch: [60][191/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 68.8	Acc@5 93.8
Epoch: [60][201/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 59.4	Acc@5 93.8
Epoch: [60][211/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 59.4	Acc@5 92.2
Epoch: [60][221/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 76.6	Acc@5 90.6
Epoch: [60][231/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 70.3	Acc@5 96.9
Epoch: [60][241/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 60.9	Acc@5 93.8
Epoch: [60][251/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 67.2	Acc@5 95.3
Epoch: [60][261/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 60.9	Acc@5 87.5
Epoch: [60][271/704]	Time 0.121	Data 0.001	Loss 4.08	Acc@1 76.6	Acc@5 96.9
Epoch: [60][281/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 67.2	Acc@5 90.6
Epoch: [60][291/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 75.0	Acc@5 95.3
Epoch: [60][301/704]	Time 0.121	Data 0.001	Loss 6.98	Acc@1 59.4	Acc@5 85.9
Epoch: [60][311/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 68.8	Acc@5 90.6
Epoch: [60][321/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 57.8	Acc@5 82.8
Epoch: [60][331/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 75.0	Acc@5 95.3
Epoch: [60][341/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 62.5	Acc@5 90.6
Epoch: [60][351/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 81.2	Acc@5 93.8
Epoch: [60][361/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 85.9
Epoch: [60][371/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 70.3	Acc@5 90.6
Epoch: [60][381/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 67.2	Acc@5 89.1
Epoch: [60][391/704]	Time 0.120	Data 0.001	Loss 4.48	Acc@1 71.9	Acc@5 93.8
Epoch: [60][401/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 64.1	Acc@5 96.9
Epoch: [60][411/704]	Time 0.120	Data 0.001	Loss 6.34	Acc@1 67.2	Acc@5 85.9
Epoch: [60][421/704]	Time 0.120	Data 0.001	Loss 6.19	Acc@1 64.1	Acc@5 89.1
Epoch: [60][431/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 62.5	Acc@5 90.6
Epoch: [60][441/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 71.9	Acc@5 96.9
Epoch: [60][451/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 93.8
Epoch: [60][461/704]	Time 0.120	Data 0.001	Loss 6.23	Acc@1 62.5	Acc@5 92.2
Epoch: [60][471/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 75.0	Acc@5 93.8
Epoch: [60][481/704]	Time 0.120	Data 0.001	Loss 5.03	Acc@1 62.5	Acc@5 95.3
Epoch: [60][491/704]	Time 0.120	Data 0.001	Loss 6.04	Acc@1 56.2	Acc@5 89.1
Epoch: [60][501/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 65.6	Acc@5 85.9
Epoch: [60][511/704]	Time 0.120	Data 0.001	Loss 5.91	Acc@1 60.9	Acc@5 87.5
Epoch: [60][521/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 68.8	Acc@5 95.3
Epoch: [60][531/704]	Time 0.120	Data 0.001	Loss 5.39	Acc@1 60.9	Acc@5 90.6
Epoch: [60][541/704]	Time 0.120	Data 0.001	Loss 6.30	Acc@1 65.6	Acc@5 85.9
Epoch: [60][551/704]	Time 0.120	Data 0.001	Loss 6.81	Acc@1 60.9	Acc@5 81.2
Epoch: [60][561/704]	Time 0.120	Data 0.001	Loss 5.30	Acc@1 60.9	Acc@5 90.6
Epoch: [60][571/704]	Time 0.120	Data 0.001	Loss 6.00	Acc@1 65.6	Acc@5 89.1
Epoch: [60][581/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 51.6	Acc@5 84.4
Epoch: [60][591/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 62.5	Acc@5 89.1
Epoch: [60][601/704]	Time 0.120	Data 0.001	Loss 6.42	Acc@1 64.1	Acc@5 89.1
Epoch: [60][611/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 71.9	Acc@5 89.1
Epoch: [60][621/704]	Time 0.120	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 87.5
Epoch: [60][631/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 64.1	Acc@5 92.2
Epoch: [60][641/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 60.9	Acc@5 90.6
Epoch: [60][651/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 67.2	Acc@5 95.3
Epoch: [60][661/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 64.1	Acc@5 92.2
Epoch: [60][671/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 59.4	Acc@5 85.9
Epoch: [60][681/704]	Time 0.120	Data 0.001	Loss 5.65	Acc@1 62.5	Acc@5 93.8
Epoch: [60][691/704]	Time 0.120	Data 0.001	Loss 6.30	Acc@1 53.1	Acc@5 87.5
Epoch: [60][701/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.3951	Acc@1 64.0625	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.2817	Acc@1 50.0000	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.9940	Acc@1 48.4375	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.0430	Acc@1 56.2500	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.6394	Acc@1 60.9375	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9901	Acc@1 67.1875	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.3196	Acc@1 48.4375	Acc@5 79.6875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.5617	Acc@1 57.8125	Acc@5 87.5000
 * prec@1 43.840 prec@5 75.180
 * prec@1 48.660 prec@5 79.120
 * prec@1 54.920 prec@5 83.960
 * prec@1 54.940 prec@5 83.700
Current best validation last_bloc_accuracy 57.54
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_060.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_060.pth.tar'
Epoch: [61][1/704]	Time 0.301	Data 0.133	Loss 6.01	Acc@1 62.5	Acc@5 89.1
Epoch: [61][11/704]	Time 0.137	Data 0.012	Loss 7.09	Acc@1 56.2	Acc@5 89.1
Epoch: [61][21/704]	Time 0.129	Data 0.007	Loss 6.20	Acc@1 68.8	Acc@5 90.6
Epoch: [61][31/704]	Time 0.126	Data 0.005	Loss 6.38	Acc@1 57.8	Acc@5 95.3
Epoch: [61][41/704]	Time 0.124	Data 0.004	Loss 4.83	Acc@1 71.9	Acc@5 98.4
Epoch: [61][51/704]	Time 0.124	Data 0.003	Loss 5.55	Acc@1 68.8	Acc@5 90.6
Epoch: [61][61/704]	Time 0.123	Data 0.003	Loss 6.35	Acc@1 67.2	Acc@5 90.6
Epoch: [61][71/704]	Time 0.123	Data 0.002	Loss 5.73	Acc@1 60.9	Acc@5 90.6
Epoch: [61][81/704]	Time 0.122	Data 0.002	Loss 5.29	Acc@1 60.9	Acc@5 90.6
Epoch: [61][91/704]	Time 0.122	Data 0.002	Loss 5.37	Acc@1 65.6	Acc@5 90.6
Epoch: [61][101/704]	Time 0.122	Data 0.002	Loss 4.78	Acc@1 70.3	Acc@5 95.3
Epoch: [61][111/704]	Time 0.122	Data 0.002	Loss 5.83	Acc@1 56.2	Acc@5 90.6
Epoch: [61][121/704]	Time 0.122	Data 0.002	Loss 4.93	Acc@1 59.4	Acc@5 96.9
Epoch: [61][131/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 65.6	Acc@5 93.8
Epoch: [61][141/704]	Time 0.122	Data 0.001	Loss 5.30	Acc@1 64.1	Acc@5 89.1
Epoch: [61][151/704]	Time 0.122	Data 0.001	Loss 4.13	Acc@1 75.0	Acc@5 98.4
Epoch: [61][161/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 71.9	Acc@5 95.3
Epoch: [61][171/704]	Time 0.121	Data 0.001	Loss 6.65	Acc@1 60.9	Acc@5 89.1
Epoch: [61][181/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 68.8	Acc@5 93.8
Epoch: [61][191/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 93.8
Epoch: [61][201/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 60.9	Acc@5 93.8
Epoch: [61][211/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 70.3	Acc@5 95.3
Epoch: [61][221/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 79.7	Acc@5 95.3
Epoch: [61][231/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 68.8	Acc@5 89.1
Epoch: [61][241/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 60.9	Acc@5 93.8
Epoch: [61][251/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 62.5	Acc@5 92.2
Epoch: [61][261/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 64.1	Acc@5 92.2
Epoch: [61][271/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 67.2	Acc@5 90.6
Epoch: [61][281/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 65.6	Acc@5 92.2
Epoch: [61][291/704]	Time 0.121	Data 0.001	Loss 6.70	Acc@1 56.2	Acc@5 87.5
Epoch: [61][301/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 62.5	Acc@5 90.6
Epoch: [61][311/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 54.7	Acc@5 84.4
Epoch: [61][321/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 57.8	Acc@5 87.5
Epoch: [61][331/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 70.3	Acc@5 90.6
Epoch: [61][341/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 60.9	Acc@5 89.1
Epoch: [61][351/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 62.5	Acc@5 89.1
Epoch: [61][361/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 60.9	Acc@5 84.4
Epoch: [61][371/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 70.3	Acc@5 87.5
Epoch: [61][381/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 67.2	Acc@5 93.8
Epoch: [61][391/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 64.1	Acc@5 93.8
Epoch: [61][401/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 62.5	Acc@5 87.5
Epoch: [61][411/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 70.3	Acc@5 90.6
Epoch: [61][421/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 67.2	Acc@5 90.6
Epoch: [61][431/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 70.3	Acc@5 95.3
Epoch: [61][441/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 71.9	Acc@5 92.2
Epoch: [61][451/704]	Time 0.121	Data 0.001	Loss 6.37	Acc@1 51.6	Acc@5 92.2
Epoch: [61][461/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 71.9	Acc@5 95.3
Epoch: [61][471/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 70.3	Acc@5 87.5
Epoch: [61][481/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 71.9	Acc@5 92.2
Epoch: [61][491/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 65.6	Acc@5 90.6
Epoch: [61][501/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 73.4	Acc@5 96.9
Epoch: [61][511/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 87.5
Epoch: [61][521/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 67.2	Acc@5 96.9
Epoch: [61][531/704]	Time 0.121	Data 0.001	Loss 7.12	Acc@1 57.8	Acc@5 89.1
Epoch: [61][541/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 75.0	Acc@5 90.6
Epoch: [61][551/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 67.2	Acc@5 93.8
Epoch: [61][561/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 59.4	Acc@5 90.6
Epoch: [61][571/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 73.4	Acc@5 87.5
Epoch: [61][581/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 64.1	Acc@5 96.9
Epoch: [61][591/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 98.4
Epoch: [61][601/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 70.3	Acc@5 96.9
Epoch: [61][611/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 65.6	Acc@5 93.8
Epoch: [61][621/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 65.6	Acc@5 93.8
Epoch: [61][631/704]	Time 0.120	Data 0.001	Loss 4.64	Acc@1 65.6	Acc@5 92.2
Epoch: [61][641/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 62.5	Acc@5 93.8
Epoch: [61][651/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 68.8	Acc@5 92.2
Epoch: [61][661/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 59.4	Acc@5 90.6
Epoch: [61][671/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 64.1	Acc@5 87.5
Epoch: [61][681/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 64.1	Acc@5 93.8
Epoch: [61][691/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 76.6	Acc@5 90.6
Epoch: [61][701/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 78.1	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 6.8692	Acc@1 62.5000	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.8484	Acc@1 60.9375	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.4350	Acc@1 57.8125	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9244	Acc@1 54.6875	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.2270	Acc@1 51.5625	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7295	Acc@1 57.8125	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.8724	Acc@1 46.8750	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.8554	Acc@1 51.5625	Acc@5 82.8125
 * prec@1 46.840 prec@5 77.920
 * prec@1 51.780 prec@5 81.980
 * prec@1 54.960 prec@5 84.480
 * prec@1 54.460 prec@5 83.800
Current best validation last_bloc_accuracy 57.54
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_061.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_061.pth.tar'
Epoch: [62][1/704]	Time 0.298	Data 0.131	Loss 4.35	Acc@1 76.6	Acc@5 92.2
Epoch: [62][11/704]	Time 0.136	Data 0.012	Loss 5.85	Acc@1 62.5	Acc@5 96.9
Epoch: [62][21/704]	Time 0.128	Data 0.007	Loss 4.57	Acc@1 70.3	Acc@5 95.3
Epoch: [62][31/704]	Time 0.125	Data 0.005	Loss 3.84	Acc@1 73.4	Acc@5 98.4
Epoch: [62][41/704]	Time 0.124	Data 0.004	Loss 5.08	Acc@1 70.3	Acc@5 95.3
Epoch: [62][51/704]	Time 0.123	Data 0.003	Loss 5.74	Acc@1 65.6	Acc@5 85.9
Epoch: [62][61/704]	Time 0.123	Data 0.003	Loss 4.73	Acc@1 65.6	Acc@5 92.2
Epoch: [62][71/704]	Time 0.123	Data 0.002	Loss 4.66	Acc@1 67.2	Acc@5 92.2
Epoch: [62][81/704]	Time 0.122	Data 0.002	Loss 5.44	Acc@1 67.2	Acc@5 90.6
Epoch: [62][91/704]	Time 0.122	Data 0.002	Loss 4.78	Acc@1 65.6	Acc@5 95.3
Epoch: [62][101/704]	Time 0.122	Data 0.002	Loss 4.97	Acc@1 67.2	Acc@5 96.9
Epoch: [62][111/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 73.4	Acc@5 98.4
Epoch: [62][121/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 54.7	Acc@5 90.6
Epoch: [62][131/704]	Time 0.121	Data 0.001	Loss 3.97	Acc@1 78.1	Acc@5 96.9
Epoch: [62][141/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 70.3	Acc@5 90.6
Epoch: [62][151/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 68.8	Acc@5 93.8
Epoch: [62][161/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 67.2	Acc@5 96.9
Epoch: [62][171/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 78.1	Acc@5 92.2
Epoch: [62][181/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 73.4	Acc@5 90.6
Epoch: [62][191/704]	Time 0.121	Data 0.001	Loss 6.50	Acc@1 62.5	Acc@5 89.1
Epoch: [62][201/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 59.4	Acc@5 89.1
Epoch: [62][211/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 67.2	Acc@5 93.8
Epoch: [62][221/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 95.3
Epoch: [62][231/704]	Time 0.121	Data 0.001	Loss 6.43	Acc@1 65.6	Acc@5 90.6
Epoch: [62][241/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 71.9	Acc@5 93.8
Epoch: [62][251/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 53.1	Acc@5 92.2
Epoch: [62][261/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 70.3	Acc@5 95.3
Epoch: [62][271/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 59.4	Acc@5 89.1
Epoch: [62][281/704]	Time 0.120	Data 0.001	Loss 4.97	Acc@1 73.4	Acc@5 95.3
Epoch: [62][291/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 60.9	Acc@5 84.4
Epoch: [62][301/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 65.6	Acc@5 89.1
Epoch: [62][311/704]	Time 0.120	Data 0.001	Loss 4.26	Acc@1 73.4	Acc@5 98.4
Epoch: [62][321/704]	Time 0.120	Data 0.001	Loss 4.96	Acc@1 71.9	Acc@5 90.6
Epoch: [62][331/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 59.4	Acc@5 89.1
Epoch: [62][341/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 67.2	Acc@5 96.9
Epoch: [62][351/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 68.8	Acc@5 96.9
Epoch: [62][361/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 76.6	Acc@5 96.9
Epoch: [62][371/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 70.3	Acc@5 90.6
Epoch: [62][381/704]	Time 0.120	Data 0.001	Loss 5.10	Acc@1 62.5	Acc@5 90.6
Epoch: [62][391/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 71.9	Acc@5 96.9
Epoch: [62][401/704]	Time 0.120	Data 0.001	Loss 3.76	Acc@1 79.7	Acc@5 95.3
Epoch: [62][411/704]	Time 0.120	Data 0.001	Loss 6.58	Acc@1 62.5	Acc@5 87.5
Epoch: [62][421/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 95.3
Epoch: [62][431/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 65.6	Acc@5 92.2
Epoch: [62][441/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 59.4	Acc@5 93.8
Epoch: [62][451/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 65.6	Acc@5 90.6
Epoch: [62][461/704]	Time 0.120	Data 0.001	Loss 6.94	Acc@1 56.2	Acc@5 84.4
Epoch: [62][471/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 62.5	Acc@5 92.2
Epoch: [62][481/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 67.2	Acc@5 89.1
Epoch: [62][491/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 57.8	Acc@5 93.8
Epoch: [62][501/704]	Time 0.120	Data 0.001	Loss 4.45	Acc@1 75.0	Acc@5 96.9
Epoch: [62][511/704]	Time 0.120	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 95.3
Epoch: [62][521/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 62.5	Acc@5 93.8
Epoch: [62][531/704]	Time 0.120	Data 0.001	Loss 6.11	Acc@1 65.6	Acc@5 85.9
Epoch: [62][541/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 92.2
Epoch: [62][551/704]	Time 0.120	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 92.2
Epoch: [62][561/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 67.2	Acc@5 95.3
Epoch: [62][571/704]	Time 0.120	Data 0.001	Loss 5.65	Acc@1 62.5	Acc@5 89.1
Epoch: [62][581/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 65.6	Acc@5 89.1
Epoch: [62][591/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 68.8	Acc@5 92.2
Epoch: [62][601/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 68.8	Acc@5 87.5
Epoch: [62][611/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 68.8	Acc@5 89.1
Epoch: [62][621/704]	Time 0.120	Data 0.001	Loss 4.64	Acc@1 68.8	Acc@5 93.8
Epoch: [62][631/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 68.8	Acc@5 93.8
Epoch: [62][641/704]	Time 0.120	Data 0.001	Loss 4.41	Acc@1 71.9	Acc@5 98.4
Epoch: [62][651/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 70.3	Acc@5 89.1
Epoch: [62][661/704]	Time 0.120	Data 0.001	Loss 4.17	Acc@1 73.4	Acc@5 92.2
Epoch: [62][671/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 73.4	Acc@5 89.1
Epoch: [62][681/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 59.4	Acc@5 90.6
Epoch: [62][691/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 67.2	Acc@5 95.3
Epoch: [62][701/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.7733	Acc@1 54.6875	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.1424	Acc@1 53.1250	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.1669	Acc@1 45.3125	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.4079	Acc@1 56.2500	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.6980	Acc@1 48.4375	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7031	Acc@1 54.6875	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.1633	Acc@1 51.5625	Acc@5 75.0000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.9244	Acc@1 50.0000	Acc@5 85.9375
 * prec@1 46.000 prec@5 78.680
 * prec@1 50.960 prec@5 81.320
 * prec@1 53.460 prec@5 83.920
 * prec@1 54.940 prec@5 84.800
Current best validation last_bloc_accuracy 57.54
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_062.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_062.pth.tar'
Epoch: [63][1/704]	Time 0.332	Data 0.165	Loss 4.58	Acc@1 67.2	Acc@5 93.8
Epoch: [63][11/704]	Time 0.140	Data 0.015	Loss 3.81	Acc@1 81.2	Acc@5 98.4
Epoch: [63][21/704]	Time 0.130	Data 0.008	Loss 4.19	Acc@1 73.4	Acc@5 93.8
Epoch: [63][31/704]	Time 0.127	Data 0.006	Loss 5.36	Acc@1 75.0	Acc@5 90.6
Epoch: [63][41/704]	Time 0.126	Data 0.004	Loss 6.93	Acc@1 56.2	Acc@5 84.4
Epoch: [63][51/704]	Time 0.124	Data 0.004	Loss 4.99	Acc@1 68.8	Acc@5 93.8
Epoch: [63][61/704]	Time 0.124	Data 0.003	Loss 6.92	Acc@1 48.4	Acc@5 90.6
Epoch: [63][71/704]	Time 0.123	Data 0.003	Loss 4.78	Acc@1 65.6	Acc@5 98.4
Epoch: [63][81/704]	Time 0.123	Data 0.002	Loss 4.87	Acc@1 71.9	Acc@5 93.8
Epoch: [63][91/704]	Time 0.123	Data 0.002	Loss 6.59	Acc@1 60.9	Acc@5 87.5
Epoch: [63][101/704]	Time 0.122	Data 0.002	Loss 5.08	Acc@1 64.1	Acc@5 93.8
Epoch: [63][111/704]	Time 0.122	Data 0.002	Loss 6.07	Acc@1 62.5	Acc@5 84.4
Epoch: [63][121/704]	Time 0.122	Data 0.002	Loss 6.14	Acc@1 62.5	Acc@5 92.2
Epoch: [63][131/704]	Time 0.122	Data 0.002	Loss 6.25	Acc@1 57.8	Acc@5 93.8
Epoch: [63][141/704]	Time 0.122	Data 0.002	Loss 4.93	Acc@1 57.8	Acc@5 93.8
Epoch: [63][151/704]	Time 0.122	Data 0.002	Loss 5.21	Acc@1 71.9	Acc@5 93.8
Epoch: [63][161/704]	Time 0.122	Data 0.001	Loss 5.56	Acc@1 60.9	Acc@5 93.8
Epoch: [63][171/704]	Time 0.122	Data 0.001	Loss 4.86	Acc@1 73.4	Acc@5 95.3
Epoch: [63][181/704]	Time 0.122	Data 0.001	Loss 5.83	Acc@1 64.1	Acc@5 89.1
Epoch: [63][191/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 68.8	Acc@5 93.8
Epoch: [63][201/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 73.4	Acc@5 90.6
Epoch: [63][211/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 70.3	Acc@5 95.3
Epoch: [63][221/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 59.4	Acc@5 85.9
Epoch: [63][231/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 65.6	Acc@5 93.8
Epoch: [63][241/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 59.4	Acc@5 90.6
Epoch: [63][251/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 70.3	Acc@5 92.2
Epoch: [63][261/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 68.8	Acc@5 85.9
Epoch: [63][271/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 60.9	Acc@5 92.2
Epoch: [63][281/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 65.6	Acc@5 92.2
Epoch: [63][291/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 67.2	Acc@5 89.1
Epoch: [63][301/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 70.3	Acc@5 93.8
Epoch: [63][311/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 59.4	Acc@5 93.8
Epoch: [63][321/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 67.2	Acc@5 92.2
Epoch: [63][331/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 64.1	Acc@5 92.2
Epoch: [63][341/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 73.4	Acc@5 90.6
Epoch: [63][351/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 75.0	Acc@5 96.9
Epoch: [63][361/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 71.9	Acc@5 90.6
Epoch: [63][371/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 65.6	Acc@5 93.8
Epoch: [63][381/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 68.8	Acc@5 92.2
Epoch: [63][391/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 62.5	Acc@5 87.5
Epoch: [63][401/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 62.5	Acc@5 90.6
Epoch: [63][411/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 68.8	Acc@5 93.8
Epoch: [63][421/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 75.0	Acc@5 93.8
Epoch: [63][431/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 70.3	Acc@5 95.3
Epoch: [63][441/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 73.4	Acc@5 93.8
Epoch: [63][451/704]	Time 0.121	Data 0.001	Loss 7.57	Acc@1 48.4	Acc@5 81.2
Epoch: [63][461/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 79.7	Acc@5 92.2
Epoch: [63][471/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 71.9	Acc@5 93.8
Epoch: [63][481/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 57.8	Acc@5 89.1
Epoch: [63][491/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 57.8	Acc@5 89.1
Epoch: [63][501/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 65.6	Acc@5 95.3
Epoch: [63][511/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 70.3	Acc@5 85.9
Epoch: [63][521/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 71.9	Acc@5 92.2
Epoch: [63][531/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 67.2	Acc@5 84.4
Epoch: [63][541/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 71.9	Acc@5 85.9
Epoch: [63][551/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 71.9	Acc@5 96.9
Epoch: [63][561/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 64.1	Acc@5 89.1
Epoch: [63][571/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 54.7	Acc@5 92.2
Epoch: [63][581/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 57.8	Acc@5 82.8
Epoch: [63][591/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 62.5	Acc@5 89.1
Epoch: [63][601/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 70.3	Acc@5 90.6
Epoch: [63][611/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 64.1	Acc@5 85.9
Epoch: [63][621/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 56.2	Acc@5 87.5
Epoch: [63][631/704]	Time 0.121	Data 0.001	Loss 7.04	Acc@1 53.1	Acc@5 89.1
Epoch: [63][641/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 60.9	Acc@5 90.6
Epoch: [63][651/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 73.4	Acc@5 93.8
Epoch: [63][661/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 68.8	Acc@5 92.2
Epoch: [63][671/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 70.3	Acc@5 95.3
Epoch: [63][681/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 62.5	Acc@5 92.2
Epoch: [63][691/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 68.8	Acc@5 89.1
Epoch: [63][701/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 59.4	Acc@5 89.1
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5860	Acc@1 62.5000	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.6164	Acc@1 48.4375	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.3366	Acc@1 53.1250	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3907	Acc@1 53.1250	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4398	Acc@1 64.0625	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.6013	Acc@1 59.3750	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6976	Acc@1 68.7500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.3188	Acc@1 64.0625	Acc@5 78.1250
 * prec@1 48.000 prec@5 78.560
 * prec@1 52.440 prec@5 83.220
 * prec@1 55.440 prec@5 84.760
 * prec@1 58.160 prec@5 85.340
New best validation last_bloc_accuracy 58.16
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_063.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_063.pth.tar'
Epoch: [64][1/704]	Time 0.334	Data 0.168	Loss 5.86	Acc@1 67.2	Acc@5 92.2
Epoch: [64][11/704]	Time 0.140	Data 0.016	Loss 4.11	Acc@1 75.0	Acc@5 98.4
Epoch: [64][21/704]	Time 0.131	Data 0.008	Loss 4.60	Acc@1 75.0	Acc@5 95.3
Epoch: [64][31/704]	Time 0.127	Data 0.006	Loss 5.24	Acc@1 65.6	Acc@5 92.2
Epoch: [64][41/704]	Time 0.125	Data 0.004	Loss 5.70	Acc@1 65.6	Acc@5 95.3
Epoch: [64][51/704]	Time 0.124	Data 0.004	Loss 5.35	Acc@1 67.2	Acc@5 92.2
Epoch: [64][61/704]	Time 0.124	Data 0.003	Loss 6.60	Acc@1 53.1	Acc@5 90.6
Epoch: [64][71/704]	Time 0.123	Data 0.003	Loss 5.43	Acc@1 65.6	Acc@5 92.2
Epoch: [64][81/704]	Time 0.123	Data 0.003	Loss 5.01	Acc@1 67.2	Acc@5 93.8
Epoch: [64][91/704]	Time 0.122	Data 0.002	Loss 7.48	Acc@1 54.7	Acc@5 87.5
Epoch: [64][101/704]	Time 0.122	Data 0.002	Loss 5.27	Acc@1 71.9	Acc@5 96.9
Epoch: [64][111/704]	Time 0.122	Data 0.002	Loss 6.70	Acc@1 57.8	Acc@5 85.9
Epoch: [64][121/704]	Time 0.122	Data 0.002	Loss 5.46	Acc@1 75.0	Acc@5 92.2
Epoch: [64][131/704]	Time 0.122	Data 0.002	Loss 5.19	Acc@1 71.9	Acc@5 93.8
Epoch: [64][141/704]	Time 0.122	Data 0.002	Loss 5.73	Acc@1 64.1	Acc@5 90.6
Epoch: [64][151/704]	Time 0.122	Data 0.002	Loss 5.20	Acc@1 68.8	Acc@5 90.6
Epoch: [64][161/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 67.2	Acc@5 93.8
Epoch: [64][171/704]	Time 0.122	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 96.9
Epoch: [64][181/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 67.2	Acc@5 84.4
Epoch: [64][191/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 76.6	Acc@5 93.8
Epoch: [64][201/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 68.8	Acc@5 90.6
Epoch: [64][211/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 65.6	Acc@5 87.5
Epoch: [64][221/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 89.1
Epoch: [64][231/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 70.3	Acc@5 95.3
Epoch: [64][241/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 70.3	Acc@5 93.8
Epoch: [64][251/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 68.8	Acc@5 87.5
Epoch: [64][261/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 68.8	Acc@5 93.8
Epoch: [64][271/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 73.4	Acc@5 95.3
Epoch: [64][281/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 79.7	Acc@5 92.2
Epoch: [64][291/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 60.9	Acc@5 89.1
Epoch: [64][301/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 60.9	Acc@5 90.6
Epoch: [64][311/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 68.8	Acc@5 89.1
Epoch: [64][321/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 68.8	Acc@5 95.3
Epoch: [64][331/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 87.5
Epoch: [64][341/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 67.2	Acc@5 89.1
Epoch: [64][351/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 95.3
Epoch: [64][361/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 65.6	Acc@5 95.3
Epoch: [64][371/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 90.6
Epoch: [64][381/704]	Time 0.121	Data 0.001	Loss 4.18	Acc@1 82.8	Acc@5 93.8
Epoch: [64][391/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 64.1	Acc@5 96.9
Epoch: [64][401/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 64.1	Acc@5 89.1
Epoch: [64][411/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 65.6	Acc@5 92.2
Epoch: [64][421/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 70.3	Acc@5 87.5
Epoch: [64][431/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 64.1	Acc@5 92.2
Epoch: [64][441/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 67.2	Acc@5 92.2
Epoch: [64][451/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 92.2
Epoch: [64][461/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 51.6	Acc@5 87.5
Epoch: [64][471/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 78.1	Acc@5 96.9
Epoch: [64][481/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 70.3	Acc@5 93.8
Epoch: [64][491/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 62.5	Acc@5 93.8
Epoch: [64][501/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 68.8	Acc@5 92.2
Epoch: [64][511/704]	Time 0.121	Data 0.001	Loss 6.43	Acc@1 57.8	Acc@5 90.6
Epoch: [64][521/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 65.6	Acc@5 90.6
Epoch: [64][531/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 73.4	Acc@5 85.9
Epoch: [64][541/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 65.6	Acc@5 89.1
Epoch: [64][551/704]	Time 0.121	Data 0.001	Loss 6.36	Acc@1 62.5	Acc@5 87.5
Epoch: [64][561/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 90.6
Epoch: [64][571/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 75.0	Acc@5 93.8
Epoch: [64][581/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 70.3	Acc@5 96.9
Epoch: [64][591/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 81.2	Acc@5 96.9
Epoch: [64][601/704]	Time 0.121	Data 0.001	Loss 3.98	Acc@1 76.6	Acc@5 95.3
Epoch: [64][611/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 87.5
Epoch: [64][621/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 76.6	Acc@5 95.3
Epoch: [64][631/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 71.9	Acc@5 89.1
Epoch: [64][641/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 64.1	Acc@5 92.2
Epoch: [64][651/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 64.1	Acc@5 89.1
Epoch: [64][661/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 67.2	Acc@5 89.1
Epoch: [64][671/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 65.6	Acc@5 93.8
Epoch: [64][681/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 62.5	Acc@5 92.2
Epoch: [64][691/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 68.8	Acc@5 89.1
Epoch: [64][701/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 65.6	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.1311	Acc@1 56.2500	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.5686	Acc@1 59.3750	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0027	Acc@1 51.5625	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0006	Acc@1 59.3750	Acc@5 79.6875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4295	Acc@1 57.8125	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.5003	Acc@1 60.9375	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7892	Acc@1 57.8125	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3315	Acc@1 65.6250	Acc@5 87.5000
 * prec@1 46.560 prec@5 77.200
 * prec@1 50.100 prec@5 80.800
 * prec@1 55.920 prec@5 84.440
 * prec@1 56.780 prec@5 85.200
Current best validation last_bloc_accuracy 58.16
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_064.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_064.pth.tar'
Epoch: [65][1/704]	Time 0.299	Data 0.131	Loss 5.75	Acc@1 56.2	Acc@5 89.1
Epoch: [65][11/704]	Time 0.137	Data 0.012	Loss 4.70	Acc@1 64.1	Acc@5 93.8
Epoch: [65][21/704]	Time 0.129	Data 0.007	Loss 6.04	Acc@1 62.5	Acc@5 89.1
Epoch: [65][31/704]	Time 0.126	Data 0.005	Loss 5.16	Acc@1 68.8	Acc@5 95.3
Epoch: [65][41/704]	Time 0.125	Data 0.004	Loss 5.51	Acc@1 54.7	Acc@5 90.6
Epoch: [65][51/704]	Time 0.124	Data 0.003	Loss 4.38	Acc@1 71.9	Acc@5 93.8
Epoch: [65][61/704]	Time 0.123	Data 0.003	Loss 5.08	Acc@1 64.1	Acc@5 89.1
Epoch: [65][71/704]	Time 0.123	Data 0.002	Loss 5.19	Acc@1 67.2	Acc@5 93.8
Epoch: [65][81/704]	Time 0.122	Data 0.002	Loss 4.37	Acc@1 78.1	Acc@5 95.3
Epoch: [65][91/704]	Time 0.123	Data 0.002	Loss 4.84	Acc@1 65.6	Acc@5 93.8
Epoch: [65][101/704]	Time 0.122	Data 0.002	Loss 4.71	Acc@1 75.0	Acc@5 93.8
Epoch: [65][111/704]	Time 0.122	Data 0.002	Loss 6.24	Acc@1 57.8	Acc@5 89.1
Epoch: [65][121/704]	Time 0.122	Data 0.002	Loss 5.32	Acc@1 67.2	Acc@5 87.5
Epoch: [65][131/704]	Time 0.122	Data 0.001	Loss 5.34	Acc@1 62.5	Acc@5 95.3
Epoch: [65][141/704]	Time 0.122	Data 0.001	Loss 5.10	Acc@1 71.9	Acc@5 87.5
Epoch: [65][151/704]	Time 0.122	Data 0.001	Loss 4.61	Acc@1 70.3	Acc@5 95.3
Epoch: [65][161/704]	Time 0.122	Data 0.001	Loss 4.64	Acc@1 68.8	Acc@5 95.3
Epoch: [65][171/704]	Time 0.122	Data 0.001	Loss 5.54	Acc@1 68.8	Acc@5 90.6
Epoch: [65][181/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 76.6	Acc@5 93.8
Epoch: [65][191/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 70.3	Acc@5 96.9
Epoch: [65][201/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 70.3	Acc@5 92.2
Epoch: [65][211/704]	Time 0.121	Data 0.001	Loss 6.41	Acc@1 62.5	Acc@5 89.1
Epoch: [65][221/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 65.6	Acc@5 92.2
Epoch: [65][231/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 59.4	Acc@5 95.3
Epoch: [65][241/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 67.2	Acc@5 95.3
Epoch: [65][251/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 73.4	Acc@5 85.9
Epoch: [65][261/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 68.8	Acc@5 92.2
Epoch: [65][271/704]	Time 0.121	Data 0.001	Loss 6.69	Acc@1 68.8	Acc@5 84.4
Epoch: [65][281/704]	Time 0.121	Data 0.001	Loss 3.74	Acc@1 79.7	Acc@5 98.4
Epoch: [65][291/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 67.2	Acc@5 89.1
Epoch: [65][301/704]	Time 0.121	Data 0.001	Loss 4.35	Acc@1 62.5	Acc@5 92.2
Epoch: [65][311/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 64.1	Acc@5 92.2
Epoch: [65][321/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 68.8	Acc@5 90.6
Epoch: [65][331/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 92.2
Epoch: [65][341/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 57.8	Acc@5 87.5
Epoch: [65][351/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 68.8	Acc@5 89.1
Epoch: [65][361/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 71.9	Acc@5 95.3
Epoch: [65][371/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 64.1	Acc@5 90.6
Epoch: [65][381/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 64.1	Acc@5 90.6
Epoch: [65][391/704]	Time 0.121	Data 0.001	Loss 3.77	Acc@1 79.7	Acc@5 95.3
Epoch: [65][401/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 90.6
Epoch: [65][411/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 64.1	Acc@5 92.2
Epoch: [65][421/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 76.6	Acc@5 96.9
Epoch: [65][431/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 71.9	Acc@5 96.9
Epoch: [65][441/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 59.4	Acc@5 90.6
Epoch: [65][451/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 75.0	Acc@5 90.6
Epoch: [65][461/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 64.1	Acc@5 89.1
Epoch: [65][471/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 62.5	Acc@5 90.6
Epoch: [65][481/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 62.5	Acc@5 89.1
Epoch: [65][491/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 90.6
Epoch: [65][501/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 71.9	Acc@5 89.1
Epoch: [65][511/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 64.1	Acc@5 90.6
Epoch: [65][521/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 65.6	Acc@5 95.3
Epoch: [65][531/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 78.1	Acc@5 96.9
Epoch: [65][541/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 70.3	Acc@5 90.6
Epoch: [65][551/704]	Time 0.121	Data 0.001	Loss 6.59	Acc@1 60.9	Acc@5 85.9
Epoch: [65][561/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 68.8	Acc@5 90.6
Epoch: [65][571/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 70.3	Acc@5 89.1
Epoch: [65][581/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 65.6	Acc@5 89.1
Epoch: [65][591/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 62.5	Acc@5 90.6
Epoch: [65][601/704]	Time 0.121	Data 0.001	Loss 7.15	Acc@1 53.1	Acc@5 85.9
Epoch: [65][611/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 60.9	Acc@5 93.8
Epoch: [65][621/704]	Time 0.121	Data 0.001	Loss 6.62	Acc@1 53.1	Acc@5 85.9
Epoch: [65][631/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 73.4	Acc@5 93.8
Epoch: [65][641/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 68.8	Acc@5 95.3
Epoch: [65][651/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 67.2	Acc@5 93.8
Epoch: [65][661/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 68.8	Acc@5 92.2
Epoch: [65][671/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 73.4	Acc@5 95.3
Epoch: [65][681/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 60.9	Acc@5 92.2
Epoch: [65][691/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 59.4	Acc@5 84.4
Epoch: [65][701/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 73.4	Acc@5 89.1
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.8935	Acc@1 64.0625	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.3119	Acc@1 56.2500	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.1575	Acc@1 65.6250	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.8670	Acc@1 45.3125	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.8539	Acc@1 59.3750	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.5835	Acc@1 51.5625	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.0389	Acc@1 51.5625	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.6571	Acc@1 51.5625	Acc@5 81.2500
 * prec@1 46.600 prec@5 77.020
 * prec@1 51.240 prec@5 81.540
 * prec@1 54.960 prec@5 83.760
 * prec@1 55.080 prec@5 84.840
Current best validation last_bloc_accuracy 58.16
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_065.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_065.pth.tar'
Epoch: [66][1/704]	Time 0.300	Data 0.132	Loss 4.75	Acc@1 70.3	Acc@5 93.8
Epoch: [66][11/704]	Time 0.140	Data 0.012	Loss 4.29	Acc@1 70.3	Acc@5 96.9
Epoch: [66][21/704]	Time 0.131	Data 0.007	Loss 5.64	Acc@1 67.2	Acc@5 92.2
Epoch: [66][31/704]	Time 0.127	Data 0.005	Loss 4.69	Acc@1 64.1	Acc@5 95.3
Epoch: [66][41/704]	Time 0.126	Data 0.004	Loss 4.78	Acc@1 65.6	Acc@5 95.3
Epoch: [66][51/704]	Time 0.125	Data 0.003	Loss 5.62	Acc@1 64.1	Acc@5 89.1
Epoch: [66][61/704]	Time 0.124	Data 0.002	Loss 4.76	Acc@1 68.8	Acc@5 92.2
Epoch: [66][71/704]	Time 0.123	Data 0.002	Loss 5.35	Acc@1 68.8	Acc@5 89.1
Epoch: [66][81/704]	Time 0.123	Data 0.002	Loss 5.96	Acc@1 64.1	Acc@5 87.5
Epoch: [66][91/704]	Time 0.123	Data 0.002	Loss 5.82	Acc@1 64.1	Acc@5 84.4
Epoch: [66][101/704]	Time 0.122	Data 0.002	Loss 5.63	Acc@1 67.2	Acc@5 96.9
Epoch: [66][111/704]	Time 0.122	Data 0.002	Loss 5.95	Acc@1 65.6	Acc@5 90.6
Epoch: [66][121/704]	Time 0.122	Data 0.001	Loss 4.95	Acc@1 70.3	Acc@5 93.8
Epoch: [66][131/704]	Time 0.122	Data 0.001	Loss 3.77	Acc@1 75.0	Acc@5 95.3
Epoch: [66][141/704]	Time 0.122	Data 0.001	Loss 5.27	Acc@1 65.6	Acc@5 92.2
Epoch: [66][151/704]	Time 0.122	Data 0.001	Loss 5.07	Acc@1 68.8	Acc@5 92.2
Epoch: [66][161/704]	Time 0.122	Data 0.001	Loss 4.67	Acc@1 71.9	Acc@5 92.2
Epoch: [66][171/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 64.1	Acc@5 89.1
Epoch: [66][181/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 68.8	Acc@5 98.4
Epoch: [66][191/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 75.0	Acc@5 92.2
Epoch: [66][201/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 68.8	Acc@5 92.2
Epoch: [66][211/704]	Time 0.121	Data 0.001	Loss 7.80	Acc@1 57.8	Acc@5 79.7
Epoch: [66][221/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 65.6	Acc@5 87.5
Epoch: [66][231/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 64.1	Acc@5 90.6
Epoch: [66][241/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 70.3	Acc@5 87.5
Epoch: [66][251/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 68.8	Acc@5 92.2
Epoch: [66][261/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 67.2	Acc@5 93.8
Epoch: [66][271/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 67.2	Acc@5 92.2
Epoch: [66][281/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 70.3	Acc@5 92.2
Epoch: [66][291/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 62.5	Acc@5 90.6
Epoch: [66][301/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 73.4	Acc@5 98.4
Epoch: [66][311/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 70.3	Acc@5 92.2
Epoch: [66][321/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 73.4	Acc@5 95.3
Epoch: [66][331/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 60.9	Acc@5 95.3
Epoch: [66][341/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 67.2	Acc@5 90.6
Epoch: [66][351/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 65.6	Acc@5 92.2
Epoch: [66][361/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 75.0	Acc@5 96.9
Epoch: [66][371/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 62.5	Acc@5 89.1
Epoch: [66][381/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 53.1	Acc@5 92.2
Epoch: [66][391/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 73.4	Acc@5 96.9
Epoch: [66][401/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 62.5	Acc@5 90.6
Epoch: [66][411/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 73.4	Acc@5 90.6
Epoch: [66][421/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 62.5	Acc@5 93.8
Epoch: [66][431/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 62.5	Acc@5 89.1
Epoch: [66][441/704]	Time 0.121	Data 0.001	Loss 6.89	Acc@1 59.4	Acc@5 93.8
Epoch: [66][451/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 60.9	Acc@5 85.9
Epoch: [66][461/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 68.8	Acc@5 95.3
Epoch: [66][471/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 71.9	Acc@5 90.6
Epoch: [66][481/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 59.4	Acc@5 82.8
Epoch: [66][491/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 68.8	Acc@5 93.8
Epoch: [66][501/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 67.2	Acc@5 87.5
Epoch: [66][511/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 68.8	Acc@5 92.2
Epoch: [66][521/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 62.5	Acc@5 95.3
Epoch: [66][531/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 89.1
Epoch: [66][541/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 65.6	Acc@5 89.1
Epoch: [66][551/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 67.2	Acc@5 95.3
Epoch: [66][561/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 62.5	Acc@5 87.5
Epoch: [66][571/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 71.9	Acc@5 92.2
Epoch: [66][581/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 57.8	Acc@5 84.4
Epoch: [66][591/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 67.2	Acc@5 92.2
Epoch: [66][601/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 67.2	Acc@5 92.2
Epoch: [66][611/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 65.6	Acc@5 93.8
Epoch: [66][621/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 56.2	Acc@5 90.6
Epoch: [66][631/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 62.5	Acc@5 89.1
Epoch: [66][641/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 60.9	Acc@5 89.1
Epoch: [66][651/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 65.6	Acc@5 90.6
Epoch: [66][661/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 67.2	Acc@5 100.0
Epoch: [66][671/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 67.2	Acc@5 90.6
Epoch: [66][681/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 70.3	Acc@5 93.8
Epoch: [66][691/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 68.8	Acc@5 96.9
Epoch: [66][701/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 57.8	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.3234	Acc@1 62.5000	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.2310	Acc@1 53.1250	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.8352	Acc@1 70.3125	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7932	Acc@1 56.2500	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4590	Acc@1 64.0625	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9693	Acc@1 51.5625	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.7871	Acc@1 54.6875	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3371	Acc@1 54.6875	Acc@5 84.3750
 * prec@1 48.260 prec@5 79.460
 * prec@1 53.720 prec@5 82.840
 * prec@1 56.340 prec@5 84.700
 * prec@1 58.260 prec@5 85.420
New best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_066.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_066.pth.tar'
Epoch: [67][1/704]	Time 0.330	Data 0.164	Loss 5.12	Acc@1 71.9	Acc@5 92.2
Epoch: [67][11/704]	Time 0.139	Data 0.015	Loss 5.79	Acc@1 67.2	Acc@5 92.2
Epoch: [67][21/704]	Time 0.130	Data 0.008	Loss 4.68	Acc@1 67.2	Acc@5 98.4
Epoch: [67][31/704]	Time 0.127	Data 0.006	Loss 6.50	Acc@1 59.4	Acc@5 90.6
Epoch: [67][41/704]	Time 0.125	Data 0.004	Loss 4.78	Acc@1 73.4	Acc@5 95.3
Epoch: [67][51/704]	Time 0.124	Data 0.004	Loss 5.53	Acc@1 64.1	Acc@5 92.2
Epoch: [67][61/704]	Time 0.123	Data 0.003	Loss 5.08	Acc@1 75.0	Acc@5 93.8
Epoch: [67][71/704]	Time 0.123	Data 0.003	Loss 5.46	Acc@1 67.2	Acc@5 92.2
Epoch: [67][81/704]	Time 0.123	Data 0.002	Loss 6.68	Acc@1 45.3	Acc@5 84.4
Epoch: [67][91/704]	Time 0.122	Data 0.002	Loss 5.60	Acc@1 64.1	Acc@5 90.6
Epoch: [67][101/704]	Time 0.122	Data 0.002	Loss 4.86	Acc@1 73.4	Acc@5 93.8
Epoch: [67][111/704]	Time 0.122	Data 0.002	Loss 4.86	Acc@1 71.9	Acc@5 96.9
Epoch: [67][121/704]	Time 0.122	Data 0.002	Loss 6.82	Acc@1 57.8	Acc@5 87.5
Epoch: [67][131/704]	Time 0.121	Data 0.002	Loss 5.52	Acc@1 65.6	Acc@5 95.3
Epoch: [67][141/704]	Time 0.121	Data 0.002	Loss 4.29	Acc@1 78.1	Acc@5 93.8
Epoch: [67][151/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 60.9	Acc@5 87.5
Epoch: [67][161/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 62.5	Acc@5 89.1
Epoch: [67][171/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 70.3	Acc@5 96.9
Epoch: [67][181/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 73.4	Acc@5 92.2
Epoch: [67][191/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 73.4	Acc@5 92.2
Epoch: [67][201/704]	Time 0.121	Data 0.001	Loss 6.78	Acc@1 56.2	Acc@5 85.9
Epoch: [67][211/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 62.5	Acc@5 90.6
Epoch: [67][221/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 71.9	Acc@5 93.8
Epoch: [67][231/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 93.8
Epoch: [67][241/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 60.9	Acc@5 87.5
Epoch: [67][251/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 67.2	Acc@5 96.9
Epoch: [67][261/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 68.8	Acc@5 98.4
Epoch: [67][271/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 67.2	Acc@5 95.3
Epoch: [67][281/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 56.2	Acc@5 89.1
Epoch: [67][291/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 65.6	Acc@5 89.1
Epoch: [67][301/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 64.1	Acc@5 89.1
Epoch: [67][311/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 71.9	Acc@5 90.6
Epoch: [67][321/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 89.1
Epoch: [67][331/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 56.2	Acc@5 87.5
Epoch: [67][341/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 70.3	Acc@5 90.6
Epoch: [67][351/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 70.3	Acc@5 95.3
Epoch: [67][361/704]	Time 0.121	Data 0.001	Loss 3.98	Acc@1 78.1	Acc@5 96.9
Epoch: [67][371/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 59.4	Acc@5 89.1
Epoch: [67][381/704]	Time 0.121	Data 0.001	Loss 3.63	Acc@1 78.1	Acc@5 93.8
Epoch: [67][391/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 67.2	Acc@5 93.8
Epoch: [67][401/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 59.4	Acc@5 90.6
Epoch: [67][411/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 60.9	Acc@5 89.1
Epoch: [67][421/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 65.6	Acc@5 85.9
Epoch: [67][431/704]	Time 0.120	Data 0.001	Loss 5.66	Acc@1 70.3	Acc@5 90.6
Epoch: [67][441/704]	Time 0.120	Data 0.001	Loss 4.89	Acc@1 78.1	Acc@5 92.2
Epoch: [67][451/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 95.3
Epoch: [67][461/704]	Time 0.120	Data 0.001	Loss 4.99	Acc@1 62.5	Acc@5 93.8
Epoch: [67][471/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 64.1	Acc@5 95.3
Epoch: [67][481/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 64.1	Acc@5 89.1
Epoch: [67][491/704]	Time 0.120	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 85.9
Epoch: [67][501/704]	Time 0.120	Data 0.001	Loss 5.46	Acc@1 68.8	Acc@5 93.8
Epoch: [67][511/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 70.3	Acc@5 85.9
Epoch: [67][521/704]	Time 0.120	Data 0.001	Loss 4.52	Acc@1 68.8	Acc@5 92.2
Epoch: [67][531/704]	Time 0.120	Data 0.001	Loss 4.74	Acc@1 75.0	Acc@5 93.8
Epoch: [67][541/704]	Time 0.120	Data 0.001	Loss 4.95	Acc@1 62.5	Acc@5 96.9
Epoch: [67][551/704]	Time 0.120	Data 0.001	Loss 4.85	Acc@1 68.8	Acc@5 95.3
Epoch: [67][561/704]	Time 0.120	Data 0.001	Loss 4.37	Acc@1 76.6	Acc@5 92.2
Epoch: [67][571/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 64.1	Acc@5 90.6
Epoch: [67][581/704]	Time 0.120	Data 0.001	Loss 6.31	Acc@1 67.2	Acc@5 85.9
Epoch: [67][591/704]	Time 0.120	Data 0.001	Loss 4.17	Acc@1 67.2	Acc@5 89.1
Epoch: [67][601/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 68.8	Acc@5 92.2
Epoch: [67][611/704]	Time 0.120	Data 0.001	Loss 5.02	Acc@1 62.5	Acc@5 92.2
Epoch: [67][621/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 92.2
Epoch: [67][631/704]	Time 0.120	Data 0.001	Loss 4.07	Acc@1 68.8	Acc@5 95.3
Epoch: [67][641/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 57.8	Acc@5 87.5
Epoch: [67][651/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 71.9	Acc@5 95.3
Epoch: [67][661/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 62.5	Acc@5 90.6
Epoch: [67][671/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 73.4	Acc@5 96.9
Epoch: [67][681/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 64.1	Acc@5 93.8
Epoch: [67][691/704]	Time 0.120	Data 0.001	Loss 5.68	Acc@1 62.5	Acc@5 93.8
Epoch: [67][701/704]	Time 0.120	Data 0.001	Loss 3.97	Acc@1 78.1	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.4103	Acc@1 67.1875	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0650	Acc@1 56.2500	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.0068	Acc@1 51.5625	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0083	Acc@1 50.0000	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4546	Acc@1 62.5000	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.2825	Acc@1 60.9375	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.8249	Acc@1 51.5625	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 9.4145	Acc@1 50.0000	Acc@5 78.1250
 * prec@1 45.740 prec@5 76.700
 * prec@1 49.900 prec@5 81.220
 * prec@1 55.060 prec@5 84.840
 * prec@1 56.400 prec@5 85.240
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_067.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_067.pth.tar'
Epoch: [68][1/704]	Time 0.300	Data 0.133	Loss 4.84	Acc@1 71.9	Acc@5 93.8
Epoch: [68][11/704]	Time 0.137	Data 0.012	Loss 4.75	Acc@1 73.4	Acc@5 95.3
Epoch: [68][21/704]	Time 0.129	Data 0.007	Loss 5.28	Acc@1 59.4	Acc@5 93.8
Epoch: [68][31/704]	Time 0.126	Data 0.005	Loss 4.89	Acc@1 65.6	Acc@5 95.3
Epoch: [68][41/704]	Time 0.124	Data 0.004	Loss 5.34	Acc@1 70.3	Acc@5 92.2
Epoch: [68][51/704]	Time 0.124	Data 0.003	Loss 4.32	Acc@1 75.0	Acc@5 96.9
Epoch: [68][61/704]	Time 0.123	Data 0.003	Loss 5.36	Acc@1 67.2	Acc@5 92.2
Epoch: [68][71/704]	Time 0.123	Data 0.002	Loss 4.96	Acc@1 70.3	Acc@5 95.3
Epoch: [68][81/704]	Time 0.122	Data 0.002	Loss 3.84	Acc@1 76.6	Acc@5 95.3
Epoch: [68][91/704]	Time 0.122	Data 0.002	Loss 4.93	Acc@1 68.8	Acc@5 92.2
Epoch: [68][101/704]	Time 0.122	Data 0.002	Loss 3.75	Acc@1 76.6	Acc@5 98.4
Epoch: [68][111/704]	Time 0.122	Data 0.002	Loss 4.77	Acc@1 62.5	Acc@5 89.1
Epoch: [68][121/704]	Time 0.122	Data 0.001	Loss 6.47	Acc@1 57.8	Acc@5 90.6
Epoch: [68][131/704]	Time 0.122	Data 0.001	Loss 5.69	Acc@1 57.8	Acc@5 92.2
Epoch: [68][141/704]	Time 0.122	Data 0.001	Loss 4.87	Acc@1 78.1	Acc@5 92.2
Epoch: [68][151/704]	Time 0.122	Data 0.001	Loss 5.94	Acc@1 65.6	Acc@5 90.6
Epoch: [68][161/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 71.9	Acc@5 96.9
Epoch: [68][171/704]	Time 0.121	Data 0.001	Loss 6.18	Acc@1 60.9	Acc@5 90.6
Epoch: [68][181/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 71.9	Acc@5 92.2
Epoch: [68][191/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 60.9	Acc@5 89.1
Epoch: [68][201/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 78.1	Acc@5 90.6
Epoch: [68][211/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 65.6	Acc@5 90.6
Epoch: [68][221/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 64.1	Acc@5 98.4
Epoch: [68][231/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 65.6	Acc@5 87.5
Epoch: [68][241/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 68.8	Acc@5 95.3
Epoch: [68][251/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 92.2
Epoch: [68][261/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 73.4	Acc@5 89.1
Epoch: [68][271/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 64.1	Acc@5 95.3
Epoch: [68][281/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 68.8	Acc@5 92.2
Epoch: [68][291/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 92.2
Epoch: [68][301/704]	Time 0.121	Data 0.001	Loss 3.95	Acc@1 67.2	Acc@5 95.3
Epoch: [68][311/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 73.4	Acc@5 90.6
Epoch: [68][321/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 68.8	Acc@5 93.8
Epoch: [68][331/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 67.2	Acc@5 92.2
Epoch: [68][341/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 65.6	Acc@5 93.8
Epoch: [68][351/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 62.5	Acc@5 95.3
Epoch: [68][361/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 62.5	Acc@5 95.3
Epoch: [68][371/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 62.5	Acc@5 90.6
Epoch: [68][381/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 67.2	Acc@5 96.9
Epoch: [68][391/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 64.1	Acc@5 89.1
Epoch: [68][401/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 59.4	Acc@5 92.2
Epoch: [68][411/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 75.0	Acc@5 95.3
Epoch: [68][421/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 57.8	Acc@5 92.2
Epoch: [68][431/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 64.1	Acc@5 95.3
Epoch: [68][441/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 62.5	Acc@5 95.3
Epoch: [68][451/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 59.4	Acc@5 92.2
Epoch: [68][461/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 65.6	Acc@5 90.6
Epoch: [68][471/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 62.5	Acc@5 89.1
Epoch: [68][481/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 71.9	Acc@5 92.2
Epoch: [68][491/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 73.4	Acc@5 98.4
Epoch: [68][501/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 82.8	Acc@5 96.9
Epoch: [68][511/704]	Time 0.121	Data 0.001	Loss 6.51	Acc@1 60.9	Acc@5 84.4
Epoch: [68][521/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 73.4	Acc@5 89.1
Epoch: [68][531/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 67.2	Acc@5 93.8
Epoch: [68][541/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 70.3	Acc@5 85.9
Epoch: [68][551/704]	Time 0.121	Data 0.001	Loss 7.16	Acc@1 51.6	Acc@5 87.5
Epoch: [68][561/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 68.8	Acc@5 93.8
Epoch: [68][571/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 89.1
Epoch: [68][581/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 71.9	Acc@5 93.8
Epoch: [68][591/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 67.2	Acc@5 96.9
Epoch: [68][601/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 60.9	Acc@5 90.6
Epoch: [68][611/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 65.6	Acc@5 92.2
Epoch: [68][621/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 57.8	Acc@5 92.2
Epoch: [68][631/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 56.2	Acc@5 89.1
Epoch: [68][641/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 71.9	Acc@5 89.1
Epoch: [68][651/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 73.4	Acc@5 93.8
Epoch: [68][661/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 73.4	Acc@5 98.4
Epoch: [68][671/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 64.1	Acc@5 92.2
Epoch: [68][681/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 87.5
Epoch: [68][691/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 68.8	Acc@5 92.2
Epoch: [68][701/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 62.5	Acc@5 95.3
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.9149	Acc@1 65.6250	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.5418	Acc@1 51.5625	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.9272	Acc@1 51.5625	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.8338	Acc@1 54.6875	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.5846	Acc@1 50.0000	Acc@5 76.5625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9116	Acc@1 56.2500	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.7039	Acc@1 56.2500	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.5191	Acc@1 50.0000	Acc@5 78.1250
 * prec@1 48.720 prec@5 80.000
 * prec@1 52.840 prec@5 82.740
 * prec@1 55.880 prec@5 85.200
 * prec@1 57.120 prec@5 85.080
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_068.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_068.pth.tar'
Epoch: [69][1/704]	Time 0.299	Data 0.131	Loss 4.69	Acc@1 71.9	Acc@5 93.8
Epoch: [69][11/704]	Time 0.136	Data 0.012	Loss 5.53	Acc@1 64.1	Acc@5 89.1
Epoch: [69][21/704]	Time 0.128	Data 0.007	Loss 5.43	Acc@1 62.5	Acc@5 89.1
Epoch: [69][31/704]	Time 0.126	Data 0.005	Loss 5.05	Acc@1 59.4	Acc@5 93.8
Epoch: [69][41/704]	Time 0.124	Data 0.004	Loss 5.68	Acc@1 64.1	Acc@5 93.8
Epoch: [69][51/704]	Time 0.123	Data 0.003	Loss 5.89	Acc@1 56.2	Acc@5 87.5
Epoch: [69][61/704]	Time 0.123	Data 0.003	Loss 5.20	Acc@1 60.9	Acc@5 92.2
Epoch: [69][71/704]	Time 0.123	Data 0.002	Loss 5.04	Acc@1 67.2	Acc@5 95.3
Epoch: [69][81/704]	Time 0.123	Data 0.002	Loss 7.00	Acc@1 50.0	Acc@5 90.6
Epoch: [69][91/704]	Time 0.122	Data 0.002	Loss 4.98	Acc@1 68.8	Acc@5 89.1
Epoch: [69][101/704]	Time 0.122	Data 0.002	Loss 6.75	Acc@1 65.6	Acc@5 84.4
Epoch: [69][111/704]	Time 0.122	Data 0.002	Loss 5.09	Acc@1 65.6	Acc@5 92.2
Epoch: [69][121/704]	Time 0.122	Data 0.001	Loss 4.96	Acc@1 73.4	Acc@5 85.9
Epoch: [69][131/704]	Time 0.122	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 95.3
Epoch: [69][141/704]	Time 0.121	Data 0.001	Loss 4.01	Acc@1 75.0	Acc@5 96.9
Epoch: [69][151/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 67.2	Acc@5 90.6
Epoch: [69][161/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 90.6
Epoch: [69][171/704]	Time 0.121	Data 0.001	Loss 6.63	Acc@1 54.7	Acc@5 87.5
Epoch: [69][181/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 70.3	Acc@5 89.1
Epoch: [69][191/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 65.6	Acc@5 85.9
Epoch: [69][201/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 62.5	Acc@5 92.2
Epoch: [69][211/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 73.4	Acc@5 90.6
Epoch: [69][221/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 67.2	Acc@5 95.3
Epoch: [69][231/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 71.9	Acc@5 92.2
Epoch: [69][241/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 64.1	Acc@5 90.6
Epoch: [69][251/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 65.6	Acc@5 93.8
Epoch: [69][261/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 65.6	Acc@5 90.6
Epoch: [69][271/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 65.6	Acc@5 92.2
Epoch: [69][281/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 70.3	Acc@5 93.8
Epoch: [69][291/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 60.9	Acc@5 89.1
Epoch: [69][301/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 93.8
Epoch: [69][311/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 71.9	Acc@5 92.2
Epoch: [69][321/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 65.6	Acc@5 89.1
Epoch: [69][331/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 68.8	Acc@5 89.1
Epoch: [69][341/704]	Time 0.120	Data 0.001	Loss 6.49	Acc@1 68.8	Acc@5 90.6
Epoch: [69][351/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 68.8	Acc@5 89.1
Epoch: [69][361/704]	Time 0.120	Data 0.001	Loss 6.50	Acc@1 59.4	Acc@5 89.1
Epoch: [69][371/704]	Time 0.120	Data 0.001	Loss 4.68	Acc@1 70.3	Acc@5 93.8
Epoch: [69][381/704]	Time 0.120	Data 0.001	Loss 5.06	Acc@1 67.2	Acc@5 92.2
Epoch: [69][391/704]	Time 0.120	Data 0.001	Loss 4.64	Acc@1 67.2	Acc@5 90.6
Epoch: [69][401/704]	Time 0.120	Data 0.001	Loss 6.35	Acc@1 64.1	Acc@5 87.5
Epoch: [69][411/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 68.8	Acc@5 90.6
Epoch: [69][421/704]	Time 0.120	Data 0.001	Loss 5.06	Acc@1 71.9	Acc@5 92.2
Epoch: [69][431/704]	Time 0.120	Data 0.001	Loss 5.06	Acc@1 60.9	Acc@5 85.9
Epoch: [69][441/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 62.5	Acc@5 89.1
Epoch: [69][451/704]	Time 0.120	Data 0.001	Loss 3.94	Acc@1 78.1	Acc@5 98.4
Epoch: [69][461/704]	Time 0.120	Data 0.001	Loss 4.66	Acc@1 73.4	Acc@5 92.2
Epoch: [69][471/704]	Time 0.120	Data 0.001	Loss 4.47	Acc@1 70.3	Acc@5 92.2
Epoch: [69][481/704]	Time 0.120	Data 0.001	Loss 5.59	Acc@1 73.4	Acc@5 92.2
Epoch: [69][491/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 65.6	Acc@5 95.3
Epoch: [69][501/704]	Time 0.120	Data 0.001	Loss 5.45	Acc@1 67.2	Acc@5 93.8
Epoch: [69][511/704]	Time 0.120	Data 0.001	Loss 5.97	Acc@1 64.1	Acc@5 87.5
Epoch: [69][521/704]	Time 0.120	Data 0.001	Loss 4.60	Acc@1 73.4	Acc@5 95.3
Epoch: [69][531/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 73.4	Acc@5 89.1
Epoch: [69][541/704]	Time 0.120	Data 0.001	Loss 4.41	Acc@1 78.1	Acc@5 92.2
Epoch: [69][551/704]	Time 0.120	Data 0.001	Loss 6.35	Acc@1 62.5	Acc@5 87.5
Epoch: [69][561/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 90.6
Epoch: [69][571/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 64.1	Acc@5 93.8
Epoch: [69][581/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 67.2	Acc@5 89.1
Epoch: [69][591/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 87.5
Epoch: [69][601/704]	Time 0.120	Data 0.001	Loss 4.65	Acc@1 75.0	Acc@5 93.8
Epoch: [69][611/704]	Time 0.120	Data 0.001	Loss 6.25	Acc@1 57.8	Acc@5 82.8
Epoch: [69][621/704]	Time 0.120	Data 0.001	Loss 4.88	Acc@1 67.2	Acc@5 92.2
Epoch: [69][631/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 57.8	Acc@5 92.2
Epoch: [69][641/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 60.9	Acc@5 85.9
Epoch: [69][651/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 68.8	Acc@5 96.9
Epoch: [69][661/704]	Time 0.120	Data 0.001	Loss 5.89	Acc@1 56.2	Acc@5 90.6
Epoch: [69][671/704]	Time 0.120	Data 0.001	Loss 5.10	Acc@1 79.7	Acc@5 93.8
Epoch: [69][681/704]	Time 0.120	Data 0.001	Loss 5.89	Acc@1 64.1	Acc@5 89.1
Epoch: [69][691/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 75.0	Acc@5 89.1
Epoch: [69][701/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 67.2	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.5119	Acc@1 51.5625	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.9813	Acc@1 50.0000	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0300	Acc@1 62.5000	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3991	Acc@1 60.9375	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.3485	Acc@1 53.1250	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.3560	Acc@1 64.0625	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.6278	Acc@1 51.5625	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.4549	Acc@1 51.5625	Acc@5 76.5625
 * prec@1 46.200 prec@5 77.340
 * prec@1 50.760 prec@5 82.220
 * prec@1 54.980 prec@5 84.160
 * prec@1 57.800 prec@5 85.520
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_069.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_069.pth.tar'
Epoch: [70][1/704]	Time 0.331	Data 0.165	Loss 4.53	Acc@1 71.9	Acc@5 93.8
Epoch: [70][11/704]	Time 0.139	Data 0.015	Loss 5.62	Acc@1 65.6	Acc@5 93.8
Epoch: [70][21/704]	Time 0.130	Data 0.008	Loss 4.45	Acc@1 71.9	Acc@5 95.3
Epoch: [70][31/704]	Time 0.127	Data 0.006	Loss 5.56	Acc@1 65.6	Acc@5 92.2
Epoch: [70][41/704]	Time 0.125	Data 0.004	Loss 5.81	Acc@1 68.8	Acc@5 85.9
Epoch: [70][51/704]	Time 0.124	Data 0.004	Loss 4.95	Acc@1 71.9	Acc@5 95.3
Epoch: [70][61/704]	Time 0.123	Data 0.003	Loss 5.40	Acc@1 75.0	Acc@5 87.5
Epoch: [70][71/704]	Time 0.123	Data 0.003	Loss 4.47	Acc@1 78.1	Acc@5 93.8
Epoch: [70][81/704]	Time 0.123	Data 0.002	Loss 4.93	Acc@1 68.8	Acc@5 96.9
Epoch: [70][91/704]	Time 0.122	Data 0.002	Loss 5.26	Acc@1 68.8	Acc@5 92.2
Epoch: [70][101/704]	Time 0.122	Data 0.002	Loss 4.46	Acc@1 68.8	Acc@5 92.2
Epoch: [70][111/704]	Time 0.122	Data 0.002	Loss 6.39	Acc@1 56.2	Acc@5 87.5
Epoch: [70][121/704]	Time 0.122	Data 0.002	Loss 4.73	Acc@1 75.0	Acc@5 92.2
Epoch: [70][131/704]	Time 0.122	Data 0.002	Loss 4.92	Acc@1 62.5	Acc@5 93.8
Epoch: [70][141/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 75.0	Acc@5 95.3
Epoch: [70][151/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 68.8	Acc@5 92.2
Epoch: [70][161/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 71.9	Acc@5 92.2
Epoch: [70][171/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 76.6	Acc@5 92.2
Epoch: [70][181/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 65.6	Acc@5 93.8
Epoch: [70][191/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 76.6	Acc@5 93.8
Epoch: [70][201/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 71.9	Acc@5 95.3
Epoch: [70][211/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 73.4	Acc@5 95.3
Epoch: [70][221/704]	Time 0.121	Data 0.001	Loss 3.71	Acc@1 75.0	Acc@5 96.9
Epoch: [70][231/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 64.1	Acc@5 93.8
Epoch: [70][241/704]	Time 0.121	Data 0.001	Loss 3.79	Acc@1 76.6	Acc@5 93.8
Epoch: [70][251/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 79.7	Acc@5 96.9
Epoch: [70][261/704]	Time 0.121	Data 0.001	Loss 3.74	Acc@1 81.2	Acc@5 98.4
Epoch: [70][271/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 62.5	Acc@5 95.3
Epoch: [70][281/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 76.6	Acc@5 95.3
Epoch: [70][291/704]	Time 0.121	Data 0.001	Loss 6.81	Acc@1 54.7	Acc@5 87.5
Epoch: [70][301/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 62.5	Acc@5 89.1
Epoch: [70][311/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 67.2	Acc@5 95.3
Epoch: [70][321/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 67.2	Acc@5 93.8
Epoch: [70][331/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 75.0	Acc@5 96.9
Epoch: [70][341/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 68.8	Acc@5 95.3
Epoch: [70][351/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 56.2	Acc@5 92.2
Epoch: [70][361/704]	Time 0.121	Data 0.001	Loss 3.71	Acc@1 76.6	Acc@5 96.9
Epoch: [70][371/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 71.9	Acc@5 93.8
Epoch: [70][381/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 73.4	Acc@5 96.9
Epoch: [70][391/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 70.3	Acc@5 90.6
Epoch: [70][401/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 56.2	Acc@5 93.8
Epoch: [70][411/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 71.9	Acc@5 95.3
Epoch: [70][421/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 68.8	Acc@5 93.8
Epoch: [70][431/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 59.4	Acc@5 92.2
Epoch: [70][441/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 59.4	Acc@5 92.2
Epoch: [70][451/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 71.9	Acc@5 93.8
Epoch: [70][461/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 65.6	Acc@5 90.6
Epoch: [70][471/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 71.9	Acc@5 93.8
Epoch: [70][481/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 65.6	Acc@5 90.6
Epoch: [70][491/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 73.4	Acc@5 93.8
Epoch: [70][501/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 60.9	Acc@5 92.2
Epoch: [70][511/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 59.4	Acc@5 87.5
Epoch: [70][521/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 71.9	Acc@5 96.9
Epoch: [70][531/704]	Time 0.120	Data 0.001	Loss 4.67	Acc@1 70.3	Acc@5 93.8
Epoch: [70][541/704]	Time 0.120	Data 0.001	Loss 4.99	Acc@1 71.9	Acc@5 93.8
Epoch: [70][551/704]	Time 0.120	Data 0.001	Loss 6.12	Acc@1 71.9	Acc@5 89.1
Epoch: [70][561/704]	Time 0.120	Data 0.001	Loss 5.42	Acc@1 60.9	Acc@5 89.1
Epoch: [70][571/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 62.5	Acc@5 92.2
Epoch: [70][581/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 60.9	Acc@5 92.2
Epoch: [70][591/704]	Time 0.120	Data 0.001	Loss 4.89	Acc@1 71.9	Acc@5 96.9
Epoch: [70][601/704]	Time 0.120	Data 0.001	Loss 4.97	Acc@1 68.8	Acc@5 92.2
Epoch: [70][611/704]	Time 0.120	Data 0.001	Loss 5.63	Acc@1 57.8	Acc@5 87.5
Epoch: [70][621/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 60.9	Acc@5 90.6
Epoch: [70][631/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 67.2	Acc@5 98.4
Epoch: [70][641/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 64.1	Acc@5 85.9
Epoch: [70][651/704]	Time 0.120	Data 0.001	Loss 5.88	Acc@1 71.9	Acc@5 87.5
Epoch: [70][661/704]	Time 0.120	Data 0.001	Loss 6.42	Acc@1 59.4	Acc@5 89.1
Epoch: [70][671/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 62.5	Acc@5 90.6
Epoch: [70][681/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 62.5	Acc@5 89.1
Epoch: [70][691/704]	Time 0.120	Data 0.001	Loss 7.03	Acc@1 56.2	Acc@5 89.1
Epoch: [70][701/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 60.9	Acc@5 89.1
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.4002	Acc@1 64.0625	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.8152	Acc@1 51.5625	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.5579	Acc@1 56.2500	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.5660	Acc@1 67.1875	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3158	Acc@1 59.3750	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.6728	Acc@1 48.4375	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4515	Acc@1 53.1250	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.5168	Acc@1 50.0000	Acc@5 75.0000
 * prec@1 46.340 prec@5 77.680
 * prec@1 51.200 prec@5 81.880
 * prec@1 55.360 prec@5 84.800
 * prec@1 56.660 prec@5 84.720
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_070.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_070.pth.tar'
Epoch: [71][1/704]	Time 0.334	Data 0.168	Loss 5.55	Acc@1 57.8	Acc@5 93.8
Epoch: [71][11/704]	Time 0.140	Data 0.015	Loss 5.65	Acc@1 65.6	Acc@5 93.8
Epoch: [71][21/704]	Time 0.130	Data 0.008	Loss 5.49	Acc@1 67.2	Acc@5 92.2
Epoch: [71][31/704]	Time 0.127	Data 0.006	Loss 6.27	Acc@1 62.5	Acc@5 82.8
Epoch: [71][41/704]	Time 0.125	Data 0.004	Loss 5.91	Acc@1 60.9	Acc@5 93.8
Epoch: [71][51/704]	Time 0.124	Data 0.004	Loss 5.14	Acc@1 71.9	Acc@5 92.2
Epoch: [71][61/704]	Time 0.124	Data 0.003	Loss 5.23	Acc@1 64.1	Acc@5 93.8
Epoch: [71][71/704]	Time 0.123	Data 0.003	Loss 4.89	Acc@1 67.2	Acc@5 93.8
Epoch: [71][81/704]	Time 0.123	Data 0.002	Loss 4.56	Acc@1 68.8	Acc@5 95.3
Epoch: [71][91/704]	Time 0.122	Data 0.002	Loss 5.78	Acc@1 65.6	Acc@5 85.9
Epoch: [71][101/704]	Time 0.122	Data 0.002	Loss 5.16	Acc@1 68.8	Acc@5 90.6
Epoch: [71][111/704]	Time 0.122	Data 0.002	Loss 5.66	Acc@1 62.5	Acc@5 92.2
Epoch: [71][121/704]	Time 0.122	Data 0.002	Loss 5.74	Acc@1 67.2	Acc@5 95.3
Epoch: [71][131/704]	Time 0.122	Data 0.002	Loss 5.75	Acc@1 64.1	Acc@5 93.8
Epoch: [71][141/704]	Time 0.122	Data 0.002	Loss 5.61	Acc@1 60.9	Acc@5 87.5
Epoch: [71][151/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 71.9	Acc@5 89.1
Epoch: [71][161/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 68.8	Acc@5 93.8
Epoch: [71][171/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 78.1	Acc@5 95.3
Epoch: [71][181/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 90.6
Epoch: [71][191/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 67.2	Acc@5 95.3
Epoch: [71][201/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 68.8	Acc@5 85.9
Epoch: [71][211/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 64.1	Acc@5 90.6
Epoch: [71][221/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 64.1	Acc@5 95.3
Epoch: [71][231/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 76.6	Acc@5 93.8
Epoch: [71][241/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 70.3	Acc@5 92.2
Epoch: [71][251/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 65.6	Acc@5 93.8
Epoch: [71][261/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 62.5	Acc@5 93.8
Epoch: [71][271/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 70.3	Acc@5 90.6
Epoch: [71][281/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 57.8	Acc@5 87.5
Epoch: [71][291/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 70.3	Acc@5 96.9
Epoch: [71][301/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 70.3	Acc@5 95.3
Epoch: [71][311/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 73.4	Acc@5 93.8
Epoch: [71][321/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 65.6	Acc@5 89.1
Epoch: [71][331/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 71.9	Acc@5 92.2
Epoch: [71][341/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 76.6	Acc@5 100.0
Epoch: [71][351/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 76.6	Acc@5 89.1
Epoch: [71][361/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 67.2	Acc@5 90.6
Epoch: [71][371/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 70.3	Acc@5 87.5
Epoch: [71][381/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 79.7	Acc@5 100.0
Epoch: [71][391/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 76.6	Acc@5 92.2
Epoch: [71][401/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 68.8	Acc@5 90.6
Epoch: [71][411/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 70.3	Acc@5 96.9
Epoch: [71][421/704]	Time 0.121	Data 0.001	Loss 4.28	Acc@1 70.3	Acc@5 93.8
Epoch: [71][431/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 56.2	Acc@5 87.5
Epoch: [71][441/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 59.4	Acc@5 89.1
Epoch: [71][451/704]	Time 0.121	Data 0.001	Loss 6.54	Acc@1 51.6	Acc@5 85.9
Epoch: [71][461/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 75.0	Acc@5 89.1
Epoch: [71][471/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 67.2	Acc@5 85.9
Epoch: [71][481/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 62.5	Acc@5 90.6
Epoch: [71][491/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 60.9	Acc@5 93.8
Epoch: [71][501/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 67.2	Acc@5 90.6
Epoch: [71][511/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 71.9	Acc@5 93.8
Epoch: [71][521/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 65.6	Acc@5 90.6
Epoch: [71][531/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 68.8	Acc@5 85.9
Epoch: [71][541/704]	Time 0.120	Data 0.001	Loss 4.37	Acc@1 71.9	Acc@5 93.8
Epoch: [71][551/704]	Time 0.120	Data 0.001	Loss 4.59	Acc@1 71.9	Acc@5 95.3
Epoch: [71][561/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 62.5	Acc@5 87.5
Epoch: [71][571/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 70.3	Acc@5 89.1
Epoch: [71][581/704]	Time 0.120	Data 0.001	Loss 4.86	Acc@1 68.8	Acc@5 92.2
Epoch: [71][591/704]	Time 0.120	Data 0.001	Loss 6.34	Acc@1 67.2	Acc@5 87.5
Epoch: [71][601/704]	Time 0.120	Data 0.001	Loss 5.96	Acc@1 67.2	Acc@5 96.9
Epoch: [71][611/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 62.5	Acc@5 92.2
Epoch: [71][621/704]	Time 0.120	Data 0.001	Loss 4.47	Acc@1 75.0	Acc@5 93.8
Epoch: [71][631/704]	Time 0.120	Data 0.001	Loss 5.06	Acc@1 71.9	Acc@5 92.2
Epoch: [71][641/704]	Time 0.120	Data 0.001	Loss 5.59	Acc@1 62.5	Acc@5 89.1
Epoch: [71][651/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 64.1	Acc@5 90.6
Epoch: [71][661/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 62.5	Acc@5 90.6
Epoch: [71][671/704]	Time 0.120	Data 0.001	Loss 6.30	Acc@1 60.9	Acc@5 92.2
Epoch: [71][681/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 78.1	Acc@5 95.3
Epoch: [71][691/704]	Time 0.120	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 89.1
Epoch: [71][701/704]	Time 0.120	Data 0.001	Loss 5.42	Acc@1 71.9	Acc@5 89.1
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.6371	Acc@1 59.3750	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.2806	Acc@1 54.6875	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.5671	Acc@1 50.0000	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6356	Acc@1 65.6250	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.0845	Acc@1 45.3125	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7252	Acc@1 48.4375	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.3036	Acc@1 53.1250	Acc@5 79.6875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.8606	Acc@1 70.3125	Acc@5 82.8125
 * prec@1 48.640 prec@5 78.960
 * prec@1 52.020 prec@5 81.960
 * prec@1 56.380 prec@5 84.980
 * prec@1 57.160 prec@5 85.120
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_071.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_071.pth.tar'
Epoch: [72][1/704]	Time 0.299	Data 0.132	Loss 5.14	Acc@1 60.9	Acc@5 93.8
Epoch: [72][11/704]	Time 0.136	Data 0.012	Loss 5.12	Acc@1 68.8	Acc@5 92.2
Epoch: [72][21/704]	Time 0.129	Data 0.007	Loss 4.91	Acc@1 71.9	Acc@5 93.8
Epoch: [72][31/704]	Time 0.126	Data 0.005	Loss 5.15	Acc@1 76.6	Acc@5 93.8
Epoch: [72][41/704]	Time 0.124	Data 0.004	Loss 4.87	Acc@1 64.1	Acc@5 95.3
Epoch: [72][51/704]	Time 0.123	Data 0.003	Loss 5.72	Acc@1 71.9	Acc@5 89.1
Epoch: [72][61/704]	Time 0.123	Data 0.003	Loss 7.03	Acc@1 54.7	Acc@5 89.1
Epoch: [72][71/704]	Time 0.122	Data 0.002	Loss 3.81	Acc@1 75.0	Acc@5 93.8
Epoch: [72][81/704]	Time 0.122	Data 0.002	Loss 5.17	Acc@1 65.6	Acc@5 93.8
Epoch: [72][91/704]	Time 0.122	Data 0.002	Loss 4.79	Acc@1 68.8	Acc@5 95.3
Epoch: [72][101/704]	Time 0.122	Data 0.002	Loss 7.15	Acc@1 56.2	Acc@5 84.4
Epoch: [72][111/704]	Time 0.122	Data 0.002	Loss 4.18	Acc@1 68.8	Acc@5 98.4
Epoch: [72][121/704]	Time 0.122	Data 0.001	Loss 5.15	Acc@1 71.9	Acc@5 90.6
Epoch: [72][131/704]	Time 0.122	Data 0.001	Loss 5.75	Acc@1 64.1	Acc@5 82.8
Epoch: [72][141/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 81.2	Acc@5 98.4
Epoch: [72][151/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 71.9	Acc@5 90.6
Epoch: [72][161/704]	Time 0.121	Data 0.001	Loss 4.01	Acc@1 73.4	Acc@5 93.8
Epoch: [72][171/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 65.6	Acc@5 95.3
Epoch: [72][181/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 79.7	Acc@5 93.8
Epoch: [72][191/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 75.0	Acc@5 90.6
Epoch: [72][201/704]	Time 0.121	Data 0.001	Loss 6.81	Acc@1 60.9	Acc@5 89.1
Epoch: [72][211/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 73.4	Acc@5 92.2
Epoch: [72][221/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 92.2
Epoch: [72][231/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 65.6	Acc@5 98.4
Epoch: [72][241/704]	Time 0.121	Data 0.001	Loss 3.77	Acc@1 75.0	Acc@5 100.0
Epoch: [72][251/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 75.0	Acc@5 87.5
Epoch: [72][261/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 73.4	Acc@5 96.9
Epoch: [72][271/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 70.3	Acc@5 90.6
Epoch: [72][281/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 65.6	Acc@5 93.8
Epoch: [72][291/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 90.6
Epoch: [72][301/704]	Time 0.121	Data 0.001	Loss 7.19	Acc@1 56.2	Acc@5 81.2
Epoch: [72][311/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 67.2	Acc@5 90.6
Epoch: [72][321/704]	Time 0.121	Data 0.001	Loss 6.69	Acc@1 60.9	Acc@5 89.1
Epoch: [72][331/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 75.0	Acc@5 98.4
Epoch: [72][341/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 81.2	Acc@5 93.8
Epoch: [72][351/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 64.1	Acc@5 89.1
Epoch: [72][361/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 65.6	Acc@5 89.1
Epoch: [72][371/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 68.8	Acc@5 95.3
Epoch: [72][381/704]	Time 0.120	Data 0.001	Loss 5.40	Acc@1 68.8	Acc@5 92.2
Epoch: [72][391/704]	Time 0.120	Data 0.001	Loss 4.53	Acc@1 78.1	Acc@5 93.8
Epoch: [72][401/704]	Time 0.120	Data 0.001	Loss 5.35	Acc@1 70.3	Acc@5 93.8
Epoch: [72][411/704]	Time 0.120	Data 0.001	Loss 4.96	Acc@1 75.0	Acc@5 93.8
Epoch: [72][421/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 75.0	Acc@5 90.6
Epoch: [72][431/704]	Time 0.120	Data 0.001	Loss 5.11	Acc@1 70.3	Acc@5 93.8
Epoch: [72][441/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 68.8	Acc@5 93.8
Epoch: [72][451/704]	Time 0.120	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 90.6
Epoch: [72][461/704]	Time 0.120	Data 0.001	Loss 5.39	Acc@1 68.8	Acc@5 92.2
Epoch: [72][471/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 64.1	Acc@5 85.9
Epoch: [72][481/704]	Time 0.120	Data 0.001	Loss 4.79	Acc@1 65.6	Acc@5 96.9
Epoch: [72][491/704]	Time 0.120	Data 0.001	Loss 4.94	Acc@1 78.1	Acc@5 93.8
Epoch: [72][501/704]	Time 0.120	Data 0.001	Loss 4.14	Acc@1 73.4	Acc@5 96.9
Epoch: [72][511/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 67.2	Acc@5 93.8
Epoch: [72][521/704]	Time 0.120	Data 0.001	Loss 4.72	Acc@1 68.8	Acc@5 95.3
Epoch: [72][531/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 68.8	Acc@5 93.8
Epoch: [72][541/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 71.9	Acc@5 93.8
Epoch: [72][551/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 64.1	Acc@5 95.3
Epoch: [72][561/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 65.6	Acc@5 89.1
Epoch: [72][571/704]	Time 0.120	Data 0.001	Loss 7.01	Acc@1 56.2	Acc@5 87.5
Epoch: [72][581/704]	Time 0.120	Data 0.001	Loss 4.75	Acc@1 68.8	Acc@5 92.2
Epoch: [72][591/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 67.2	Acc@5 93.8
Epoch: [72][601/704]	Time 0.120	Data 0.001	Loss 6.12	Acc@1 56.2	Acc@5 93.8
Epoch: [72][611/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 65.6	Acc@5 98.4
Epoch: [72][621/704]	Time 0.120	Data 0.001	Loss 5.65	Acc@1 59.4	Acc@5 93.8
Epoch: [72][631/704]	Time 0.120	Data 0.001	Loss 4.89	Acc@1 64.1	Acc@5 92.2
Epoch: [72][641/704]	Time 0.120	Data 0.001	Loss 6.80	Acc@1 56.2	Acc@5 82.8
Epoch: [72][651/704]	Time 0.120	Data 0.001	Loss 4.97	Acc@1 76.6	Acc@5 93.8
Epoch: [72][661/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 68.8	Acc@5 95.3
Epoch: [72][671/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 64.1	Acc@5 85.9
Epoch: [72][681/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 93.8
Epoch: [72][691/704]	Time 0.120	Data 0.001	Loss 4.97	Acc@1 67.2	Acc@5 92.2
Epoch: [72][701/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 60.9	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 5.7251	Acc@1 65.6250	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.2987	Acc@1 62.5000	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 9.3474	Acc@1 39.0625	Acc@5 73.4375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0011	Acc@1 56.2500	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3273	Acc@1 56.2500	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9498	Acc@1 51.5625	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.4567	Acc@1 56.2500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.4012	Acc@1 62.5000	Acc@5 89.0625
 * prec@1 47.100 prec@5 77.840
 * prec@1 51.260 prec@5 80.540
 * prec@1 53.940 prec@5 83.680
 * prec@1 56.140 prec@5 84.400
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_072.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_072.pth.tar'
Epoch: [73][1/704]	Time 0.303	Data 0.134	Loss 6.16	Acc@1 57.8	Acc@5 92.2
Epoch: [73][11/704]	Time 0.141	Data 0.013	Loss 5.43	Acc@1 59.4	Acc@5 90.6
Epoch: [73][21/704]	Time 0.131	Data 0.007	Loss 5.13	Acc@1 67.2	Acc@5 89.1
Epoch: [73][31/704]	Time 0.127	Data 0.005	Loss 5.33	Acc@1 64.1	Acc@5 92.2
Epoch: [73][41/704]	Time 0.126	Data 0.004	Loss 4.82	Acc@1 71.9	Acc@5 93.8
Epoch: [73][51/704]	Time 0.124	Data 0.003	Loss 5.08	Acc@1 68.8	Acc@5 93.8
Epoch: [73][61/704]	Time 0.124	Data 0.003	Loss 5.41	Acc@1 60.9	Acc@5 93.8
Epoch: [73][71/704]	Time 0.123	Data 0.002	Loss 5.05	Acc@1 62.5	Acc@5 93.8
Epoch: [73][81/704]	Time 0.123	Data 0.002	Loss 4.27	Acc@1 76.6	Acc@5 93.8
Epoch: [73][91/704]	Time 0.123	Data 0.002	Loss 5.76	Acc@1 67.2	Acc@5 93.8
Epoch: [73][101/704]	Time 0.122	Data 0.002	Loss 4.38	Acc@1 73.4	Acc@5 96.9
Epoch: [73][111/704]	Time 0.122	Data 0.001	Loss 5.42	Acc@1 60.9	Acc@5 92.2
Epoch: [73][121/704]	Time 0.122	Data 0.001	Loss 4.65	Acc@1 73.4	Acc@5 95.3
Epoch: [73][131/704]	Time 0.122	Data 0.001	Loss 5.06	Acc@1 70.3	Acc@5 96.9
Epoch: [73][141/704]	Time 0.122	Data 0.001	Loss 5.89	Acc@1 57.8	Acc@5 92.2
Epoch: [73][151/704]	Time 0.122	Data 0.001	Loss 6.81	Acc@1 60.9	Acc@5 78.1
Epoch: [73][161/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 93.8
Epoch: [73][171/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 64.1	Acc@5 95.3
Epoch: [73][181/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 73.4	Acc@5 89.1
Epoch: [73][191/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 60.9	Acc@5 90.6
Epoch: [73][201/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 67.2	Acc@5 93.8
Epoch: [73][211/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 71.9	Acc@5 92.2
Epoch: [73][221/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 71.9	Acc@5 89.1
Epoch: [73][231/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 73.4	Acc@5 92.2
Epoch: [73][241/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 73.4	Acc@5 93.8
Epoch: [73][251/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 68.8	Acc@5 93.8
Epoch: [73][261/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 76.6	Acc@5 93.8
Epoch: [73][271/704]	Time 0.121	Data 0.001	Loss 6.60	Acc@1 56.2	Acc@5 87.5
Epoch: [73][281/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 56.2	Acc@5 93.8
Epoch: [73][291/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 59.4	Acc@5 93.8
Epoch: [73][301/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 96.9
Epoch: [73][311/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 65.6	Acc@5 93.8
Epoch: [73][321/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 67.2	Acc@5 95.3
Epoch: [73][331/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 70.3	Acc@5 93.8
Epoch: [73][341/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 65.6	Acc@5 89.1
Epoch: [73][351/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 92.2
Epoch: [73][361/704]	Time 0.121	Data 0.001	Loss 3.35	Acc@1 81.2	Acc@5 98.4
Epoch: [73][371/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 73.4	Acc@5 92.2
Epoch: [73][381/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 76.6	Acc@5 98.4
Epoch: [73][391/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 71.9	Acc@5 89.1
Epoch: [73][401/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 68.8	Acc@5 93.8
Epoch: [73][411/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 65.6	Acc@5 95.3
Epoch: [73][421/704]	Time 0.121	Data 0.001	Loss 6.36	Acc@1 51.6	Acc@5 87.5
Epoch: [73][431/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 59.4	Acc@5 90.6
Epoch: [73][441/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 67.2	Acc@5 89.1
Epoch: [73][451/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 60.9	Acc@5 100.0
Epoch: [73][461/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 67.2	Acc@5 95.3
Epoch: [73][471/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 73.4	Acc@5 92.2
Epoch: [73][481/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 64.1	Acc@5 92.2
Epoch: [73][491/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 93.8
Epoch: [73][501/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 73.4	Acc@5 92.2
Epoch: [73][511/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 68.8	Acc@5 96.9
Epoch: [73][521/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 70.3	Acc@5 96.9
Epoch: [73][531/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 60.9	Acc@5 85.9
Epoch: [73][541/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 71.9	Acc@5 92.2
Epoch: [73][551/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 71.9	Acc@5 89.1
Epoch: [73][561/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 68.8	Acc@5 90.6
Epoch: [73][571/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 65.6	Acc@5 96.9
Epoch: [73][581/704]	Time 0.121	Data 0.001	Loss 6.80	Acc@1 60.9	Acc@5 89.1
Epoch: [73][591/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 90.6
Epoch: [73][601/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 70.3	Acc@5 95.3
Epoch: [73][611/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 70.3	Acc@5 92.2
Epoch: [73][621/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 71.9	Acc@5 90.6
Epoch: [73][631/704]	Time 0.120	Data 0.001	Loss 4.96	Acc@1 70.3	Acc@5 95.3
Epoch: [73][641/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 60.9	Acc@5 89.1
Epoch: [73][651/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 64.1	Acc@5 92.2
Epoch: [73][661/704]	Time 0.120	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 93.8
Epoch: [73][671/704]	Time 0.120	Data 0.001	Loss 7.14	Acc@1 59.4	Acc@5 90.6
Epoch: [73][681/704]	Time 0.120	Data 0.001	Loss 5.73	Acc@1 57.8	Acc@5 89.1
Epoch: [73][691/704]	Time 0.120	Data 0.001	Loss 6.11	Acc@1 70.3	Acc@5 87.5
Epoch: [73][701/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 67.2	Acc@5 93.8
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.7274	Acc@1 59.3750	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.3940	Acc@1 56.2500	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8336	Acc@1 62.5000	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4362	Acc@1 54.6875	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4528	Acc@1 54.6875	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1937	Acc@1 59.3750	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.3550	Acc@1 68.7500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.1716	Acc@1 53.1250	Acc@5 82.8125
 * prec@1 48.200 prec@5 78.940
 * prec@1 52.760 prec@5 82.980
 * prec@1 54.640 prec@5 84.520
 * prec@1 57.420 prec@5 85.620
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_073.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_073.pth.tar'
Epoch: [74][1/704]	Time 0.330	Data 0.164	Loss 4.83	Acc@1 70.3	Acc@5 90.6
Epoch: [74][11/704]	Time 0.139	Data 0.015	Loss 7.20	Acc@1 53.1	Acc@5 89.1
Epoch: [74][21/704]	Time 0.130	Data 0.008	Loss 5.24	Acc@1 68.8	Acc@5 90.6
Epoch: [74][31/704]	Time 0.127	Data 0.006	Loss 5.00	Acc@1 71.9	Acc@5 92.2
Epoch: [74][41/704]	Time 0.125	Data 0.004	Loss 4.37	Acc@1 70.3	Acc@5 96.9
Epoch: [74][51/704]	Time 0.124	Data 0.004	Loss 5.23	Acc@1 67.2	Acc@5 89.1
Epoch: [74][61/704]	Time 0.123	Data 0.003	Loss 4.32	Acc@1 78.1	Acc@5 96.9
Epoch: [74][71/704]	Time 0.123	Data 0.003	Loss 6.43	Acc@1 57.8	Acc@5 87.5
Epoch: [74][81/704]	Time 0.123	Data 0.002	Loss 4.63	Acc@1 68.8	Acc@5 93.8
Epoch: [74][91/704]	Time 0.122	Data 0.002	Loss 5.19	Acc@1 64.1	Acc@5 93.8
Epoch: [74][101/704]	Time 0.122	Data 0.002	Loss 5.00	Acc@1 71.9	Acc@5 87.5
Epoch: [74][111/704]	Time 0.122	Data 0.002	Loss 5.79	Acc@1 73.4	Acc@5 87.5
Epoch: [74][121/704]	Time 0.122	Data 0.002	Loss 5.31	Acc@1 73.4	Acc@5 89.1
Epoch: [74][131/704]	Time 0.122	Data 0.002	Loss 6.21	Acc@1 59.4	Acc@5 89.1
Epoch: [74][141/704]	Time 0.121	Data 0.002	Loss 4.04	Acc@1 78.1	Acc@5 93.8
Epoch: [74][151/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 75.0	Acc@5 90.6
Epoch: [74][161/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 62.5	Acc@5 87.5
Epoch: [74][171/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 62.5	Acc@5 87.5
Epoch: [74][181/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 70.3	Acc@5 92.2
Epoch: [74][191/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 75.0	Acc@5 98.4
Epoch: [74][201/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 62.5	Acc@5 87.5
Epoch: [74][211/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 59.4	Acc@5 92.2
Epoch: [74][221/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 70.3	Acc@5 95.3
Epoch: [74][231/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 89.1
Epoch: [74][241/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 62.5	Acc@5 92.2
Epoch: [74][251/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 65.6	Acc@5 90.6
Epoch: [74][261/704]	Time 0.121	Data 0.001	Loss 7.13	Acc@1 56.2	Acc@5 85.9
Epoch: [74][271/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 78.1	Acc@5 96.9
Epoch: [74][281/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 64.1	Acc@5 89.1
Epoch: [74][291/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 59.4	Acc@5 93.8
Epoch: [74][301/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 78.1	Acc@5 92.2
Epoch: [74][311/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 59.4	Acc@5 98.4
Epoch: [74][321/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 95.3
Epoch: [74][331/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 68.8	Acc@5 93.8
Epoch: [74][341/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 62.5	Acc@5 90.6
Epoch: [74][351/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 68.8	Acc@5 87.5
Epoch: [74][361/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 67.2	Acc@5 92.2
Epoch: [74][371/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 60.9	Acc@5 92.2
Epoch: [74][381/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 64.1	Acc@5 90.6
Epoch: [74][391/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 68.8	Acc@5 87.5
Epoch: [74][401/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 76.6	Acc@5 95.3
Epoch: [74][411/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 65.6	Acc@5 85.9
Epoch: [74][421/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 76.6	Acc@5 96.9
Epoch: [74][431/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 71.9	Acc@5 93.8
Epoch: [74][441/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 68.8	Acc@5 93.8
Epoch: [74][451/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 73.4	Acc@5 92.2
Epoch: [74][461/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 68.8	Acc@5 93.8
Epoch: [74][471/704]	Time 0.120	Data 0.001	Loss 4.57	Acc@1 70.3	Acc@5 90.6
Epoch: [74][481/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 64.1	Acc@5 89.1
Epoch: [74][491/704]	Time 0.120	Data 0.001	Loss 4.82	Acc@1 75.0	Acc@5 95.3
Epoch: [74][501/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 68.8	Acc@5 92.2
Epoch: [74][511/704]	Time 0.120	Data 0.001	Loss 4.52	Acc@1 78.1	Acc@5 93.8
Epoch: [74][521/704]	Time 0.120	Data 0.001	Loss 6.47	Acc@1 70.3	Acc@5 90.6
Epoch: [74][531/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 65.6	Acc@5 96.9
Epoch: [74][541/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 65.6	Acc@5 87.5
Epoch: [74][551/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 65.6	Acc@5 90.6
Epoch: [74][561/704]	Time 0.120	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 90.6
Epoch: [74][571/704]	Time 0.120	Data 0.001	Loss 4.99	Acc@1 68.8	Acc@5 90.6
Epoch: [74][581/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 64.1	Acc@5 92.2
Epoch: [74][591/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 62.5	Acc@5 90.6
Epoch: [74][601/704]	Time 0.120	Data 0.001	Loss 4.67	Acc@1 65.6	Acc@5 95.3
Epoch: [74][611/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 70.3	Acc@5 90.6
Epoch: [74][621/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 65.6	Acc@5 89.1
Epoch: [74][631/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 71.9	Acc@5 93.8
Epoch: [74][641/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 64.1	Acc@5 93.8
Epoch: [74][651/704]	Time 0.120	Data 0.001	Loss 6.74	Acc@1 62.5	Acc@5 82.8
Epoch: [74][661/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 67.2	Acc@5 95.3
Epoch: [74][671/704]	Time 0.120	Data 0.001	Loss 4.87	Acc@1 73.4	Acc@5 92.2
Epoch: [74][681/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 64.1	Acc@5 92.2
Epoch: [74][691/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 64.1	Acc@5 87.5
Epoch: [74][701/704]	Time 0.120	Data 0.001	Loss 5.09	Acc@1 70.3	Acc@5 89.1
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.1096	Acc@1 53.1250	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.4920	Acc@1 60.9375	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0625	Acc@1 60.9375	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5704	Acc@1 48.4375	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.8626	Acc@1 45.3125	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.3469	Acc@1 60.9375	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.1938	Acc@1 56.2500	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.1309	Acc@1 56.2500	Acc@5 85.9375
 * prec@1 46.780 prec@5 77.640
 * prec@1 50.780 prec@5 81.160
 * prec@1 54.920 prec@5 84.400
 * prec@1 56.040 prec@5 85.380
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_074.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_074.pth.tar'
Epoch: [75][1/704]	Time 0.300	Data 0.133	Loss 4.83	Acc@1 65.6	Acc@5 93.8
Epoch: [75][11/704]	Time 0.137	Data 0.012	Loss 5.82	Acc@1 62.5	Acc@5 89.1
Epoch: [75][21/704]	Time 0.129	Data 0.007	Loss 4.83	Acc@1 71.9	Acc@5 92.2
Epoch: [75][31/704]	Time 0.126	Data 0.005	Loss 4.70	Acc@1 67.2	Acc@5 95.3
Epoch: [75][41/704]	Time 0.125	Data 0.004	Loss 5.38	Acc@1 59.4	Acc@5 96.9
Epoch: [75][51/704]	Time 0.124	Data 0.003	Loss 5.46	Acc@1 65.6	Acc@5 96.9
Epoch: [75][61/704]	Time 0.123	Data 0.002	Loss 4.63	Acc@1 65.6	Acc@5 95.3
Epoch: [75][71/704]	Time 0.123	Data 0.002	Loss 5.04	Acc@1 76.6	Acc@5 96.9
Epoch: [75][81/704]	Time 0.123	Data 0.002	Loss 5.12	Acc@1 68.8	Acc@5 90.6
Epoch: [75][91/704]	Time 0.122	Data 0.002	Loss 4.49	Acc@1 71.9	Acc@5 96.9
Epoch: [75][101/704]	Time 0.122	Data 0.002	Loss 5.13	Acc@1 60.9	Acc@5 96.9
Epoch: [75][111/704]	Time 0.122	Data 0.002	Loss 5.65	Acc@1 67.2	Acc@5 89.1
Epoch: [75][121/704]	Time 0.122	Data 0.001	Loss 4.60	Acc@1 71.9	Acc@5 95.3
Epoch: [75][131/704]	Time 0.122	Data 0.001	Loss 5.17	Acc@1 65.6	Acc@5 92.2
Epoch: [75][141/704]	Time 0.122	Data 0.001	Loss 5.56	Acc@1 71.9	Acc@5 89.1
Epoch: [75][151/704]	Time 0.122	Data 0.001	Loss 5.27	Acc@1 65.6	Acc@5 92.2
Epoch: [75][161/704]	Time 0.122	Data 0.001	Loss 4.50	Acc@1 71.9	Acc@5 92.2
Epoch: [75][171/704]	Time 0.122	Data 0.001	Loss 5.64	Acc@1 65.6	Acc@5 87.5
Epoch: [75][181/704]	Time 0.122	Data 0.001	Loss 4.61	Acc@1 76.6	Acc@5 96.9
Epoch: [75][191/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 68.8	Acc@5 93.8
Epoch: [75][201/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 73.4	Acc@5 92.2
Epoch: [75][211/704]	Time 0.121	Data 0.001	Loss 7.15	Acc@1 53.1	Acc@5 85.9
Epoch: [75][221/704]	Time 0.121	Data 0.001	Loss 6.38	Acc@1 64.1	Acc@5 87.5
Epoch: [75][231/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 75.0	Acc@5 96.9
Epoch: [75][241/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 68.8	Acc@5 95.3
Epoch: [75][251/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 62.5	Acc@5 85.9
Epoch: [75][261/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 64.1	Acc@5 92.2
Epoch: [75][271/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 53.1	Acc@5 93.8
Epoch: [75][281/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 73.4	Acc@5 92.2
Epoch: [75][291/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 68.8	Acc@5 93.8
Epoch: [75][301/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 71.9	Acc@5 93.8
Epoch: [75][311/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 68.8	Acc@5 92.2
Epoch: [75][321/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 64.1	Acc@5 92.2
Epoch: [75][331/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 73.4	Acc@5 92.2
Epoch: [75][341/704]	Time 0.121	Data 0.001	Loss 4.15	Acc@1 73.4	Acc@5 96.9
Epoch: [75][351/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 64.1	Acc@5 93.8
Epoch: [75][361/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 62.5	Acc@5 95.3
Epoch: [75][371/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 62.5	Acc@5 93.8
Epoch: [75][381/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 67.2	Acc@5 92.2
Epoch: [75][391/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 85.9
Epoch: [75][401/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 64.1	Acc@5 90.6
Epoch: [75][411/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 60.9	Acc@5 92.2
Epoch: [75][421/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 67.2	Acc@5 89.1
Epoch: [75][431/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 67.2	Acc@5 92.2
Epoch: [75][441/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 73.4	Acc@5 90.6
Epoch: [75][451/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 48.4	Acc@5 90.6
Epoch: [75][461/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 67.2	Acc@5 89.1
Epoch: [75][471/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 65.6	Acc@5 90.6
Epoch: [75][481/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 71.9	Acc@5 93.8
Epoch: [75][491/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 73.4	Acc@5 92.2
Epoch: [75][501/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 75.0	Acc@5 92.2
Epoch: [75][511/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 68.8	Acc@5 92.2
Epoch: [75][521/704]	Time 0.121	Data 0.001	Loss 7.47	Acc@1 54.7	Acc@5 84.4
Epoch: [75][531/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 60.9	Acc@5 89.1
Epoch: [75][541/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 78.1	Acc@5 96.9
Epoch: [75][551/704]	Time 0.121	Data 0.001	Loss 7.29	Acc@1 60.9	Acc@5 84.4
Epoch: [75][561/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 68.8	Acc@5 90.6
Epoch: [75][571/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 81.2	Acc@5 93.8
Epoch: [75][581/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 96.9
Epoch: [75][591/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 67.2	Acc@5 85.9
Epoch: [75][601/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 70.3	Acc@5 89.1
Epoch: [75][611/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 60.9	Acc@5 85.9
Epoch: [75][621/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 65.6	Acc@5 89.1
Epoch: [75][631/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 73.4	Acc@5 90.6
Epoch: [75][641/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 81.2	Acc@5 95.3
Epoch: [75][651/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 59.4	Acc@5 92.2
Epoch: [75][661/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 64.1	Acc@5 92.2
Epoch: [75][671/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 92.2
Epoch: [75][681/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 68.8	Acc@5 92.2
Epoch: [75][691/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 65.6	Acc@5 87.5
Epoch: [75][701/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 71.9	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.0566	Acc@1 64.0625	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.3915	Acc@1 51.5625	Acc@5 76.5625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8550	Acc@1 56.2500	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.2214	Acc@1 53.1250	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.4199	Acc@1 65.6250	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2371	Acc@1 60.9375	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4444	Acc@1 64.0625	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 9.3554	Acc@1 50.0000	Acc@5 78.1250
 * prec@1 47.980 prec@5 78.560
 * prec@1 52.980 prec@5 83.440
 * prec@1 57.560 prec@5 85.900
 * prec@1 58.140 prec@5 86.180
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_075.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_075.pth.tar'
Epoch: [76][1/704]	Time 0.299	Data 0.131	Loss 5.24	Acc@1 75.0	Acc@5 93.8
Epoch: [76][11/704]	Time 0.137	Data 0.012	Loss 6.17	Acc@1 62.5	Acc@5 87.5
Epoch: [76][21/704]	Time 0.129	Data 0.007	Loss 4.56	Acc@1 71.9	Acc@5 96.9
Epoch: [76][31/704]	Time 0.127	Data 0.004	Loss 4.97	Acc@1 67.2	Acc@5 93.8
Epoch: [76][41/704]	Time 0.125	Data 0.003	Loss 4.48	Acc@1 64.1	Acc@5 92.2
Epoch: [76][51/704]	Time 0.124	Data 0.003	Loss 4.51	Acc@1 71.9	Acc@5 92.2
Epoch: [76][61/704]	Time 0.124	Data 0.002	Loss 6.34	Acc@1 54.7	Acc@5 89.1
Epoch: [76][71/704]	Time 0.124	Data 0.002	Loss 5.38	Acc@1 70.3	Acc@5 92.2
Epoch: [76][81/704]	Time 0.124	Data 0.002	Loss 5.10	Acc@1 70.3	Acc@5 93.8
Epoch: [76][91/704]	Time 0.123	Data 0.002	Loss 5.29	Acc@1 75.0	Acc@5 92.2
Epoch: [76][101/704]	Time 0.123	Data 0.002	Loss 4.85	Acc@1 67.2	Acc@5 92.2
Epoch: [76][111/704]	Time 0.123	Data 0.002	Loss 5.77	Acc@1 65.6	Acc@5 95.3
Epoch: [76][121/704]	Time 0.123	Data 0.001	Loss 5.44	Acc@1 62.5	Acc@5 93.8
Epoch: [76][131/704]	Time 0.122	Data 0.001	Loss 3.73	Acc@1 76.6	Acc@5 96.9
Epoch: [76][141/704]	Time 0.122	Data 0.001	Loss 5.33	Acc@1 79.7	Acc@5 92.2
Epoch: [76][151/704]	Time 0.122	Data 0.001	Loss 5.67	Acc@1 59.4	Acc@5 87.5
Epoch: [76][161/704]	Time 0.122	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 95.3
Epoch: [76][171/704]	Time 0.122	Data 0.001	Loss 5.53	Acc@1 65.6	Acc@5 93.8
Epoch: [76][181/704]	Time 0.122	Data 0.001	Loss 6.11	Acc@1 62.5	Acc@5 92.2
Epoch: [76][191/704]	Time 0.122	Data 0.001	Loss 5.89	Acc@1 75.0	Acc@5 90.6
Epoch: [76][201/704]	Time 0.122	Data 0.001	Loss 4.82	Acc@1 68.8	Acc@5 90.6
Epoch: [76][211/704]	Time 0.122	Data 0.001	Loss 4.65	Acc@1 75.0	Acc@5 93.8
Epoch: [76][221/704]	Time 0.122	Data 0.001	Loss 6.15	Acc@1 62.5	Acc@5 87.5
Epoch: [76][231/704]	Time 0.122	Data 0.001	Loss 6.09	Acc@1 67.2	Acc@5 90.6
Epoch: [76][241/704]	Time 0.122	Data 0.001	Loss 6.33	Acc@1 62.5	Acc@5 89.1
Epoch: [76][251/704]	Time 0.122	Data 0.001	Loss 4.62	Acc@1 73.4	Acc@5 87.5
Epoch: [76][261/704]	Time 0.122	Data 0.001	Loss 4.46	Acc@1 73.4	Acc@5 95.3
Epoch: [76][271/704]	Time 0.122	Data 0.001	Loss 6.61	Acc@1 64.1	Acc@5 85.9
Epoch: [76][281/704]	Time 0.122	Data 0.001	Loss 5.80	Acc@1 68.8	Acc@5 92.2
Epoch: [76][291/704]	Time 0.122	Data 0.001	Loss 4.17	Acc@1 71.9	Acc@5 96.9
Epoch: [76][301/704]	Time 0.122	Data 0.001	Loss 4.51	Acc@1 73.4	Acc@5 92.2
Epoch: [76][311/704]	Time 0.122	Data 0.001	Loss 5.03	Acc@1 65.6	Acc@5 90.6
Epoch: [76][321/704]	Time 0.122	Data 0.001	Loss 4.74	Acc@1 71.9	Acc@5 95.3
Epoch: [76][331/704]	Time 0.121	Data 0.001	Loss 6.24	Acc@1 60.9	Acc@5 84.4
Epoch: [76][341/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 64.1	Acc@5 95.3
Epoch: [76][351/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 65.6	Acc@5 89.1
Epoch: [76][361/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 90.6
Epoch: [76][371/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 78.1	Acc@5 96.9
Epoch: [76][381/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 67.2	Acc@5 95.3
Epoch: [76][391/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 65.6	Acc@5 92.2
Epoch: [76][401/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 62.5	Acc@5 93.8
Epoch: [76][411/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 71.9	Acc@5 95.3
Epoch: [76][421/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 68.8	Acc@5 95.3
Epoch: [76][431/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 64.1	Acc@5 82.8
Epoch: [76][441/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 75.0	Acc@5 96.9
Epoch: [76][451/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 64.1	Acc@5 89.1
Epoch: [76][461/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 59.4	Acc@5 93.8
Epoch: [76][471/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 67.2	Acc@5 95.3
Epoch: [76][481/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 93.8
Epoch: [76][491/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 76.6	Acc@5 92.2
Epoch: [76][501/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 73.4	Acc@5 93.8
Epoch: [76][511/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 62.5	Acc@5 90.6
Epoch: [76][521/704]	Time 0.121	Data 0.001	Loss 6.56	Acc@1 64.1	Acc@5 85.9
Epoch: [76][531/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 65.6	Acc@5 95.3
Epoch: [76][541/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 73.4	Acc@5 93.8
Epoch: [76][551/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 64.1	Acc@5 87.5
Epoch: [76][561/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 70.3	Acc@5 92.2
Epoch: [76][571/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 75.0	Acc@5 95.3
Epoch: [76][581/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 62.5	Acc@5 92.2
Epoch: [76][591/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 68.8	Acc@5 85.9
Epoch: [76][601/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 70.3	Acc@5 87.5
Epoch: [76][611/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 73.4	Acc@5 87.5
Epoch: [76][621/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 62.5	Acc@5 93.8
Epoch: [76][631/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 60.9	Acc@5 93.8
Epoch: [76][641/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 64.1	Acc@5 93.8
Epoch: [76][651/704]	Time 0.121	Data 0.001	Loss 3.97	Acc@1 67.2	Acc@5 96.9
Epoch: [76][661/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 70.3	Acc@5 90.6
Epoch: [76][671/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 67.2	Acc@5 92.2
Epoch: [76][681/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 68.8	Acc@5 90.6
Epoch: [76][691/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 73.4	Acc@5 95.3
Epoch: [76][701/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 62.5	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5398	Acc@1 64.0625	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.3491	Acc@1 50.0000	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.4333	Acc@1 48.4375	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0274	Acc@1 62.5000	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.4080	Acc@1 40.6250	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 9.1900	Acc@1 50.0000	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.1844	Acc@1 56.2500	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9217	Acc@1 57.8125	Acc@5 82.8125
 * prec@1 47.720 prec@5 77.880
 * prec@1 52.660 prec@5 82.320
 * prec@1 57.580 prec@5 85.340
 * prec@1 56.200 prec@5 85.680
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_076.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_076.pth.tar'
Epoch: [77][1/704]	Time 0.331	Data 0.166	Loss 4.62	Acc@1 68.8	Acc@5 95.3
Epoch: [77][11/704]	Time 0.140	Data 0.015	Loss 4.76	Acc@1 67.2	Acc@5 95.3
Epoch: [77][21/704]	Time 0.130	Data 0.008	Loss 5.68	Acc@1 64.1	Acc@5 90.6
Epoch: [77][31/704]	Time 0.127	Data 0.006	Loss 5.46	Acc@1 71.9	Acc@5 87.5
Epoch: [77][41/704]	Time 0.125	Data 0.004	Loss 5.05	Acc@1 70.3	Acc@5 89.1
Epoch: [77][51/704]	Time 0.124	Data 0.004	Loss 5.21	Acc@1 64.1	Acc@5 92.2
Epoch: [77][61/704]	Time 0.124	Data 0.003	Loss 4.76	Acc@1 81.2	Acc@5 90.6
Epoch: [77][71/704]	Time 0.123	Data 0.003	Loss 4.87	Acc@1 70.3	Acc@5 90.6
Epoch: [77][81/704]	Time 0.123	Data 0.002	Loss 4.34	Acc@1 75.0	Acc@5 93.8
Epoch: [77][91/704]	Time 0.123	Data 0.002	Loss 5.29	Acc@1 62.5	Acc@5 89.1
Epoch: [77][101/704]	Time 0.122	Data 0.002	Loss 5.21	Acc@1 76.6	Acc@5 93.8
Epoch: [77][111/704]	Time 0.122	Data 0.002	Loss 4.88	Acc@1 64.1	Acc@5 96.9
Epoch: [77][121/704]	Time 0.122	Data 0.002	Loss 6.52	Acc@1 59.4	Acc@5 93.8
Epoch: [77][131/704]	Time 0.122	Data 0.002	Loss 5.44	Acc@1 62.5	Acc@5 90.6
Epoch: [77][141/704]	Time 0.122	Data 0.001	Loss 6.33	Acc@1 64.1	Acc@5 93.8
Epoch: [77][151/704]	Time 0.122	Data 0.001	Loss 3.97	Acc@1 78.1	Acc@5 98.4
Epoch: [77][161/704]	Time 0.122	Data 0.001	Loss 4.92	Acc@1 75.0	Acc@5 92.2
Epoch: [77][171/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 68.8	Acc@5 90.6
Epoch: [77][181/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 70.3	Acc@5 95.3
Epoch: [77][191/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 65.6	Acc@5 89.1
Epoch: [77][201/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 93.8
Epoch: [77][211/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 50.0	Acc@5 92.2
Epoch: [77][221/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 65.6	Acc@5 89.1
Epoch: [77][231/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 89.1
Epoch: [77][241/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 67.2	Acc@5 92.2
Epoch: [77][251/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 67.2	Acc@5 95.3
Epoch: [77][261/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 81.2	Acc@5 93.8
Epoch: [77][271/704]	Time 0.121	Data 0.001	Loss 3.91	Acc@1 71.9	Acc@5 96.9
Epoch: [77][281/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 68.8	Acc@5 95.3
Epoch: [77][291/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 71.9	Acc@5 90.6
Epoch: [77][301/704]	Time 0.121	Data 0.001	Loss 6.63	Acc@1 57.8	Acc@5 95.3
Epoch: [77][311/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 65.6	Acc@5 90.6
Epoch: [77][321/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 59.4	Acc@5 92.2
Epoch: [77][331/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 57.8	Acc@5 85.9
Epoch: [77][341/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 75.0	Acc@5 98.4
Epoch: [77][351/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 78.1	Acc@5 98.4
Epoch: [77][361/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 73.4	Acc@5 89.1
Epoch: [77][371/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 65.6	Acc@5 84.4
Epoch: [77][381/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 68.8	Acc@5 93.8
Epoch: [77][391/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 68.8	Acc@5 95.3
Epoch: [77][401/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 90.6
Epoch: [77][411/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 73.4	Acc@5 92.2
Epoch: [77][421/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 67.2	Acc@5 85.9
Epoch: [77][431/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 67.2	Acc@5 92.2
Epoch: [77][441/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 71.9	Acc@5 96.9
Epoch: [77][451/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 60.9	Acc@5 93.8
Epoch: [77][461/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 70.3	Acc@5 90.6
Epoch: [77][471/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 68.8	Acc@5 95.3
Epoch: [77][481/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 59.4	Acc@5 84.4
Epoch: [77][491/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 71.9	Acc@5 93.8
Epoch: [77][501/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 75.0	Acc@5 92.2
Epoch: [77][511/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 65.6	Acc@5 93.8
Epoch: [77][521/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 65.6	Acc@5 95.3
Epoch: [77][531/704]	Time 0.121	Data 0.001	Loss 3.91	Acc@1 76.6	Acc@5 98.4
Epoch: [77][541/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 96.9
Epoch: [77][551/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 62.5	Acc@5 92.2
Epoch: [77][561/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 90.6
Epoch: [77][571/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 70.3	Acc@5 95.3
Epoch: [77][581/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 62.5	Acc@5 93.8
Epoch: [77][591/704]	Time 0.121	Data 0.001	Loss 6.79	Acc@1 57.8	Acc@5 90.6
Epoch: [77][601/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 68.8	Acc@5 87.5
Epoch: [77][611/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 59.4	Acc@5 89.1
Epoch: [77][621/704]	Time 0.121	Data 0.001	Loss 4.28	Acc@1 62.5	Acc@5 96.9
Epoch: [77][631/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 68.8	Acc@5 95.3
Epoch: [77][641/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 81.2	Acc@5 96.9
Epoch: [77][651/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 70.3	Acc@5 95.3
Epoch: [77][661/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 70.3	Acc@5 89.1
Epoch: [77][671/704]	Time 0.121	Data 0.001	Loss 6.59	Acc@1 56.2	Acc@5 87.5
Epoch: [77][681/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 73.4	Acc@5 93.8
Epoch: [77][691/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 68.8	Acc@5 96.9
Epoch: [77][701/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 68.8	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.0279	Acc@1 48.4375	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.1302	Acc@1 53.1250	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5677	Acc@1 65.6250	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3830	Acc@1 64.0625	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.8916	Acc@1 56.2500	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.0668	Acc@1 54.6875	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.7587	Acc@1 46.8750	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.3818	Acc@1 50.0000	Acc@5 85.9375
 * prec@1 48.060 prec@5 78.660
 * prec@1 51.680 prec@5 82.560
 * prec@1 55.040 prec@5 84.760
 * prec@1 56.680 prec@5 86.020
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_077.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_077.pth.tar'
Epoch: [78][1/704]	Time 0.334	Data 0.167	Loss 5.69	Acc@1 67.2	Acc@5 90.6
Epoch: [78][11/704]	Time 0.140	Data 0.016	Loss 5.33	Acc@1 68.8	Acc@5 93.8
Epoch: [78][21/704]	Time 0.131	Data 0.008	Loss 4.76	Acc@1 65.6	Acc@5 95.3
Epoch: [78][31/704]	Time 0.127	Data 0.006	Loss 5.05	Acc@1 64.1	Acc@5 96.9
Epoch: [78][41/704]	Time 0.126	Data 0.004	Loss 4.54	Acc@1 79.7	Acc@5 95.3
Epoch: [78][51/704]	Time 0.124	Data 0.004	Loss 5.01	Acc@1 68.8	Acc@5 95.3
Epoch: [78][61/704]	Time 0.124	Data 0.003	Loss 4.69	Acc@1 65.6	Acc@5 89.1
Epoch: [78][71/704]	Time 0.123	Data 0.003	Loss 4.24	Acc@1 76.6	Acc@5 93.8
Epoch: [78][81/704]	Time 0.123	Data 0.002	Loss 5.42	Acc@1 70.3	Acc@5 87.5
Epoch: [78][91/704]	Time 0.123	Data 0.002	Loss 4.63	Acc@1 75.0	Acc@5 90.6
Epoch: [78][101/704]	Time 0.122	Data 0.002	Loss 5.85	Acc@1 64.1	Acc@5 93.8
Epoch: [78][111/704]	Time 0.122	Data 0.002	Loss 4.77	Acc@1 68.8	Acc@5 92.2
Epoch: [78][121/704]	Time 0.122	Data 0.002	Loss 5.36	Acc@1 71.9	Acc@5 90.6
Epoch: [78][131/704]	Time 0.122	Data 0.002	Loss 5.50	Acc@1 64.1	Acc@5 92.2
Epoch: [78][141/704]	Time 0.122	Data 0.002	Loss 5.87	Acc@1 68.8	Acc@5 93.8
Epoch: [78][151/704]	Time 0.122	Data 0.001	Loss 4.31	Acc@1 79.7	Acc@5 98.4
Epoch: [78][161/704]	Time 0.122	Data 0.001	Loss 5.77	Acc@1 59.4	Acc@5 100.0
Epoch: [78][171/704]	Time 0.122	Data 0.001	Loss 5.98	Acc@1 57.8	Acc@5 89.1
Epoch: [78][181/704]	Time 0.122	Data 0.001	Loss 4.19	Acc@1 78.1	Acc@5 93.8
Epoch: [78][191/704]	Time 0.122	Data 0.001	Loss 5.95	Acc@1 60.9	Acc@5 93.8
Epoch: [78][201/704]	Time 0.122	Data 0.001	Loss 4.65	Acc@1 70.3	Acc@5 93.8
Epoch: [78][211/704]	Time 0.121	Data 0.001	Loss 3.99	Acc@1 70.3	Acc@5 98.4
Epoch: [78][221/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 95.3
Epoch: [78][231/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 78.1	Acc@5 96.9
Epoch: [78][241/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 67.2	Acc@5 87.5
Epoch: [78][251/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 70.3	Acc@5 89.1
Epoch: [78][261/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 96.9
Epoch: [78][271/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 67.2	Acc@5 89.1
Epoch: [78][281/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 60.9	Acc@5 89.1
Epoch: [78][291/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 54.7	Acc@5 92.2
Epoch: [78][301/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 68.8	Acc@5 90.6
Epoch: [78][311/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 71.9	Acc@5 89.1
Epoch: [78][321/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 64.1	Acc@5 89.1
Epoch: [78][331/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 70.3	Acc@5 89.1
Epoch: [78][341/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 67.2	Acc@5 89.1
Epoch: [78][351/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 59.4	Acc@5 90.6
Epoch: [78][361/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 68.8	Acc@5 92.2
Epoch: [78][371/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 79.7	Acc@5 95.3
Epoch: [78][381/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 73.4	Acc@5 93.8
Epoch: [78][391/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 68.8	Acc@5 89.1
Epoch: [78][401/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 65.6	Acc@5 93.8
Epoch: [78][411/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 73.4	Acc@5 93.8
Epoch: [78][421/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 62.5	Acc@5 89.1
Epoch: [78][431/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 68.8	Acc@5 93.8
Epoch: [78][441/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 78.1	Acc@5 95.3
Epoch: [78][451/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 75.0	Acc@5 89.1
Epoch: [78][461/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 82.8	Acc@5 95.3
Epoch: [78][471/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 89.1
Epoch: [78][481/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 73.4	Acc@5 96.9
Epoch: [78][491/704]	Time 0.121	Data 0.001	Loss 6.94	Acc@1 53.1	Acc@5 84.4
Epoch: [78][501/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 65.6	Acc@5 92.2
Epoch: [78][511/704]	Time 0.121	Data 0.001	Loss 6.59	Acc@1 60.9	Acc@5 85.9
Epoch: [78][521/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 68.8	Acc@5 90.6
Epoch: [78][531/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 73.4	Acc@5 89.1
Epoch: [78][541/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 57.8	Acc@5 90.6
Epoch: [78][551/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 92.2
Epoch: [78][561/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 59.4	Acc@5 89.1
Epoch: [78][571/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 68.8	Acc@5 87.5
Epoch: [78][581/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 64.1	Acc@5 90.6
Epoch: [78][591/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 67.2	Acc@5 95.3
Epoch: [78][601/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 67.2	Acc@5 89.1
Epoch: [78][611/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 75.0	Acc@5 95.3
Epoch: [78][621/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 68.8	Acc@5 89.1
Epoch: [78][631/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 60.9	Acc@5 85.9
Epoch: [78][641/704]	Time 0.121	Data 0.001	Loss 3.88	Acc@1 78.1	Acc@5 93.8
Epoch: [78][651/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 65.6	Acc@5 87.5
Epoch: [78][661/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 60.9	Acc@5 92.2
Epoch: [78][671/704]	Time 0.121	Data 0.001	Loss 6.43	Acc@1 60.9	Acc@5 95.3
Epoch: [78][681/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 70.3	Acc@5 90.6
Epoch: [78][691/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 64.1	Acc@5 90.6
Epoch: [78][701/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 65.6	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.6131	Acc@1 57.8125	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.6770	Acc@1 56.2500	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.5941	Acc@1 56.2500	Acc@5 79.6875
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 5.7389	Acc@1 62.5000	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.2835	Acc@1 51.5625	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9300	Acc@1 67.1875	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4177	Acc@1 57.8125	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.3079	Acc@1 57.8125	Acc@5 82.8125
 * prec@1 48.020 prec@5 78.580
 * prec@1 52.300 prec@5 82.700
 * prec@1 55.720 prec@5 83.960
 * prec@1 57.220 prec@5 85.540
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_078.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_078.pth.tar'
Epoch: [79][1/704]	Time 0.299	Data 0.131	Loss 3.97	Acc@1 73.4	Acc@5 100.0
Epoch: [79][11/704]	Time 0.136	Data 0.012	Loss 5.22	Acc@1 67.2	Acc@5 96.9
Epoch: [79][21/704]	Time 0.129	Data 0.007	Loss 5.29	Acc@1 68.8	Acc@5 92.2
Epoch: [79][31/704]	Time 0.126	Data 0.005	Loss 5.32	Acc@1 76.6	Acc@5 90.6
Epoch: [79][41/704]	Time 0.124	Data 0.003	Loss 7.03	Acc@1 67.2	Acc@5 81.2
Epoch: [79][51/704]	Time 0.124	Data 0.003	Loss 5.98	Acc@1 68.8	Acc@5 95.3
Epoch: [79][61/704]	Time 0.123	Data 0.002	Loss 5.24	Acc@1 62.5	Acc@5 90.6
Epoch: [79][71/704]	Time 0.122	Data 0.002	Loss 5.30	Acc@1 67.2	Acc@5 92.2
Epoch: [79][81/704]	Time 0.122	Data 0.002	Loss 5.72	Acc@1 64.1	Acc@5 89.1
Epoch: [79][91/704]	Time 0.122	Data 0.002	Loss 5.76	Acc@1 71.9	Acc@5 92.2
Epoch: [79][101/704]	Time 0.122	Data 0.002	Loss 5.06	Acc@1 68.8	Acc@5 93.8
Epoch: [79][111/704]	Time 0.122	Data 0.002	Loss 4.79	Acc@1 75.0	Acc@5 96.9
Epoch: [79][121/704]	Time 0.122	Data 0.001	Loss 5.60	Acc@1 60.9	Acc@5 93.8
Epoch: [79][131/704]	Time 0.122	Data 0.001	Loss 6.30	Acc@1 60.9	Acc@5 85.9
Epoch: [79][141/704]	Time 0.122	Data 0.001	Loss 5.35	Acc@1 71.9	Acc@5 93.8
Epoch: [79][151/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 73.4	Acc@5 93.8
Epoch: [79][161/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 67.2	Acc@5 92.2
Epoch: [79][171/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 73.4	Acc@5 96.9
Epoch: [79][181/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 59.4	Acc@5 90.6
Epoch: [79][191/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 68.8	Acc@5 96.9
Epoch: [79][201/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 71.9	Acc@5 96.9
Epoch: [79][211/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 68.8	Acc@5 92.2
Epoch: [79][221/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 71.9	Acc@5 93.8
Epoch: [79][231/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 68.8	Acc@5 92.2
Epoch: [79][241/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 67.2	Acc@5 92.2
Epoch: [79][251/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 73.4	Acc@5 95.3
Epoch: [79][261/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 70.3	Acc@5 87.5
Epoch: [79][271/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 68.8	Acc@5 90.6
Epoch: [79][281/704]	Time 0.121	Data 0.001	Loss 6.49	Acc@1 68.8	Acc@5 92.2
Epoch: [79][291/704]	Time 0.121	Data 0.001	Loss 3.91	Acc@1 75.0	Acc@5 96.9
Epoch: [79][301/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 95.3
Epoch: [79][311/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 68.8	Acc@5 90.6
Epoch: [79][321/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 65.6	Acc@5 89.1
Epoch: [79][331/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 70.3	Acc@5 93.8
Epoch: [79][341/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 71.9	Acc@5 95.3
Epoch: [79][351/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 62.5	Acc@5 93.8
Epoch: [79][361/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 68.8	Acc@5 92.2
Epoch: [79][371/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 92.2
Epoch: [79][381/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 75.0	Acc@5 93.8
Epoch: [79][391/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 68.8	Acc@5 89.1
Epoch: [79][401/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 68.8	Acc@5 84.4
Epoch: [79][411/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 53.1	Acc@5 93.8
Epoch: [79][421/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 68.8	Acc@5 93.8
Epoch: [79][431/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 71.9	Acc@5 95.3
Epoch: [79][441/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 65.6	Acc@5 93.8
Epoch: [79][451/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 64.1	Acc@5 89.1
Epoch: [79][461/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 71.9	Acc@5 93.8
Epoch: [79][471/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 67.2	Acc@5 90.6
Epoch: [79][481/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 75.0	Acc@5 92.2
Epoch: [79][491/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 62.5	Acc@5 89.1
Epoch: [79][501/704]	Time 0.120	Data 0.001	Loss 6.13	Acc@1 67.2	Acc@5 87.5
Epoch: [79][511/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 64.1	Acc@5 89.1
Epoch: [79][521/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 67.2	Acc@5 93.8
Epoch: [79][531/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 87.5
Epoch: [79][541/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 59.4	Acc@5 92.2
Epoch: [79][551/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 65.6	Acc@5 95.3
Epoch: [79][561/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 62.5	Acc@5 90.6
Epoch: [79][571/704]	Time 0.120	Data 0.001	Loss 4.53	Acc@1 71.9	Acc@5 93.8
Epoch: [79][581/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 60.9	Acc@5 87.5
Epoch: [79][591/704]	Time 0.120	Data 0.001	Loss 6.01	Acc@1 64.1	Acc@5 92.2
Epoch: [79][601/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 56.2	Acc@5 85.9
Epoch: [79][611/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 67.2	Acc@5 90.6
Epoch: [79][621/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 90.6
Epoch: [79][631/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 71.9	Acc@5 90.6
Epoch: [79][641/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 59.4	Acc@5 92.2
Epoch: [79][651/704]	Time 0.120	Data 0.001	Loss 4.13	Acc@1 79.7	Acc@5 96.9
Epoch: [79][661/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 67.2	Acc@5 95.3
Epoch: [79][671/704]	Time 0.120	Data 0.001	Loss 5.73	Acc@1 64.1	Acc@5 92.2
Epoch: [79][681/704]	Time 0.120	Data 0.001	Loss 6.01	Acc@1 60.9	Acc@5 87.5
Epoch: [79][691/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 65.6	Acc@5 89.1
Epoch: [79][701/704]	Time 0.120	Data 0.001	Loss 4.16	Acc@1 76.6	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.1703	Acc@1 48.4375	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.6329	Acc@1 51.5625	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 9.0943	Acc@1 43.7500	Acc@5 75.0000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.5069	Acc@1 50.0000	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4169	Acc@1 67.1875	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7130	Acc@1 51.5625	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.0212	Acc@1 64.0625	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7634	Acc@1 65.6250	Acc@5 82.8125
 * prec@1 46.060 prec@5 76.540
 * prec@1 50.100 prec@5 80.980
 * prec@1 54.440 prec@5 84.680
 * prec@1 56.900 prec@5 84.800
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_079.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_079.pth.tar'
Epoch: [80][1/704]	Time 0.299	Data 0.131	Loss 5.36	Acc@1 62.5	Acc@5 96.9
Epoch: [80][11/704]	Time 0.140	Data 0.012	Loss 6.78	Acc@1 54.7	Acc@5 89.1
Epoch: [80][21/704]	Time 0.131	Data 0.007	Loss 5.69	Acc@1 70.3	Acc@5 92.2
Epoch: [80][31/704]	Time 0.127	Data 0.004	Loss 5.57	Acc@1 62.5	Acc@5 85.9
Epoch: [80][41/704]	Time 0.125	Data 0.004	Loss 6.00	Acc@1 59.4	Acc@5 89.1
Epoch: [80][51/704]	Time 0.124	Data 0.003	Loss 6.01	Acc@1 59.4	Acc@5 87.5
Epoch: [80][61/704]	Time 0.124	Data 0.002	Loss 5.08	Acc@1 78.1	Acc@5 93.8
Epoch: [80][71/704]	Time 0.123	Data 0.002	Loss 4.53	Acc@1 68.8	Acc@5 93.8
Epoch: [80][81/704]	Time 0.123	Data 0.002	Loss 5.80	Acc@1 59.4	Acc@5 93.8
Epoch: [80][91/704]	Time 0.123	Data 0.002	Loss 4.94	Acc@1 73.4	Acc@5 92.2
Epoch: [80][101/704]	Time 0.122	Data 0.002	Loss 4.67	Acc@1 70.3	Acc@5 92.2
Epoch: [80][111/704]	Time 0.122	Data 0.002	Loss 5.35	Acc@1 65.6	Acc@5 90.6
Epoch: [80][121/704]	Time 0.122	Data 0.001	Loss 4.92	Acc@1 70.3	Acc@5 96.9
Epoch: [80][131/704]	Time 0.122	Data 0.001	Loss 4.35	Acc@1 70.3	Acc@5 100.0
Epoch: [80][141/704]	Time 0.122	Data 0.001	Loss 4.54	Acc@1 79.7	Acc@5 90.6
Epoch: [80][151/704]	Time 0.122	Data 0.001	Loss 4.53	Acc@1 70.3	Acc@5 96.9
Epoch: [80][161/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 65.6	Acc@5 95.3
Epoch: [80][171/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 65.6	Acc@5 90.6
Epoch: [80][181/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 64.1	Acc@5 93.8
Epoch: [80][191/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 62.5	Acc@5 93.8
Epoch: [80][201/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 67.2	Acc@5 89.1
Epoch: [80][211/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 67.2	Acc@5 90.6
Epoch: [80][221/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 90.6
Epoch: [80][231/704]	Time 0.121	Data 0.001	Loss 4.22	Acc@1 76.6	Acc@5 95.3
Epoch: [80][241/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 71.9	Acc@5 93.8
Epoch: [80][251/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 87.5
Epoch: [80][261/704]	Time 0.121	Data 0.001	Loss 3.85	Acc@1 78.1	Acc@5 95.3
Epoch: [80][271/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 64.1	Acc@5 92.2
Epoch: [80][281/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 79.7	Acc@5 93.8
Epoch: [80][291/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 73.4	Acc@5 92.2
Epoch: [80][301/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 78.1	Acc@5 98.4
Epoch: [80][311/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 56.2	Acc@5 89.1
Epoch: [80][321/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 71.9	Acc@5 95.3
Epoch: [80][331/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 60.9	Acc@5 95.3
Epoch: [80][341/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 68.8	Acc@5 93.8
Epoch: [80][351/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 92.2
Epoch: [80][361/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 67.2	Acc@5 95.3
Epoch: [80][371/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 62.5	Acc@5 93.8
Epoch: [80][381/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 71.9	Acc@5 90.6
Epoch: [80][391/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 70.3	Acc@5 95.3
Epoch: [80][401/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 73.4	Acc@5 92.2
Epoch: [80][411/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 73.4	Acc@5 95.3
Epoch: [80][421/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 65.6	Acc@5 93.8
Epoch: [80][431/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 57.8	Acc@5 93.8
Epoch: [80][441/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 67.2	Acc@5 87.5
Epoch: [80][451/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 67.2	Acc@5 92.2
Epoch: [80][461/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 70.3	Acc@5 92.2
Epoch: [80][471/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 60.9	Acc@5 92.2
Epoch: [80][481/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 81.2	Acc@5 90.6
Epoch: [80][491/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 92.2
Epoch: [80][501/704]	Time 0.121	Data 0.001	Loss 6.84	Acc@1 59.4	Acc@5 87.5
Epoch: [80][511/704]	Time 0.121	Data 0.001	Loss 4.15	Acc@1 68.8	Acc@5 92.2
Epoch: [80][521/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 65.6	Acc@5 87.5
Epoch: [80][531/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 62.5	Acc@5 89.1
Epoch: [80][541/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 75.0	Acc@5 95.3
Epoch: [80][551/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 65.6	Acc@5 93.8
Epoch: [80][561/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 70.3	Acc@5 98.4
Epoch: [80][571/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 75.0	Acc@5 92.2
Epoch: [80][581/704]	Time 0.121	Data 0.001	Loss 6.65	Acc@1 53.1	Acc@5 92.2
Epoch: [80][591/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 71.9	Acc@5 95.3
Epoch: [80][601/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 65.6	Acc@5 93.8
Epoch: [80][611/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 68.8	Acc@5 93.8
Epoch: [80][621/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 67.2	Acc@5 93.8
Epoch: [80][631/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 78.1	Acc@5 89.1
Epoch: [80][641/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 65.6	Acc@5 92.2
Epoch: [80][651/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 70.3	Acc@5 95.3
Epoch: [80][661/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 71.9	Acc@5 93.8
Epoch: [80][671/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 62.5	Acc@5 95.3
Epoch: [80][681/704]	Time 0.121	Data 0.001	Loss 6.41	Acc@1 67.2	Acc@5 89.1
Epoch: [80][691/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 64.1	Acc@5 92.2
Epoch: [80][701/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 59.4	Acc@5 87.5
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.6525	Acc@1 60.9375	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1827	Acc@1 65.6250	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 9.3481	Acc@1 45.3125	Acc@5 73.4375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.7318	Acc@1 53.1250	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3675	Acc@1 60.9375	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.6385	Acc@1 59.3750	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.4515	Acc@1 53.1250	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.0880	Acc@1 57.8125	Acc@5 82.8125
 * prec@1 45.360 prec@5 76.260
 * prec@1 48.800 prec@5 79.640
 * prec@1 54.020 prec@5 84.420
 * prec@1 56.540 prec@5 85.020
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_080.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_080.pth.tar'
Epoch: [81][1/704]	Time 0.329	Data 0.163	Loss 4.18	Acc@1 81.2	Acc@5 90.6
Epoch: [81][11/704]	Time 0.139	Data 0.015	Loss 5.41	Acc@1 68.8	Acc@5 95.3
Epoch: [81][21/704]	Time 0.130	Data 0.008	Loss 4.09	Acc@1 78.1	Acc@5 98.4
Epoch: [81][31/704]	Time 0.127	Data 0.006	Loss 5.80	Acc@1 62.5	Acc@5 90.6
Epoch: [81][41/704]	Time 0.125	Data 0.004	Loss 5.04	Acc@1 65.6	Acc@5 92.2
Epoch: [81][51/704]	Time 0.124	Data 0.003	Loss 4.64	Acc@1 70.3	Acc@5 90.6
Epoch: [81][61/704]	Time 0.123	Data 0.003	Loss 6.11	Acc@1 71.9	Acc@5 85.9
Epoch: [81][71/704]	Time 0.123	Data 0.003	Loss 4.88	Acc@1 67.2	Acc@5 92.2
Epoch: [81][81/704]	Time 0.123	Data 0.002	Loss 5.61	Acc@1 60.9	Acc@5 87.5
Epoch: [81][91/704]	Time 0.122	Data 0.002	Loss 5.26	Acc@1 57.8	Acc@5 93.8
Epoch: [81][101/704]	Time 0.122	Data 0.002	Loss 5.08	Acc@1 71.9	Acc@5 95.3
Epoch: [81][111/704]	Time 0.122	Data 0.002	Loss 3.88	Acc@1 73.4	Acc@5 96.9
Epoch: [81][121/704]	Time 0.122	Data 0.002	Loss 5.28	Acc@1 68.8	Acc@5 93.8
Epoch: [81][131/704]	Time 0.122	Data 0.002	Loss 4.88	Acc@1 62.5	Acc@5 95.3
Epoch: [81][141/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 64.1	Acc@5 96.9
Epoch: [81][151/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 70.3	Acc@5 90.6
Epoch: [81][161/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 68.8	Acc@5 93.8
Epoch: [81][171/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 76.6	Acc@5 95.3
Epoch: [81][181/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 76.6	Acc@5 96.9
Epoch: [81][191/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 62.5	Acc@5 92.2
Epoch: [81][201/704]	Time 0.121	Data 0.001	Loss 6.62	Acc@1 59.4	Acc@5 87.5
Epoch: [81][211/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 68.8	Acc@5 85.9
Epoch: [81][221/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 67.2	Acc@5 90.6
Epoch: [81][231/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 70.3	Acc@5 93.8
Epoch: [81][241/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 71.9	Acc@5 93.8
Epoch: [81][251/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 60.9	Acc@5 92.2
Epoch: [81][261/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 67.2	Acc@5 87.5
Epoch: [81][271/704]	Time 0.121	Data 0.001	Loss 6.62	Acc@1 64.1	Acc@5 87.5
Epoch: [81][281/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 67.2	Acc@5 87.5
Epoch: [81][291/704]	Time 0.121	Data 0.001	Loss 6.56	Acc@1 62.5	Acc@5 92.2
Epoch: [81][301/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 65.6	Acc@5 95.3
Epoch: [81][311/704]	Time 0.121	Data 0.001	Loss 6.82	Acc@1 62.5	Acc@5 84.4
Epoch: [81][321/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 68.8	Acc@5 95.3
Epoch: [81][331/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 70.3	Acc@5 92.2
Epoch: [81][341/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 70.3	Acc@5 95.3
Epoch: [81][351/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 71.9	Acc@5 90.6
Epoch: [81][361/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 73.4	Acc@5 95.3
Epoch: [81][371/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 75.0	Acc@5 93.8
Epoch: [81][381/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 68.8	Acc@5 89.1
Epoch: [81][391/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 67.2	Acc@5 90.6
Epoch: [81][401/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 68.8	Acc@5 87.5
Epoch: [81][411/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 64.1	Acc@5 93.8
Epoch: [81][421/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 71.9	Acc@5 96.9
Epoch: [81][431/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 67.2	Acc@5 93.8
Epoch: [81][441/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 70.3	Acc@5 96.9
Epoch: [81][451/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 90.6
Epoch: [81][461/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 51.6	Acc@5 84.4
Epoch: [81][471/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 78.1	Acc@5 93.8
Epoch: [81][481/704]	Time 0.120	Data 0.001	Loss 6.04	Acc@1 62.5	Acc@5 93.8
Epoch: [81][491/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 56.2	Acc@5 96.9
Epoch: [81][501/704]	Time 0.120	Data 0.001	Loss 6.67	Acc@1 62.5	Acc@5 85.9
Epoch: [81][511/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 65.6	Acc@5 92.2
Epoch: [81][521/704]	Time 0.120	Data 0.001	Loss 6.88	Acc@1 57.8	Acc@5 84.4
Epoch: [81][531/704]	Time 0.120	Data 0.001	Loss 6.09	Acc@1 64.1	Acc@5 87.5
Epoch: [81][541/704]	Time 0.120	Data 0.001	Loss 4.10	Acc@1 73.4	Acc@5 93.8
Epoch: [81][551/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 64.1	Acc@5 84.4
Epoch: [81][561/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 65.6	Acc@5 89.1
Epoch: [81][571/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 60.9	Acc@5 90.6
Epoch: [81][581/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 64.1	Acc@5 90.6
Epoch: [81][591/704]	Time 0.120	Data 0.001	Loss 4.70	Acc@1 71.9	Acc@5 95.3
Epoch: [81][601/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 67.2	Acc@5 92.2
Epoch: [81][611/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 68.8	Acc@5 95.3
Epoch: [81][621/704]	Time 0.120	Data 0.001	Loss 4.58	Acc@1 70.3	Acc@5 96.9
Epoch: [81][631/704]	Time 0.120	Data 0.001	Loss 4.44	Acc@1 73.4	Acc@5 96.9
Epoch: [81][641/704]	Time 0.120	Data 0.001	Loss 4.97	Acc@1 65.6	Acc@5 92.2
Epoch: [81][651/704]	Time 0.120	Data 0.001	Loss 4.65	Acc@1 70.3	Acc@5 93.8
Epoch: [81][661/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 59.4	Acc@5 89.1
Epoch: [81][671/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 71.9	Acc@5 89.1
Epoch: [81][681/704]	Time 0.120	Data 0.001	Loss 6.32	Acc@1 54.7	Acc@5 85.9
Epoch: [81][691/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 62.5	Acc@5 93.8
Epoch: [81][701/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 89.1
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 8.2644	Acc@1 46.8750	Acc@5 75.0000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8402	Acc@1 59.3750	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.3683	Acc@1 56.2500	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6567	Acc@1 65.6250	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2342	Acc@1 57.8125	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.7603	Acc@1 67.1875	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4141	Acc@1 51.5625	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7301	Acc@1 59.3750	Acc@5 92.1875
 * prec@1 46.220 prec@5 78.080
 * prec@1 51.480 prec@5 82.580
 * prec@1 56.140 prec@5 85.720
 * prec@1 56.560 prec@5 86.060
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_081.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_081.pth.tar'
Epoch: [82][1/704]	Time 0.296	Data 0.129	Loss 4.31	Acc@1 78.1	Acc@5 93.8
Epoch: [82][11/704]	Time 0.136	Data 0.012	Loss 6.43	Acc@1 56.2	Acc@5 87.5
Epoch: [82][21/704]	Time 0.129	Data 0.006	Loss 5.51	Acc@1 62.5	Acc@5 90.6
Epoch: [82][31/704]	Time 0.126	Data 0.004	Loss 5.10	Acc@1 65.6	Acc@5 92.2
Epoch: [82][41/704]	Time 0.124	Data 0.004	Loss 4.75	Acc@1 64.1	Acc@5 93.8
Epoch: [82][51/704]	Time 0.124	Data 0.003	Loss 5.57	Acc@1 62.5	Acc@5 87.5
Epoch: [82][61/704]	Time 0.123	Data 0.002	Loss 4.69	Acc@1 70.3	Acc@5 95.3
Epoch: [82][71/704]	Time 0.123	Data 0.002	Loss 5.16	Acc@1 76.6	Acc@5 92.2
Epoch: [82][81/704]	Time 0.122	Data 0.002	Loss 5.49	Acc@1 70.3	Acc@5 89.1
Epoch: [82][91/704]	Time 0.122	Data 0.002	Loss 5.06	Acc@1 68.8	Acc@5 90.6
Epoch: [82][101/704]	Time 0.122	Data 0.002	Loss 5.85	Acc@1 57.8	Acc@5 93.8
Epoch: [82][111/704]	Time 0.122	Data 0.002	Loss 5.23	Acc@1 65.6	Acc@5 90.6
Epoch: [82][121/704]	Time 0.122	Data 0.001	Loss 5.91	Acc@1 62.5	Acc@5 92.2
Epoch: [82][131/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 68.8	Acc@5 84.4
Epoch: [82][141/704]	Time 0.122	Data 0.001	Loss 4.98	Acc@1 71.9	Acc@5 92.2
Epoch: [82][151/704]	Time 0.122	Data 0.001	Loss 4.79	Acc@1 78.1	Acc@5 95.3
Epoch: [82][161/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 70.3	Acc@5 95.3
Epoch: [82][171/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 62.5	Acc@5 92.2
Epoch: [82][181/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 59.4	Acc@5 92.2
Epoch: [82][191/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 68.8	Acc@5 95.3
Epoch: [82][201/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 78.1	Acc@5 96.9
Epoch: [82][211/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 71.9	Acc@5 95.3
Epoch: [82][221/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 67.2	Acc@5 90.6
Epoch: [82][231/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 76.6	Acc@5 90.6
Epoch: [82][241/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 67.2	Acc@5 92.2
Epoch: [82][251/704]	Time 0.121	Data 0.001	Loss 6.23	Acc@1 53.1	Acc@5 92.2
Epoch: [82][261/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 71.9	Acc@5 89.1
Epoch: [82][271/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 57.8	Acc@5 89.1
Epoch: [82][281/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 68.8	Acc@5 93.8
Epoch: [82][291/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 67.2	Acc@5 95.3
Epoch: [82][301/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 65.6	Acc@5 87.5
Epoch: [82][311/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 62.5	Acc@5 87.5
Epoch: [82][321/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 75.0	Acc@5 92.2
Epoch: [82][331/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 73.4	Acc@5 96.9
Epoch: [82][341/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 65.6	Acc@5 92.2
Epoch: [82][351/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 75.0	Acc@5 93.8
Epoch: [82][361/704]	Time 0.121	Data 0.001	Loss 3.82	Acc@1 73.4	Acc@5 100.0
Epoch: [82][371/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 65.6	Acc@5 89.1
Epoch: [82][381/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 62.5	Acc@5 90.6
Epoch: [82][391/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 73.4	Acc@5 92.2
Epoch: [82][401/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 92.2
Epoch: [82][411/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 71.9	Acc@5 90.6
Epoch: [82][421/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 67.2	Acc@5 85.9
Epoch: [82][431/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 93.8
Epoch: [82][441/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 62.5	Acc@5 92.2
Epoch: [82][451/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 65.6	Acc@5 92.2
Epoch: [82][461/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 64.1	Acc@5 96.9
Epoch: [82][471/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 65.6	Acc@5 85.9
Epoch: [82][481/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 65.6	Acc@5 87.5
Epoch: [82][491/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 65.6	Acc@5 90.6
Epoch: [82][501/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 67.2	Acc@5 90.6
Epoch: [82][511/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 75.0	Acc@5 95.3
Epoch: [82][521/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 60.9	Acc@5 93.8
Epoch: [82][531/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 76.6	Acc@5 96.9
Epoch: [82][541/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 68.8	Acc@5 98.4
Epoch: [82][551/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 70.3	Acc@5 96.9
Epoch: [82][561/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 73.4	Acc@5 95.3
Epoch: [82][571/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 96.9
Epoch: [82][581/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 65.6	Acc@5 92.2
Epoch: [82][591/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 65.6	Acc@5 90.6
Epoch: [82][601/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 71.9	Acc@5 93.8
Epoch: [82][611/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 64.1	Acc@5 95.3
Epoch: [82][621/704]	Time 0.121	Data 0.001	Loss 6.90	Acc@1 56.2	Acc@5 87.5
Epoch: [82][631/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 62.5	Acc@5 90.6
Epoch: [82][641/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 70.3	Acc@5 89.1
Epoch: [82][651/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 68.8	Acc@5 93.8
Epoch: [82][661/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 70.3	Acc@5 95.3
Epoch: [82][671/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 73.4	Acc@5 96.9
Epoch: [82][681/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 75.0	Acc@5 89.1
Epoch: [82][691/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 73.4	Acc@5 96.9
Epoch: [82][701/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 73.4	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.7978	Acc@1 67.1875	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.9680	Acc@1 62.5000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.5468	Acc@1 56.2500	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7058	Acc@1 54.6875	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.7901	Acc@1 53.1250	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2389	Acc@1 54.6875	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.7899	Acc@1 54.6875	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.6486	Acc@1 64.0625	Acc@5 84.3750
 * prec@1 49.020 prec@5 78.960
 * prec@1 52.860 prec@5 82.560
 * prec@1 55.420 prec@5 84.400
 * prec@1 56.360 prec@5 84.820
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_082.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_082.pth.tar'
Epoch: [83][1/704]	Time 0.298	Data 0.131	Loss 5.91	Acc@1 67.2	Acc@5 90.6
Epoch: [83][11/704]	Time 0.136	Data 0.012	Loss 6.31	Acc@1 56.2	Acc@5 89.1
Epoch: [83][21/704]	Time 0.129	Data 0.007	Loss 4.74	Acc@1 68.8	Acc@5 93.8
Epoch: [83][31/704]	Time 0.126	Data 0.005	Loss 4.98	Acc@1 71.9	Acc@5 95.3
Epoch: [83][41/704]	Time 0.124	Data 0.004	Loss 4.45	Acc@1 68.8	Acc@5 98.4
Epoch: [83][51/704]	Time 0.123	Data 0.003	Loss 5.83	Acc@1 65.6	Acc@5 92.2
Epoch: [83][61/704]	Time 0.124	Data 0.002	Loss 5.77	Acc@1 65.6	Acc@5 90.6
Epoch: [83][71/704]	Time 0.123	Data 0.002	Loss 3.95	Acc@1 79.7	Acc@5 96.9
Epoch: [83][81/704]	Time 0.123	Data 0.002	Loss 5.72	Acc@1 65.6	Acc@5 90.6
Epoch: [83][91/704]	Time 0.122	Data 0.002	Loss 4.62	Acc@1 73.4	Acc@5 98.4
Epoch: [83][101/704]	Time 0.122	Data 0.002	Loss 3.58	Acc@1 79.7	Acc@5 98.4
Epoch: [83][111/704]	Time 0.122	Data 0.002	Loss 5.42	Acc@1 67.2	Acc@5 96.9
Epoch: [83][121/704]	Time 0.122	Data 0.001	Loss 5.00	Acc@1 68.8	Acc@5 95.3
Epoch: [83][131/704]	Time 0.122	Data 0.001	Loss 4.71	Acc@1 64.1	Acc@5 96.9
Epoch: [83][141/704]	Time 0.122	Data 0.001	Loss 6.44	Acc@1 57.8	Acc@5 92.2
Epoch: [83][151/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 68.8	Acc@5 95.3
Epoch: [83][161/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 64.1	Acc@5 89.1
Epoch: [83][171/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 67.2	Acc@5 100.0
Epoch: [83][181/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 95.3
Epoch: [83][191/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 67.2	Acc@5 95.3
Epoch: [83][201/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 70.3	Acc@5 96.9
Epoch: [83][211/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 68.8	Acc@5 90.6
Epoch: [83][221/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 67.2	Acc@5 92.2
Epoch: [83][231/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 75.0	Acc@5 90.6
Epoch: [83][241/704]	Time 0.121	Data 0.001	Loss 6.23	Acc@1 60.9	Acc@5 87.5
Epoch: [83][251/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 64.1	Acc@5 92.2
Epoch: [83][261/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 59.4	Acc@5 93.8
Epoch: [83][271/704]	Time 0.121	Data 0.001	Loss 3.79	Acc@1 78.1	Acc@5 98.4
Epoch: [83][281/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 73.4	Acc@5 93.8
Epoch: [83][291/704]	Time 0.121	Data 0.001	Loss 4.07	Acc@1 68.8	Acc@5 92.2
Epoch: [83][301/704]	Time 0.121	Data 0.001	Loss 3.70	Acc@1 78.1	Acc@5 93.8
Epoch: [83][311/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 87.5
Epoch: [83][321/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 65.6	Acc@5 92.2
Epoch: [83][331/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 71.9	Acc@5 87.5
Epoch: [83][341/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 70.3	Acc@5 93.8
Epoch: [83][351/704]	Time 0.121	Data 0.001	Loss 3.86	Acc@1 70.3	Acc@5 95.3
Epoch: [83][361/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 71.9	Acc@5 93.8
Epoch: [83][371/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 90.6
Epoch: [83][381/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 76.6	Acc@5 98.4
Epoch: [83][391/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 59.4	Acc@5 89.1
Epoch: [83][401/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 70.3	Acc@5 95.3
Epoch: [83][411/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 71.9	Acc@5 92.2
Epoch: [83][421/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 62.5	Acc@5 89.1
Epoch: [83][431/704]	Time 0.120	Data 0.001	Loss 4.20	Acc@1 73.4	Acc@5 95.3
Epoch: [83][441/704]	Time 0.120	Data 0.001	Loss 4.55	Acc@1 67.2	Acc@5 98.4
Epoch: [83][451/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 68.8	Acc@5 93.8
Epoch: [83][461/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 70.3	Acc@5 90.6
Epoch: [83][471/704]	Time 0.120	Data 0.001	Loss 5.02	Acc@1 71.9	Acc@5 92.2
Epoch: [83][481/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 64.1	Acc@5 93.8
Epoch: [83][491/704]	Time 0.120	Data 0.001	Loss 5.05	Acc@1 75.0	Acc@5 95.3
Epoch: [83][501/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 68.8	Acc@5 95.3
Epoch: [83][511/704]	Time 0.120	Data 0.001	Loss 4.14	Acc@1 75.0	Acc@5 96.9
Epoch: [83][521/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 65.6	Acc@5 89.1
Epoch: [83][531/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 65.6	Acc@5 96.9
Epoch: [83][541/704]	Time 0.120	Data 0.001	Loss 6.28	Acc@1 65.6	Acc@5 89.1
Epoch: [83][551/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 71.9	Acc@5 93.8
Epoch: [83][561/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 95.3
Epoch: [83][571/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 90.6
Epoch: [83][581/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 60.9	Acc@5 89.1
Epoch: [83][591/704]	Time 0.120	Data 0.001	Loss 5.39	Acc@1 64.1	Acc@5 92.2
Epoch: [83][601/704]	Time 0.120	Data 0.001	Loss 5.30	Acc@1 75.0	Acc@5 93.8
Epoch: [83][611/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 70.3	Acc@5 96.9
Epoch: [83][621/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 93.8
Epoch: [83][631/704]	Time 0.120	Data 0.001	Loss 6.63	Acc@1 56.2	Acc@5 90.6
Epoch: [83][641/704]	Time 0.120	Data 0.001	Loss 6.05	Acc@1 62.5	Acc@5 90.6
Epoch: [83][651/704]	Time 0.120	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 96.9
Epoch: [83][661/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 79.7	Acc@5 92.2
Epoch: [83][671/704]	Time 0.120	Data 0.001	Loss 5.45	Acc@1 56.2	Acc@5 93.8
Epoch: [83][681/704]	Time 0.120	Data 0.001	Loss 6.25	Acc@1 62.5	Acc@5 89.1
Epoch: [83][691/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 68.8	Acc@5 92.2
Epoch: [83][701/704]	Time 0.120	Data 0.001	Loss 4.68	Acc@1 64.1	Acc@5 93.8
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 9.6558	Acc@1 48.4375	Acc@5 78.1250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.7956	Acc@1 65.6250	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.8082	Acc@1 50.0000	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.1540	Acc@1 57.8125	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6901	Acc@1 65.6250	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.9061	Acc@1 46.8750	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6908	Acc@1 59.3750	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.4107	Acc@1 60.9375	Acc@5 93.7500
 * prec@1 46.460 prec@5 78.100
 * prec@1 51.900 prec@5 80.580
 * prec@1 55.960 prec@5 84.800
 * prec@1 57.080 prec@5 85.160
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_083.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_083.pth.tar'
Epoch: [84][1/704]	Time 0.331	Data 0.165	Loss 4.42	Acc@1 75.0	Acc@5 95.3
Epoch: [84][11/704]	Time 0.139	Data 0.015	Loss 4.68	Acc@1 70.3	Acc@5 93.8
Epoch: [84][21/704]	Time 0.130	Data 0.008	Loss 4.99	Acc@1 67.2	Acc@5 95.3
Epoch: [84][31/704]	Time 0.127	Data 0.006	Loss 4.80	Acc@1 70.3	Acc@5 93.8
Epoch: [84][41/704]	Time 0.125	Data 0.004	Loss 5.80	Acc@1 67.2	Acc@5 92.2
Epoch: [84][51/704]	Time 0.124	Data 0.004	Loss 4.67	Acc@1 75.0	Acc@5 98.4
Epoch: [84][61/704]	Time 0.124	Data 0.003	Loss 5.16	Acc@1 71.9	Acc@5 93.8
Epoch: [84][71/704]	Time 0.123	Data 0.003	Loss 5.89	Acc@1 64.1	Acc@5 87.5
Epoch: [84][81/704]	Time 0.123	Data 0.002	Loss 5.05	Acc@1 64.1	Acc@5 90.6
Epoch: [84][91/704]	Time 0.123	Data 0.002	Loss 5.70	Acc@1 65.6	Acc@5 89.1
Epoch: [84][101/704]	Time 0.122	Data 0.002	Loss 4.08	Acc@1 81.2	Acc@5 98.4
Epoch: [84][111/704]	Time 0.122	Data 0.002	Loss 4.72	Acc@1 67.2	Acc@5 89.1
Epoch: [84][121/704]	Time 0.122	Data 0.002	Loss 5.03	Acc@1 78.1	Acc@5 92.2
Epoch: [84][131/704]	Time 0.122	Data 0.002	Loss 5.48	Acc@1 65.6	Acc@5 90.6
Epoch: [84][141/704]	Time 0.122	Data 0.002	Loss 5.98	Acc@1 65.6	Acc@5 89.1
Epoch: [84][151/704]	Time 0.122	Data 0.001	Loss 4.59	Acc@1 75.0	Acc@5 95.3
Epoch: [84][161/704]	Time 0.122	Data 0.001	Loss 5.37	Acc@1 62.5	Acc@5 90.6
Epoch: [84][171/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 59.4	Acc@5 95.3
Epoch: [84][181/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 62.5	Acc@5 93.8
Epoch: [84][191/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 65.6	Acc@5 85.9
Epoch: [84][201/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 62.5	Acc@5 93.8
Epoch: [84][211/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 64.1	Acc@5 92.2
Epoch: [84][221/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 65.6	Acc@5 93.8
Epoch: [84][231/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 65.6	Acc@5 92.2
Epoch: [84][241/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 67.2	Acc@5 93.8
Epoch: [84][251/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 67.2	Acc@5 90.6
Epoch: [84][261/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 70.3	Acc@5 89.1
Epoch: [84][271/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 67.2	Acc@5 95.3
Epoch: [84][281/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 65.6	Acc@5 92.2
Epoch: [84][291/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 71.9	Acc@5 89.1
Epoch: [84][301/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 78.1	Acc@5 95.3
Epoch: [84][311/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 68.8	Acc@5 90.6
Epoch: [84][321/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 75.0	Acc@5 93.8
Epoch: [84][331/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 68.8	Acc@5 100.0
Epoch: [84][341/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 65.6	Acc@5 96.9
Epoch: [84][351/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 75.0	Acc@5 92.2
Epoch: [84][361/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 64.1	Acc@5 96.9
Epoch: [84][371/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 70.3	Acc@5 96.9
Epoch: [84][381/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 68.8	Acc@5 93.8
Epoch: [84][391/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 67.2	Acc@5 90.6
Epoch: [84][401/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 67.2	Acc@5 93.8
Epoch: [84][411/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 65.6	Acc@5 90.6
Epoch: [84][421/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 64.1	Acc@5 95.3
Epoch: [84][431/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 64.1	Acc@5 92.2
Epoch: [84][441/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 68.8	Acc@5 95.3
Epoch: [84][451/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 65.6	Acc@5 92.2
Epoch: [84][461/704]	Time 0.121	Data 0.001	Loss 6.51	Acc@1 62.5	Acc@5 90.6
Epoch: [84][471/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 75.0	Acc@5 98.4
Epoch: [84][481/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 68.8	Acc@5 95.3
Epoch: [84][491/704]	Time 0.121	Data 0.001	Loss 6.83	Acc@1 62.5	Acc@5 84.4
Epoch: [84][501/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 67.2	Acc@5 90.6
Epoch: [84][511/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 73.4	Acc@5 93.8
Epoch: [84][521/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 67.2	Acc@5 92.2
Epoch: [84][531/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 64.1	Acc@5 89.1
Epoch: [84][541/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 71.9	Acc@5 89.1
Epoch: [84][551/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 76.6	Acc@5 95.3
Epoch: [84][561/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 60.9	Acc@5 92.2
Epoch: [84][571/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 67.2	Acc@5 90.6
Epoch: [84][581/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 95.3
Epoch: [84][591/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 70.3	Acc@5 90.6
Epoch: [84][601/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 65.6	Acc@5 95.3
Epoch: [84][611/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 70.3	Acc@5 95.3
Epoch: [84][621/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 73.4	Acc@5 92.2
Epoch: [84][631/704]	Time 0.121	Data 0.001	Loss 6.42	Acc@1 67.2	Acc@5 87.5
Epoch: [84][641/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 73.4	Acc@5 90.6
Epoch: [84][651/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 60.9	Acc@5 92.2
Epoch: [84][661/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 90.6
Epoch: [84][671/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 68.8	Acc@5 93.8
Epoch: [84][681/704]	Time 0.121	Data 0.001	Loss 4.07	Acc@1 73.4	Acc@5 98.4
Epoch: [84][691/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 68.8	Acc@5 96.9
Epoch: [84][701/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 67.2	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.1119	Acc@1 62.5000	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.9413	Acc@1 57.8125	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2348	Acc@1 54.6875	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0120	Acc@1 48.4375	Acc@5 79.6875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.2223	Acc@1 50.0000	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.6159	Acc@1 53.1250	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.8462	Acc@1 45.3125	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.7002	Acc@1 46.8750	Acc@5 82.8125
 * prec@1 48.520 prec@5 78.420
 * prec@1 51.160 prec@5 82.080
 * prec@1 55.620 prec@5 84.060
 * prec@1 56.860 prec@5 84.620
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_084.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_084.pth.tar'
Epoch: [85][1/704]	Time 0.333	Data 0.167	Loss 5.21	Acc@1 71.9	Acc@5 95.3
Epoch: [85][11/704]	Time 0.140	Data 0.015	Loss 6.06	Acc@1 57.8	Acc@5 89.1
Epoch: [85][21/704]	Time 0.130	Data 0.008	Loss 4.69	Acc@1 75.0	Acc@5 92.2
Epoch: [85][31/704]	Time 0.127	Data 0.006	Loss 4.82	Acc@1 71.9	Acc@5 95.3
Epoch: [85][41/704]	Time 0.125	Data 0.004	Loss 4.96	Acc@1 70.3	Acc@5 98.4
Epoch: [85][51/704]	Time 0.124	Data 0.004	Loss 5.37	Acc@1 65.6	Acc@5 90.6
Epoch: [85][61/704]	Time 0.124	Data 0.003	Loss 4.74	Acc@1 70.3	Acc@5 95.3
Epoch: [85][71/704]	Time 0.123	Data 0.003	Loss 5.70	Acc@1 59.4	Acc@5 96.9
Epoch: [85][81/704]	Time 0.123	Data 0.002	Loss 3.40	Acc@1 76.6	Acc@5 93.8
Epoch: [85][91/704]	Time 0.123	Data 0.002	Loss 4.55	Acc@1 73.4	Acc@5 95.3
Epoch: [85][101/704]	Time 0.122	Data 0.002	Loss 4.49	Acc@1 75.0	Acc@5 96.9
Epoch: [85][111/704]	Time 0.122	Data 0.002	Loss 4.62	Acc@1 75.0	Acc@5 95.3
Epoch: [85][121/704]	Time 0.122	Data 0.002	Loss 5.20	Acc@1 64.1	Acc@5 90.6
Epoch: [85][131/704]	Time 0.122	Data 0.002	Loss 5.46	Acc@1 67.2	Acc@5 93.8
Epoch: [85][141/704]	Time 0.122	Data 0.002	Loss 4.81	Acc@1 73.4	Acc@5 96.9
Epoch: [85][151/704]	Time 0.122	Data 0.001	Loss 6.27	Acc@1 59.4	Acc@5 89.1
Epoch: [85][161/704]	Time 0.122	Data 0.001	Loss 3.75	Acc@1 79.7	Acc@5 95.3
Epoch: [85][171/704]	Time 0.122	Data 0.001	Loss 6.81	Acc@1 60.9	Acc@5 87.5
Epoch: [85][181/704]	Time 0.122	Data 0.001	Loss 5.38	Acc@1 70.3	Acc@5 92.2
Epoch: [85][191/704]	Time 0.122	Data 0.001	Loss 4.34	Acc@1 76.6	Acc@5 93.8
Epoch: [85][201/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 70.3	Acc@5 92.2
Epoch: [85][211/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 65.6	Acc@5 89.1
Epoch: [85][221/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 65.6	Acc@5 92.2
Epoch: [85][231/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 59.4	Acc@5 89.1
Epoch: [85][241/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 73.4	Acc@5 95.3
Epoch: [85][251/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 68.8	Acc@5 95.3
Epoch: [85][261/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 64.1	Acc@5 92.2
Epoch: [85][271/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 71.9	Acc@5 95.3
Epoch: [85][281/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 71.9	Acc@5 92.2
Epoch: [85][291/704]	Time 0.121	Data 0.001	Loss 3.82	Acc@1 75.0	Acc@5 100.0
Epoch: [85][301/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 60.9	Acc@5 93.8
Epoch: [85][311/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 76.6	Acc@5 96.9
Epoch: [85][321/704]	Time 0.121	Data 0.001	Loss 6.97	Acc@1 56.2	Acc@5 90.6
Epoch: [85][331/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 70.3	Acc@5 95.3
Epoch: [85][341/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 59.4	Acc@5 93.8
Epoch: [85][351/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 70.3	Acc@5 93.8
Epoch: [85][361/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 62.5	Acc@5 92.2
Epoch: [85][371/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 70.3	Acc@5 92.2
Epoch: [85][381/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 59.4	Acc@5 95.3
Epoch: [85][391/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 92.2
Epoch: [85][401/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 65.6	Acc@5 93.8
Epoch: [85][411/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 67.2	Acc@5 89.1
Epoch: [85][421/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 73.4	Acc@5 92.2
Epoch: [85][431/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 68.8	Acc@5 96.9
Epoch: [85][441/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 65.6	Acc@5 96.9
Epoch: [85][451/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 59.4	Acc@5 92.2
Epoch: [85][461/704]	Time 0.121	Data 0.001	Loss 6.53	Acc@1 62.5	Acc@5 87.5
Epoch: [85][471/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 71.9	Acc@5 93.8
Epoch: [85][481/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 92.2
Epoch: [85][491/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 68.8	Acc@5 92.2
Epoch: [85][501/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 71.9	Acc@5 90.6
Epoch: [85][511/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 71.9	Acc@5 90.6
Epoch: [85][521/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 64.1	Acc@5 92.2
Epoch: [85][531/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 75.0	Acc@5 93.8
Epoch: [85][541/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 64.1	Acc@5 93.8
Epoch: [85][551/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 64.1	Acc@5 93.8
Epoch: [85][561/704]	Time 0.121	Data 0.001	Loss 6.38	Acc@1 62.5	Acc@5 89.1
Epoch: [85][571/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 67.2	Acc@5 95.3
Epoch: [85][581/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 92.2
Epoch: [85][591/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 56.2	Acc@5 92.2
Epoch: [85][601/704]	Time 0.121	Data 0.001	Loss 6.43	Acc@1 59.4	Acc@5 85.9
Epoch: [85][611/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 70.3	Acc@5 89.1
Epoch: [85][621/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 60.9	Acc@5 90.6
Epoch: [85][631/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 62.5	Acc@5 89.1
Epoch: [85][641/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 64.1	Acc@5 82.8
Epoch: [85][651/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 67.2	Acc@5 87.5
Epoch: [85][661/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 89.1
Epoch: [85][671/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 76.6	Acc@5 95.3
Epoch: [85][681/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 65.6	Acc@5 87.5
Epoch: [85][691/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 67.2	Acc@5 95.3
Epoch: [85][701/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 70.3	Acc@5 95.3
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.8620	Acc@1 50.0000	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.2966	Acc@1 68.7500	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6494	Acc@1 56.2500	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.5687	Acc@1 53.1250	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.7724	Acc@1 48.4375	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9441	Acc@1 51.5625	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.8588	Acc@1 56.2500	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7456	Acc@1 57.8125	Acc@5 87.5000
 * prec@1 45.500 prec@5 77.600
 * prec@1 50.420 prec@5 81.320
 * prec@1 55.400 prec@5 84.800
 * prec@1 57.560 prec@5 86.100
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_085.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_085.pth.tar'
Epoch: [86][1/704]	Time 0.300	Data 0.132	Loss 5.09	Acc@1 64.1	Acc@5 92.2
Epoch: [86][11/704]	Time 0.137	Data 0.012	Loss 5.67	Acc@1 67.2	Acc@5 87.5
Epoch: [86][21/704]	Time 0.129	Data 0.007	Loss 4.19	Acc@1 70.3	Acc@5 95.3
Epoch: [86][31/704]	Time 0.126	Data 0.005	Loss 5.00	Acc@1 68.8	Acc@5 93.8
Epoch: [86][41/704]	Time 0.125	Data 0.004	Loss 4.18	Acc@1 78.1	Acc@5 96.9
Epoch: [86][51/704]	Time 0.124	Data 0.003	Loss 4.94	Acc@1 70.3	Acc@5 90.6
Epoch: [86][61/704]	Time 0.123	Data 0.003	Loss 4.53	Acc@1 71.9	Acc@5 93.8
Epoch: [86][71/704]	Time 0.123	Data 0.002	Loss 4.75	Acc@1 75.0	Acc@5 93.8
Epoch: [86][81/704]	Time 0.122	Data 0.002	Loss 5.34	Acc@1 59.4	Acc@5 93.8
Epoch: [86][91/704]	Time 0.123	Data 0.002	Loss 4.79	Acc@1 60.9	Acc@5 90.6
Epoch: [86][101/704]	Time 0.123	Data 0.002	Loss 5.52	Acc@1 64.1	Acc@5 87.5
Epoch: [86][111/704]	Time 0.122	Data 0.002	Loss 5.66	Acc@1 67.2	Acc@5 92.2
Epoch: [86][121/704]	Time 0.122	Data 0.001	Loss 4.90	Acc@1 71.9	Acc@5 92.2
Epoch: [86][131/704]	Time 0.122	Data 0.001	Loss 4.11	Acc@1 75.0	Acc@5 95.3
Epoch: [86][141/704]	Time 0.122	Data 0.001	Loss 4.67	Acc@1 75.0	Acc@5 92.2
Epoch: [86][151/704]	Time 0.122	Data 0.001	Loss 4.63	Acc@1 76.6	Acc@5 90.6
Epoch: [86][161/704]	Time 0.122	Data 0.001	Loss 4.35	Acc@1 75.0	Acc@5 98.4
Epoch: [86][171/704]	Time 0.122	Data 0.001	Loss 4.53	Acc@1 79.7	Acc@5 92.2
Epoch: [86][181/704]	Time 0.122	Data 0.001	Loss 4.47	Acc@1 76.6	Acc@5 89.1
Epoch: [86][191/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 68.8	Acc@5 95.3
Epoch: [86][201/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 70.3	Acc@5 92.2
Epoch: [86][211/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 70.3	Acc@5 95.3
Epoch: [86][221/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 62.5	Acc@5 95.3
Epoch: [86][231/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 62.5	Acc@5 90.6
Epoch: [86][241/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 70.3	Acc@5 96.9
Epoch: [86][251/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 65.6	Acc@5 95.3
Epoch: [86][261/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 65.6	Acc@5 95.3
Epoch: [86][271/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 73.4	Acc@5 92.2
Epoch: [86][281/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 65.6	Acc@5 95.3
Epoch: [86][291/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 59.4	Acc@5 90.6
Epoch: [86][301/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 75.0	Acc@5 90.6
Epoch: [86][311/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 78.1	Acc@5 96.9
Epoch: [86][321/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 71.9	Acc@5 90.6
Epoch: [86][331/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 75.0	Acc@5 93.8
Epoch: [86][341/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 79.7	Acc@5 96.9
Epoch: [86][351/704]	Time 0.121	Data 0.001	Loss 7.29	Acc@1 45.3	Acc@5 82.8
Epoch: [86][361/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 68.8	Acc@5 93.8
Epoch: [86][371/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 95.3
Epoch: [86][381/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 71.9	Acc@5 90.6
Epoch: [86][391/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 71.9	Acc@5 93.8
Epoch: [86][401/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 65.6	Acc@5 85.9
Epoch: [86][411/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 64.1	Acc@5 93.8
Epoch: [86][421/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 70.3	Acc@5 90.6
Epoch: [86][431/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 57.8	Acc@5 90.6
Epoch: [86][441/704]	Time 0.121	Data 0.001	Loss 6.57	Acc@1 57.8	Acc@5 82.8
Epoch: [86][451/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 67.2	Acc@5 92.2
Epoch: [86][461/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 70.3	Acc@5 96.9
Epoch: [86][471/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 67.2	Acc@5 90.6
Epoch: [86][481/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 73.4	Acc@5 87.5
Epoch: [86][491/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 71.9	Acc@5 96.9
Epoch: [86][501/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 65.6	Acc@5 92.2
Epoch: [86][511/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 64.1	Acc@5 90.6
Epoch: [86][521/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 68.8	Acc@5 96.9
Epoch: [86][531/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 67.2	Acc@5 95.3
Epoch: [86][541/704]	Time 0.121	Data 0.001	Loss 6.50	Acc@1 56.2	Acc@5 89.1
Epoch: [86][551/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 68.8	Acc@5 90.6
Epoch: [86][561/704]	Time 0.121	Data 0.001	Loss 6.99	Acc@1 56.2	Acc@5 84.4
Epoch: [86][571/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 62.5	Acc@5 81.2
Epoch: [86][581/704]	Time 0.121	Data 0.001	Loss 4.15	Acc@1 76.6	Acc@5 90.6
Epoch: [86][591/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 70.3	Acc@5 93.8
Epoch: [86][601/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 73.4	Acc@5 89.1
Epoch: [86][611/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 68.8	Acc@5 92.2
Epoch: [86][621/704]	Time 0.121	Data 0.001	Loss 6.61	Acc@1 59.4	Acc@5 87.5
Epoch: [86][631/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 95.3
Epoch: [86][641/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 64.1	Acc@5 92.2
Epoch: [86][651/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 64.1	Acc@5 98.4
Epoch: [86][661/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 60.9	Acc@5 89.1
Epoch: [86][671/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 79.7	Acc@5 96.9
Epoch: [86][681/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 68.8	Acc@5 89.1
Epoch: [86][691/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 62.5	Acc@5 87.5
Epoch: [86][701/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 68.8	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.3006	Acc@1 65.6250	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.5223	Acc@1 48.4375	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.4700	Acc@1 56.2500	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.6856	Acc@1 50.0000	Acc@5 76.5625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.7863	Acc@1 59.3750	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.2673	Acc@1 64.0625	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.1566	Acc@1 53.1250	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.4227	Acc@1 48.4375	Acc@5 82.8125
 * prec@1 47.600 prec@5 78.160
 * prec@1 51.360 prec@5 82.760
 * prec@1 56.220 prec@5 85.480
 * prec@1 56.500 prec@5 85.520
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_086.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_086.pth.tar'
Epoch: [87][1/704]	Time 0.299	Data 0.131	Loss 5.08	Acc@1 68.8	Acc@5 90.6
Epoch: [87][11/704]	Time 0.140	Data 0.012	Loss 4.85	Acc@1 70.3	Acc@5 93.8
Epoch: [87][21/704]	Time 0.131	Data 0.007	Loss 6.01	Acc@1 62.5	Acc@5 93.8
Epoch: [87][31/704]	Time 0.127	Data 0.005	Loss 4.98	Acc@1 75.0	Acc@5 93.8
Epoch: [87][41/704]	Time 0.125	Data 0.004	Loss 5.04	Acc@1 64.1	Acc@5 92.2
Epoch: [87][51/704]	Time 0.124	Data 0.003	Loss 5.60	Acc@1 57.8	Acc@5 95.3
Epoch: [87][61/704]	Time 0.124	Data 0.002	Loss 5.18	Acc@1 75.0	Acc@5 93.8
Epoch: [87][71/704]	Time 0.123	Data 0.002	Loss 5.36	Acc@1 64.1	Acc@5 89.1
Epoch: [87][81/704]	Time 0.123	Data 0.002	Loss 5.02	Acc@1 75.0	Acc@5 89.1
Epoch: [87][91/704]	Time 0.122	Data 0.002	Loss 4.77	Acc@1 76.6	Acc@5 95.3
Epoch: [87][101/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 67.2	Acc@5 96.9
Epoch: [87][111/704]	Time 0.122	Data 0.002	Loss 4.66	Acc@1 68.8	Acc@5 98.4
Epoch: [87][121/704]	Time 0.122	Data 0.001	Loss 4.72	Acc@1 73.4	Acc@5 95.3
Epoch: [87][131/704]	Time 0.122	Data 0.001	Loss 4.93	Acc@1 70.3	Acc@5 90.6
Epoch: [87][141/704]	Time 0.122	Data 0.001	Loss 5.94	Acc@1 60.9	Acc@5 87.5
Epoch: [87][151/704]	Time 0.122	Data 0.001	Loss 5.71	Acc@1 70.3	Acc@5 93.8
Epoch: [87][161/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 65.6	Acc@5 95.3
Epoch: [87][171/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 70.3	Acc@5 98.4
Epoch: [87][181/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 79.7	Acc@5 96.9
Epoch: [87][191/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 65.6	Acc@5 96.9
Epoch: [87][201/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 68.8	Acc@5 93.8
Epoch: [87][211/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 67.2	Acc@5 100.0
Epoch: [87][221/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 57.8	Acc@5 87.5
Epoch: [87][231/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 75.0	Acc@5 93.8
Epoch: [87][241/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 89.1	Acc@5 98.4
Epoch: [87][251/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 78.1	Acc@5 93.8
Epoch: [87][261/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 75.0	Acc@5 96.9
Epoch: [87][271/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 71.9	Acc@5 92.2
Epoch: [87][281/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 67.2	Acc@5 93.8
Epoch: [87][291/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 68.8	Acc@5 93.8
Epoch: [87][301/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 62.5	Acc@5 96.9
Epoch: [87][311/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 68.8	Acc@5 95.3
Epoch: [87][321/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 68.8	Acc@5 92.2
Epoch: [87][331/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 68.8	Acc@5 92.2
Epoch: [87][341/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 65.6	Acc@5 89.1
Epoch: [87][351/704]	Time 0.121	Data 0.001	Loss 4.01	Acc@1 75.0	Acc@5 92.2
Epoch: [87][361/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 78.1	Acc@5 92.2
Epoch: [87][371/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 75.0	Acc@5 93.8
Epoch: [87][381/704]	Time 0.121	Data 0.001	Loss 3.72	Acc@1 76.6	Acc@5 98.4
Epoch: [87][391/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 65.6	Acc@5 89.1
Epoch: [87][401/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 70.3	Acc@5 95.3
Epoch: [87][411/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 64.1	Acc@5 89.1
Epoch: [87][421/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 65.6	Acc@5 89.1
Epoch: [87][431/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 71.9	Acc@5 93.8
Epoch: [87][441/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 76.6	Acc@5 96.9
Epoch: [87][451/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 70.3	Acc@5 93.8
Epoch: [87][461/704]	Time 0.121	Data 0.001	Loss 6.72	Acc@1 53.1	Acc@5 89.1
Epoch: [87][471/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 73.4	Acc@5 95.3
Epoch: [87][481/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 65.6	Acc@5 90.6
Epoch: [87][491/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 70.3	Acc@5 93.8
Epoch: [87][501/704]	Time 0.121	Data 0.001	Loss 6.35	Acc@1 59.4	Acc@5 89.1
Epoch: [87][511/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 70.3	Acc@5 98.4
Epoch: [87][521/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 65.6	Acc@5 96.9
Epoch: [87][531/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 68.8	Acc@5 93.8
Epoch: [87][541/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 62.5	Acc@5 92.2
Epoch: [87][551/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 65.6	Acc@5 96.9
Epoch: [87][561/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 71.9	Acc@5 95.3
Epoch: [87][571/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 64.1	Acc@5 90.6
Epoch: [87][581/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 76.6	Acc@5 95.3
Epoch: [87][591/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 73.4	Acc@5 87.5
Epoch: [87][601/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 65.6	Acc@5 93.8
Epoch: [87][611/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 67.2	Acc@5 89.1
Epoch: [87][621/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 62.5	Acc@5 87.5
Epoch: [87][631/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 71.9	Acc@5 93.8
Epoch: [87][641/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 67.2	Acc@5 93.8
Epoch: [87][651/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 73.4	Acc@5 89.1
Epoch: [87][661/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 64.1	Acc@5 89.1
Epoch: [87][671/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 65.6	Acc@5 89.1
Epoch: [87][681/704]	Time 0.120	Data 0.001	Loss 4.38	Acc@1 71.9	Acc@5 96.9
Epoch: [87][691/704]	Time 0.120	Data 0.001	Loss 6.12	Acc@1 62.5	Acc@5 90.6
Epoch: [87][701/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 70.3	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5899	Acc@1 51.5625	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7473	Acc@1 64.0625	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.1435	Acc@1 62.5000	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0519	Acc@1 50.0000	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.7540	Acc@1 53.1250	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.5669	Acc@1 53.1250	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.0246	Acc@1 59.3750	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.5213	Acc@1 73.4375	Acc@5 92.1875
 * prec@1 46.840 prec@5 78.460
 * prec@1 52.240 prec@5 82.300
 * prec@1 56.160 prec@5 85.220
 * prec@1 57.200 prec@5 86.280
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_087.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_087.pth.tar'
Epoch: [88][1/704]	Time 0.330	Data 0.164	Loss 4.22	Acc@1 73.4	Acc@5 93.8
Epoch: [88][11/704]	Time 0.140	Data 0.015	Loss 5.27	Acc@1 68.8	Acc@5 95.3
Epoch: [88][21/704]	Time 0.130	Data 0.008	Loss 5.19	Acc@1 64.1	Acc@5 93.8
Epoch: [88][31/704]	Time 0.127	Data 0.006	Loss 4.70	Acc@1 62.5	Acc@5 93.8
Epoch: [88][41/704]	Time 0.126	Data 0.004	Loss 4.37	Acc@1 78.1	Acc@5 95.3
Epoch: [88][51/704]	Time 0.124	Data 0.004	Loss 5.14	Acc@1 64.1	Acc@5 90.6
Epoch: [88][61/704]	Time 0.124	Data 0.003	Loss 6.03	Acc@1 62.5	Acc@5 90.6
Epoch: [88][71/704]	Time 0.123	Data 0.003	Loss 4.14	Acc@1 76.6	Acc@5 96.9
Epoch: [88][81/704]	Time 0.123	Data 0.002	Loss 6.51	Acc@1 57.8	Acc@5 89.1
Epoch: [88][91/704]	Time 0.123	Data 0.002	Loss 4.93	Acc@1 65.6	Acc@5 93.8
Epoch: [88][101/704]	Time 0.122	Data 0.002	Loss 4.14	Acc@1 78.1	Acc@5 93.8
Epoch: [88][111/704]	Time 0.122	Data 0.002	Loss 5.14	Acc@1 65.6	Acc@5 89.1
Epoch: [88][121/704]	Time 0.122	Data 0.002	Loss 5.38	Acc@1 75.0	Acc@5 95.3
Epoch: [88][131/704]	Time 0.122	Data 0.002	Loss 4.52	Acc@1 67.2	Acc@5 98.4
Epoch: [88][141/704]	Time 0.122	Data 0.002	Loss 3.73	Acc@1 75.0	Acc@5 96.9
Epoch: [88][151/704]	Time 0.122	Data 0.001	Loss 5.35	Acc@1 68.8	Acc@5 89.1
Epoch: [88][161/704]	Time 0.122	Data 0.001	Loss 5.56	Acc@1 67.2	Acc@5 93.8
Epoch: [88][171/704]	Time 0.122	Data 0.001	Loss 5.45	Acc@1 60.9	Acc@5 92.2
Epoch: [88][181/704]	Time 0.121	Data 0.001	Loss 3.88	Acc@1 82.8	Acc@5 96.9
Epoch: [88][191/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 68.8	Acc@5 90.6
Epoch: [88][201/704]	Time 0.121	Data 0.001	Loss 7.08	Acc@1 60.9	Acc@5 89.1
Epoch: [88][211/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 67.2	Acc@5 92.2
Epoch: [88][221/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 73.4	Acc@5 90.6
Epoch: [88][231/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 64.1	Acc@5 89.1
Epoch: [88][241/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 65.6	Acc@5 90.6
Epoch: [88][251/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 81.2	Acc@5 95.3
Epoch: [88][261/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 68.8	Acc@5 87.5
Epoch: [88][271/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 62.5	Acc@5 85.9
Epoch: [88][281/704]	Time 0.121	Data 0.001	Loss 6.62	Acc@1 57.8	Acc@5 89.1
Epoch: [88][291/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 67.2	Acc@5 92.2
Epoch: [88][301/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 89.1
Epoch: [88][311/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 60.9	Acc@5 92.2
Epoch: [88][321/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 64.1	Acc@5 92.2
Epoch: [88][331/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 70.3	Acc@5 92.2
Epoch: [88][341/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 60.9	Acc@5 90.6
Epoch: [88][351/704]	Time 0.121	Data 0.001	Loss 7.06	Acc@1 53.1	Acc@5 85.9
Epoch: [88][361/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 62.5	Acc@5 95.3
Epoch: [88][371/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 65.6	Acc@5 90.6
Epoch: [88][381/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 68.8	Acc@5 93.8
Epoch: [88][391/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 62.5	Acc@5 95.3
Epoch: [88][401/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 71.9	Acc@5 90.6
Epoch: [88][411/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 67.2	Acc@5 89.1
Epoch: [88][421/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 68.8	Acc@5 90.6
Epoch: [88][431/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 67.2	Acc@5 84.4
Epoch: [88][441/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 62.5	Acc@5 92.2
Epoch: [88][451/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 73.4	Acc@5 95.3
Epoch: [88][461/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 75.0	Acc@5 96.9
Epoch: [88][471/704]	Time 0.121	Data 0.001	Loss 4.28	Acc@1 73.4	Acc@5 98.4
Epoch: [88][481/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 93.8
Epoch: [88][491/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 60.9	Acc@5 90.6
Epoch: [88][501/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 81.2	Acc@5 92.2
Epoch: [88][511/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 59.4	Acc@5 93.8
Epoch: [88][521/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 65.6	Acc@5 95.3
Epoch: [88][531/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 60.9	Acc@5 89.1
Epoch: [88][541/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 70.3	Acc@5 95.3
Epoch: [88][551/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 76.6	Acc@5 98.4
Epoch: [88][561/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 62.5	Acc@5 89.1
Epoch: [88][571/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 75.0	Acc@5 96.9
Epoch: [88][581/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 65.6	Acc@5 93.8
Epoch: [88][591/704]	Time 0.121	Data 0.001	Loss 6.35	Acc@1 59.4	Acc@5 90.6
Epoch: [88][601/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 67.2	Acc@5 93.8
Epoch: [88][611/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 65.6	Acc@5 90.6
Epoch: [88][621/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 68.8	Acc@5 95.3
Epoch: [88][631/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 68.8	Acc@5 93.8
Epoch: [88][641/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 68.8	Acc@5 92.2
Epoch: [88][651/704]	Time 0.121	Data 0.001	Loss 6.85	Acc@1 54.7	Acc@5 87.5
Epoch: [88][661/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 76.6	Acc@5 96.9
Epoch: [88][671/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 70.3	Acc@5 98.4
Epoch: [88][681/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 70.3	Acc@5 90.6
Epoch: [88][691/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 73.4	Acc@5 90.6
Epoch: [88][701/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 62.5	Acc@5 95.3
Epoch: [1/79]	Time 0.103	Data 0.088	Loss 6.7448	Acc@1 46.8750	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8092	Acc@1 51.5625	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.2610	Acc@1 45.3125	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.4565	Acc@1 53.1250	Acc@5 78.1250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.1072	Acc@1 48.4375	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.4502	Acc@1 54.6875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.5255	Acc@1 67.1875	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.7773	Acc@1 54.6875	Acc@5 81.2500
 * prec@1 46.020 prec@5 77.820
 * prec@1 50.400 prec@5 82.080
 * prec@1 55.140 prec@5 84.280
 * prec@1 56.180 prec@5 85.280
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_088.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_088.pth.tar'
Epoch: [89][1/704]	Time 0.302	Data 0.135	Loss 5.57	Acc@1 60.9	Acc@5 93.8
Epoch: [89][11/704]	Time 0.137	Data 0.013	Loss 4.34	Acc@1 73.4	Acc@5 92.2
Epoch: [89][21/704]	Time 0.129	Data 0.007	Loss 5.33	Acc@1 64.1	Acc@5 93.8
Epoch: [89][31/704]	Time 0.126	Data 0.005	Loss 4.54	Acc@1 70.3	Acc@5 95.3
Epoch: [89][41/704]	Time 0.125	Data 0.004	Loss 5.46	Acc@1 64.1	Acc@5 90.6
Epoch: [89][51/704]	Time 0.124	Data 0.003	Loss 5.47	Acc@1 71.9	Acc@5 93.8
Epoch: [89][61/704]	Time 0.123	Data 0.003	Loss 4.80	Acc@1 67.2	Acc@5 95.3
Epoch: [89][71/704]	Time 0.123	Data 0.002	Loss 4.52	Acc@1 75.0	Acc@5 90.6
Epoch: [89][81/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 75.0	Acc@5 93.8
Epoch: [89][91/704]	Time 0.122	Data 0.002	Loss 3.52	Acc@1 78.1	Acc@5 96.9
Epoch: [89][101/704]	Time 0.122	Data 0.002	Loss 5.18	Acc@1 62.5	Acc@5 90.6
Epoch: [89][111/704]	Time 0.122	Data 0.002	Loss 5.51	Acc@1 70.3	Acc@5 89.1
Epoch: [89][121/704]	Time 0.122	Data 0.001	Loss 5.41	Acc@1 59.4	Acc@5 92.2
Epoch: [89][131/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 73.4	Acc@5 92.2
Epoch: [89][141/704]	Time 0.122	Data 0.001	Loss 4.44	Acc@1 75.0	Acc@5 95.3
Epoch: [89][151/704]	Time 0.122	Data 0.001	Loss 4.43	Acc@1 73.4	Acc@5 96.9
Epoch: [89][161/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 73.4	Acc@5 98.4
Epoch: [89][171/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 93.8
Epoch: [89][181/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 68.8	Acc@5 93.8
Epoch: [89][191/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 70.3	Acc@5 92.2
Epoch: [89][201/704]	Time 0.121	Data 0.001	Loss 6.93	Acc@1 59.4	Acc@5 89.1
Epoch: [89][211/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 70.3	Acc@5 90.6
Epoch: [89][221/704]	Time 0.121	Data 0.001	Loss 6.56	Acc@1 62.5	Acc@5 85.9
Epoch: [89][231/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 70.3	Acc@5 92.2
Epoch: [89][241/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 70.3	Acc@5 92.2
Epoch: [89][251/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 71.9	Acc@5 96.9
Epoch: [89][261/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 68.8	Acc@5 95.3
Epoch: [89][271/704]	Time 0.121	Data 0.001	Loss 4.25	Acc@1 67.2	Acc@5 95.3
Epoch: [89][281/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 71.9	Acc@5 96.9
Epoch: [89][291/704]	Time 0.121	Data 0.001	Loss 6.78	Acc@1 57.8	Acc@5 82.8
Epoch: [89][301/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 90.6
Epoch: [89][311/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 51.6	Acc@5 89.1
Epoch: [89][321/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 76.6	Acc@5 95.3
Epoch: [89][331/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 65.6	Acc@5 92.2
Epoch: [89][341/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 65.6	Acc@5 92.2
Epoch: [89][351/704]	Time 0.121	Data 0.001	Loss 6.26	Acc@1 64.1	Acc@5 87.5
Epoch: [89][361/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 68.8	Acc@5 93.8
Epoch: [89][371/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 71.9	Acc@5 89.1
Epoch: [89][381/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 70.3	Acc@5 93.8
Epoch: [89][391/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 70.3	Acc@5 96.9
Epoch: [89][401/704]	Time 0.121	Data 0.001	Loss 3.68	Acc@1 75.0	Acc@5 92.2
Epoch: [89][411/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 60.9	Acc@5 90.6
Epoch: [89][421/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 70.3	Acc@5 92.2
Epoch: [89][431/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 68.8	Acc@5 90.6
Epoch: [89][441/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 57.8	Acc@5 90.6
Epoch: [89][451/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 67.2	Acc@5 93.8
Epoch: [89][461/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 73.4	Acc@5 93.8
Epoch: [89][471/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 70.3	Acc@5 92.2
Epoch: [89][481/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 67.2	Acc@5 92.2
Epoch: [89][491/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 75.0	Acc@5 96.9
Epoch: [89][501/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 60.9	Acc@5 87.5
Epoch: [89][511/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 68.8	Acc@5 90.6
Epoch: [89][521/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 85.9	Acc@5 100.0
Epoch: [89][531/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 64.1	Acc@5 92.2
Epoch: [89][541/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 71.9	Acc@5 93.8
Epoch: [89][551/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 64.1	Acc@5 90.6
Epoch: [89][561/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 65.6	Acc@5 93.8
Epoch: [89][571/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 59.4	Acc@5 95.3
Epoch: [89][581/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 68.8	Acc@5 93.8
Epoch: [89][591/704]	Time 0.120	Data 0.001	Loss 7.21	Acc@1 62.5	Acc@5 85.9
Epoch: [89][601/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 64.1	Acc@5 92.2
Epoch: [89][611/704]	Time 0.120	Data 0.001	Loss 5.46	Acc@1 67.2	Acc@5 95.3
Epoch: [89][621/704]	Time 0.120	Data 0.001	Loss 5.01	Acc@1 71.9	Acc@5 90.6
Epoch: [89][631/704]	Time 0.120	Data 0.001	Loss 6.64	Acc@1 64.1	Acc@5 87.5
Epoch: [89][641/704]	Time 0.120	Data 0.001	Loss 6.51	Acc@1 64.1	Acc@5 87.5
Epoch: [89][651/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 71.9	Acc@5 95.3
Epoch: [89][661/704]	Time 0.120	Data 0.001	Loss 5.68	Acc@1 65.6	Acc@5 90.6
Epoch: [89][671/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 67.2	Acc@5 93.8
Epoch: [89][681/704]	Time 0.120	Data 0.001	Loss 5.10	Acc@1 68.8	Acc@5 92.2
Epoch: [89][691/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 71.9	Acc@5 90.6
Epoch: [89][701/704]	Time 0.120	Data 0.001	Loss 4.69	Acc@1 76.6	Acc@5 96.9
Epoch: [1/79]	Time 0.104	Data 0.089	Loss 6.4546	Acc@1 54.6875	Acc@5 89.0625
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 6.5009	Acc@1 62.5000	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.1701	Acc@1 51.5625	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.0013	Acc@1 59.3750	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.2892	Acc@1 53.1250	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.3217	Acc@1 64.0625	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.1740	Acc@1 62.5000	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.4863	Acc@1 53.1250	Acc@5 82.8125
 * prec@1 47.080 prec@5 77.280
 * prec@1 51.280 prec@5 81.040
 * prec@1 56.280 prec@5 84.740
 * prec@1 57.480 prec@5 85.340
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_089.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_089.pth.tar'
Epoch: [90][1/704]	Time 0.299	Data 0.132	Loss 4.63	Acc@1 71.9	Acc@5 92.2
Epoch: [90][11/704]	Time 0.136	Data 0.012	Loss 4.40	Acc@1 78.1	Acc@5 93.8
Epoch: [90][21/704]	Time 0.128	Data 0.007	Loss 4.83	Acc@1 71.9	Acc@5 96.9
Epoch: [90][31/704]	Time 0.126	Data 0.005	Loss 5.57	Acc@1 67.2	Acc@5 92.2
Epoch: [90][41/704]	Time 0.124	Data 0.004	Loss 5.13	Acc@1 75.0	Acc@5 92.2
Epoch: [90][51/704]	Time 0.123	Data 0.003	Loss 5.62	Acc@1 57.8	Acc@5 89.1
Epoch: [90][61/704]	Time 0.124	Data 0.002	Loss 6.38	Acc@1 56.2	Acc@5 90.6
Epoch: [90][71/704]	Time 0.123	Data 0.002	Loss 5.13	Acc@1 68.8	Acc@5 95.3
Epoch: [90][81/704]	Time 0.123	Data 0.002	Loss 4.91	Acc@1 70.3	Acc@5 98.4
Epoch: [90][91/704]	Time 0.122	Data 0.002	Loss 5.82	Acc@1 67.2	Acc@5 92.2
Epoch: [90][101/704]	Time 0.122	Data 0.002	Loss 4.42	Acc@1 73.4	Acc@5 96.9
Epoch: [90][111/704]	Time 0.122	Data 0.001	Loss 5.38	Acc@1 62.5	Acc@5 90.6
Epoch: [90][121/704]	Time 0.122	Data 0.001	Loss 6.07	Acc@1 59.4	Acc@5 87.5
Epoch: [90][131/704]	Time 0.122	Data 0.001	Loss 5.83	Acc@1 65.6	Acc@5 90.6
Epoch: [90][141/704]	Time 0.122	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 92.2
Epoch: [90][151/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 75.0	Acc@5 90.6
Epoch: [90][161/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 75.0	Acc@5 95.3
Epoch: [90][171/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 71.9	Acc@5 93.8
Epoch: [90][181/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 68.8	Acc@5 96.9
Epoch: [90][191/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 67.2	Acc@5 95.3
Epoch: [90][201/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 75.0	Acc@5 93.8
Epoch: [90][211/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 70.3	Acc@5 95.3
Epoch: [90][221/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 65.6	Acc@5 89.1
Epoch: [90][231/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 67.2	Acc@5 93.8
Epoch: [90][241/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 70.3	Acc@5 87.5
Epoch: [90][251/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 71.9	Acc@5 90.6
Epoch: [90][261/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 59.4	Acc@5 89.1
Epoch: [90][271/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 65.6	Acc@5 89.1
Epoch: [90][281/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 70.3	Acc@5 96.9
Epoch: [90][291/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 64.1	Acc@5 90.6
Epoch: [90][301/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 56.2	Acc@5 85.9
Epoch: [90][311/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 68.8	Acc@5 89.1
Epoch: [90][321/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 68.8	Acc@5 85.9
Epoch: [90][331/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 73.4	Acc@5 93.8
Epoch: [90][341/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 67.2	Acc@5 95.3
Epoch: [90][351/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 68.8	Acc@5 90.6
Epoch: [90][361/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 60.9	Acc@5 87.5
Epoch: [90][371/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 67.2	Acc@5 87.5
Epoch: [90][381/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 75.0	Acc@5 95.3
Epoch: [90][391/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 90.6
Epoch: [90][401/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 73.4	Acc@5 93.8
Epoch: [90][411/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 64.1	Acc@5 96.9
Epoch: [90][421/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 65.6	Acc@5 96.9
Epoch: [90][431/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 70.3	Acc@5 93.8
Epoch: [90][441/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 57.8	Acc@5 89.1
Epoch: [90][451/704]	Time 0.121	Data 0.001	Loss 3.98	Acc@1 73.4	Acc@5 96.9
Epoch: [90][461/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 60.9	Acc@5 92.2
Epoch: [90][471/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 71.9	Acc@5 92.2
Epoch: [90][481/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 73.4	Acc@5 92.2
Epoch: [90][491/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 57.8	Acc@5 89.1
Epoch: [90][501/704]	Time 0.120	Data 0.001	Loss 6.11	Acc@1 62.5	Acc@5 92.2
Epoch: [90][511/704]	Time 0.120	Data 0.001	Loss 5.70	Acc@1 67.2	Acc@5 93.8
Epoch: [90][521/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 65.6	Acc@5 87.5
Epoch: [90][531/704]	Time 0.120	Data 0.001	Loss 4.77	Acc@1 71.9	Acc@5 95.3
Epoch: [90][541/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 71.9	Acc@5 84.4
Epoch: [90][551/704]	Time 0.120	Data 0.001	Loss 4.31	Acc@1 73.4	Acc@5 95.3
Epoch: [90][561/704]	Time 0.120	Data 0.001	Loss 4.53	Acc@1 75.0	Acc@5 98.4
Epoch: [90][571/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 70.3	Acc@5 96.9
Epoch: [90][581/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 54.7	Acc@5 89.1
Epoch: [90][591/704]	Time 0.120	Data 0.001	Loss 4.55	Acc@1 71.9	Acc@5 93.8
Epoch: [90][601/704]	Time 0.120	Data 0.001	Loss 4.28	Acc@1 73.4	Acc@5 95.3
Epoch: [90][611/704]	Time 0.120	Data 0.001	Loss 4.38	Acc@1 73.4	Acc@5 98.4
Epoch: [90][621/704]	Time 0.120	Data 0.001	Loss 6.06	Acc@1 64.1	Acc@5 92.2
Epoch: [90][631/704]	Time 0.120	Data 0.001	Loss 5.67	Acc@1 67.2	Acc@5 90.6
Epoch: [90][641/704]	Time 0.120	Data 0.001	Loss 6.89	Acc@1 51.6	Acc@5 85.9
Epoch: [90][651/704]	Time 0.120	Data 0.001	Loss 5.39	Acc@1 65.6	Acc@5 89.1
Epoch: [90][661/704]	Time 0.120	Data 0.001	Loss 4.07	Acc@1 78.1	Acc@5 90.6
Epoch: [90][671/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 70.3	Acc@5 84.4
Epoch: [90][681/704]	Time 0.120	Data 0.001	Loss 4.83	Acc@1 78.1	Acc@5 93.8
Epoch: [90][691/704]	Time 0.120	Data 0.001	Loss 5.09	Acc@1 64.1	Acc@5 92.2
Epoch: [90][701/704]	Time 0.120	Data 0.001	Loss 4.22	Acc@1 75.0	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.8204	Acc@1 56.2500	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.2237	Acc@1 53.1250	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.3035	Acc@1 64.0625	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3908	Acc@1 64.0625	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6327	Acc@1 65.6250	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9694	Acc@1 57.8125	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.2122	Acc@1 70.3125	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.9654	Acc@1 56.2500	Acc@5 89.0625
 * prec@1 46.020 prec@5 76.980
 * prec@1 52.500 prec@5 82.360
 * prec@1 56.900 prec@5 84.540
 * prec@1 57.000 prec@5 85.780
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_090.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_090.pth.tar'
Epoch: [91][1/704]	Time 0.330	Data 0.165	Loss 4.44	Acc@1 70.3	Acc@5 90.6
Epoch: [91][11/704]	Time 0.139	Data 0.015	Loss 5.40	Acc@1 67.2	Acc@5 92.2
Epoch: [91][21/704]	Time 0.130	Data 0.008	Loss 5.32	Acc@1 65.6	Acc@5 95.3
Epoch: [91][31/704]	Time 0.127	Data 0.006	Loss 4.71	Acc@1 73.4	Acc@5 95.3
Epoch: [91][41/704]	Time 0.125	Data 0.004	Loss 5.92	Acc@1 65.6	Acc@5 92.2
Epoch: [91][51/704]	Time 0.124	Data 0.004	Loss 4.12	Acc@1 78.1	Acc@5 95.3
Epoch: [91][61/704]	Time 0.123	Data 0.003	Loss 4.85	Acc@1 71.9	Acc@5 95.3
Epoch: [91][71/704]	Time 0.123	Data 0.003	Loss 5.24	Acc@1 70.3	Acc@5 90.6
Epoch: [91][81/704]	Time 0.122	Data 0.002	Loss 3.91	Acc@1 70.3	Acc@5 96.9
Epoch: [91][91/704]	Time 0.122	Data 0.002	Loss 5.08	Acc@1 68.8	Acc@5 90.6
Epoch: [91][101/704]	Time 0.122	Data 0.002	Loss 5.43	Acc@1 67.2	Acc@5 92.2
Epoch: [91][111/704]	Time 0.122	Data 0.002	Loss 4.63	Acc@1 65.6	Acc@5 93.8
Epoch: [91][121/704]	Time 0.122	Data 0.002	Loss 4.03	Acc@1 79.7	Acc@5 96.9
Epoch: [91][131/704]	Time 0.121	Data 0.002	Loss 4.05	Acc@1 76.6	Acc@5 95.3
Epoch: [91][141/704]	Time 0.121	Data 0.002	Loss 4.37	Acc@1 75.0	Acc@5 93.8
Epoch: [91][151/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 71.9	Acc@5 95.3
Epoch: [91][161/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 62.5	Acc@5 89.1
Epoch: [91][171/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 67.2	Acc@5 95.3
Epoch: [91][181/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 73.4	Acc@5 96.9
Epoch: [91][191/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 71.9	Acc@5 92.2
Epoch: [91][201/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 65.6	Acc@5 93.8
Epoch: [91][211/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 70.3	Acc@5 92.2
Epoch: [91][221/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 71.9	Acc@5 92.2
Epoch: [91][231/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 70.3	Acc@5 93.8
Epoch: [91][241/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 70.3	Acc@5 96.9
Epoch: [91][251/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 62.5	Acc@5 92.2
Epoch: [91][261/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 65.6	Acc@5 90.6
Epoch: [91][271/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 68.8	Acc@5 96.9
Epoch: [91][281/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 62.5	Acc@5 98.4
Epoch: [91][291/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 71.9	Acc@5 87.5
Epoch: [91][301/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 68.8	Acc@5 90.6
Epoch: [91][311/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 57.8	Acc@5 87.5
Epoch: [91][321/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 68.8	Acc@5 93.8
Epoch: [91][331/704]	Time 0.120	Data 0.001	Loss 4.55	Acc@1 71.9	Acc@5 90.6
Epoch: [91][341/704]	Time 0.120	Data 0.001	Loss 4.68	Acc@1 73.4	Acc@5 95.3
Epoch: [91][351/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 68.8	Acc@5 89.1
Epoch: [91][361/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 78.1	Acc@5 95.3
Epoch: [91][371/704]	Time 0.120	Data 0.001	Loss 4.85	Acc@1 73.4	Acc@5 96.9
Epoch: [91][381/704]	Time 0.120	Data 0.001	Loss 5.76	Acc@1 65.6	Acc@5 89.1
Epoch: [91][391/704]	Time 0.120	Data 0.001	Loss 6.40	Acc@1 60.9	Acc@5 93.8
Epoch: [91][401/704]	Time 0.120	Data 0.001	Loss 6.45	Acc@1 60.9	Acc@5 89.1
Epoch: [91][411/704]	Time 0.120	Data 0.001	Loss 4.07	Acc@1 76.6	Acc@5 95.3
Epoch: [91][421/704]	Time 0.120	Data 0.001	Loss 5.65	Acc@1 64.1	Acc@5 89.1
Epoch: [91][431/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 73.4	Acc@5 95.3
Epoch: [91][441/704]	Time 0.120	Data 0.001	Loss 6.07	Acc@1 64.1	Acc@5 87.5
Epoch: [91][451/704]	Time 0.120	Data 0.001	Loss 4.96	Acc@1 64.1	Acc@5 87.5
Epoch: [91][461/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 62.5	Acc@5 93.8
Epoch: [91][471/704]	Time 0.120	Data 0.001	Loss 4.43	Acc@1 70.3	Acc@5 92.2
Epoch: [91][481/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 60.9	Acc@5 92.2
Epoch: [91][491/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 62.5	Acc@5 89.1
Epoch: [91][501/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 78.1	Acc@5 95.3
Epoch: [91][511/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 64.1	Acc@5 92.2
Epoch: [91][521/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 68.8	Acc@5 85.9
Epoch: [91][531/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 73.4	Acc@5 85.9
Epoch: [91][541/704]	Time 0.120	Data 0.001	Loss 5.73	Acc@1 56.2	Acc@5 93.8
Epoch: [91][551/704]	Time 0.120	Data 0.001	Loss 5.35	Acc@1 60.9	Acc@5 93.8
Epoch: [91][561/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 71.9	Acc@5 93.8
Epoch: [91][571/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 59.4	Acc@5 93.8
Epoch: [91][581/704]	Time 0.120	Data 0.001	Loss 4.52	Acc@1 73.4	Acc@5 92.2
Epoch: [91][591/704]	Time 0.120	Data 0.001	Loss 4.60	Acc@1 67.2	Acc@5 98.4
Epoch: [91][601/704]	Time 0.120	Data 0.001	Loss 4.82	Acc@1 73.4	Acc@5 95.3
Epoch: [91][611/704]	Time 0.120	Data 0.001	Loss 6.15	Acc@1 57.8	Acc@5 92.2
Epoch: [91][621/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 70.3	Acc@5 93.8
Epoch: [91][631/704]	Time 0.120	Data 0.001	Loss 5.89	Acc@1 53.1	Acc@5 93.8
Epoch: [91][641/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 64.1	Acc@5 95.3
Epoch: [91][651/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 64.1	Acc@5 90.6
Epoch: [91][661/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 59.4	Acc@5 82.8
Epoch: [91][671/704]	Time 0.120	Data 0.001	Loss 5.86	Acc@1 68.8	Acc@5 92.2
Epoch: [91][681/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 60.9	Acc@5 92.2
Epoch: [91][691/704]	Time 0.120	Data 0.001	Loss 4.83	Acc@1 73.4	Acc@5 90.6
Epoch: [91][701/704]	Time 0.120	Data 0.001	Loss 5.88	Acc@1 70.3	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5245	Acc@1 64.0625	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.3070	Acc@1 60.9375	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.9514	Acc@1 60.9375	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9624	Acc@1 51.5625	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4790	Acc@1 57.8125	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7879	Acc@1 60.9375	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.5897	Acc@1 56.2500	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.4289	Acc@1 67.1875	Acc@5 82.8125
 * prec@1 48.600 prec@5 80.060
 * prec@1 53.660 prec@5 82.860
 * prec@1 56.500 prec@5 85.280
 * prec@1 57.900 prec@5 85.500
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_091.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_091.pth.tar'
Epoch: [92][1/704]	Time 0.335	Data 0.168	Loss 5.21	Acc@1 70.3	Acc@5 89.1
Epoch: [92][11/704]	Time 0.140	Data 0.016	Loss 5.11	Acc@1 73.4	Acc@5 95.3
Epoch: [92][21/704]	Time 0.131	Data 0.008	Loss 5.71	Acc@1 68.8	Acc@5 85.9
Epoch: [92][31/704]	Time 0.128	Data 0.006	Loss 3.49	Acc@1 76.6	Acc@5 98.4
Epoch: [92][41/704]	Time 0.126	Data 0.004	Loss 5.14	Acc@1 64.1	Acc@5 93.8
Epoch: [92][51/704]	Time 0.125	Data 0.004	Loss 5.17	Acc@1 67.2	Acc@5 93.8
Epoch: [92][61/704]	Time 0.124	Data 0.003	Loss 4.52	Acc@1 62.5	Acc@5 92.2
Epoch: [92][71/704]	Time 0.124	Data 0.003	Loss 4.54	Acc@1 73.4	Acc@5 93.8
Epoch: [92][81/704]	Time 0.123	Data 0.002	Loss 4.22	Acc@1 75.0	Acc@5 96.9
Epoch: [92][91/704]	Time 0.123	Data 0.002	Loss 4.43	Acc@1 68.8	Acc@5 93.8
Epoch: [92][101/704]	Time 0.123	Data 0.002	Loss 4.81	Acc@1 64.1	Acc@5 95.3
Epoch: [92][111/704]	Time 0.122	Data 0.002	Loss 4.26	Acc@1 73.4	Acc@5 90.6
Epoch: [92][121/704]	Time 0.122	Data 0.002	Loss 4.08	Acc@1 76.6	Acc@5 96.9
Epoch: [92][131/704]	Time 0.122	Data 0.002	Loss 4.85	Acc@1 71.9	Acc@5 89.1
Epoch: [92][141/704]	Time 0.122	Data 0.002	Loss 4.57	Acc@1 70.3	Acc@5 93.8
Epoch: [92][151/704]	Time 0.122	Data 0.001	Loss 5.50	Acc@1 70.3	Acc@5 92.2
Epoch: [92][161/704]	Time 0.122	Data 0.001	Loss 4.03	Acc@1 71.9	Acc@5 92.2
Epoch: [92][171/704]	Time 0.122	Data 0.001	Loss 5.59	Acc@1 60.9	Acc@5 95.3
Epoch: [92][181/704]	Time 0.122	Data 0.001	Loss 6.07	Acc@1 59.4	Acc@5 93.8
Epoch: [92][191/704]	Time 0.122	Data 0.001	Loss 5.60	Acc@1 71.9	Acc@5 90.6
Epoch: [92][201/704]	Time 0.122	Data 0.001	Loss 5.52	Acc@1 67.2	Acc@5 93.8
Epoch: [92][211/704]	Time 0.122	Data 0.001	Loss 4.82	Acc@1 67.2	Acc@5 93.8
Epoch: [92][221/704]	Time 0.122	Data 0.001	Loss 4.02	Acc@1 68.8	Acc@5 95.3
Epoch: [92][231/704]	Time 0.122	Data 0.001	Loss 4.92	Acc@1 76.6	Acc@5 95.3
Epoch: [92][241/704]	Time 0.122	Data 0.001	Loss 4.84	Acc@1 70.3	Acc@5 93.8
Epoch: [92][251/704]	Time 0.122	Data 0.001	Loss 4.83	Acc@1 71.9	Acc@5 89.1
Epoch: [92][261/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 76.6	Acc@5 92.2
Epoch: [92][271/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 65.6	Acc@5 89.1
Epoch: [92][281/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 59.4	Acc@5 92.2
Epoch: [92][291/704]	Time 0.121	Data 0.001	Loss 4.07	Acc@1 76.6	Acc@5 96.9
Epoch: [92][301/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 73.4	Acc@5 93.8
Epoch: [92][311/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 73.4	Acc@5 89.1
Epoch: [92][321/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 92.2
Epoch: [92][331/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 75.0	Acc@5 84.4
Epoch: [92][341/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 70.3	Acc@5 96.9
Epoch: [92][351/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 64.1	Acc@5 92.2
Epoch: [92][361/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 73.4	Acc@5 93.8
Epoch: [92][371/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 71.9	Acc@5 95.3
Epoch: [92][381/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 75.0	Acc@5 93.8
Epoch: [92][391/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 68.8	Acc@5 84.4
Epoch: [92][401/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 70.3	Acc@5 95.3
Epoch: [92][411/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 70.3	Acc@5 90.6
Epoch: [92][421/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 75.0	Acc@5 95.3
Epoch: [92][431/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 68.8	Acc@5 90.6
Epoch: [92][441/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 64.1	Acc@5 93.8
Epoch: [92][451/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 70.3	Acc@5 92.2
Epoch: [92][461/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 67.2	Acc@5 93.8
Epoch: [92][471/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 75.0	Acc@5 95.3
Epoch: [92][481/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 65.6	Acc@5 90.6
Epoch: [92][491/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 64.1	Acc@5 90.6
Epoch: [92][501/704]	Time 0.121	Data 0.001	Loss 6.26	Acc@1 57.8	Acc@5 87.5
Epoch: [92][511/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 71.9	Acc@5 95.3
Epoch: [92][521/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 93.8
Epoch: [92][531/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 76.6	Acc@5 93.8
Epoch: [92][541/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 68.8	Acc@5 95.3
Epoch: [92][551/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 71.9	Acc@5 96.9
Epoch: [92][561/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 68.8	Acc@5 96.9
Epoch: [92][571/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 65.6	Acc@5 85.9
Epoch: [92][581/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 71.9	Acc@5 89.1
Epoch: [92][591/704]	Time 0.121	Data 0.001	Loss 4.22	Acc@1 70.3	Acc@5 96.9
Epoch: [92][601/704]	Time 0.121	Data 0.001	Loss 3.74	Acc@1 78.1	Acc@5 96.9
Epoch: [92][611/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 64.1	Acc@5 93.8
Epoch: [92][621/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 71.9	Acc@5 89.1
Epoch: [92][631/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 67.2	Acc@5 90.6
Epoch: [92][641/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 56.2	Acc@5 85.9
Epoch: [92][651/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 68.8	Acc@5 92.2
Epoch: [92][661/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 53.1	Acc@5 87.5
Epoch: [92][671/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 64.1	Acc@5 89.1
Epoch: [92][681/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 70.3	Acc@5 92.2
Epoch: [92][691/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 75.0	Acc@5 96.9
Epoch: [92][701/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 71.9	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.3137	Acc@1 60.9375	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.3175	Acc@1 46.8750	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.4654	Acc@1 51.5625	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.5461	Acc@1 48.4375	Acc@5 79.6875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6111	Acc@1 54.6875	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7399	Acc@1 62.5000	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.7491	Acc@1 54.6875	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2847	Acc@1 53.1250	Acc@5 84.3750
 * prec@1 48.240 prec@5 78.780
 * prec@1 52.180 prec@5 82.840
 * prec@1 55.900 prec@5 84.400
 * prec@1 57.800 prec@5 85.680
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_092.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_092.pth.tar'
Epoch: [93][1/704]	Time 0.299	Data 0.131	Loss 4.88	Acc@1 71.9	Acc@5 93.8
Epoch: [93][11/704]	Time 0.137	Data 0.012	Loss 4.75	Acc@1 70.3	Acc@5 95.3
Epoch: [93][21/704]	Time 0.129	Data 0.007	Loss 5.67	Acc@1 59.4	Acc@5 85.9
Epoch: [93][31/704]	Time 0.126	Data 0.005	Loss 4.39	Acc@1 76.6	Acc@5 96.9
Epoch: [93][41/704]	Time 0.125	Data 0.004	Loss 4.21	Acc@1 75.0	Acc@5 98.4
Epoch: [93][51/704]	Time 0.124	Data 0.003	Loss 4.64	Acc@1 73.4	Acc@5 93.8
Epoch: [93][61/704]	Time 0.123	Data 0.003	Loss 5.39	Acc@1 65.6	Acc@5 89.1
Epoch: [93][71/704]	Time 0.123	Data 0.002	Loss 4.41	Acc@1 73.4	Acc@5 93.8
Epoch: [93][81/704]	Time 0.123	Data 0.002	Loss 4.76	Acc@1 64.1	Acc@5 96.9
Epoch: [93][91/704]	Time 0.123	Data 0.002	Loss 5.79	Acc@1 60.9	Acc@5 89.1
Epoch: [93][101/704]	Time 0.123	Data 0.002	Loss 4.68	Acc@1 73.4	Acc@5 95.3
Epoch: [93][111/704]	Time 0.123	Data 0.002	Loss 3.95	Acc@1 70.3	Acc@5 96.9
Epoch: [93][121/704]	Time 0.122	Data 0.001	Loss 5.12	Acc@1 60.9	Acc@5 92.2
Epoch: [93][131/704]	Time 0.122	Data 0.001	Loss 6.35	Acc@1 56.2	Acc@5 85.9
Epoch: [93][141/704]	Time 0.122	Data 0.001	Loss 4.13	Acc@1 76.6	Acc@5 96.9
Epoch: [93][151/704]	Time 0.122	Data 0.001	Loss 4.94	Acc@1 67.2	Acc@5 95.3
Epoch: [93][161/704]	Time 0.122	Data 0.001	Loss 5.84	Acc@1 60.9	Acc@5 84.4
Epoch: [93][171/704]	Time 0.122	Data 0.001	Loss 4.97	Acc@1 71.9	Acc@5 93.8
Epoch: [93][181/704]	Time 0.122	Data 0.001	Loss 4.68	Acc@1 68.8	Acc@5 95.3
Epoch: [93][191/704]	Time 0.122	Data 0.001	Loss 5.14	Acc@1 70.3	Acc@5 95.3
Epoch: [93][201/704]	Time 0.122	Data 0.001	Loss 4.50	Acc@1 68.8	Acc@5 95.3
Epoch: [93][211/704]	Time 0.122	Data 0.001	Loss 4.44	Acc@1 71.9	Acc@5 93.8
Epoch: [93][221/704]	Time 0.122	Data 0.001	Loss 4.41	Acc@1 70.3	Acc@5 93.8
Epoch: [93][231/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 93.8
Epoch: [93][241/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 70.3	Acc@5 92.2
Epoch: [93][251/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 76.6	Acc@5 95.3
Epoch: [93][261/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 70.3	Acc@5 87.5
Epoch: [93][271/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 68.8	Acc@5 96.9
Epoch: [93][281/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 68.8	Acc@5 90.6
Epoch: [93][291/704]	Time 0.121	Data 0.001	Loss 6.73	Acc@1 57.8	Acc@5 90.6
Epoch: [93][301/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 73.4	Acc@5 98.4
Epoch: [93][311/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 65.6	Acc@5 90.6
Epoch: [93][321/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 68.8	Acc@5 92.2
Epoch: [93][331/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 67.2	Acc@5 96.9
Epoch: [93][341/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 81.2	Acc@5 96.9
Epoch: [93][351/704]	Time 0.121	Data 0.001	Loss 6.66	Acc@1 53.1	Acc@5 87.5
Epoch: [93][361/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 67.2	Acc@5 90.6
Epoch: [93][371/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 70.3	Acc@5 92.2
Epoch: [93][381/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 75.0	Acc@5 93.8
Epoch: [93][391/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 60.9	Acc@5 90.6
Epoch: [93][401/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 70.3	Acc@5 93.8
Epoch: [93][411/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 62.5	Acc@5 90.6
Epoch: [93][421/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 64.1	Acc@5 96.9
Epoch: [93][431/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 67.2	Acc@5 87.5
Epoch: [93][441/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 71.9	Acc@5 95.3
Epoch: [93][451/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 65.6	Acc@5 93.8
Epoch: [93][461/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 70.3	Acc@5 90.6
Epoch: [93][471/704]	Time 0.121	Data 0.001	Loss 6.89	Acc@1 59.4	Acc@5 87.5
Epoch: [93][481/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 93.8
Epoch: [93][491/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 78.1	Acc@5 95.3
Epoch: [93][501/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 59.4	Acc@5 82.8
Epoch: [93][511/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 67.2	Acc@5 87.5
Epoch: [93][521/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 68.8	Acc@5 95.3
Epoch: [93][531/704]	Time 0.121	Data 0.001	Loss 6.48	Acc@1 53.1	Acc@5 82.8
Epoch: [93][541/704]	Time 0.121	Data 0.001	Loss 3.82	Acc@1 75.0	Acc@5 98.4
Epoch: [93][551/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 75.0	Acc@5 92.2
Epoch: [93][561/704]	Time 0.121	Data 0.001	Loss 3.85	Acc@1 75.0	Acc@5 96.9
Epoch: [93][571/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 64.1	Acc@5 89.1
Epoch: [93][581/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 67.2	Acc@5 90.6
Epoch: [93][591/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 67.2	Acc@5 92.2
Epoch: [93][601/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 57.8	Acc@5 87.5
Epoch: [93][611/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 60.9	Acc@5 93.8
Epoch: [93][621/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 64.1	Acc@5 95.3
Epoch: [93][631/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 60.9	Acc@5 98.4
Epoch: [93][641/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 64.1	Acc@5 96.9
Epoch: [93][651/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 68.8	Acc@5 93.8
Epoch: [93][661/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 62.5	Acc@5 92.2
Epoch: [93][671/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 75.0	Acc@5 95.3
Epoch: [93][681/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 67.2	Acc@5 95.3
Epoch: [93][691/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 93.8
Epoch: [93][701/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 65.6	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.0146	Acc@1 48.4375	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.0412	Acc@1 56.2500	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.3175	Acc@1 51.5625	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9622	Acc@1 53.1250	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4729	Acc@1 64.0625	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 9.5534	Acc@1 53.1250	Acc@5 73.4375
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.0740	Acc@1 57.8125	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9379	Acc@1 53.1250	Acc@5 84.3750
 * prec@1 46.700 prec@5 76.880
 * prec@1 51.440 prec@5 81.420
 * prec@1 54.260 prec@5 83.640
 * prec@1 56.820 prec@5 84.820
Current best validation last_bloc_accuracy 58.26
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_093.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_093.pth.tar'
Epoch: [94][1/704]	Time 0.300	Data 0.132	Loss 5.20	Acc@1 64.1	Acc@5 95.3
Epoch: [94][11/704]	Time 0.140	Data 0.012	Loss 5.75	Acc@1 62.5	Acc@5 90.6
Epoch: [94][21/704]	Time 0.131	Data 0.007	Loss 5.63	Acc@1 65.6	Acc@5 92.2
Epoch: [94][31/704]	Time 0.127	Data 0.005	Loss 4.78	Acc@1 73.4	Acc@5 92.2
Epoch: [94][41/704]	Time 0.125	Data 0.004	Loss 5.83	Acc@1 59.4	Acc@5 92.2
Epoch: [94][51/704]	Time 0.124	Data 0.003	Loss 4.08	Acc@1 73.4	Acc@5 95.3
Epoch: [94][61/704]	Time 0.124	Data 0.002	Loss 5.54	Acc@1 68.8	Acc@5 95.3
Epoch: [94][71/704]	Time 0.123	Data 0.002	Loss 4.07	Acc@1 81.2	Acc@5 96.9
Epoch: [94][81/704]	Time 0.123	Data 0.002	Loss 5.07	Acc@1 75.0	Acc@5 96.9
Epoch: [94][91/704]	Time 0.122	Data 0.002	Loss 4.92	Acc@1 68.8	Acc@5 92.2
Epoch: [94][101/704]	Time 0.122	Data 0.002	Loss 4.72	Acc@1 65.6	Acc@5 96.9
Epoch: [94][111/704]	Time 0.122	Data 0.002	Loss 5.43	Acc@1 65.6	Acc@5 95.3
Epoch: [94][121/704]	Time 0.122	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 96.9
Epoch: [94][131/704]	Time 0.122	Data 0.001	Loss 6.94	Acc@1 56.2	Acc@5 87.5
Epoch: [94][141/704]	Time 0.122	Data 0.001	Loss 4.64	Acc@1 70.3	Acc@5 90.6
Epoch: [94][151/704]	Time 0.121	Data 0.001	Loss 3.41	Acc@1 82.8	Acc@5 96.9
Epoch: [94][161/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 75.0	Acc@5 92.2
Epoch: [94][171/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 76.6	Acc@5 98.4
Epoch: [94][181/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 68.8	Acc@5 92.2
Epoch: [94][191/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 67.2	Acc@5 95.3
Epoch: [94][201/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 71.9	Acc@5 92.2
Epoch: [94][211/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 73.4	Acc@5 96.9
Epoch: [94][221/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 95.3
Epoch: [94][231/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 73.4	Acc@5 96.9
Epoch: [94][241/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 64.1	Acc@5 95.3
Epoch: [94][251/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 64.1	Acc@5 90.6
Epoch: [94][261/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 68.8	Acc@5 95.3
Epoch: [94][271/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 92.2
Epoch: [94][281/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 67.2	Acc@5 87.5
Epoch: [94][291/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 57.8	Acc@5 90.6
Epoch: [94][301/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 73.4	Acc@5 93.8
Epoch: [94][311/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 68.8	Acc@5 90.6
Epoch: [94][321/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 78.1	Acc@5 92.2
Epoch: [94][331/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 60.9	Acc@5 92.2
Epoch: [94][341/704]	Time 0.121	Data 0.001	Loss 6.28	Acc@1 57.8	Acc@5 90.6
Epoch: [94][351/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 68.8	Acc@5 92.2
Epoch: [94][361/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 64.1	Acc@5 96.9
Epoch: [94][371/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 70.3	Acc@5 93.8
Epoch: [94][381/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 70.3	Acc@5 90.6
Epoch: [94][391/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 78.1	Acc@5 93.8
Epoch: [94][401/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 68.8	Acc@5 87.5
Epoch: [94][411/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 70.3	Acc@5 90.6
Epoch: [94][421/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 73.4	Acc@5 89.1
Epoch: [94][431/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 65.6	Acc@5 89.1
Epoch: [94][441/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 73.4	Acc@5 92.2
Epoch: [94][451/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 65.6	Acc@5 93.8
Epoch: [94][461/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 71.9	Acc@5 93.8
Epoch: [94][471/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 67.2	Acc@5 90.6
Epoch: [94][481/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 65.6	Acc@5 90.6
Epoch: [94][491/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 70.3	Acc@5 93.8
Epoch: [94][501/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 68.8	Acc@5 93.8
Epoch: [94][511/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 71.9	Acc@5 90.6
Epoch: [94][521/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 60.9	Acc@5 89.1
Epoch: [94][531/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 67.2	Acc@5 87.5
Epoch: [94][541/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 71.9	Acc@5 93.8
Epoch: [94][551/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 90.6
Epoch: [94][561/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 64.1	Acc@5 89.1
Epoch: [94][571/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 95.3
Epoch: [94][581/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 67.2	Acc@5 89.1
Epoch: [94][591/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 76.6	Acc@5 96.9
Epoch: [94][601/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 70.3	Acc@5 95.3
Epoch: [94][611/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 70.3	Acc@5 96.9
Epoch: [94][621/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 76.6	Acc@5 93.8
Epoch: [94][631/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 75.0	Acc@5 95.3
Epoch: [94][641/704]	Time 0.121	Data 0.001	Loss 4.01	Acc@1 76.6	Acc@5 95.3
Epoch: [94][651/704]	Time 0.120	Data 0.001	Loss 4.49	Acc@1 79.7	Acc@5 95.3
Epoch: [94][661/704]	Time 0.120	Data 0.001	Loss 6.27	Acc@1 53.1	Acc@5 87.5
Epoch: [94][671/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 64.1	Acc@5 90.6
Epoch: [94][681/704]	Time 0.120	Data 0.001	Loss 4.66	Acc@1 75.0	Acc@5 93.8
Epoch: [94][691/704]	Time 0.120	Data 0.001	Loss 6.51	Acc@1 60.9	Acc@5 92.2
Epoch: [94][701/704]	Time 0.120	Data 0.001	Loss 6.00	Acc@1 67.2	Acc@5 87.5
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.7044	Acc@1 59.3750	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0198	Acc@1 57.8125	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.9049	Acc@1 64.0625	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.6026	Acc@1 53.1250	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9047	Acc@1 64.0625	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9902	Acc@1 54.6875	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.1277	Acc@1 65.6250	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.0023	Acc@1 64.0625	Acc@5 92.1875
 * prec@1 46.820 prec@5 77.280
 * prec@1 52.920 prec@5 82.700
 * prec@1 56.300 prec@5 84.980
 * prec@1 58.440 prec@5 86.300
New best validation last_bloc_accuracy 58.44
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_094.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_094.pth.tar'
Epoch: [95][1/704]	Time 0.330	Data 0.164	Loss 4.53	Acc@1 70.3	Acc@5 93.8
Epoch: [95][11/704]	Time 0.139	Data 0.015	Loss 5.72	Acc@1 57.8	Acc@5 96.9
Epoch: [95][21/704]	Time 0.130	Data 0.008	Loss 4.38	Acc@1 73.4	Acc@5 95.3
Epoch: [95][31/704]	Time 0.127	Data 0.006	Loss 5.54	Acc@1 70.3	Acc@5 89.1
Epoch: [95][41/704]	Time 0.125	Data 0.004	Loss 5.58	Acc@1 67.2	Acc@5 89.1
Epoch: [95][51/704]	Time 0.124	Data 0.004	Loss 5.02	Acc@1 64.1	Acc@5 93.8
Epoch: [95][61/704]	Time 0.123	Data 0.003	Loss 5.01	Acc@1 70.3	Acc@5 90.6
Epoch: [95][71/704]	Time 0.123	Data 0.003	Loss 3.92	Acc@1 76.6	Acc@5 98.4
Epoch: [95][81/704]	Time 0.123	Data 0.002	Loss 5.03	Acc@1 73.4	Acc@5 93.8
Epoch: [95][91/704]	Time 0.122	Data 0.002	Loss 4.19	Acc@1 73.4	Acc@5 95.3
Epoch: [95][101/704]	Time 0.122	Data 0.002	Loss 3.78	Acc@1 79.7	Acc@5 93.8
Epoch: [95][111/704]	Time 0.122	Data 0.002	Loss 5.35	Acc@1 62.5	Acc@5 92.2
Epoch: [95][121/704]	Time 0.122	Data 0.002	Loss 4.44	Acc@1 71.9	Acc@5 95.3
Epoch: [95][131/704]	Time 0.122	Data 0.002	Loss 3.82	Acc@1 70.3	Acc@5 90.6
Epoch: [95][141/704]	Time 0.121	Data 0.001	Loss 3.95	Acc@1 75.0	Acc@5 95.3
Epoch: [95][151/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 64.1	Acc@5 92.2
Epoch: [95][161/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 95.3
Epoch: [95][171/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 70.3	Acc@5 92.2
Epoch: [95][181/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 76.6	Acc@5 98.4
Epoch: [95][191/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 75.0	Acc@5 95.3
Epoch: [95][201/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 71.9	Acc@5 95.3
Epoch: [95][211/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 73.4	Acc@5 89.1
Epoch: [95][221/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 71.9	Acc@5 93.8
Epoch: [95][231/704]	Time 0.121	Data 0.001	Loss 7.08	Acc@1 62.5	Acc@5 85.9
Epoch: [95][241/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 67.2	Acc@5 89.1
Epoch: [95][251/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 62.5	Acc@5 82.8
Epoch: [95][261/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 68.8	Acc@5 90.6
Epoch: [95][271/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 96.9
Epoch: [95][281/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 62.5	Acc@5 90.6
Epoch: [95][291/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 71.9	Acc@5 93.8
Epoch: [95][301/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 67.2	Acc@5 93.8
Epoch: [95][311/704]	Time 0.121	Data 0.001	Loss 6.41	Acc@1 65.6	Acc@5 92.2
Epoch: [95][321/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 96.9
Epoch: [95][331/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 62.5	Acc@5 89.1
Epoch: [95][341/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 67.2	Acc@5 92.2
Epoch: [95][351/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 64.1	Acc@5 84.4
Epoch: [95][361/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 70.3	Acc@5 89.1
Epoch: [95][371/704]	Time 0.121	Data 0.001	Loss 3.88	Acc@1 79.7	Acc@5 100.0
Epoch: [95][381/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 59.4	Acc@5 87.5
Epoch: [95][391/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 60.9	Acc@5 92.2
Epoch: [95][401/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 73.4	Acc@5 90.6
Epoch: [95][411/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 73.4	Acc@5 96.9
Epoch: [95][421/704]	Time 0.120	Data 0.001	Loss 3.63	Acc@1 87.5	Acc@5 98.4
Epoch: [95][431/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 62.5	Acc@5 90.6
Epoch: [95][441/704]	Time 0.120	Data 0.001	Loss 6.44	Acc@1 62.5	Acc@5 90.6
Epoch: [95][451/704]	Time 0.120	Data 0.001	Loss 5.80	Acc@1 59.4	Acc@5 93.8
Epoch: [95][461/704]	Time 0.120	Data 0.001	Loss 4.20	Acc@1 78.1	Acc@5 96.9
Epoch: [95][471/704]	Time 0.120	Data 0.001	Loss 3.97	Acc@1 79.7	Acc@5 95.3
Epoch: [95][481/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 67.2	Acc@5 93.8
Epoch: [95][491/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 56.2	Acc@5 89.1
Epoch: [95][501/704]	Time 0.120	Data 0.001	Loss 6.09	Acc@1 42.2	Acc@5 85.9
Epoch: [95][511/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 60.9	Acc@5 90.6
Epoch: [95][521/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 67.2	Acc@5 93.8
Epoch: [95][531/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 73.4	Acc@5 89.1
Epoch: [95][541/704]	Time 0.120	Data 0.001	Loss 5.30	Acc@1 68.8	Acc@5 89.1
Epoch: [95][551/704]	Time 0.120	Data 0.001	Loss 4.49	Acc@1 70.3	Acc@5 95.3
Epoch: [95][561/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 71.9	Acc@5 92.2
Epoch: [95][571/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 62.5	Acc@5 92.2
Epoch: [95][581/704]	Time 0.120	Data 0.001	Loss 4.74	Acc@1 73.4	Acc@5 95.3
Epoch: [95][591/704]	Time 0.120	Data 0.001	Loss 5.95	Acc@1 60.9	Acc@5 90.6
Epoch: [95][601/704]	Time 0.120	Data 0.001	Loss 6.39	Acc@1 60.9	Acc@5 90.6
Epoch: [95][611/704]	Time 0.120	Data 0.001	Loss 6.14	Acc@1 68.8	Acc@5 85.9
Epoch: [95][621/704]	Time 0.120	Data 0.001	Loss 5.40	Acc@1 64.1	Acc@5 90.6
Epoch: [95][631/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 70.3	Acc@5 92.2
Epoch: [95][641/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 70.3	Acc@5 89.1
Epoch: [95][651/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 92.2
Epoch: [95][661/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 60.9	Acc@5 92.2
Epoch: [95][671/704]	Time 0.120	Data 0.001	Loss 5.27	Acc@1 81.2	Acc@5 92.2
Epoch: [95][681/704]	Time 0.120	Data 0.001	Loss 5.93	Acc@1 60.9	Acc@5 95.3
Epoch: [95][691/704]	Time 0.120	Data 0.001	Loss 4.59	Acc@1 70.3	Acc@5 90.6
Epoch: [95][701/704]	Time 0.120	Data 0.001	Loss 5.41	Acc@1 64.1	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 9.0827	Acc@1 46.8750	Acc@5 79.6875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.6705	Acc@1 57.8125	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.4951	Acc@1 57.8125	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.2320	Acc@1 53.1250	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.7600	Acc@1 53.1250	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.0906	Acc@1 57.8125	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.0852	Acc@1 68.7500	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.7211	Acc@1 59.3750	Acc@5 85.9375
 * prec@1 46.380 prec@5 77.520
 * prec@1 50.800 prec@5 82.460
 * prec@1 54.960 prec@5 85.220
 * prec@1 56.300 prec@5 84.740
Current best validation last_bloc_accuracy 58.44
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_095.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_095.pth.tar'
Epoch: [96][1/704]	Time 0.300	Data 0.133	Loss 5.57	Acc@1 68.8	Acc@5 92.2
Epoch: [96][11/704]	Time 0.137	Data 0.012	Loss 4.67	Acc@1 75.0	Acc@5 92.2
Epoch: [96][21/704]	Time 0.129	Data 0.007	Loss 4.44	Acc@1 76.6	Acc@5 93.8
Epoch: [96][31/704]	Time 0.126	Data 0.005	Loss 4.51	Acc@1 75.0	Acc@5 96.9
Epoch: [96][41/704]	Time 0.124	Data 0.004	Loss 4.89	Acc@1 70.3	Acc@5 93.8
Epoch: [96][51/704]	Time 0.124	Data 0.003	Loss 4.88	Acc@1 76.6	Acc@5 93.8
Epoch: [96][61/704]	Time 0.123	Data 0.002	Loss 4.33	Acc@1 67.2	Acc@5 98.4
Epoch: [96][71/704]	Time 0.123	Data 0.002	Loss 4.52	Acc@1 71.9	Acc@5 90.6
Epoch: [96][81/704]	Time 0.122	Data 0.002	Loss 4.60	Acc@1 71.9	Acc@5 95.3
Epoch: [96][91/704]	Time 0.122	Data 0.002	Loss 4.57	Acc@1 73.4	Acc@5 89.1
Epoch: [96][101/704]	Time 0.122	Data 0.002	Loss 4.72	Acc@1 68.8	Acc@5 92.2
Epoch: [96][111/704]	Time 0.122	Data 0.002	Loss 4.27	Acc@1 75.0	Acc@5 98.4
Epoch: [96][121/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 73.4	Acc@5 96.9
Epoch: [96][131/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 60.9	Acc@5 92.2
Epoch: [96][141/704]	Time 0.122	Data 0.001	Loss 6.19	Acc@1 68.8	Acc@5 92.2
Epoch: [96][151/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 73.4	Acc@5 90.6
Epoch: [96][161/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 62.5	Acc@5 89.1
Epoch: [96][171/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 79.7	Acc@5 96.9
Epoch: [96][181/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 68.8	Acc@5 92.2
Epoch: [96][191/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 95.3
Epoch: [96][201/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 78.1	Acc@5 95.3
Epoch: [96][211/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 89.1
Epoch: [96][221/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 71.9	Acc@5 93.8
Epoch: [96][231/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 65.6	Acc@5 89.1
Epoch: [96][241/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 56.2	Acc@5 93.8
Epoch: [96][251/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 73.4	Acc@5 87.5
Epoch: [96][261/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 62.5	Acc@5 93.8
Epoch: [96][271/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 70.3	Acc@5 92.2
Epoch: [96][281/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 90.6
Epoch: [96][291/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 93.8
Epoch: [96][301/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 95.3
Epoch: [96][311/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 92.2
Epoch: [96][321/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 65.6	Acc@5 93.8
Epoch: [96][331/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 71.9	Acc@5 85.9
Epoch: [96][341/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 73.4	Acc@5 89.1
Epoch: [96][351/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 65.6	Acc@5 90.6
Epoch: [96][361/704]	Time 0.121	Data 0.001	Loss 4.21	Acc@1 70.3	Acc@5 93.8
Epoch: [96][371/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 67.2	Acc@5 93.8
Epoch: [96][381/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 64.1	Acc@5 90.6
Epoch: [96][391/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 67.2	Acc@5 92.2
Epoch: [96][401/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 65.6	Acc@5 93.8
Epoch: [96][411/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 68.8	Acc@5 93.8
Epoch: [96][421/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 62.5	Acc@5 92.2
Epoch: [96][431/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 70.3	Acc@5 92.2
Epoch: [96][441/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 68.8	Acc@5 93.8
Epoch: [96][451/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 64.1	Acc@5 95.3
Epoch: [96][461/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 67.2	Acc@5 92.2
Epoch: [96][471/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 60.9	Acc@5 98.4
Epoch: [96][481/704]	Time 0.121	Data 0.001	Loss 6.43	Acc@1 56.2	Acc@5 92.2
Epoch: [96][491/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 76.6	Acc@5 95.3
Epoch: [96][501/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 76.6	Acc@5 93.8
Epoch: [96][511/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 70.3	Acc@5 92.2
Epoch: [96][521/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 71.9	Acc@5 95.3
Epoch: [96][531/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 59.4	Acc@5 90.6
Epoch: [96][541/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 73.4	Acc@5 93.8
Epoch: [96][551/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 70.3	Acc@5 85.9
Epoch: [96][561/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 68.8	Acc@5 92.2
Epoch: [96][571/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 60.9	Acc@5 90.6
Epoch: [96][581/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 62.5	Acc@5 90.6
Epoch: [96][591/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 67.2	Acc@5 92.2
Epoch: [96][601/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 75.0	Acc@5 95.3
Epoch: [96][611/704]	Time 0.121	Data 0.001	Loss 7.79	Acc@1 56.2	Acc@5 73.4
Epoch: [96][621/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 73.4	Acc@5 93.8
Epoch: [96][631/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 67.2	Acc@5 87.5
Epoch: [96][641/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 70.3	Acc@5 92.2
Epoch: [96][651/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 62.5	Acc@5 93.8
Epoch: [96][661/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 67.2	Acc@5 92.2
Epoch: [96][671/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 71.9	Acc@5 93.8
Epoch: [96][681/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 65.6	Acc@5 93.8
Epoch: [96][691/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 62.5	Acc@5 90.6
Epoch: [96][701/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 70.3	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.2594	Acc@1 50.0000	Acc@5 76.5625
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.5133	Acc@1 57.8125	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.9985	Acc@1 56.2500	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.2077	Acc@1 59.3750	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 9.3154	Acc@1 40.6250	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.3101	Acc@1 64.0625	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.1004	Acc@1 54.6875	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.6778	Acc@1 59.3750	Acc@5 81.2500
 * prec@1 47.640 prec@5 78.060
 * prec@1 53.040 prec@5 83.580
 * prec@1 57.760 prec@5 85.880
 * prec@1 58.520 prec@5 86.440
New best validation last_bloc_accuracy 58.52
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_096.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_096.pth.tar'
Epoch: [97][1/704]	Time 0.298	Data 0.131	Loss 3.65	Acc@1 81.2	Acc@5 96.9
Epoch: [97][11/704]	Time 0.136	Data 0.012	Loss 5.48	Acc@1 65.6	Acc@5 95.3
Epoch: [97][21/704]	Time 0.129	Data 0.007	Loss 4.15	Acc@1 75.0	Acc@5 93.8
Epoch: [97][31/704]	Time 0.126	Data 0.005	Loss 5.19	Acc@1 67.2	Acc@5 92.2
Epoch: [97][41/704]	Time 0.124	Data 0.004	Loss 4.85	Acc@1 68.8	Acc@5 90.6
Epoch: [97][51/704]	Time 0.124	Data 0.003	Loss 4.73	Acc@1 67.2	Acc@5 96.9
Epoch: [97][61/704]	Time 0.124	Data 0.003	Loss 5.61	Acc@1 64.1	Acc@5 93.8
Epoch: [97][71/704]	Time 0.123	Data 0.002	Loss 4.70	Acc@1 79.7	Acc@5 89.1
Epoch: [97][81/704]	Time 0.123	Data 0.002	Loss 4.14	Acc@1 78.1	Acc@5 96.9
Epoch: [97][91/704]	Time 0.122	Data 0.002	Loss 4.64	Acc@1 70.3	Acc@5 95.3
Epoch: [97][101/704]	Time 0.122	Data 0.002	Loss 4.97	Acc@1 75.0	Acc@5 100.0
Epoch: [97][111/704]	Time 0.122	Data 0.002	Loss 4.13	Acc@1 76.6	Acc@5 95.3
Epoch: [97][121/704]	Time 0.122	Data 0.001	Loss 4.92	Acc@1 67.2	Acc@5 95.3
Epoch: [97][131/704]	Time 0.122	Data 0.001	Loss 5.60	Acc@1 60.9	Acc@5 93.8
Epoch: [97][141/704]	Time 0.122	Data 0.001	Loss 3.70	Acc@1 65.6	Acc@5 96.9
Epoch: [97][151/704]	Time 0.122	Data 0.001	Loss 3.46	Acc@1 75.0	Acc@5 96.9
Epoch: [97][161/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 65.6	Acc@5 96.9
Epoch: [97][171/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 75.0	Acc@5 96.9
Epoch: [97][181/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 65.6	Acc@5 93.8
Epoch: [97][191/704]	Time 0.121	Data 0.001	Loss 7.09	Acc@1 65.6	Acc@5 87.5
Epoch: [97][201/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 56.2	Acc@5 93.8
Epoch: [97][211/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 67.2	Acc@5 93.8
Epoch: [97][221/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 96.9
Epoch: [97][231/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 54.7	Acc@5 89.1
Epoch: [97][241/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 78.1	Acc@5 96.9
Epoch: [97][251/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 60.9	Acc@5 90.6
Epoch: [97][261/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 64.1	Acc@5 87.5
Epoch: [97][271/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 76.6	Acc@5 98.4
Epoch: [97][281/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 73.4	Acc@5 92.2
Epoch: [97][291/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 59.4	Acc@5 90.6
Epoch: [97][301/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 64.1	Acc@5 85.9
Epoch: [97][311/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 92.2
Epoch: [97][321/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 64.1	Acc@5 92.2
Epoch: [97][331/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 71.9	Acc@5 95.3
Epoch: [97][341/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 62.5	Acc@5 89.1
Epoch: [97][351/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 73.4	Acc@5 93.8
Epoch: [97][361/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 90.6
Epoch: [97][371/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 67.2	Acc@5 92.2
Epoch: [97][381/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 73.4	Acc@5 92.2
Epoch: [97][391/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 65.6	Acc@5 92.2
Epoch: [97][401/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 57.8	Acc@5 87.5
Epoch: [97][411/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 62.5	Acc@5 93.8
Epoch: [97][421/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 56.2	Acc@5 89.1
Epoch: [97][431/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 76.6	Acc@5 95.3
Epoch: [97][441/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 54.7	Acc@5 96.9
Epoch: [97][451/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 70.3	Acc@5 90.6
Epoch: [97][461/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 92.2
Epoch: [97][471/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 64.1	Acc@5 82.8
Epoch: [97][481/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 62.5	Acc@5 93.8
Epoch: [97][491/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 79.7	Acc@5 95.3
Epoch: [97][501/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 73.4	Acc@5 96.9
Epoch: [97][511/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 60.9	Acc@5 93.8
Epoch: [97][521/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 67.2	Acc@5 93.8
Epoch: [97][531/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 67.2	Acc@5 93.8
Epoch: [97][541/704]	Time 0.120	Data 0.001	Loss 5.97	Acc@1 67.2	Acc@5 93.8
Epoch: [97][551/704]	Time 0.120	Data 0.001	Loss 6.53	Acc@1 59.4	Acc@5 85.9
Epoch: [97][561/704]	Time 0.120	Data 0.001	Loss 4.47	Acc@1 73.4	Acc@5 98.4
Epoch: [97][571/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 71.9	Acc@5 95.3
Epoch: [97][581/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 67.2	Acc@5 93.8
Epoch: [97][591/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 64.1	Acc@5 95.3
Epoch: [97][601/704]	Time 0.120	Data 0.001	Loss 4.20	Acc@1 70.3	Acc@5 100.0
Epoch: [97][611/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 64.1	Acc@5 95.3
Epoch: [97][621/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 73.4	Acc@5 95.3
Epoch: [97][631/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 93.8
Epoch: [97][641/704]	Time 0.120	Data 0.001	Loss 4.10	Acc@1 75.0	Acc@5 96.9
Epoch: [97][651/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 60.9	Acc@5 92.2
Epoch: [97][661/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 64.1	Acc@5 93.8
Epoch: [97][671/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 71.9	Acc@5 95.3
Epoch: [97][681/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 64.1	Acc@5 90.6
Epoch: [97][691/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 71.9	Acc@5 96.9
Epoch: [97][701/704]	Time 0.120	Data 0.001	Loss 4.49	Acc@1 79.7	Acc@5 89.1
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.5682	Acc@1 57.8125	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7057	Acc@1 64.0625	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.0362	Acc@1 67.1875	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.5023	Acc@1 62.5000	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5259	Acc@1 59.3750	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.4052	Acc@1 62.5000	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6158	Acc@1 51.5625	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7185	Acc@1 57.8125	Acc@5 89.0625
 * prec@1 48.660 prec@5 79.020
 * prec@1 53.480 prec@5 82.900
 * prec@1 57.900 prec@5 86.140
 * prec@1 59.300 prec@5 87.220
New best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_097.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_097.pth.tar'
Epoch: [98][1/704]	Time 0.332	Data 0.166	Loss 4.56	Acc@1 70.3	Acc@5 92.2
Epoch: [98][11/704]	Time 0.139	Data 0.015	Loss 4.66	Acc@1 62.5	Acc@5 93.8
Epoch: [98][21/704]	Time 0.130	Data 0.008	Loss 5.73	Acc@1 71.9	Acc@5 90.6
Epoch: [98][31/704]	Time 0.127	Data 0.006	Loss 4.39	Acc@1 68.8	Acc@5 95.3
Epoch: [98][41/704]	Time 0.125	Data 0.004	Loss 4.65	Acc@1 73.4	Acc@5 93.8
Epoch: [98][51/704]	Time 0.124	Data 0.004	Loss 5.40	Acc@1 60.9	Acc@5 95.3
Epoch: [98][61/704]	Time 0.123	Data 0.003	Loss 4.28	Acc@1 73.4	Acc@5 93.8
Epoch: [98][71/704]	Time 0.123	Data 0.003	Loss 3.76	Acc@1 73.4	Acc@5 93.8
Epoch: [98][81/704]	Time 0.122	Data 0.002	Loss 3.37	Acc@1 78.1	Acc@5 98.4
Epoch: [98][91/704]	Time 0.122	Data 0.002	Loss 5.24	Acc@1 67.2	Acc@5 95.3
Epoch: [98][101/704]	Time 0.122	Data 0.002	Loss 4.99	Acc@1 73.4	Acc@5 95.3
Epoch: [98][111/704]	Time 0.122	Data 0.002	Loss 5.81	Acc@1 65.6	Acc@5 85.9
Epoch: [98][121/704]	Time 0.122	Data 0.002	Loss 4.25	Acc@1 76.6	Acc@5 96.9
Epoch: [98][131/704]	Time 0.121	Data 0.002	Loss 5.45	Acc@1 70.3	Acc@5 93.8
Epoch: [98][141/704]	Time 0.121	Data 0.002	Loss 4.36	Acc@1 68.8	Acc@5 93.8
Epoch: [98][151/704]	Time 0.121	Data 0.002	Loss 5.08	Acc@1 71.9	Acc@5 92.2
Epoch: [98][161/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 67.2	Acc@5 89.1
Epoch: [98][171/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 76.6	Acc@5 90.6
Epoch: [98][181/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 67.2	Acc@5 89.1
Epoch: [98][191/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 76.6	Acc@5 90.6
Epoch: [98][201/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 67.2	Acc@5 92.2
Epoch: [98][211/704]	Time 0.121	Data 0.001	Loss 3.41	Acc@1 82.8	Acc@5 98.4
Epoch: [98][221/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 59.4	Acc@5 92.2
Epoch: [98][231/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 70.3	Acc@5 87.5
Epoch: [98][241/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 60.9	Acc@5 95.3
Epoch: [98][251/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 60.9	Acc@5 87.5
Epoch: [98][261/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 73.4	Acc@5 95.3
Epoch: [98][271/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 71.9	Acc@5 87.5
Epoch: [98][281/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 76.6	Acc@5 96.9
Epoch: [98][291/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 76.6	Acc@5 93.8
Epoch: [98][301/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 75.0	Acc@5 92.2
Epoch: [98][311/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 96.9
Epoch: [98][321/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 76.6	Acc@5 95.3
Epoch: [98][331/704]	Time 0.120	Data 0.001	Loss 5.79	Acc@1 59.4	Acc@5 89.1
Epoch: [98][341/704]	Time 0.120	Data 0.001	Loss 6.20	Acc@1 62.5	Acc@5 87.5
Epoch: [98][351/704]	Time 0.121	Data 0.001	Loss 6.54	Acc@1 50.0	Acc@5 82.8
Epoch: [98][361/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 65.6	Acc@5 92.2
Epoch: [98][371/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 82.8	Acc@5 96.9
Epoch: [98][381/704]	Time 0.120	Data 0.001	Loss 5.05	Acc@1 68.8	Acc@5 93.8
Epoch: [98][391/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 67.2	Acc@5 90.6
Epoch: [98][401/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 62.5	Acc@5 100.0
Epoch: [98][411/704]	Time 0.120	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 98.4
Epoch: [98][421/704]	Time 0.120	Data 0.001	Loss 4.75	Acc@1 78.1	Acc@5 96.9
Epoch: [98][431/704]	Time 0.120	Data 0.001	Loss 5.40	Acc@1 70.3	Acc@5 96.9
Epoch: [98][441/704]	Time 0.120	Data 0.001	Loss 4.81	Acc@1 68.8	Acc@5 95.3
Epoch: [98][451/704]	Time 0.120	Data 0.001	Loss 5.49	Acc@1 57.8	Acc@5 93.8
Epoch: [98][461/704]	Time 0.120	Data 0.001	Loss 6.06	Acc@1 60.9	Acc@5 89.1
Epoch: [98][471/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 57.8	Acc@5 92.2
Epoch: [98][481/704]	Time 0.120	Data 0.001	Loss 6.33	Acc@1 60.9	Acc@5 87.5
Epoch: [98][491/704]	Time 0.120	Data 0.001	Loss 4.82	Acc@1 67.2	Acc@5 92.2
Epoch: [98][501/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 64.1	Acc@5 92.2
Epoch: [98][511/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 65.6	Acc@5 90.6
Epoch: [98][521/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 60.9	Acc@5 95.3
Epoch: [98][531/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 70.3	Acc@5 89.1
Epoch: [98][541/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 65.6	Acc@5 95.3
Epoch: [98][551/704]	Time 0.120	Data 0.001	Loss 7.36	Acc@1 54.7	Acc@5 82.8
Epoch: [98][561/704]	Time 0.120	Data 0.001	Loss 4.87	Acc@1 65.6	Acc@5 89.1
Epoch: [98][571/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 71.9	Acc@5 95.3
Epoch: [98][581/704]	Time 0.120	Data 0.001	Loss 4.94	Acc@1 70.3	Acc@5 90.6
Epoch: [98][591/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 60.9	Acc@5 89.1
Epoch: [98][601/704]	Time 0.120	Data 0.001	Loss 4.01	Acc@1 75.0	Acc@5 95.3
Epoch: [98][611/704]	Time 0.120	Data 0.001	Loss 6.03	Acc@1 68.8	Acc@5 89.1
Epoch: [98][621/704]	Time 0.120	Data 0.001	Loss 4.67	Acc@1 68.8	Acc@5 95.3
Epoch: [98][631/704]	Time 0.120	Data 0.001	Loss 4.54	Acc@1 71.9	Acc@5 95.3
Epoch: [98][641/704]	Time 0.120	Data 0.001	Loss 3.87	Acc@1 79.7	Acc@5 93.8
Epoch: [98][651/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 71.9	Acc@5 89.1
Epoch: [98][661/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 68.8	Acc@5 90.6
Epoch: [98][671/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 56.2	Acc@5 92.2
Epoch: [98][681/704]	Time 0.120	Data 0.001	Loss 5.02	Acc@1 64.1	Acc@5 92.2
Epoch: [98][691/704]	Time 0.120	Data 0.001	Loss 6.08	Acc@1 62.5	Acc@5 89.1
Epoch: [98][701/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 71.9	Acc@5 96.9
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.0554	Acc@1 59.3750	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.5502	Acc@1 54.6875	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.5454	Acc@1 50.0000	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.1702	Acc@1 50.0000	Acc@5 79.6875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.8985	Acc@1 59.3750	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.9259	Acc@1 50.0000	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7328	Acc@1 57.8125	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2083	Acc@1 46.8750	Acc@5 89.0625
 * prec@1 48.260 prec@5 78.440
 * prec@1 52.340 prec@5 82.360
 * prec@1 54.920 prec@5 84.820
 * prec@1 57.800 prec@5 86.000
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_098.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_098.pth.tar'
Epoch: [99][1/704]	Time 0.335	Data 0.168	Loss 5.55	Acc@1 62.5	Acc@5 92.2
Epoch: [99][11/704]	Time 0.140	Data 0.016	Loss 5.91	Acc@1 64.1	Acc@5 92.2
Epoch: [99][21/704]	Time 0.131	Data 0.008	Loss 5.93	Acc@1 64.1	Acc@5 89.1
Epoch: [99][31/704]	Time 0.127	Data 0.006	Loss 6.12	Acc@1 54.7	Acc@5 92.2
Epoch: [99][41/704]	Time 0.126	Data 0.004	Loss 4.82	Acc@1 71.9	Acc@5 95.3
Epoch: [99][51/704]	Time 0.125	Data 0.004	Loss 4.48	Acc@1 68.8	Acc@5 93.8
Epoch: [99][61/704]	Time 0.124	Data 0.003	Loss 4.80	Acc@1 59.4	Acc@5 93.8
Epoch: [99][71/704]	Time 0.124	Data 0.003	Loss 4.31	Acc@1 68.8	Acc@5 92.2
Epoch: [99][81/704]	Time 0.123	Data 0.002	Loss 5.27	Acc@1 73.4	Acc@5 89.1
Epoch: [99][91/704]	Time 0.123	Data 0.002	Loss 5.26	Acc@1 75.0	Acc@5 93.8
Epoch: [99][101/704]	Time 0.123	Data 0.002	Loss 6.11	Acc@1 60.9	Acc@5 89.1
Epoch: [99][111/704]	Time 0.123	Data 0.002	Loss 4.00	Acc@1 75.0	Acc@5 100.0
Epoch: [99][121/704]	Time 0.123	Data 0.002	Loss 5.00	Acc@1 73.4	Acc@5 90.6
Epoch: [99][131/704]	Time 0.122	Data 0.002	Loss 5.05	Acc@1 68.8	Acc@5 93.8
Epoch: [99][141/704]	Time 0.122	Data 0.002	Loss 4.30	Acc@1 75.0	Acc@5 98.4
Epoch: [99][151/704]	Time 0.122	Data 0.001	Loss 4.41	Acc@1 76.6	Acc@5 95.3
Epoch: [99][161/704]	Time 0.122	Data 0.001	Loss 5.59	Acc@1 70.3	Acc@5 90.6
Epoch: [99][171/704]	Time 0.122	Data 0.001	Loss 5.26	Acc@1 62.5	Acc@5 93.8
Epoch: [99][181/704]	Time 0.122	Data 0.001	Loss 4.65	Acc@1 75.0	Acc@5 98.4
Epoch: [99][191/704]	Time 0.122	Data 0.001	Loss 4.40	Acc@1 76.6	Acc@5 96.9
Epoch: [99][201/704]	Time 0.122	Data 0.001	Loss 4.81	Acc@1 75.0	Acc@5 95.3
Epoch: [99][211/704]	Time 0.122	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 93.8
Epoch: [99][221/704]	Time 0.122	Data 0.001	Loss 4.71	Acc@1 73.4	Acc@5 93.8
Epoch: [99][231/704]	Time 0.122	Data 0.001	Loss 4.54	Acc@1 70.3	Acc@5 93.8
Epoch: [99][241/704]	Time 0.122	Data 0.001	Loss 4.06	Acc@1 73.4	Acc@5 93.8
Epoch: [99][251/704]	Time 0.122	Data 0.001	Loss 5.01	Acc@1 76.6	Acc@5 95.3
Epoch: [99][261/704]	Time 0.122	Data 0.001	Loss 4.71	Acc@1 71.9	Acc@5 96.9
Epoch: [99][271/704]	Time 0.122	Data 0.001	Loss 4.13	Acc@1 79.7	Acc@5 93.8
Epoch: [99][281/704]	Time 0.122	Data 0.001	Loss 4.51	Acc@1 68.8	Acc@5 96.9
Epoch: [99][291/704]	Time 0.122	Data 0.001	Loss 4.42	Acc@1 71.9	Acc@5 93.8
Epoch: [99][301/704]	Time 0.122	Data 0.001	Loss 3.61	Acc@1 79.7	Acc@5 95.3
Epoch: [99][311/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 57.8	Acc@5 89.1
Epoch: [99][321/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 70.3	Acc@5 93.8
Epoch: [99][331/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 75.0	Acc@5 100.0
Epoch: [99][341/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 70.3	Acc@5 92.2
Epoch: [99][351/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 65.6	Acc@5 90.6
Epoch: [99][361/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 76.6	Acc@5 95.3
Epoch: [99][371/704]	Time 0.121	Data 0.001	Loss 6.37	Acc@1 60.9	Acc@5 92.2
Epoch: [99][381/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 73.4	Acc@5 96.9
Epoch: [99][391/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 67.2	Acc@5 95.3
Epoch: [99][401/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 71.9	Acc@5 95.3
Epoch: [99][411/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 73.4	Acc@5 95.3
Epoch: [99][421/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 65.6	Acc@5 95.3
Epoch: [99][431/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 70.3	Acc@5 93.8
Epoch: [99][441/704]	Time 0.121	Data 0.001	Loss 6.36	Acc@1 64.1	Acc@5 85.9
Epoch: [99][451/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 65.6	Acc@5 92.2
Epoch: [99][461/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 71.9	Acc@5 92.2
Epoch: [99][471/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 65.6	Acc@5 93.8
Epoch: [99][481/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 64.1	Acc@5 90.6
Epoch: [99][491/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 56.2	Acc@5 93.8
Epoch: [99][501/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 71.9	Acc@5 93.8
Epoch: [99][511/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 67.2	Acc@5 85.9
Epoch: [99][521/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 56.2	Acc@5 92.2
Epoch: [99][531/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 68.8	Acc@5 98.4
Epoch: [99][541/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 67.2	Acc@5 92.2
Epoch: [99][551/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 68.8	Acc@5 87.5
Epoch: [99][561/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 70.3	Acc@5 95.3
Epoch: [99][571/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 76.6	Acc@5 95.3
Epoch: [99][581/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 68.8	Acc@5 98.4
Epoch: [99][591/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 68.8	Acc@5 95.3
Epoch: [99][601/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 59.4	Acc@5 90.6
Epoch: [99][611/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 68.8	Acc@5 89.1
Epoch: [99][621/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 64.1	Acc@5 92.2
Epoch: [99][631/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 71.9	Acc@5 93.8
Epoch: [99][641/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 75.0	Acc@5 95.3
Epoch: [99][651/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 70.3	Acc@5 95.3
Epoch: [99][661/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 78.1	Acc@5 95.3
Epoch: [99][671/704]	Time 0.121	Data 0.001	Loss 3.90	Acc@1 76.6	Acc@5 96.9
Epoch: [99][681/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 76.6	Acc@5 98.4
Epoch: [99][691/704]	Time 0.121	Data 0.001	Loss 6.35	Acc@1 56.2	Acc@5 89.1
Epoch: [99][701/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 60.9	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.8259	Acc@1 60.9375	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.2877	Acc@1 56.2500	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.9516	Acc@1 50.0000	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.5847	Acc@1 64.0625	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9980	Acc@1 54.6875	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.4524	Acc@1 50.0000	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6786	Acc@1 68.7500	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.1577	Acc@1 53.1250	Acc@5 81.2500
 * prec@1 47.320 prec@5 79.300
 * prec@1 50.880 prec@5 81.320
 * prec@1 55.240 prec@5 85.080
 * prec@1 56.780 prec@5 85.160
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_099.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_099.pth.tar'
Epoch: [100][1/704]	Time 0.300	Data 0.132	Loss 5.03	Acc@1 71.9	Acc@5 93.8
Epoch: [100][11/704]	Time 0.137	Data 0.012	Loss 4.67	Acc@1 70.3	Acc@5 95.3
Epoch: [100][21/704]	Time 0.129	Data 0.007	Loss 3.61	Acc@1 79.7	Acc@5 96.9
Epoch: [100][31/704]	Time 0.126	Data 0.005	Loss 4.45	Acc@1 67.2	Acc@5 93.8
Epoch: [100][41/704]	Time 0.125	Data 0.004	Loss 5.65	Acc@1 70.3	Acc@5 92.2
Epoch: [100][51/704]	Time 0.124	Data 0.003	Loss 5.13	Acc@1 71.9	Acc@5 95.3
Epoch: [100][61/704]	Time 0.123	Data 0.003	Loss 4.97	Acc@1 67.2	Acc@5 95.3
Epoch: [100][71/704]	Time 0.123	Data 0.002	Loss 5.36	Acc@1 64.1	Acc@5 95.3
Epoch: [100][81/704]	Time 0.122	Data 0.002	Loss 5.63	Acc@1 65.6	Acc@5 85.9
Epoch: [100][91/704]	Time 0.123	Data 0.002	Loss 5.59	Acc@1 64.1	Acc@5 90.6
Epoch: [100][101/704]	Time 0.122	Data 0.002	Loss 5.15	Acc@1 67.2	Acc@5 90.6
Epoch: [100][111/704]	Time 0.122	Data 0.002	Loss 6.89	Acc@1 53.1	Acc@5 81.2
Epoch: [100][121/704]	Time 0.122	Data 0.001	Loss 5.21	Acc@1 67.2	Acc@5 90.6
Epoch: [100][131/704]	Time 0.122	Data 0.001	Loss 4.56	Acc@1 71.9	Acc@5 92.2
Epoch: [100][141/704]	Time 0.122	Data 0.001	Loss 6.06	Acc@1 57.8	Acc@5 93.8
Epoch: [100][151/704]	Time 0.122	Data 0.001	Loss 4.84	Acc@1 76.6	Acc@5 96.9
Epoch: [100][161/704]	Time 0.122	Data 0.001	Loss 4.62	Acc@1 68.8	Acc@5 95.3
Epoch: [100][171/704]	Time 0.121	Data 0.001	Loss 3.74	Acc@1 76.6	Acc@5 93.8
Epoch: [100][181/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 73.4	Acc@5 95.3
Epoch: [100][191/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 65.6	Acc@5 93.8
Epoch: [100][201/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 71.9	Acc@5 93.8
Epoch: [100][211/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 79.7	Acc@5 95.3
Epoch: [100][221/704]	Time 0.121	Data 0.001	Loss 4.22	Acc@1 70.3	Acc@5 93.8
Epoch: [100][231/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 64.1	Acc@5 90.6
Epoch: [100][241/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 64.1	Acc@5 90.6
Epoch: [100][251/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 70.3	Acc@5 90.6
Epoch: [100][261/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 62.5	Acc@5 89.1
Epoch: [100][271/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 67.2	Acc@5 92.2
Epoch: [100][281/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 62.5	Acc@5 92.2
Epoch: [100][291/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 71.9	Acc@5 90.6
Epoch: [100][301/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 59.4	Acc@5 90.6
Epoch: [100][311/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 76.6	Acc@5 96.9
Epoch: [100][321/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 75.0	Acc@5 92.2
Epoch: [100][331/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 92.2
Epoch: [100][341/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 65.6	Acc@5 92.2
Epoch: [100][351/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 60.9	Acc@5 93.8
Epoch: [100][361/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 73.4	Acc@5 90.6
Epoch: [100][371/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 92.2
Epoch: [100][381/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 92.2
Epoch: [100][391/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 57.8	Acc@5 95.3
Epoch: [100][401/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 68.8	Acc@5 95.3
Epoch: [100][411/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 65.6	Acc@5 90.6
Epoch: [100][421/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 70.3	Acc@5 85.9
Epoch: [100][431/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 81.2	Acc@5 98.4
Epoch: [100][441/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 64.1	Acc@5 96.9
Epoch: [100][451/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 57.8	Acc@5 84.4
Epoch: [100][461/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 70.3	Acc@5 92.2
Epoch: [100][471/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 71.9	Acc@5 93.8
Epoch: [100][481/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 65.6	Acc@5 95.3
Epoch: [100][491/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 57.8	Acc@5 92.2
Epoch: [100][501/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 73.4	Acc@5 95.3
Epoch: [100][511/704]	Time 0.121	Data 0.001	Loss 3.63	Acc@1 78.1	Acc@5 98.4
Epoch: [100][521/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 70.3	Acc@5 90.6
Epoch: [100][531/704]	Time 0.121	Data 0.001	Loss 3.99	Acc@1 84.4	Acc@5 98.4
Epoch: [100][541/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 68.8	Acc@5 98.4
Epoch: [100][551/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 70.3	Acc@5 93.8
Epoch: [100][561/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 73.4	Acc@5 96.9
Epoch: [100][571/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 73.4	Acc@5 89.1
Epoch: [100][581/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 64.1	Acc@5 93.8
Epoch: [100][591/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 60.9	Acc@5 93.8
Epoch: [100][601/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 67.2	Acc@5 92.2
Epoch: [100][611/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 71.9	Acc@5 96.9
Epoch: [100][621/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 68.8	Acc@5 93.8
Epoch: [100][631/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 68.8	Acc@5 98.4
Epoch: [100][641/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 70.3	Acc@5 95.3
Epoch: [100][651/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 71.9	Acc@5 93.8
Epoch: [100][661/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 71.9	Acc@5 93.8
Epoch: [100][671/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 71.9	Acc@5 95.3
Epoch: [100][681/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 65.6	Acc@5 89.1
Epoch: [100][691/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 68.8	Acc@5 90.6
Epoch: [100][701/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 67.2	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.6488	Acc@1 50.0000	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.7622	Acc@1 64.0625	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8113	Acc@1 60.9375	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.6423	Acc@1 45.3125	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.6945	Acc@1 51.5625	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1902	Acc@1 62.5000	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.1158	Acc@1 59.3750	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.2420	Acc@1 56.2500	Acc@5 87.5000
 * prec@1 47.800 prec@5 78.340
 * prec@1 51.820 prec@5 82.840
 * prec@1 54.900 prec@5 85.200
 * prec@1 56.440 prec@5 85.680
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_100.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_100.pth.tar'
Epoch: [101][1/704]	Time 0.297	Data 0.128	Loss 4.93	Acc@1 60.9	Acc@5 96.9
Epoch: [101][11/704]	Time 0.140	Data 0.012	Loss 4.17	Acc@1 73.4	Acc@5 96.9
Epoch: [101][21/704]	Time 0.130	Data 0.006	Loss 5.26	Acc@1 73.4	Acc@5 85.9
Epoch: [101][31/704]	Time 0.127	Data 0.004	Loss 4.22	Acc@1 78.1	Acc@5 96.9
Epoch: [101][41/704]	Time 0.125	Data 0.003	Loss 5.44	Acc@1 75.0	Acc@5 93.8
Epoch: [101][51/704]	Time 0.124	Data 0.003	Loss 5.13	Acc@1 73.4	Acc@5 93.8
Epoch: [101][61/704]	Time 0.124	Data 0.002	Loss 5.36	Acc@1 67.2	Acc@5 90.6
Epoch: [101][71/704]	Time 0.123	Data 0.002	Loss 4.88	Acc@1 70.3	Acc@5 93.8
Epoch: [101][81/704]	Time 0.123	Data 0.002	Loss 4.72	Acc@1 71.9	Acc@5 93.8
Epoch: [101][91/704]	Time 0.122	Data 0.002	Loss 5.75	Acc@1 68.8	Acc@5 87.5
Epoch: [101][101/704]	Time 0.122	Data 0.002	Loss 6.01	Acc@1 67.2	Acc@5 89.1
Epoch: [101][111/704]	Time 0.122	Data 0.002	Loss 3.92	Acc@1 78.1	Acc@5 95.3
Epoch: [101][121/704]	Time 0.122	Data 0.001	Loss 5.78	Acc@1 68.8	Acc@5 90.6
Epoch: [101][131/704]	Time 0.122	Data 0.001	Loss 4.94	Acc@1 70.3	Acc@5 92.2
Epoch: [101][141/704]	Time 0.122	Data 0.001	Loss 4.72	Acc@1 70.3	Acc@5 93.8
Epoch: [101][151/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 70.3	Acc@5 98.4
Epoch: [101][161/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 68.8	Acc@5 95.3
Epoch: [101][171/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 68.8	Acc@5 92.2
Epoch: [101][181/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 70.3	Acc@5 90.6
Epoch: [101][191/704]	Time 0.121	Data 0.001	Loss 3.98	Acc@1 70.3	Acc@5 93.8
Epoch: [101][201/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 93.8
Epoch: [101][211/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 65.6	Acc@5 96.9
Epoch: [101][221/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 62.5	Acc@5 85.9
Epoch: [101][231/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 64.1	Acc@5 92.2
Epoch: [101][241/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 57.8	Acc@5 90.6
Epoch: [101][251/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 67.2	Acc@5 90.6
Epoch: [101][261/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 64.1	Acc@5 93.8
Epoch: [101][271/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 65.6	Acc@5 87.5
Epoch: [101][281/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 67.2	Acc@5 93.8
Epoch: [101][291/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 75.0	Acc@5 90.6
Epoch: [101][301/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 59.4	Acc@5 89.1
Epoch: [101][311/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 92.2
Epoch: [101][321/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 67.2	Acc@5 95.3
Epoch: [101][331/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 59.4	Acc@5 90.6
Epoch: [101][341/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 71.9	Acc@5 96.9
Epoch: [101][351/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 56.2	Acc@5 90.6
Epoch: [101][361/704]	Time 0.121	Data 0.001	Loss 3.29	Acc@1 81.2	Acc@5 96.9
Epoch: [101][371/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 70.3	Acc@5 98.4
Epoch: [101][381/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 71.9	Acc@5 93.8
Epoch: [101][391/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 62.5	Acc@5 89.1
Epoch: [101][401/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 64.1	Acc@5 90.6
Epoch: [101][411/704]	Time 0.121	Data 0.001	Loss 7.39	Acc@1 56.2	Acc@5 84.4
Epoch: [101][421/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 65.6	Acc@5 90.6
Epoch: [101][431/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 70.3	Acc@5 90.6
Epoch: [101][441/704]	Time 0.120	Data 0.001	Loss 4.05	Acc@1 76.6	Acc@5 95.3
Epoch: [101][451/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 62.5	Acc@5 92.2
Epoch: [101][461/704]	Time 0.120	Data 0.001	Loss 3.93	Acc@1 78.1	Acc@5 98.4
Epoch: [101][471/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 62.5	Acc@5 92.2
Epoch: [101][481/704]	Time 0.120	Data 0.001	Loss 4.93	Acc@1 65.6	Acc@5 95.3
Epoch: [101][491/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 65.6	Acc@5 92.2
Epoch: [101][501/704]	Time 0.120	Data 0.001	Loss 5.10	Acc@1 68.8	Acc@5 92.2
Epoch: [101][511/704]	Time 0.120	Data 0.001	Loss 4.41	Acc@1 70.3	Acc@5 93.8
Epoch: [101][521/704]	Time 0.120	Data 0.001	Loss 4.81	Acc@1 64.1	Acc@5 96.9
Epoch: [101][531/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 65.6	Acc@5 95.3
Epoch: [101][541/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 71.9	Acc@5 87.5
Epoch: [101][551/704]	Time 0.120	Data 0.001	Loss 4.39	Acc@1 68.8	Acc@5 93.8
Epoch: [101][561/704]	Time 0.120	Data 0.001	Loss 6.19	Acc@1 62.5	Acc@5 93.8
Epoch: [101][571/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 76.6	Acc@5 90.6
Epoch: [101][581/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 64.1	Acc@5 96.9
Epoch: [101][591/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 68.8	Acc@5 92.2
Epoch: [101][601/704]	Time 0.120	Data 0.001	Loss 4.65	Acc@1 78.1	Acc@5 93.8
Epoch: [101][611/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 64.1	Acc@5 90.6
Epoch: [101][621/704]	Time 0.120	Data 0.001	Loss 4.69	Acc@1 71.9	Acc@5 92.2
Epoch: [101][631/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 60.9	Acc@5 93.8
Epoch: [101][641/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 65.6	Acc@5 90.6
Epoch: [101][651/704]	Time 0.120	Data 0.001	Loss 5.63	Acc@1 70.3	Acc@5 95.3
Epoch: [101][661/704]	Time 0.120	Data 0.001	Loss 4.75	Acc@1 65.6	Acc@5 92.2
Epoch: [101][671/704]	Time 0.120	Data 0.001	Loss 5.96	Acc@1 57.8	Acc@5 85.9
Epoch: [101][681/704]	Time 0.120	Data 0.001	Loss 4.38	Acc@1 64.1	Acc@5 98.4
Epoch: [101][691/704]	Time 0.120	Data 0.001	Loss 3.87	Acc@1 76.6	Acc@5 93.8
Epoch: [101][701/704]	Time 0.120	Data 0.001	Loss 4.77	Acc@1 64.1	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.9038	Acc@1 53.1250	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.2560	Acc@1 51.5625	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6169	Acc@1 53.1250	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6279	Acc@1 56.2500	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.7549	Acc@1 60.9375	Acc@5 76.5625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1665	Acc@1 57.8125	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7774	Acc@1 62.5000	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.8809	Acc@1 60.9375	Acc@5 81.2500
 * prec@1 48.940 prec@5 79.100
 * prec@1 53.580 prec@5 82.820
 * prec@1 57.160 prec@5 85.220
 * prec@1 57.620 prec@5 84.760
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_101.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_101.pth.tar'
Epoch: [102][1/704]	Time 0.334	Data 0.168	Loss 5.05	Acc@1 60.9	Acc@5 93.8
Epoch: [102][11/704]	Time 0.140	Data 0.016	Loss 4.07	Acc@1 71.9	Acc@5 92.2
Epoch: [102][21/704]	Time 0.130	Data 0.008	Loss 5.55	Acc@1 70.3	Acc@5 87.5
Epoch: [102][31/704]	Time 0.127	Data 0.006	Loss 4.70	Acc@1 71.9	Acc@5 90.6
Epoch: [102][41/704]	Time 0.125	Data 0.004	Loss 4.96	Acc@1 73.4	Acc@5 93.8
Epoch: [102][51/704]	Time 0.124	Data 0.004	Loss 5.02	Acc@1 68.8	Acc@5 93.8
Epoch: [102][61/704]	Time 0.124	Data 0.003	Loss 5.48	Acc@1 75.0	Acc@5 89.1
Epoch: [102][71/704]	Time 0.123	Data 0.003	Loss 4.74	Acc@1 68.8	Acc@5 90.6
Epoch: [102][81/704]	Time 0.123	Data 0.002	Loss 5.10	Acc@1 67.2	Acc@5 92.2
Epoch: [102][91/704]	Time 0.123	Data 0.002	Loss 4.93	Acc@1 70.3	Acc@5 90.6
Epoch: [102][101/704]	Time 0.122	Data 0.002	Loss 4.71	Acc@1 73.4	Acc@5 95.3
Epoch: [102][111/704]	Time 0.122	Data 0.002	Loss 5.77	Acc@1 68.8	Acc@5 85.9
Epoch: [102][121/704]	Time 0.122	Data 0.002	Loss 4.32	Acc@1 78.1	Acc@5 92.2
Epoch: [102][131/704]	Time 0.122	Data 0.002	Loss 5.85	Acc@1 71.9	Acc@5 90.6
Epoch: [102][141/704]	Time 0.122	Data 0.002	Loss 4.06	Acc@1 76.6	Acc@5 95.3
Epoch: [102][151/704]	Time 0.122	Data 0.001	Loss 4.90	Acc@1 71.9	Acc@5 95.3
Epoch: [102][161/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 75.0	Acc@5 96.9
Epoch: [102][171/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 56.2	Acc@5 92.2
Epoch: [102][181/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 59.4	Acc@5 92.2
Epoch: [102][191/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 92.2
Epoch: [102][201/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 68.8	Acc@5 95.3
Epoch: [102][211/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 73.4	Acc@5 93.8
Epoch: [102][221/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 76.6	Acc@5 95.3
Epoch: [102][231/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 65.6	Acc@5 92.2
Epoch: [102][241/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 70.3	Acc@5 96.9
Epoch: [102][251/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 65.6	Acc@5 90.6
Epoch: [102][261/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 75.0	Acc@5 92.2
Epoch: [102][271/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 75.0	Acc@5 92.2
Epoch: [102][281/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 73.4	Acc@5 96.9
Epoch: [102][291/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 68.8	Acc@5 98.4
Epoch: [102][301/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 67.2	Acc@5 87.5
Epoch: [102][311/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 65.6	Acc@5 95.3
Epoch: [102][321/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 53.1	Acc@5 92.2
Epoch: [102][331/704]	Time 0.121	Data 0.001	Loss 6.56	Acc@1 67.2	Acc@5 89.1
Epoch: [102][341/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 75.0	Acc@5 92.2
Epoch: [102][351/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 93.8
Epoch: [102][361/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 64.1	Acc@5 93.8
Epoch: [102][371/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 67.2	Acc@5 90.6
Epoch: [102][381/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 70.3	Acc@5 95.3
Epoch: [102][391/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 60.9	Acc@5 95.3
Epoch: [102][401/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 75.0	Acc@5 92.2
Epoch: [102][411/704]	Time 0.121	Data 0.001	Loss 3.77	Acc@1 73.4	Acc@5 98.4
Epoch: [102][421/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 70.3	Acc@5 96.9
Epoch: [102][431/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 75.0	Acc@5 92.2
Epoch: [102][441/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 62.5	Acc@5 89.1
Epoch: [102][451/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 68.8	Acc@5 96.9
Epoch: [102][461/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 59.4	Acc@5 89.1
Epoch: [102][471/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 68.8	Acc@5 92.2
Epoch: [102][481/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 62.5	Acc@5 82.8
Epoch: [102][491/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 70.3	Acc@5 98.4
Epoch: [102][501/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 73.4	Acc@5 95.3
Epoch: [102][511/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 75.0	Acc@5 93.8
Epoch: [102][521/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 59.4	Acc@5 85.9
Epoch: [102][531/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 71.9	Acc@5 92.2
Epoch: [102][541/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 60.9	Acc@5 95.3
Epoch: [102][551/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 65.6	Acc@5 90.6
Epoch: [102][561/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 76.6	Acc@5 90.6
Epoch: [102][571/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 70.3	Acc@5 95.3
Epoch: [102][581/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 71.9	Acc@5 87.5
Epoch: [102][591/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 68.8	Acc@5 90.6
Epoch: [102][601/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 71.9	Acc@5 90.6
Epoch: [102][611/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 65.6	Acc@5 93.8
Epoch: [102][621/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 71.9	Acc@5 92.2
Epoch: [102][631/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 70.3	Acc@5 89.1
Epoch: [102][641/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 73.4	Acc@5 95.3
Epoch: [102][651/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 68.8	Acc@5 95.3
Epoch: [102][661/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 65.6	Acc@5 85.9
Epoch: [102][671/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 65.6	Acc@5 93.8
Epoch: [102][681/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 60.9	Acc@5 85.9
Epoch: [102][691/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 65.6	Acc@5 93.8
Epoch: [102][701/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 70.3	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.6943	Acc@1 64.0625	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.9418	Acc@1 68.7500	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8460	Acc@1 62.5000	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7338	Acc@1 60.9375	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.2209	Acc@1 48.4375	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.5795	Acc@1 62.5000	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.1949	Acc@1 59.3750	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.4828	Acc@1 54.6875	Acc@5 84.3750
 * prec@1 47.620 prec@5 76.680
 * prec@1 52.380 prec@5 82.000
 * prec@1 55.860 prec@5 84.580
 * prec@1 57.800 prec@5 86.540
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_102.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_102.pth.tar'
Epoch: [103][1/704]	Time 0.302	Data 0.135	Loss 4.19	Acc@1 71.9	Acc@5 92.2
Epoch: [103][11/704]	Time 0.137	Data 0.012	Loss 5.64	Acc@1 70.3	Acc@5 90.6
Epoch: [103][21/704]	Time 0.129	Data 0.007	Loss 4.64	Acc@1 71.9	Acc@5 89.1
Epoch: [103][31/704]	Time 0.126	Data 0.005	Loss 4.85	Acc@1 75.0	Acc@5 92.2
Epoch: [103][41/704]	Time 0.124	Data 0.004	Loss 4.48	Acc@1 75.0	Acc@5 93.8
Epoch: [103][51/704]	Time 0.124	Data 0.003	Loss 5.26	Acc@1 68.8	Acc@5 93.8
Epoch: [103][61/704]	Time 0.123	Data 0.003	Loss 4.01	Acc@1 76.6	Acc@5 98.4
Epoch: [103][71/704]	Time 0.123	Data 0.002	Loss 4.85	Acc@1 68.8	Acc@5 95.3
Epoch: [103][81/704]	Time 0.122	Data 0.002	Loss 4.71	Acc@1 64.1	Acc@5 96.9
Epoch: [103][91/704]	Time 0.122	Data 0.002	Loss 4.41	Acc@1 78.1	Acc@5 96.9
Epoch: [103][101/704]	Time 0.122	Data 0.002	Loss 4.19	Acc@1 75.0	Acc@5 96.9
Epoch: [103][111/704]	Time 0.122	Data 0.002	Loss 5.53	Acc@1 68.8	Acc@5 92.2
Epoch: [103][121/704]	Time 0.122	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 90.6
Epoch: [103][131/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 71.9	Acc@5 96.9
Epoch: [103][141/704]	Time 0.122	Data 0.001	Loss 5.00	Acc@1 68.8	Acc@5 89.1
Epoch: [103][151/704]	Time 0.122	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 95.3
Epoch: [103][161/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 73.4	Acc@5 93.8
Epoch: [103][171/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 95.3
Epoch: [103][181/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 73.4	Acc@5 92.2
Epoch: [103][191/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 67.2	Acc@5 92.2
Epoch: [103][201/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 70.3	Acc@5 96.9
Epoch: [103][211/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 75.0	Acc@5 89.1
Epoch: [103][221/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 73.4	Acc@5 95.3
Epoch: [103][231/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 75.0	Acc@5 93.8
Epoch: [103][241/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 71.9	Acc@5 95.3
Epoch: [103][251/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 92.2
Epoch: [103][261/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 62.5	Acc@5 92.2
Epoch: [103][271/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 60.9	Acc@5 89.1
Epoch: [103][281/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 64.1	Acc@5 93.8
Epoch: [103][291/704]	Time 0.121	Data 0.001	Loss 4.35	Acc@1 67.2	Acc@5 95.3
Epoch: [103][301/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 65.6	Acc@5 90.6
Epoch: [103][311/704]	Time 0.121	Data 0.001	Loss 6.46	Acc@1 56.2	Acc@5 89.1
Epoch: [103][321/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 68.8	Acc@5 95.3
Epoch: [103][331/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 67.2	Acc@5 90.6
Epoch: [103][341/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 50.0	Acc@5 95.3
Epoch: [103][351/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 71.9	Acc@5 92.2
Epoch: [103][361/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 68.8	Acc@5 92.2
Epoch: [103][371/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 59.4	Acc@5 90.6
Epoch: [103][381/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 71.9	Acc@5 95.3
Epoch: [103][391/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 65.6	Acc@5 90.6
Epoch: [103][401/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 65.6	Acc@5 93.8
Epoch: [103][411/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 87.5
Epoch: [103][421/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 79.7	Acc@5 92.2
Epoch: [103][431/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 73.4	Acc@5 93.8
Epoch: [103][441/704]	Time 0.121	Data 0.001	Loss 3.83	Acc@1 79.7	Acc@5 96.9
Epoch: [103][451/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 70.3	Acc@5 95.3
Epoch: [103][461/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 64.1	Acc@5 96.9
Epoch: [103][471/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 62.5	Acc@5 92.2
Epoch: [103][481/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 73.4	Acc@5 93.8
Epoch: [103][491/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 75.0	Acc@5 90.6
Epoch: [103][501/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 70.3	Acc@5 95.3
Epoch: [103][511/704]	Time 0.121	Data 0.001	Loss 4.35	Acc@1 68.8	Acc@5 95.3
Epoch: [103][521/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 93.8
Epoch: [103][531/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 59.4	Acc@5 85.9
Epoch: [103][541/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 67.2	Acc@5 87.5
Epoch: [103][551/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 71.9	Acc@5 98.4
Epoch: [103][561/704]	Time 0.120	Data 0.001	Loss 4.48	Acc@1 73.4	Acc@5 92.2
Epoch: [103][571/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 90.6
Epoch: [103][581/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 64.1	Acc@5 92.2
Epoch: [103][591/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 67.2	Acc@5 90.6
Epoch: [103][601/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 75.0	Acc@5 90.6
Epoch: [103][611/704]	Time 0.120	Data 0.001	Loss 4.27	Acc@1 82.8	Acc@5 95.3
Epoch: [103][621/704]	Time 0.120	Data 0.001	Loss 7.19	Acc@1 60.9	Acc@5 89.1
Epoch: [103][631/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 73.4	Acc@5 92.2
Epoch: [103][641/704]	Time 0.120	Data 0.001	Loss 5.49	Acc@1 60.9	Acc@5 87.5
Epoch: [103][651/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 62.5	Acc@5 92.2
Epoch: [103][661/704]	Time 0.120	Data 0.001	Loss 4.00	Acc@1 70.3	Acc@5 93.8
Epoch: [103][671/704]	Time 0.120	Data 0.001	Loss 4.95	Acc@1 78.1	Acc@5 92.2
Epoch: [103][681/704]	Time 0.120	Data 0.001	Loss 4.30	Acc@1 73.4	Acc@5 96.9
Epoch: [103][691/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 70.3	Acc@5 85.9
Epoch: [103][701/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 68.8	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.2904	Acc@1 54.6875	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8670	Acc@1 62.5000	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2719	Acc@1 67.1875	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.2475	Acc@1 54.6875	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.5561	Acc@1 57.8125	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.9760	Acc@1 46.8750	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4616	Acc@1 50.0000	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2771	Acc@1 54.6875	Acc@5 81.2500
 * prec@1 47.480 prec@5 77.320
 * prec@1 52.580 prec@5 82.100
 * prec@1 55.300 prec@5 84.860
 * prec@1 56.680 prec@5 85.360
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_103.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_103.pth.tar'
Epoch: [104][1/704]	Time 0.300	Data 0.133	Loss 4.56	Acc@1 70.3	Acc@5 92.2
Epoch: [104][11/704]	Time 0.137	Data 0.012	Loss 5.56	Acc@1 64.1	Acc@5 87.5
Epoch: [104][21/704]	Time 0.129	Data 0.007	Loss 5.86	Acc@1 57.8	Acc@5 84.4
Epoch: [104][31/704]	Time 0.126	Data 0.005	Loss 5.79	Acc@1 68.8	Acc@5 90.6
Epoch: [104][41/704]	Time 0.124	Data 0.004	Loss 6.11	Acc@1 65.6	Acc@5 90.6
Epoch: [104][51/704]	Time 0.123	Data 0.003	Loss 4.98	Acc@1 67.2	Acc@5 92.2
Epoch: [104][61/704]	Time 0.124	Data 0.003	Loss 4.56	Acc@1 68.8	Acc@5 96.9
Epoch: [104][71/704]	Time 0.123	Data 0.002	Loss 5.10	Acc@1 65.6	Acc@5 95.3
Epoch: [104][81/704]	Time 0.123	Data 0.002	Loss 5.09	Acc@1 67.2	Acc@5 92.2
Epoch: [104][91/704]	Time 0.122	Data 0.002	Loss 5.35	Acc@1 71.9	Acc@5 92.2
Epoch: [104][101/704]	Time 0.122	Data 0.002	Loss 5.36	Acc@1 67.2	Acc@5 92.2
Epoch: [104][111/704]	Time 0.122	Data 0.002	Loss 4.68	Acc@1 68.8	Acc@5 90.6
Epoch: [104][121/704]	Time 0.122	Data 0.001	Loss 5.01	Acc@1 73.4	Acc@5 95.3
Epoch: [104][131/704]	Time 0.122	Data 0.001	Loss 4.20	Acc@1 67.2	Acc@5 95.3
Epoch: [104][141/704]	Time 0.122	Data 0.001	Loss 5.06	Acc@1 67.2	Acc@5 90.6
Epoch: [104][151/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 71.9	Acc@5 95.3
Epoch: [104][161/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 65.6	Acc@5 93.8
Epoch: [104][171/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 75.0	Acc@5 96.9
Epoch: [104][181/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 68.8	Acc@5 95.3
Epoch: [104][191/704]	Time 0.121	Data 0.001	Loss 3.34	Acc@1 84.4	Acc@5 96.9
Epoch: [104][201/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 70.3	Acc@5 93.8
Epoch: [104][211/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 70.3	Acc@5 87.5
Epoch: [104][221/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 59.4	Acc@5 87.5
Epoch: [104][231/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 67.2	Acc@5 93.8
Epoch: [104][241/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 67.2	Acc@5 90.6
Epoch: [104][251/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 75.0	Acc@5 92.2
Epoch: [104][261/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 73.4	Acc@5 95.3
Epoch: [104][271/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 70.3	Acc@5 95.3
Epoch: [104][281/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 76.6	Acc@5 96.9
Epoch: [104][291/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 68.8	Acc@5 89.1
Epoch: [104][301/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 65.6	Acc@5 90.6
Epoch: [104][311/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 67.2	Acc@5 93.8
Epoch: [104][321/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 70.3	Acc@5 92.2
Epoch: [104][331/704]	Time 0.121	Data 0.001	Loss 4.18	Acc@1 70.3	Acc@5 93.8
Epoch: [104][341/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 67.2	Acc@5 93.8
Epoch: [104][351/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 60.9	Acc@5 92.2
Epoch: [104][361/704]	Time 0.121	Data 0.001	Loss 4.19	Acc@1 68.8	Acc@5 96.9
Epoch: [104][371/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 70.3	Acc@5 90.6
Epoch: [104][381/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 64.1	Acc@5 90.6
Epoch: [104][391/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 68.8	Acc@5 98.4
Epoch: [104][401/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 73.4	Acc@5 93.8
Epoch: [104][411/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 78.1	Acc@5 92.2
Epoch: [104][421/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 64.1	Acc@5 87.5
Epoch: [104][431/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 78.1	Acc@5 93.8
Epoch: [104][441/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 65.6	Acc@5 95.3
Epoch: [104][451/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 71.9	Acc@5 93.8
Epoch: [104][461/704]	Time 0.121	Data 0.001	Loss 7.41	Acc@1 60.9	Acc@5 82.8
Epoch: [104][471/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 73.4	Acc@5 93.8
Epoch: [104][481/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 67.2	Acc@5 90.6
Epoch: [104][491/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 68.8	Acc@5 98.4
Epoch: [104][501/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 95.3
Epoch: [104][511/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 68.8	Acc@5 93.8
Epoch: [104][521/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 92.2
Epoch: [104][531/704]	Time 0.120	Data 0.001	Loss 4.75	Acc@1 73.4	Acc@5 96.9
Epoch: [104][541/704]	Time 0.120	Data 0.001	Loss 4.69	Acc@1 71.9	Acc@5 96.9
Epoch: [104][551/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 70.3	Acc@5 92.2
Epoch: [104][561/704]	Time 0.120	Data 0.001	Loss 5.48	Acc@1 64.1	Acc@5 93.8
Epoch: [104][571/704]	Time 0.121	Data 0.001	Loss 6.89	Acc@1 59.4	Acc@5 90.6
Epoch: [104][581/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 71.9	Acc@5 89.1
Epoch: [104][591/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 62.5	Acc@5 90.6
Epoch: [104][601/704]	Time 0.120	Data 0.001	Loss 4.35	Acc@1 70.3	Acc@5 96.9
Epoch: [104][611/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 64.1	Acc@5 96.9
Epoch: [104][621/704]	Time 0.120	Data 0.001	Loss 7.38	Acc@1 54.7	Acc@5 85.9
Epoch: [104][631/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 65.6	Acc@5 93.8
Epoch: [104][641/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 62.5	Acc@5 89.1
Epoch: [104][651/704]	Time 0.120	Data 0.001	Loss 6.68	Acc@1 67.2	Acc@5 87.5
Epoch: [104][661/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 71.9	Acc@5 95.3
Epoch: [104][671/704]	Time 0.120	Data 0.001	Loss 4.98	Acc@1 68.8	Acc@5 92.2
Epoch: [104][681/704]	Time 0.120	Data 0.001	Loss 4.21	Acc@1 75.0	Acc@5 95.3
Epoch: [104][691/704]	Time 0.120	Data 0.001	Loss 6.54	Acc@1 62.5	Acc@5 87.5
Epoch: [104][701/704]	Time 0.120	Data 0.001	Loss 4.70	Acc@1 65.6	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.5340	Acc@1 62.5000	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.4773	Acc@1 56.2500	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2444	Acc@1 62.5000	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.2103	Acc@1 53.1250	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.0463	Acc@1 56.2500	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.3269	Acc@1 57.8125	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.3387	Acc@1 53.1250	Acc@5 79.6875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.5553	Acc@1 60.9375	Acc@5 87.5000
 * prec@1 48.180 prec@5 78.700
 * prec@1 52.300 prec@5 83.560
 * prec@1 55.540 prec@5 85.240
 * prec@1 57.280 prec@5 86.060
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_104.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_104.pth.tar'
Epoch: [105][1/704]	Time 0.334	Data 0.168	Loss 4.92	Acc@1 64.1	Acc@5 93.8
Epoch: [105][11/704]	Time 0.140	Data 0.016	Loss 5.18	Acc@1 62.5	Acc@5 90.6
Epoch: [105][21/704]	Time 0.130	Data 0.008	Loss 5.00	Acc@1 73.4	Acc@5 96.9
Epoch: [105][31/704]	Time 0.127	Data 0.006	Loss 5.07	Acc@1 67.2	Acc@5 93.8
Epoch: [105][41/704]	Time 0.125	Data 0.004	Loss 4.70	Acc@1 73.4	Acc@5 95.3
Epoch: [105][51/704]	Time 0.124	Data 0.004	Loss 5.31	Acc@1 64.1	Acc@5 92.2
Epoch: [105][61/704]	Time 0.123	Data 0.003	Loss 5.92	Acc@1 65.6	Acc@5 93.8
Epoch: [105][71/704]	Time 0.123	Data 0.003	Loss 6.14	Acc@1 64.1	Acc@5 87.5
Epoch: [105][81/704]	Time 0.123	Data 0.002	Loss 4.82	Acc@1 70.3	Acc@5 93.8
Epoch: [105][91/704]	Time 0.122	Data 0.002	Loss 5.34	Acc@1 57.8	Acc@5 92.2
Epoch: [105][101/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 73.4	Acc@5 93.8
Epoch: [105][111/704]	Time 0.122	Data 0.002	Loss 4.73	Acc@1 70.3	Acc@5 95.3
Epoch: [105][121/704]	Time 0.122	Data 0.002	Loss 4.86	Acc@1 65.6	Acc@5 92.2
Epoch: [105][131/704]	Time 0.122	Data 0.002	Loss 4.16	Acc@1 65.6	Acc@5 96.9
Epoch: [105][141/704]	Time 0.121	Data 0.002	Loss 3.88	Acc@1 73.4	Acc@5 95.3
Epoch: [105][151/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 71.9	Acc@5 93.8
Epoch: [105][161/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 62.5	Acc@5 95.3
Epoch: [105][171/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 92.2
Epoch: [105][181/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 70.3	Acc@5 93.8
Epoch: [105][191/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 67.2	Acc@5 90.6
Epoch: [105][201/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 68.8	Acc@5 95.3
Epoch: [105][211/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 70.3	Acc@5 92.2
Epoch: [105][221/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 71.9	Acc@5 90.6
Epoch: [105][231/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 65.6	Acc@5 95.3
Epoch: [105][241/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 65.6	Acc@5 96.9
Epoch: [105][251/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 92.2
Epoch: [105][261/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 64.1	Acc@5 89.1
Epoch: [105][271/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 65.6	Acc@5 92.2
Epoch: [105][281/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 57.8	Acc@5 93.8
Epoch: [105][291/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 57.8	Acc@5 87.5
Epoch: [105][301/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 67.2	Acc@5 90.6
Epoch: [105][311/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 62.5	Acc@5 92.2
Epoch: [105][321/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 71.9	Acc@5 93.8
Epoch: [105][331/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 64.1	Acc@5 95.3
Epoch: [105][341/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 78.1	Acc@5 93.8
Epoch: [105][351/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 65.6	Acc@5 89.1
Epoch: [105][361/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 71.9	Acc@5 93.8
Epoch: [105][371/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 64.1	Acc@5 90.6
Epoch: [105][381/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 68.8	Acc@5 93.8
Epoch: [105][391/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 68.8	Acc@5 95.3
Epoch: [105][401/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 65.6	Acc@5 98.4
Epoch: [105][411/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 73.4	Acc@5 100.0
Epoch: [105][421/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 60.9	Acc@5 95.3
Epoch: [105][431/704]	Time 0.120	Data 0.001	Loss 5.81	Acc@1 68.8	Acc@5 93.8
Epoch: [105][441/704]	Time 0.120	Data 0.001	Loss 5.42	Acc@1 70.3	Acc@5 90.6
Epoch: [105][451/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 70.3	Acc@5 90.6
Epoch: [105][461/704]	Time 0.120	Data 0.001	Loss 4.40	Acc@1 71.9	Acc@5 93.8
Epoch: [105][471/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 70.3	Acc@5 95.3
Epoch: [105][481/704]	Time 0.120	Data 0.001	Loss 5.57	Acc@1 57.8	Acc@5 93.8
Epoch: [105][491/704]	Time 0.120	Data 0.001	Loss 5.16	Acc@1 62.5	Acc@5 92.2
Epoch: [105][501/704]	Time 0.120	Data 0.001	Loss 4.69	Acc@1 73.4	Acc@5 93.8
Epoch: [105][511/704]	Time 0.120	Data 0.001	Loss 6.09	Acc@1 65.6	Acc@5 90.6
Epoch: [105][521/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 68.8	Acc@5 87.5
Epoch: [105][531/704]	Time 0.120	Data 0.001	Loss 4.29	Acc@1 75.0	Acc@5 93.8
Epoch: [105][541/704]	Time 0.120	Data 0.001	Loss 3.69	Acc@1 75.0	Acc@5 98.4
Epoch: [105][551/704]	Time 0.120	Data 0.001	Loss 3.94	Acc@1 73.4	Acc@5 96.9
Epoch: [105][561/704]	Time 0.120	Data 0.001	Loss 4.63	Acc@1 71.9	Acc@5 95.3
Epoch: [105][571/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 87.5
Epoch: [105][581/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 60.9	Acc@5 89.1
Epoch: [105][591/704]	Time 0.120	Data 0.001	Loss 6.37	Acc@1 62.5	Acc@5 87.5
Epoch: [105][601/704]	Time 0.120	Data 0.001	Loss 4.35	Acc@1 70.3	Acc@5 98.4
Epoch: [105][611/704]	Time 0.120	Data 0.001	Loss 5.69	Acc@1 64.1	Acc@5 90.6
Epoch: [105][621/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 73.4	Acc@5 93.8
Epoch: [105][631/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 64.1	Acc@5 82.8
Epoch: [105][641/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 70.3	Acc@5 89.1
Epoch: [105][651/704]	Time 0.120	Data 0.001	Loss 5.78	Acc@1 68.8	Acc@5 85.9
Epoch: [105][661/704]	Time 0.120	Data 0.001	Loss 6.47	Acc@1 60.9	Acc@5 87.5
Epoch: [105][671/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 64.1	Acc@5 93.8
Epoch: [105][681/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 62.5	Acc@5 89.1
Epoch: [105][691/704]	Time 0.120	Data 0.001	Loss 4.57	Acc@1 71.9	Acc@5 92.2
Epoch: [105][701/704]	Time 0.120	Data 0.001	Loss 5.43	Acc@1 65.6	Acc@5 93.8
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 7.3170	Acc@1 46.8750	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0815	Acc@1 53.1250	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.3250	Acc@1 59.3750	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4653	Acc@1 57.8125	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5078	Acc@1 57.8125	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9626	Acc@1 53.1250	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.0217	Acc@1 65.6250	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.2504	Acc@1 78.1250	Acc@5 95.3125
 * prec@1 48.500 prec@5 78.420
 * prec@1 52.080 prec@5 83.340
 * prec@1 57.180 prec@5 86.060
 * prec@1 58.380 prec@5 86.460
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_105.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_105.pth.tar'
Epoch: [106][1/704]	Time 0.334	Data 0.167	Loss 4.75	Acc@1 71.9	Acc@5 92.2
Epoch: [106][11/704]	Time 0.140	Data 0.016	Loss 5.17	Acc@1 68.8	Acc@5 90.6
Epoch: [106][21/704]	Time 0.130	Data 0.008	Loss 4.54	Acc@1 75.0	Acc@5 92.2
Epoch: [106][31/704]	Time 0.127	Data 0.006	Loss 4.40	Acc@1 75.0	Acc@5 93.8
Epoch: [106][41/704]	Time 0.125	Data 0.004	Loss 5.37	Acc@1 67.2	Acc@5 90.6
Epoch: [106][51/704]	Time 0.124	Data 0.004	Loss 4.81	Acc@1 75.0	Acc@5 95.3
Epoch: [106][61/704]	Time 0.124	Data 0.003	Loss 4.74	Acc@1 70.3	Acc@5 95.3
Epoch: [106][71/704]	Time 0.123	Data 0.003	Loss 4.22	Acc@1 76.6	Acc@5 95.3
Epoch: [106][81/704]	Time 0.123	Data 0.002	Loss 4.00	Acc@1 76.6	Acc@5 95.3
Epoch: [106][91/704]	Time 0.122	Data 0.002	Loss 4.77	Acc@1 68.8	Acc@5 95.3
Epoch: [106][101/704]	Time 0.122	Data 0.002	Loss 4.05	Acc@1 73.4	Acc@5 95.3
Epoch: [106][111/704]	Time 0.122	Data 0.002	Loss 5.56	Acc@1 70.3	Acc@5 90.6
Epoch: [106][121/704]	Time 0.122	Data 0.002	Loss 4.47	Acc@1 68.8	Acc@5 93.8
Epoch: [106][131/704]	Time 0.122	Data 0.002	Loss 4.44	Acc@1 75.0	Acc@5 95.3
Epoch: [106][141/704]	Time 0.122	Data 0.001	Loss 3.98	Acc@1 73.4	Acc@5 96.9
Epoch: [106][151/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 70.3	Acc@5 93.8
Epoch: [106][161/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 68.8	Acc@5 96.9
Epoch: [106][171/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 64.1	Acc@5 92.2
Epoch: [106][181/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 60.9	Acc@5 93.8
Epoch: [106][191/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 60.9	Acc@5 92.2
Epoch: [106][201/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 67.2	Acc@5 90.6
Epoch: [106][211/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 70.3	Acc@5 92.2
Epoch: [106][221/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 59.4	Acc@5 90.6
Epoch: [106][231/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 70.3	Acc@5 96.9
Epoch: [106][241/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 60.9	Acc@5 93.8
Epoch: [106][251/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 59.4	Acc@5 93.8
Epoch: [106][261/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 60.9	Acc@5 90.6
Epoch: [106][271/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 64.1	Acc@5 89.1
Epoch: [106][281/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 67.2	Acc@5 93.8
Epoch: [106][291/704]	Time 0.121	Data 0.001	Loss 6.37	Acc@1 62.5	Acc@5 85.9
Epoch: [106][301/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 60.9	Acc@5 93.8
Epoch: [106][311/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 71.9	Acc@5 93.8
Epoch: [106][321/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 67.2	Acc@5 96.9
Epoch: [106][331/704]	Time 0.121	Data 0.001	Loss 6.64	Acc@1 48.4	Acc@5 87.5
Epoch: [106][341/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 76.6	Acc@5 93.8
Epoch: [106][351/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 68.8	Acc@5 93.8
Epoch: [106][361/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 71.9	Acc@5 92.2
Epoch: [106][371/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 65.6	Acc@5 93.8
Epoch: [106][381/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 71.9	Acc@5 92.2
Epoch: [106][391/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 95.3
Epoch: [106][401/704]	Time 0.121	Data 0.001	Loss 4.08	Acc@1 71.9	Acc@5 92.2
Epoch: [106][411/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 70.3	Acc@5 95.3
Epoch: [106][421/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 76.6	Acc@5 96.9
Epoch: [106][431/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 68.8	Acc@5 87.5
Epoch: [106][441/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 67.2	Acc@5 95.3
Epoch: [106][451/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 56.2	Acc@5 87.5
Epoch: [106][461/704]	Time 0.121	Data 0.001	Loss 4.18	Acc@1 70.3	Acc@5 93.8
Epoch: [106][471/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 79.7	Acc@5 95.3
Epoch: [106][481/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 81.2	Acc@5 96.9
Epoch: [106][491/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 71.9	Acc@5 85.9
Epoch: [106][501/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 67.2	Acc@5 93.8
Epoch: [106][511/704]	Time 0.120	Data 0.001	Loss 3.90	Acc@1 76.6	Acc@5 93.8
Epoch: [106][521/704]	Time 0.120	Data 0.001	Loss 5.23	Acc@1 64.1	Acc@5 95.3
Epoch: [106][531/704]	Time 0.120	Data 0.001	Loss 5.08	Acc@1 70.3	Acc@5 93.8
Epoch: [106][541/704]	Time 0.120	Data 0.001	Loss 4.81	Acc@1 70.3	Acc@5 95.3
Epoch: [106][551/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 67.2	Acc@5 93.8
Epoch: [106][561/704]	Time 0.120	Data 0.001	Loss 6.02	Acc@1 67.2	Acc@5 90.6
Epoch: [106][571/704]	Time 0.120	Data 0.001	Loss 4.34	Acc@1 71.9	Acc@5 98.4
Epoch: [106][581/704]	Time 0.120	Data 0.001	Loss 4.50	Acc@1 82.8	Acc@5 93.8
Epoch: [106][591/704]	Time 0.120	Data 0.001	Loss 4.27	Acc@1 79.7	Acc@5 96.9
Epoch: [106][601/704]	Time 0.120	Data 0.001	Loss 6.09	Acc@1 57.8	Acc@5 90.6
Epoch: [106][611/704]	Time 0.120	Data 0.001	Loss 4.70	Acc@1 79.7	Acc@5 90.6
Epoch: [106][621/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 56.2	Acc@5 90.6
Epoch: [106][631/704]	Time 0.120	Data 0.001	Loss 5.07	Acc@1 70.3	Acc@5 93.8
Epoch: [106][641/704]	Time 0.120	Data 0.001	Loss 5.41	Acc@1 68.8	Acc@5 84.4
Epoch: [106][651/704]	Time 0.120	Data 0.001	Loss 4.10	Acc@1 65.6	Acc@5 95.3
Epoch: [106][661/704]	Time 0.120	Data 0.001	Loss 6.16	Acc@1 60.9	Acc@5 87.5
Epoch: [106][671/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 68.8	Acc@5 92.2
Epoch: [106][681/704]	Time 0.120	Data 0.001	Loss 4.82	Acc@1 73.4	Acc@5 92.2
Epoch: [106][691/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 65.6	Acc@5 87.5
Epoch: [106][701/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 65.6	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 6.7434	Acc@1 56.2500	Acc@5 79.6875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.6858	Acc@1 64.0625	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.0084	Acc@1 51.5625	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.8552	Acc@1 64.0625	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.5761	Acc@1 65.6250	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.0897	Acc@1 60.9375	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.9480	Acc@1 62.5000	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3127	Acc@1 62.5000	Acc@5 84.3750
 * prec@1 48.160 prec@5 79.220
 * prec@1 51.500 prec@5 81.380
 * prec@1 56.060 prec@5 85.520
 * prec@1 57.000 prec@5 85.540
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_106.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_106.pth.tar'
Epoch: [107][1/704]	Time 0.301	Data 0.132	Loss 5.18	Acc@1 65.6	Acc@5 90.6
Epoch: [107][11/704]	Time 0.137	Data 0.012	Loss 5.31	Acc@1 67.2	Acc@5 96.9
Epoch: [107][21/704]	Time 0.129	Data 0.007	Loss 7.24	Acc@1 59.4	Acc@5 87.5
Epoch: [107][31/704]	Time 0.126	Data 0.005	Loss 4.60	Acc@1 73.4	Acc@5 93.8
Epoch: [107][41/704]	Time 0.125	Data 0.004	Loss 4.53	Acc@1 68.8	Acc@5 93.8
Epoch: [107][51/704]	Time 0.124	Data 0.003	Loss 4.17	Acc@1 75.0	Acc@5 92.2
Epoch: [107][61/704]	Time 0.123	Data 0.002	Loss 4.34	Acc@1 70.3	Acc@5 96.9
Epoch: [107][71/704]	Time 0.123	Data 0.002	Loss 4.51	Acc@1 68.8	Acc@5 95.3
Epoch: [107][81/704]	Time 0.123	Data 0.002	Loss 4.10	Acc@1 81.2	Acc@5 95.3
Epoch: [107][91/704]	Time 0.123	Data 0.002	Loss 4.21	Acc@1 75.0	Acc@5 95.3
Epoch: [107][101/704]	Time 0.123	Data 0.002	Loss 4.40	Acc@1 78.1	Acc@5 89.1
Epoch: [107][111/704]	Time 0.122	Data 0.001	Loss 4.79	Acc@1 75.0	Acc@5 93.8
Epoch: [107][121/704]	Time 0.122	Data 0.001	Loss 5.48	Acc@1 75.0	Acc@5 87.5
Epoch: [107][131/704]	Time 0.122	Data 0.001	Loss 4.71	Acc@1 78.1	Acc@5 93.8
Epoch: [107][141/704]	Time 0.122	Data 0.001	Loss 3.81	Acc@1 76.6	Acc@5 93.8
Epoch: [107][151/704]	Time 0.122	Data 0.001	Loss 5.31	Acc@1 70.3	Acc@5 90.6
Epoch: [107][161/704]	Time 0.122	Data 0.001	Loss 5.57	Acc@1 62.5	Acc@5 87.5
Epoch: [107][171/704]	Time 0.122	Data 0.001	Loss 5.18	Acc@1 65.6	Acc@5 92.2
Epoch: [107][181/704]	Time 0.122	Data 0.001	Loss 5.42	Acc@1 71.9	Acc@5 92.2
Epoch: [107][191/704]	Time 0.122	Data 0.001	Loss 4.76	Acc@1 75.0	Acc@5 92.2
Epoch: [107][201/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 70.3	Acc@5 93.8
Epoch: [107][211/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 71.9	Acc@5 93.8
Epoch: [107][221/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 71.9	Acc@5 93.8
Epoch: [107][231/704]	Time 0.121	Data 0.001	Loss 6.02	Acc@1 68.8	Acc@5 90.6
Epoch: [107][241/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 78.1	Acc@5 96.9
Epoch: [107][251/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 64.1	Acc@5 92.2
Epoch: [107][261/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 65.6	Acc@5 85.9
Epoch: [107][271/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 65.6	Acc@5 95.3
Epoch: [107][281/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 71.9	Acc@5 90.6
Epoch: [107][291/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 84.4	Acc@5 96.9
Epoch: [107][301/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 78.1	Acc@5 98.4
Epoch: [107][311/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 73.4	Acc@5 87.5
Epoch: [107][321/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 73.4	Acc@5 92.2
Epoch: [107][331/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 73.4	Acc@5 93.8
Epoch: [107][341/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 73.4	Acc@5 92.2
Epoch: [107][351/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 73.4	Acc@5 92.2
Epoch: [107][361/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 67.2	Acc@5 89.1
Epoch: [107][371/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 70.3	Acc@5 93.8
Epoch: [107][381/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 67.2	Acc@5 96.9
Epoch: [107][391/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 70.3	Acc@5 95.3
Epoch: [107][401/704]	Time 0.121	Data 0.001	Loss 6.23	Acc@1 64.1	Acc@5 87.5
Epoch: [107][411/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 70.3	Acc@5 93.8
Epoch: [107][421/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 67.2	Acc@5 92.2
Epoch: [107][431/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 90.6
Epoch: [107][441/704]	Time 0.121	Data 0.001	Loss 4.08	Acc@1 78.1	Acc@5 98.4
Epoch: [107][451/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 60.9	Acc@5 90.6
Epoch: [107][461/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 75.0	Acc@5 95.3
Epoch: [107][471/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 65.6	Acc@5 82.8
Epoch: [107][481/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 75.0	Acc@5 96.9
Epoch: [107][491/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 71.9	Acc@5 92.2
Epoch: [107][501/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 65.6	Acc@5 90.6
Epoch: [107][511/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 62.5	Acc@5 92.2
Epoch: [107][521/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 73.4	Acc@5 100.0
Epoch: [107][531/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 67.2	Acc@5 89.1
Epoch: [107][541/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 70.3	Acc@5 89.1
Epoch: [107][551/704]	Time 0.121	Data 0.001	Loss 7.20	Acc@1 57.8	Acc@5 87.5
Epoch: [107][561/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 79.7	Acc@5 95.3
Epoch: [107][571/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 65.6	Acc@5 90.6
Epoch: [107][581/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 73.4	Acc@5 90.6
Epoch: [107][591/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 64.1	Acc@5 93.8
Epoch: [107][601/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 65.6	Acc@5 93.8
Epoch: [107][611/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 70.3	Acc@5 87.5
Epoch: [107][621/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 62.5	Acc@5 89.1
Epoch: [107][631/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 65.6	Acc@5 89.1
Epoch: [107][641/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 71.9	Acc@5 90.6
Epoch: [107][651/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 70.3	Acc@5 89.1
Epoch: [107][661/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 57.8	Acc@5 93.8
Epoch: [107][671/704]	Time 0.121	Data 0.001	Loss 6.56	Acc@1 59.4	Acc@5 89.1
Epoch: [107][681/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 60.9	Acc@5 89.1
Epoch: [107][691/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 79.7	Acc@5 96.9
Epoch: [107][701/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 70.3	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.6097	Acc@1 60.9375	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.6307	Acc@1 57.8125	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.0591	Acc@1 64.0625	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.1531	Acc@1 54.6875	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.3691	Acc@1 54.6875	Acc@5 78.1250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.0492	Acc@1 67.1875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.5282	Acc@1 51.5625	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.6447	Acc@1 62.5000	Acc@5 85.9375
 * prec@1 47.960 prec@5 78.520
 * prec@1 51.300 prec@5 82.080
 * prec@1 55.180 prec@5 84.280
 * prec@1 58.200 prec@5 86.500
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_107.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_107.pth.tar'
Epoch: [108][1/704]	Time 0.304	Data 0.135	Loss 5.78	Acc@1 59.4	Acc@5 92.2
Epoch: [108][11/704]	Time 0.141	Data 0.013	Loss 4.07	Acc@1 75.0	Acc@5 96.9
Epoch: [108][21/704]	Time 0.131	Data 0.007	Loss 3.92	Acc@1 79.7	Acc@5 96.9
Epoch: [108][31/704]	Time 0.128	Data 0.005	Loss 6.03	Acc@1 71.9	Acc@5 89.1
Epoch: [108][41/704]	Time 0.126	Data 0.004	Loss 4.31	Acc@1 73.4	Acc@5 95.3
Epoch: [108][51/704]	Time 0.125	Data 0.003	Loss 3.94	Acc@1 71.9	Acc@5 96.9
Epoch: [108][61/704]	Time 0.124	Data 0.003	Loss 5.28	Acc@1 67.2	Acc@5 92.2
Epoch: [108][71/704]	Time 0.123	Data 0.002	Loss 4.60	Acc@1 67.2	Acc@5 96.9
Epoch: [108][81/704]	Time 0.123	Data 0.002	Loss 5.62	Acc@1 68.8	Acc@5 89.1
Epoch: [108][91/704]	Time 0.123	Data 0.002	Loss 4.07	Acc@1 73.4	Acc@5 100.0
Epoch: [108][101/704]	Time 0.122	Data 0.002	Loss 5.73	Acc@1 62.5	Acc@5 90.6
Epoch: [108][111/704]	Time 0.122	Data 0.002	Loss 3.94	Acc@1 71.9	Acc@5 96.9
Epoch: [108][121/704]	Time 0.122	Data 0.001	Loss 4.54	Acc@1 71.9	Acc@5 92.2
Epoch: [108][131/704]	Time 0.122	Data 0.001	Loss 5.87	Acc@1 68.8	Acc@5 87.5
Epoch: [108][141/704]	Time 0.122	Data 0.001	Loss 5.67	Acc@1 70.3	Acc@5 90.6
Epoch: [108][151/704]	Time 0.122	Data 0.001	Loss 5.19	Acc@1 62.5	Acc@5 87.5
Epoch: [108][161/704]	Time 0.122	Data 0.001	Loss 5.03	Acc@1 68.8	Acc@5 92.2
Epoch: [108][171/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 75.0	Acc@5 90.6
Epoch: [108][181/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 70.3	Acc@5 95.3
Epoch: [108][191/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 70.3	Acc@5 87.5
Epoch: [108][201/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 67.2	Acc@5 92.2
Epoch: [108][211/704]	Time 0.121	Data 0.001	Loss 3.50	Acc@1 78.1	Acc@5 98.4
Epoch: [108][221/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 76.6	Acc@5 95.3
Epoch: [108][231/704]	Time 0.121	Data 0.001	Loss 3.94	Acc@1 79.7	Acc@5 100.0
Epoch: [108][241/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 92.2
Epoch: [108][251/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 67.2	Acc@5 95.3
Epoch: [108][261/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 65.6	Acc@5 89.1
Epoch: [108][271/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 73.4	Acc@5 96.9
Epoch: [108][281/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 90.6
Epoch: [108][291/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 65.6	Acc@5 92.2
Epoch: [108][301/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 59.4	Acc@5 98.4
Epoch: [108][311/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 67.2	Acc@5 98.4
Epoch: [108][321/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 62.5	Acc@5 90.6
Epoch: [108][331/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 64.1	Acc@5 92.2
Epoch: [108][341/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 70.3	Acc@5 95.3
Epoch: [108][351/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 67.2	Acc@5 93.8
Epoch: [108][361/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 73.4	Acc@5 95.3
Epoch: [108][371/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 76.6	Acc@5 96.9
Epoch: [108][381/704]	Time 0.121	Data 0.001	Loss 4.35	Acc@1 78.1	Acc@5 96.9
Epoch: [108][391/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 65.6	Acc@5 93.8
Epoch: [108][401/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 75.0	Acc@5 92.2
Epoch: [108][411/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 90.6
Epoch: [108][421/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 67.2	Acc@5 87.5
Epoch: [108][431/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 62.5	Acc@5 92.2
Epoch: [108][441/704]	Time 0.121	Data 0.001	Loss 6.44	Acc@1 53.1	Acc@5 93.8
Epoch: [108][451/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 73.4	Acc@5 92.2
Epoch: [108][461/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 68.8	Acc@5 84.4
Epoch: [108][471/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 73.4	Acc@5 93.8
Epoch: [108][481/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 67.2	Acc@5 90.6
Epoch: [108][491/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 68.8	Acc@5 92.2
Epoch: [108][501/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 67.2	Acc@5 92.2
Epoch: [108][511/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 73.4	Acc@5 92.2
Epoch: [108][521/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 70.3	Acc@5 93.8
Epoch: [108][531/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 73.4	Acc@5 89.1
Epoch: [108][541/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 60.9	Acc@5 92.2
Epoch: [108][551/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 70.3	Acc@5 93.8
Epoch: [108][561/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 59.4	Acc@5 87.5
Epoch: [108][571/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 65.6	Acc@5 93.8
Epoch: [108][581/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 62.5	Acc@5 93.8
Epoch: [108][591/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 56.2	Acc@5 90.6
Epoch: [108][601/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 76.6	Acc@5 93.8
Epoch: [108][611/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 57.8	Acc@5 89.1
Epoch: [108][621/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 65.6	Acc@5 96.9
Epoch: [108][631/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 71.9	Acc@5 93.8
Epoch: [108][641/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 78.1	Acc@5 95.3
Epoch: [108][651/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 65.6	Acc@5 96.9
Epoch: [108][661/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 71.9	Acc@5 93.8
Epoch: [108][671/704]	Time 0.121	Data 0.001	Loss 4.28	Acc@1 76.6	Acc@5 95.3
Epoch: [108][681/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 62.5	Acc@5 95.3
Epoch: [108][691/704]	Time 0.121	Data 0.001	Loss 3.75	Acc@1 71.9	Acc@5 95.3
Epoch: [108][701/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 67.2	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.0613	Acc@1 51.5625	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.4111	Acc@1 57.8125	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6445	Acc@1 51.5625	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.9727	Acc@1 59.3750	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7991	Acc@1 59.3750	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2720	Acc@1 48.4375	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.1232	Acc@1 45.3125	Acc@5 76.5625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9029	Acc@1 51.5625	Acc@5 84.3750
 * prec@1 47.600 prec@5 78.400
 * prec@1 51.660 prec@5 81.800
 * prec@1 56.900 prec@5 84.860
 * prec@1 55.880 prec@5 84.660
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_108.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_108.pth.tar'
Epoch: [109][1/704]	Time 0.334	Data 0.168	Loss 4.26	Acc@1 76.6	Acc@5 93.8
Epoch: [109][11/704]	Time 0.140	Data 0.016	Loss 4.76	Acc@1 67.2	Acc@5 95.3
Epoch: [109][21/704]	Time 0.130	Data 0.008	Loss 5.25	Acc@1 59.4	Acc@5 93.8
Epoch: [109][31/704]	Time 0.127	Data 0.006	Loss 4.35	Acc@1 78.1	Acc@5 93.8
Epoch: [109][41/704]	Time 0.126	Data 0.004	Loss 4.09	Acc@1 84.4	Acc@5 100.0
Epoch: [109][51/704]	Time 0.124	Data 0.004	Loss 6.50	Acc@1 64.1	Acc@5 87.5
Epoch: [109][61/704]	Time 0.124	Data 0.003	Loss 3.67	Acc@1 76.6	Acc@5 93.8
Epoch: [109][71/704]	Time 0.123	Data 0.003	Loss 4.75	Acc@1 68.8	Acc@5 96.9
Epoch: [109][81/704]	Time 0.123	Data 0.002	Loss 4.31	Acc@1 73.4	Acc@5 95.3
Epoch: [109][91/704]	Time 0.122	Data 0.002	Loss 4.38	Acc@1 71.9	Acc@5 98.4
Epoch: [109][101/704]	Time 0.122	Data 0.002	Loss 6.08	Acc@1 64.1	Acc@5 93.8
Epoch: [109][111/704]	Time 0.122	Data 0.002	Loss 5.02	Acc@1 65.6	Acc@5 89.1
Epoch: [109][121/704]	Time 0.122	Data 0.002	Loss 5.18	Acc@1 71.9	Acc@5 90.6
Epoch: [109][131/704]	Time 0.122	Data 0.002	Loss 4.67	Acc@1 67.2	Acc@5 92.2
Epoch: [109][141/704]	Time 0.121	Data 0.002	Loss 6.09	Acc@1 62.5	Acc@5 90.6
Epoch: [109][151/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 78.1	Acc@5 96.9
Epoch: [109][161/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 78.1	Acc@5 92.2
Epoch: [109][171/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 67.2	Acc@5 92.2
Epoch: [109][181/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 68.8	Acc@5 89.1
Epoch: [109][191/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 65.6	Acc@5 85.9
Epoch: [109][201/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 70.3	Acc@5 92.2
Epoch: [109][211/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 56.2	Acc@5 92.2
Epoch: [109][221/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 65.6	Acc@5 98.4
Epoch: [109][231/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 67.2	Acc@5 93.8
Epoch: [109][241/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 73.4	Acc@5 89.1
Epoch: [109][251/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 70.3	Acc@5 95.3
Epoch: [109][261/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 65.6	Acc@5 90.6
Epoch: [109][271/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 70.3	Acc@5 93.8
Epoch: [109][281/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 67.2	Acc@5 98.4
Epoch: [109][291/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 75.0	Acc@5 95.3
Epoch: [109][301/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 71.9	Acc@5 90.6
Epoch: [109][311/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 71.9	Acc@5 93.8
Epoch: [109][321/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 70.3	Acc@5 93.8
Epoch: [109][331/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 64.1	Acc@5 93.8
Epoch: [109][341/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 60.9	Acc@5 92.2
Epoch: [109][351/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 70.3	Acc@5 90.6
Epoch: [109][361/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 67.2	Acc@5 89.1
Epoch: [109][371/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 70.3	Acc@5 92.2
Epoch: [109][381/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 65.6	Acc@5 92.2
Epoch: [109][391/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 68.8	Acc@5 95.3
Epoch: [109][401/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 64.1	Acc@5 90.6
Epoch: [109][411/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 65.6	Acc@5 92.2
Epoch: [109][421/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 73.4	Acc@5 93.8
Epoch: [109][431/704]	Time 0.120	Data 0.001	Loss 4.71	Acc@1 75.0	Acc@5 92.2
Epoch: [109][441/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 64.1	Acc@5 93.8
Epoch: [109][451/704]	Time 0.120	Data 0.001	Loss 5.11	Acc@1 64.1	Acc@5 90.6
Epoch: [109][461/704]	Time 0.120	Data 0.001	Loss 7.50	Acc@1 57.8	Acc@5 87.5
Epoch: [109][471/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 62.5	Acc@5 93.8
Epoch: [109][481/704]	Time 0.120	Data 0.001	Loss 3.61	Acc@1 79.7	Acc@5 100.0
Epoch: [109][491/704]	Time 0.120	Data 0.001	Loss 5.75	Acc@1 60.9	Acc@5 85.9
Epoch: [109][501/704]	Time 0.120	Data 0.001	Loss 5.39	Acc@1 67.2	Acc@5 90.6
Epoch: [109][511/704]	Time 0.120	Data 0.001	Loss 5.05	Acc@1 67.2	Acc@5 95.3
Epoch: [109][521/704]	Time 0.120	Data 0.001	Loss 4.39	Acc@1 71.9	Acc@5 96.9
Epoch: [109][531/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 71.9	Acc@5 90.6
Epoch: [109][541/704]	Time 0.120	Data 0.001	Loss 5.70	Acc@1 68.8	Acc@5 92.2
Epoch: [109][551/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 65.6	Acc@5 90.6
Epoch: [109][561/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 68.8	Acc@5 92.2
Epoch: [109][571/704]	Time 0.120	Data 0.001	Loss 3.88	Acc@1 81.2	Acc@5 95.3
Epoch: [109][581/704]	Time 0.120	Data 0.001	Loss 4.66	Acc@1 73.4	Acc@5 90.6
Epoch: [109][591/704]	Time 0.120	Data 0.001	Loss 5.80	Acc@1 59.4	Acc@5 85.9
Epoch: [109][601/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 68.8	Acc@5 93.8
Epoch: [109][611/704]	Time 0.120	Data 0.001	Loss 5.25	Acc@1 62.5	Acc@5 92.2
Epoch: [109][621/704]	Time 0.120	Data 0.001	Loss 6.32	Acc@1 65.6	Acc@5 82.8
Epoch: [109][631/704]	Time 0.120	Data 0.001	Loss 3.74	Acc@1 73.4	Acc@5 96.9
Epoch: [109][641/704]	Time 0.120	Data 0.001	Loss 4.98	Acc@1 67.2	Acc@5 93.8
Epoch: [109][651/704]	Time 0.120	Data 0.001	Loss 5.68	Acc@1 62.5	Acc@5 95.3
Epoch: [109][661/704]	Time 0.120	Data 0.001	Loss 4.63	Acc@1 70.3	Acc@5 93.8
Epoch: [109][671/704]	Time 0.120	Data 0.001	Loss 5.88	Acc@1 65.6	Acc@5 90.6
Epoch: [109][681/704]	Time 0.120	Data 0.001	Loss 4.82	Acc@1 70.3	Acc@5 93.8
Epoch: [109][691/704]	Time 0.120	Data 0.001	Loss 6.48	Acc@1 68.8	Acc@5 92.2
Epoch: [109][701/704]	Time 0.120	Data 0.001	Loss 4.58	Acc@1 71.9	Acc@5 95.3
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.4703	Acc@1 56.2500	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.2416	Acc@1 68.7500	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.6407	Acc@1 50.0000	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.8099	Acc@1 51.5625	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6884	Acc@1 65.6250	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.5755	Acc@1 46.8750	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.3441	Acc@1 57.8125	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3925	Acc@1 56.2500	Acc@5 87.5000
 * prec@1 46.000 prec@5 77.020
 * prec@1 52.640 prec@5 81.880
 * prec@1 56.880 prec@5 85.340
 * prec@1 58.720 prec@5 86.040
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_109.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_109.pth.tar'
Epoch: [110][1/704]	Time 0.301	Data 0.134	Loss 5.83	Acc@1 71.9	Acc@5 85.9
Epoch: [110][11/704]	Time 0.137	Data 0.013	Loss 4.90	Acc@1 73.4	Acc@5 92.2
Epoch: [110][21/704]	Time 0.129	Data 0.007	Loss 5.95	Acc@1 59.4	Acc@5 87.5
Epoch: [110][31/704]	Time 0.126	Data 0.005	Loss 4.46	Acc@1 73.4	Acc@5 95.3
Epoch: [110][41/704]	Time 0.124	Data 0.004	Loss 4.85	Acc@1 67.2	Acc@5 95.3
Epoch: [110][51/704]	Time 0.123	Data 0.003	Loss 4.98	Acc@1 60.9	Acc@5 95.3
Epoch: [110][61/704]	Time 0.123	Data 0.003	Loss 3.70	Acc@1 81.2	Acc@5 96.9
Epoch: [110][71/704]	Time 0.122	Data 0.002	Loss 5.46	Acc@1 70.3	Acc@5 96.9
Epoch: [110][81/704]	Time 0.122	Data 0.002	Loss 5.35	Acc@1 64.1	Acc@5 90.6
Epoch: [110][91/704]	Time 0.122	Data 0.002	Loss 4.33	Acc@1 71.9	Acc@5 98.4
Epoch: [110][101/704]	Time 0.122	Data 0.002	Loss 5.43	Acc@1 76.6	Acc@5 89.1
Epoch: [110][111/704]	Time 0.122	Data 0.002	Loss 4.72	Acc@1 71.9	Acc@5 93.8
Epoch: [110][121/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 70.3	Acc@5 90.6
Epoch: [110][131/704]	Time 0.121	Data 0.001	Loss 3.69	Acc@1 76.6	Acc@5 95.3
Epoch: [110][141/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 71.9	Acc@5 93.8
Epoch: [110][151/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 95.3
Epoch: [110][161/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 73.4	Acc@5 93.8
Epoch: [110][171/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 60.9	Acc@5 90.6
Epoch: [110][181/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 73.4	Acc@5 98.4
Epoch: [110][191/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 73.4	Acc@5 96.9
Epoch: [110][201/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 67.2	Acc@5 92.2
Epoch: [110][211/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 64.1	Acc@5 95.3
Epoch: [110][221/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 73.4	Acc@5 96.9
Epoch: [110][231/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 67.2	Acc@5 93.8
Epoch: [110][241/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 76.6	Acc@5 93.8
Epoch: [110][251/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 65.6	Acc@5 96.9
Epoch: [110][261/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 71.9	Acc@5 95.3
Epoch: [110][271/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 62.5	Acc@5 90.6
Epoch: [110][281/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 64.1	Acc@5 93.8
Epoch: [110][291/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 65.6	Acc@5 92.2
Epoch: [110][301/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 90.6
Epoch: [110][311/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 75.0	Acc@5 96.9
Epoch: [110][321/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 79.7	Acc@5 98.4
Epoch: [110][331/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 59.4	Acc@5 89.1
Epoch: [110][341/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 73.4	Acc@5 98.4
Epoch: [110][351/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 70.3	Acc@5 89.1
Epoch: [110][361/704]	Time 0.120	Data 0.001	Loss 5.21	Acc@1 78.1	Acc@5 93.8
Epoch: [110][371/704]	Time 0.120	Data 0.001	Loss 6.44	Acc@1 64.1	Acc@5 85.9
Epoch: [110][381/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 57.8	Acc@5 92.2
Epoch: [110][391/704]	Time 0.120	Data 0.001	Loss 5.42	Acc@1 67.2	Acc@5 93.8
Epoch: [110][401/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 71.9	Acc@5 90.6
Epoch: [110][411/704]	Time 0.120	Data 0.001	Loss 4.14	Acc@1 70.3	Acc@5 93.8
Epoch: [110][421/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 68.8	Acc@5 93.8
Epoch: [110][431/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 71.9	Acc@5 90.6
Epoch: [110][441/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 75.0	Acc@5 95.3
Epoch: [110][451/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 67.2	Acc@5 90.6
Epoch: [110][461/704]	Time 0.120	Data 0.001	Loss 4.47	Acc@1 75.0	Acc@5 98.4
Epoch: [110][471/704]	Time 0.120	Data 0.001	Loss 5.85	Acc@1 65.6	Acc@5 87.5
Epoch: [110][481/704]	Time 0.120	Data 0.001	Loss 4.83	Acc@1 70.3	Acc@5 93.8
Epoch: [110][491/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 57.8	Acc@5 90.6
Epoch: [110][501/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 70.3	Acc@5 92.2
Epoch: [110][511/704]	Time 0.120	Data 0.001	Loss 4.44	Acc@1 78.1	Acc@5 93.8
Epoch: [110][521/704]	Time 0.120	Data 0.001	Loss 5.61	Acc@1 75.0	Acc@5 92.2
Epoch: [110][531/704]	Time 0.120	Data 0.001	Loss 4.29	Acc@1 76.6	Acc@5 96.9
Epoch: [110][541/704]	Time 0.120	Data 0.001	Loss 5.01	Acc@1 67.2	Acc@5 95.3
Epoch: [110][551/704]	Time 0.120	Data 0.001	Loss 4.65	Acc@1 79.7	Acc@5 92.2
Epoch: [110][561/704]	Time 0.120	Data 0.001	Loss 3.72	Acc@1 71.9	Acc@5 96.9
Epoch: [110][571/704]	Time 0.120	Data 0.001	Loss 4.20	Acc@1 71.9	Acc@5 93.8
Epoch: [110][581/704]	Time 0.120	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 92.2
Epoch: [110][591/704]	Time 0.120	Data 0.001	Loss 5.50	Acc@1 65.6	Acc@5 89.1
Epoch: [110][601/704]	Time 0.120	Data 0.001	Loss 5.38	Acc@1 71.9	Acc@5 92.2
Epoch: [110][611/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 57.8	Acc@5 93.8
Epoch: [110][621/704]	Time 0.120	Data 0.001	Loss 5.43	Acc@1 67.2	Acc@5 93.8
Epoch: [110][631/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 76.6	Acc@5 90.6
Epoch: [110][641/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 65.6	Acc@5 96.9
Epoch: [110][651/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 71.9	Acc@5 92.2
Epoch: [110][661/704]	Time 0.120	Data 0.001	Loss 4.88	Acc@1 68.8	Acc@5 89.1
Epoch: [110][671/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 73.4	Acc@5 95.3
Epoch: [110][681/704]	Time 0.120	Data 0.001	Loss 6.44	Acc@1 57.8	Acc@5 85.9
Epoch: [110][691/704]	Time 0.120	Data 0.001	Loss 5.52	Acc@1 57.8	Acc@5 92.2
Epoch: [110][701/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 64.1	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.5048	Acc@1 54.6875	Acc@5 78.1250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.4169	Acc@1 54.6875	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.1650	Acc@1 59.3750	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5191	Acc@1 54.6875	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.1849	Acc@1 56.2500	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.6332	Acc@1 54.6875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.0329	Acc@1 62.5000	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7362	Acc@1 57.8125	Acc@5 84.3750
 * prec@1 47.000 prec@5 77.920
 * prec@1 53.020 prec@5 82.560
 * prec@1 56.380 prec@5 85.200
 * prec@1 57.800 prec@5 86.580
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_110.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_110.pth.tar'
Epoch: [111][1/704]	Time 0.300	Data 0.132	Loss 4.91	Acc@1 68.8	Acc@5 96.9
Epoch: [111][11/704]	Time 0.137	Data 0.012	Loss 6.23	Acc@1 60.9	Acc@5 89.1
Epoch: [111][21/704]	Time 0.129	Data 0.007	Loss 3.78	Acc@1 76.6	Acc@5 95.3
Epoch: [111][31/704]	Time 0.126	Data 0.005	Loss 5.94	Acc@1 62.5	Acc@5 89.1
Epoch: [111][41/704]	Time 0.125	Data 0.004	Loss 4.42	Acc@1 70.3	Acc@5 96.9
Epoch: [111][51/704]	Time 0.124	Data 0.003	Loss 6.25	Acc@1 56.2	Acc@5 93.8
Epoch: [111][61/704]	Time 0.124	Data 0.002	Loss 4.01	Acc@1 78.1	Acc@5 96.9
Epoch: [111][71/704]	Time 0.124	Data 0.002	Loss 5.20	Acc@1 64.1	Acc@5 92.2
Epoch: [111][81/704]	Time 0.123	Data 0.002	Loss 4.51	Acc@1 76.6	Acc@5 92.2
Epoch: [111][91/704]	Time 0.123	Data 0.002	Loss 4.93	Acc@1 78.1	Acc@5 96.9
Epoch: [111][101/704]	Time 0.123	Data 0.002	Loss 5.83	Acc@1 64.1	Acc@5 92.2
Epoch: [111][111/704]	Time 0.123	Data 0.002	Loss 4.95	Acc@1 68.8	Acc@5 89.1
Epoch: [111][121/704]	Time 0.122	Data 0.001	Loss 5.72	Acc@1 67.2	Acc@5 89.1
Epoch: [111][131/704]	Time 0.122	Data 0.001	Loss 4.16	Acc@1 75.0	Acc@5 98.4
Epoch: [111][141/704]	Time 0.122	Data 0.001	Loss 5.98	Acc@1 70.3	Acc@5 89.1
Epoch: [111][151/704]	Time 0.122	Data 0.001	Loss 4.62	Acc@1 75.0	Acc@5 98.4
Epoch: [111][161/704]	Time 0.122	Data 0.001	Loss 4.95	Acc@1 67.2	Acc@5 92.2
Epoch: [111][171/704]	Time 0.122	Data 0.001	Loss 4.36	Acc@1 71.9	Acc@5 92.2
Epoch: [111][181/704]	Time 0.122	Data 0.001	Loss 4.87	Acc@1 73.4	Acc@5 95.3
Epoch: [111][191/704]	Time 0.122	Data 0.001	Loss 4.65	Acc@1 67.2	Acc@5 96.9
Epoch: [111][201/704]	Time 0.122	Data 0.001	Loss 4.92	Acc@1 70.3	Acc@5 92.2
Epoch: [111][211/704]	Time 0.122	Data 0.001	Loss 4.41	Acc@1 65.6	Acc@5 93.8
Epoch: [111][221/704]	Time 0.122	Data 0.001	Loss 5.32	Acc@1 60.9	Acc@5 92.2
Epoch: [111][231/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 64.1	Acc@5 93.8
Epoch: [111][241/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 71.9	Acc@5 93.8
Epoch: [111][251/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 71.9	Acc@5 96.9
Epoch: [111][261/704]	Time 0.121	Data 0.001	Loss 4.21	Acc@1 82.8	Acc@5 95.3
Epoch: [111][271/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 67.2	Acc@5 96.9
Epoch: [111][281/704]	Time 0.121	Data 0.001	Loss 6.23	Acc@1 75.0	Acc@5 92.2
Epoch: [111][291/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 60.9	Acc@5 95.3
Epoch: [111][301/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 67.2	Acc@5 95.3
Epoch: [111][311/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 60.9	Acc@5 92.2
Epoch: [111][321/704]	Time 0.121	Data 0.001	Loss 3.84	Acc@1 81.2	Acc@5 98.4
Epoch: [111][331/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 67.2	Acc@5 92.2
Epoch: [111][341/704]	Time 0.121	Data 0.001	Loss 7.56	Acc@1 57.8	Acc@5 90.6
Epoch: [111][351/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 60.9	Acc@5 93.8
Epoch: [111][361/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 90.6
Epoch: [111][371/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 67.2	Acc@5 87.5
Epoch: [111][381/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 64.1	Acc@5 93.8
Epoch: [111][391/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 78.1	Acc@5 89.1
Epoch: [111][401/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 68.8	Acc@5 95.3
Epoch: [111][411/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 81.2	Acc@5 87.5
Epoch: [111][421/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 95.3
Epoch: [111][431/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 65.6	Acc@5 92.2
Epoch: [111][441/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 73.4	Acc@5 92.2
Epoch: [111][451/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 67.2	Acc@5 95.3
Epoch: [111][461/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 59.4	Acc@5 90.6
Epoch: [111][471/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 70.3	Acc@5 98.4
Epoch: [111][481/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 90.6
Epoch: [111][491/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 60.9	Acc@5 100.0
Epoch: [111][501/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 73.4	Acc@5 96.9
Epoch: [111][511/704]	Time 0.121	Data 0.001	Loss 4.15	Acc@1 73.4	Acc@5 95.3
Epoch: [111][521/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 71.9	Acc@5 93.8
Epoch: [111][531/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 73.4	Acc@5 96.9
Epoch: [111][541/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 73.4	Acc@5 95.3
Epoch: [111][551/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 62.5	Acc@5 93.8
Epoch: [111][561/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 70.3	Acc@5 93.8
Epoch: [111][571/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 64.1	Acc@5 82.8
Epoch: [111][581/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 60.9	Acc@5 90.6
Epoch: [111][591/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 65.6	Acc@5 87.5
Epoch: [111][601/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 81.2	Acc@5 95.3
Epoch: [111][611/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 64.1	Acc@5 93.8
Epoch: [111][621/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 70.3	Acc@5 95.3
Epoch: [111][631/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 76.6	Acc@5 95.3
Epoch: [111][641/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 68.8	Acc@5 95.3
Epoch: [111][651/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 73.4	Acc@5 90.6
Epoch: [111][661/704]	Time 0.121	Data 0.001	Loss 3.85	Acc@1 78.1	Acc@5 100.0
Epoch: [111][671/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 78.1	Acc@5 93.8
Epoch: [111][681/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 73.4	Acc@5 92.2
Epoch: [111][691/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 68.8	Acc@5 95.3
Epoch: [111][701/704]	Time 0.121	Data 0.001	Loss 7.21	Acc@1 54.7	Acc@5 82.8
Epoch: [1/79]	Time 0.103	Data 0.087	Loss 7.3393	Acc@1 60.9375	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0411	Acc@1 54.6875	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6674	Acc@1 62.5000	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5335	Acc@1 59.3750	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.8848	Acc@1 67.1875	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.5179	Acc@1 48.4375	Acc@5 71.8750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4059	Acc@1 54.6875	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.8678	Acc@1 57.8125	Acc@5 81.2500
 * prec@1 47.600 prec@5 78.460
 * prec@1 52.440 prec@5 82.580
 * prec@1 56.340 prec@5 85.720
 * prec@1 58.460 prec@5 85.300
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_111.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_111.pth.tar'
Epoch: [112][1/704]	Time 0.335	Data 0.169	Loss 4.88	Acc@1 71.9	Acc@5 93.8
Epoch: [112][11/704]	Time 0.140	Data 0.016	Loss 6.59	Acc@1 56.2	Acc@5 85.9
Epoch: [112][21/704]	Time 0.130	Data 0.008	Loss 4.83	Acc@1 68.8	Acc@5 92.2
Epoch: [112][31/704]	Time 0.127	Data 0.006	Loss 4.49	Acc@1 68.8	Acc@5 93.8
Epoch: [112][41/704]	Time 0.125	Data 0.005	Loss 5.68	Acc@1 64.1	Acc@5 92.2
Epoch: [112][51/704]	Time 0.124	Data 0.004	Loss 4.64	Acc@1 71.9	Acc@5 92.2
Epoch: [112][61/704]	Time 0.124	Data 0.003	Loss 4.62	Acc@1 71.9	Acc@5 95.3
Epoch: [112][71/704]	Time 0.123	Data 0.003	Loss 4.60	Acc@1 73.4	Acc@5 95.3
Epoch: [112][81/704]	Time 0.123	Data 0.002	Loss 5.13	Acc@1 64.1	Acc@5 90.6
Epoch: [112][91/704]	Time 0.122	Data 0.002	Loss 6.11	Acc@1 65.6	Acc@5 89.1
Epoch: [112][101/704]	Time 0.122	Data 0.002	Loss 4.81	Acc@1 65.6	Acc@5 92.2
Epoch: [112][111/704]	Time 0.122	Data 0.002	Loss 3.82	Acc@1 75.0	Acc@5 98.4
Epoch: [112][121/704]	Time 0.122	Data 0.002	Loss 4.64	Acc@1 71.9	Acc@5 93.8
Epoch: [112][131/704]	Time 0.122	Data 0.002	Loss 4.75	Acc@1 75.0	Acc@5 89.1
Epoch: [112][141/704]	Time 0.122	Data 0.002	Loss 5.11	Acc@1 73.4	Acc@5 90.6
Epoch: [112][151/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 68.8	Acc@5 96.9
Epoch: [112][161/704]	Time 0.121	Data 0.001	Loss 4.25	Acc@1 73.4	Acc@5 96.9
Epoch: [112][171/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 70.3	Acc@5 93.8
Epoch: [112][181/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 70.3	Acc@5 90.6
Epoch: [112][191/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 62.5	Acc@5 89.1
Epoch: [112][201/704]	Time 0.121	Data 0.001	Loss 6.60	Acc@1 64.1	Acc@5 85.9
Epoch: [112][211/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 70.3	Acc@5 92.2
Epoch: [112][221/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 68.8	Acc@5 95.3
Epoch: [112][231/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 71.9	Acc@5 98.4
Epoch: [112][241/704]	Time 0.121	Data 0.001	Loss 3.66	Acc@1 79.7	Acc@5 93.8
Epoch: [112][251/704]	Time 0.121	Data 0.001	Loss 4.15	Acc@1 71.9	Acc@5 96.9
Epoch: [112][261/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 67.2	Acc@5 93.8
Epoch: [112][271/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 75.0	Acc@5 93.8
Epoch: [112][281/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 68.8	Acc@5 95.3
Epoch: [112][291/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 70.3	Acc@5 90.6
Epoch: [112][301/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 60.9	Acc@5 87.5
Epoch: [112][311/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 67.2	Acc@5 93.8
Epoch: [112][321/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 70.3	Acc@5 87.5
Epoch: [112][331/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 73.4	Acc@5 95.3
Epoch: [112][341/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 78.1	Acc@5 96.9
Epoch: [112][351/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 60.9	Acc@5 92.2
Epoch: [112][361/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 73.4	Acc@5 90.6
Epoch: [112][371/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 71.9	Acc@5 96.9
Epoch: [112][381/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 71.9	Acc@5 93.8
Epoch: [112][391/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 65.6	Acc@5 87.5
Epoch: [112][401/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 73.4	Acc@5 92.2
Epoch: [112][411/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 70.3	Acc@5 93.8
Epoch: [112][421/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 76.6	Acc@5 96.9
Epoch: [112][431/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 67.2	Acc@5 87.5
Epoch: [112][441/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 67.2	Acc@5 90.6
Epoch: [112][451/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 65.6	Acc@5 90.6
Epoch: [112][461/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 65.6	Acc@5 96.9
Epoch: [112][471/704]	Time 0.120	Data 0.001	Loss 4.22	Acc@1 73.4	Acc@5 96.9
Epoch: [112][481/704]	Time 0.120	Data 0.001	Loss 4.98	Acc@1 67.2	Acc@5 96.9
Epoch: [112][491/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 60.9	Acc@5 85.9
Epoch: [112][501/704]	Time 0.120	Data 0.001	Loss 4.14	Acc@1 65.6	Acc@5 93.8
Epoch: [112][511/704]	Time 0.120	Data 0.001	Loss 4.73	Acc@1 76.6	Acc@5 93.8
Epoch: [112][521/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 67.2	Acc@5 95.3
Epoch: [112][531/704]	Time 0.120	Data 0.001	Loss 7.09	Acc@1 51.6	Acc@5 81.2
Epoch: [112][541/704]	Time 0.120	Data 0.001	Loss 4.83	Acc@1 59.4	Acc@5 92.2
Epoch: [112][551/704]	Time 0.120	Data 0.001	Loss 6.00	Acc@1 64.1	Acc@5 87.5
Epoch: [112][561/704]	Time 0.120	Data 0.001	Loss 4.20	Acc@1 67.2	Acc@5 95.3
Epoch: [112][571/704]	Time 0.120	Data 0.001	Loss 5.01	Acc@1 70.3	Acc@5 90.6
Epoch: [112][581/704]	Time 0.120	Data 0.001	Loss 5.64	Acc@1 68.8	Acc@5 90.6
Epoch: [112][591/704]	Time 0.120	Data 0.001	Loss 4.49	Acc@1 73.4	Acc@5 96.9
Epoch: [112][601/704]	Time 0.120	Data 0.001	Loss 4.77	Acc@1 65.6	Acc@5 95.3
Epoch: [112][611/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 62.5	Acc@5 92.2
Epoch: [112][621/704]	Time 0.120	Data 0.001	Loss 5.60	Acc@1 70.3	Acc@5 90.6
Epoch: [112][631/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 67.2	Acc@5 90.6
Epoch: [112][641/704]	Time 0.120	Data 0.001	Loss 4.85	Acc@1 70.3	Acc@5 93.8
Epoch: [112][651/704]	Time 0.120	Data 0.001	Loss 3.60	Acc@1 85.9	Acc@5 96.9
Epoch: [112][661/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 68.8	Acc@5 93.8
Epoch: [112][671/704]	Time 0.120	Data 0.001	Loss 4.98	Acc@1 71.9	Acc@5 90.6
Epoch: [112][681/704]	Time 0.120	Data 0.001	Loss 3.97	Acc@1 75.0	Acc@5 96.9
Epoch: [112][691/704]	Time 0.120	Data 0.001	Loss 5.63	Acc@1 56.2	Acc@5 92.2
Epoch: [112][701/704]	Time 0.120	Data 0.001	Loss 4.47	Acc@1 70.3	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.1743	Acc@1 60.9375	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1933	Acc@1 67.1875	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0991	Acc@1 54.6875	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.1433	Acc@1 67.1875	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9002	Acc@1 60.9375	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7298	Acc@1 56.2500	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7882	Acc@1 56.2500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.5358	Acc@1 59.3750	Acc@5 87.5000
 * prec@1 48.500 prec@5 79.260
 * prec@1 51.260 prec@5 82.960
 * prec@1 56.960 prec@5 85.320
 * prec@1 58.860 prec@5 86.340
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_112.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_112.pth.tar'
Epoch: [113][1/704]	Time 0.334	Data 0.168	Loss 4.29	Acc@1 71.9	Acc@5 93.8
Epoch: [113][11/704]	Time 0.140	Data 0.016	Loss 3.98	Acc@1 79.7	Acc@5 95.3
Epoch: [113][21/704]	Time 0.131	Data 0.008	Loss 4.20	Acc@1 82.8	Acc@5 98.4
Epoch: [113][31/704]	Time 0.127	Data 0.006	Loss 6.88	Acc@1 56.2	Acc@5 87.5
Epoch: [113][41/704]	Time 0.126	Data 0.004	Loss 5.04	Acc@1 73.4	Acc@5 92.2
Epoch: [113][51/704]	Time 0.125	Data 0.004	Loss 4.12	Acc@1 75.0	Acc@5 96.9
Epoch: [113][61/704]	Time 0.124	Data 0.003	Loss 5.01	Acc@1 67.2	Acc@5 93.8
Epoch: [113][71/704]	Time 0.123	Data 0.003	Loss 5.94	Acc@1 60.9	Acc@5 87.5
Epoch: [113][81/704]	Time 0.123	Data 0.002	Loss 5.87	Acc@1 54.7	Acc@5 92.2
Epoch: [113][91/704]	Time 0.123	Data 0.002	Loss 4.95	Acc@1 65.6	Acc@5 95.3
Epoch: [113][101/704]	Time 0.122	Data 0.002	Loss 5.23	Acc@1 64.1	Acc@5 95.3
Epoch: [113][111/704]	Time 0.122	Data 0.002	Loss 6.90	Acc@1 59.4	Acc@5 89.1
Epoch: [113][121/704]	Time 0.122	Data 0.002	Loss 4.87	Acc@1 67.2	Acc@5 93.8
Epoch: [113][131/704]	Time 0.122	Data 0.002	Loss 5.05	Acc@1 68.8	Acc@5 93.8
Epoch: [113][141/704]	Time 0.122	Data 0.002	Loss 4.56	Acc@1 71.9	Acc@5 95.3
Epoch: [113][151/704]	Time 0.122	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 95.3
Epoch: [113][161/704]	Time 0.122	Data 0.001	Loss 3.84	Acc@1 70.3	Acc@5 95.3
Epoch: [113][171/704]	Time 0.122	Data 0.001	Loss 4.61	Acc@1 71.9	Acc@5 93.8
Epoch: [113][181/704]	Time 0.122	Data 0.001	Loss 5.21	Acc@1 73.4	Acc@5 93.8
Epoch: [113][191/704]	Time 0.122	Data 0.001	Loss 4.29	Acc@1 71.9	Acc@5 95.3
Epoch: [113][201/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 71.9	Acc@5 95.3
Epoch: [113][211/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 68.8	Acc@5 93.8
Epoch: [113][221/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 64.1	Acc@5 95.3
Epoch: [113][231/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 67.2	Acc@5 95.3
Epoch: [113][241/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 65.6	Acc@5 84.4
Epoch: [113][251/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 67.2	Acc@5 95.3
Epoch: [113][261/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 62.5	Acc@5 92.2
Epoch: [113][271/704]	Time 0.121	Data 0.001	Loss 3.44	Acc@1 79.7	Acc@5 98.4
Epoch: [113][281/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 89.1
Epoch: [113][291/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 71.9	Acc@5 93.8
Epoch: [113][301/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 75.0	Acc@5 93.8
Epoch: [113][311/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 65.6	Acc@5 95.3
Epoch: [113][321/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 56.2	Acc@5 95.3
Epoch: [113][331/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 71.9	Acc@5 93.8
Epoch: [113][341/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 79.7	Acc@5 90.6
Epoch: [113][351/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 73.4	Acc@5 93.8
Epoch: [113][361/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 64.1	Acc@5 95.3
Epoch: [113][371/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 76.6	Acc@5 90.6
Epoch: [113][381/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 59.4	Acc@5 85.9
Epoch: [113][391/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 60.9	Acc@5 93.8
Epoch: [113][401/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 73.4	Acc@5 89.1
Epoch: [113][411/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 76.6	Acc@5 95.3
Epoch: [113][421/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 78.1	Acc@5 96.9
Epoch: [113][431/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 62.5	Acc@5 92.2
Epoch: [113][441/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 64.1	Acc@5 92.2
Epoch: [113][451/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 78.1	Acc@5 96.9
Epoch: [113][461/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 68.8	Acc@5 95.3
Epoch: [113][471/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 62.5	Acc@5 93.8
Epoch: [113][481/704]	Time 0.121	Data 0.001	Loss 3.75	Acc@1 79.7	Acc@5 95.3
Epoch: [113][491/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 65.6	Acc@5 89.1
Epoch: [113][501/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 59.4	Acc@5 92.2
Epoch: [113][511/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 59.4	Acc@5 92.2
Epoch: [113][521/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 62.5	Acc@5 93.8
Epoch: [113][531/704]	Time 0.121	Data 0.001	Loss 3.77	Acc@1 78.1	Acc@5 96.9
Epoch: [113][541/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 60.9	Acc@5 85.9
Epoch: [113][551/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 68.8	Acc@5 93.8
Epoch: [113][561/704]	Time 0.121	Data 0.001	Loss 6.41	Acc@1 57.8	Acc@5 87.5
Epoch: [113][571/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 64.1	Acc@5 87.5
Epoch: [113][581/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 75.0	Acc@5 92.2
Epoch: [113][591/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 71.9	Acc@5 90.6
Epoch: [113][601/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 81.2	Acc@5 95.3
Epoch: [113][611/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 64.1	Acc@5 93.8
Epoch: [113][621/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 62.5	Acc@5 85.9
Epoch: [113][631/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 65.6	Acc@5 90.6
Epoch: [113][641/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 78.1	Acc@5 96.9
Epoch: [113][651/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 62.5	Acc@5 90.6
Epoch: [113][661/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 71.9	Acc@5 89.1
Epoch: [113][671/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 75.0	Acc@5 100.0
Epoch: [113][681/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 67.2	Acc@5 89.1
Epoch: [113][691/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 68.8	Acc@5 95.3
Epoch: [113][701/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 71.9	Acc@5 96.9
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.8898	Acc@1 56.2500	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.8917	Acc@1 51.5625	Acc@5 75.0000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2603	Acc@1 62.5000	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.3337	Acc@1 67.1875	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.0628	Acc@1 39.0625	Acc@5 75.0000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.1962	Acc@1 53.1250	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7868	Acc@1 59.3750	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.4429	Acc@1 57.8125	Acc@5 89.0625
 * prec@1 47.840 prec@5 79.540
 * prec@1 52.540 prec@5 82.680
 * prec@1 58.400 prec@5 85.920
 * prec@1 57.760 prec@5 86.360
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_113.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_113.pth.tar'
Epoch: [114][1/704]	Time 0.300	Data 0.132	Loss 5.33	Acc@1 70.3	Acc@5 89.1
Epoch: [114][11/704]	Time 0.137	Data 0.012	Loss 5.88	Acc@1 59.4	Acc@5 93.8
Epoch: [114][21/704]	Time 0.129	Data 0.007	Loss 5.43	Acc@1 67.2	Acc@5 93.8
Epoch: [114][31/704]	Time 0.126	Data 0.005	Loss 3.40	Acc@1 76.6	Acc@5 100.0
Epoch: [114][41/704]	Time 0.125	Data 0.004	Loss 4.40	Acc@1 75.0	Acc@5 96.9
Epoch: [114][51/704]	Time 0.124	Data 0.003	Loss 4.87	Acc@1 68.8	Acc@5 95.3
Epoch: [114][61/704]	Time 0.123	Data 0.002	Loss 4.54	Acc@1 71.9	Acc@5 96.9
Epoch: [114][71/704]	Time 0.123	Data 0.002	Loss 6.01	Acc@1 57.8	Acc@5 93.8
Epoch: [114][81/704]	Time 0.123	Data 0.002	Loss 4.53	Acc@1 70.3	Acc@5 93.8
Epoch: [114][91/704]	Time 0.123	Data 0.002	Loss 5.88	Acc@1 57.8	Acc@5 90.6
Epoch: [114][101/704]	Time 0.123	Data 0.002	Loss 4.37	Acc@1 62.5	Acc@5 98.4
Epoch: [114][111/704]	Time 0.122	Data 0.002	Loss 5.37	Acc@1 73.4	Acc@5 93.8
Epoch: [114][121/704]	Time 0.122	Data 0.001	Loss 5.42	Acc@1 68.8	Acc@5 87.5
Epoch: [114][131/704]	Time 0.122	Data 0.001	Loss 5.47	Acc@1 67.2	Acc@5 87.5
Epoch: [114][141/704]	Time 0.122	Data 0.001	Loss 4.00	Acc@1 71.9	Acc@5 96.9
Epoch: [114][151/704]	Time 0.122	Data 0.001	Loss 5.45	Acc@1 60.9	Acc@5 92.2
Epoch: [114][161/704]	Time 0.122	Data 0.001	Loss 4.80	Acc@1 68.8	Acc@5 95.3
Epoch: [114][171/704]	Time 0.122	Data 0.001	Loss 4.26	Acc@1 65.6	Acc@5 98.4
Epoch: [114][181/704]	Time 0.122	Data 0.001	Loss 4.56	Acc@1 65.6	Acc@5 90.6
Epoch: [114][191/704]	Time 0.122	Data 0.001	Loss 4.76	Acc@1 75.0	Acc@5 93.8
Epoch: [114][201/704]	Time 0.121	Data 0.001	Loss 4.18	Acc@1 70.3	Acc@5 92.2
Epoch: [114][211/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 65.6	Acc@5 92.2
Epoch: [114][221/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 76.6	Acc@5 95.3
Epoch: [114][231/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 64.1	Acc@5 92.2
Epoch: [114][241/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 75.0	Acc@5 93.8
Epoch: [114][251/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 81.2	Acc@5 96.9
Epoch: [114][261/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 79.7	Acc@5 95.3
Epoch: [114][271/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 67.2	Acc@5 92.2
Epoch: [114][281/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 65.6	Acc@5 90.6
Epoch: [114][291/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 75.0	Acc@5 96.9
Epoch: [114][301/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 65.6	Acc@5 98.4
Epoch: [114][311/704]	Time 0.121	Data 0.001	Loss 6.23	Acc@1 59.4	Acc@5 92.2
Epoch: [114][321/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 59.4	Acc@5 89.1
Epoch: [114][331/704]	Time 0.121	Data 0.001	Loss 6.42	Acc@1 53.1	Acc@5 89.1
Epoch: [114][341/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 65.6	Acc@5 92.2
Epoch: [114][351/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 70.3	Acc@5 93.8
Epoch: [114][361/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 64.1	Acc@5 90.6
Epoch: [114][371/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 70.3	Acc@5 93.8
Epoch: [114][381/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 75.0	Acc@5 89.1
Epoch: [114][391/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 92.2
Epoch: [114][401/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 75.0	Acc@5 92.2
Epoch: [114][411/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 73.4	Acc@5 95.3
Epoch: [114][421/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 70.3	Acc@5 90.6
Epoch: [114][431/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 78.1	Acc@5 96.9
Epoch: [114][441/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 62.5	Acc@5 92.2
Epoch: [114][451/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 68.8	Acc@5 92.2
Epoch: [114][461/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 70.3	Acc@5 93.8
Epoch: [114][471/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 71.9	Acc@5 96.9
Epoch: [114][481/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 70.3	Acc@5 95.3
Epoch: [114][491/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 70.3	Acc@5 98.4
Epoch: [114][501/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 68.8	Acc@5 90.6
Epoch: [114][511/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 62.5	Acc@5 87.5
Epoch: [114][521/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 68.8	Acc@5 95.3
Epoch: [114][531/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 70.3	Acc@5 92.2
Epoch: [114][541/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 70.3	Acc@5 93.8
Epoch: [114][551/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 67.2	Acc@5 93.8
Epoch: [114][561/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 64.1	Acc@5 93.8
Epoch: [114][571/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 59.4	Acc@5 90.6
Epoch: [114][581/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 70.3	Acc@5 92.2
Epoch: [114][591/704]	Time 0.121	Data 0.001	Loss 3.67	Acc@1 71.9	Acc@5 95.3
Epoch: [114][601/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 57.8	Acc@5 87.5
Epoch: [114][611/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 96.9
Epoch: [114][621/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 68.8	Acc@5 92.2
Epoch: [114][631/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 68.8	Acc@5 89.1
Epoch: [114][641/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 65.6	Acc@5 89.1
Epoch: [114][651/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 70.3	Acc@5 95.3
Epoch: [114][661/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 70.3	Acc@5 92.2
Epoch: [114][671/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 71.9	Acc@5 89.1
Epoch: [114][681/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 67.2	Acc@5 95.3
Epoch: [114][691/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 64.1	Acc@5 90.6
Epoch: [114][701/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 75.0	Acc@5 92.2
Epoch: [1/79]	Time 0.103	Data 0.087	Loss 7.1586	Acc@1 50.0000	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.1802	Acc@1 57.8125	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8577	Acc@1 59.3750	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.5047	Acc@1 56.2500	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6080	Acc@1 59.3750	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7361	Acc@1 53.1250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.8747	Acc@1 50.0000	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.6254	Acc@1 48.4375	Acc@5 84.3750
 * prec@1 47.040 prec@5 78.220
 * prec@1 50.960 prec@5 81.220
 * prec@1 56.100 prec@5 85.000
 * prec@1 57.580 prec@5 85.160
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_114.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_114.pth.tar'
Epoch: [115][1/704]	Time 0.300	Data 0.131	Loss 5.51	Acc@1 65.6	Acc@5 89.1
Epoch: [115][11/704]	Time 0.141	Data 0.012	Loss 5.41	Acc@1 60.9	Acc@5 93.8
Epoch: [115][21/704]	Time 0.131	Data 0.007	Loss 4.91	Acc@1 68.8	Acc@5 95.3
Epoch: [115][31/704]	Time 0.128	Data 0.005	Loss 5.14	Acc@1 68.8	Acc@5 92.2
Epoch: [115][41/704]	Time 0.126	Data 0.004	Loss 4.55	Acc@1 68.8	Acc@5 92.2
Epoch: [115][51/704]	Time 0.125	Data 0.003	Loss 4.95	Acc@1 73.4	Acc@5 93.8
Epoch: [115][61/704]	Time 0.124	Data 0.002	Loss 4.89	Acc@1 68.8	Acc@5 92.2
Epoch: [115][71/704]	Time 0.123	Data 0.002	Loss 3.91	Acc@1 78.1	Acc@5 96.9
Epoch: [115][81/704]	Time 0.123	Data 0.002	Loss 4.51	Acc@1 76.6	Acc@5 96.9
Epoch: [115][91/704]	Time 0.123	Data 0.002	Loss 4.85	Acc@1 68.8	Acc@5 93.8
Epoch: [115][101/704]	Time 0.122	Data 0.002	Loss 4.37	Acc@1 75.0	Acc@5 98.4
Epoch: [115][111/704]	Time 0.122	Data 0.002	Loss 4.92	Acc@1 70.3	Acc@5 92.2
Epoch: [115][121/704]	Time 0.122	Data 0.001	Loss 5.89	Acc@1 59.4	Acc@5 92.2
Epoch: [115][131/704]	Time 0.122	Data 0.001	Loss 5.63	Acc@1 64.1	Acc@5 92.2
Epoch: [115][141/704]	Time 0.122	Data 0.001	Loss 4.89	Acc@1 65.6	Acc@5 93.8
Epoch: [115][151/704]	Time 0.122	Data 0.001	Loss 5.68	Acc@1 70.3	Acc@5 87.5
Epoch: [115][161/704]	Time 0.122	Data 0.001	Loss 4.99	Acc@1 68.8	Acc@5 92.2
Epoch: [115][171/704]	Time 0.122	Data 0.001	Loss 5.77	Acc@1 70.3	Acc@5 85.9
Epoch: [115][181/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 73.4	Acc@5 95.3
Epoch: [115][191/704]	Time 0.121	Data 0.001	Loss 4.08	Acc@1 79.7	Acc@5 95.3
Epoch: [115][201/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 64.1	Acc@5 95.3
Epoch: [115][211/704]	Time 0.121	Data 0.001	Loss 5.95	Acc@1 53.1	Acc@5 90.6
Epoch: [115][221/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 62.5	Acc@5 96.9
Epoch: [115][231/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 71.9	Acc@5 96.9
Epoch: [115][241/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 95.3
Epoch: [115][251/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 60.9	Acc@5 87.5
Epoch: [115][261/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 71.9	Acc@5 92.2
Epoch: [115][271/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 81.2	Acc@5 96.9
Epoch: [115][281/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 67.2	Acc@5 90.6
Epoch: [115][291/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 73.4	Acc@5 92.2
Epoch: [115][301/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 65.6	Acc@5 92.2
Epoch: [115][311/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 73.4	Acc@5 89.1
Epoch: [115][321/704]	Time 0.121	Data 0.001	Loss 3.39	Acc@1 78.1	Acc@5 100.0
Epoch: [115][331/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 78.1	Acc@5 95.3
Epoch: [115][341/704]	Time 0.121	Data 0.001	Loss 4.25	Acc@1 71.9	Acc@5 100.0
Epoch: [115][351/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 76.6	Acc@5 93.8
Epoch: [115][361/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 65.6	Acc@5 96.9
Epoch: [115][371/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 70.3	Acc@5 90.6
Epoch: [115][381/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 65.6	Acc@5 92.2
Epoch: [115][391/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 64.1	Acc@5 92.2
Epoch: [115][401/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 57.8	Acc@5 95.3
Epoch: [115][411/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 76.6	Acc@5 89.1
Epoch: [115][421/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 73.4	Acc@5 92.2
Epoch: [115][431/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 67.2	Acc@5 93.8
Epoch: [115][441/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 62.5	Acc@5 93.8
Epoch: [115][451/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 73.4	Acc@5 92.2
Epoch: [115][461/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 71.9	Acc@5 92.2
Epoch: [115][471/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 60.9	Acc@5 95.3
Epoch: [115][481/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 64.1	Acc@5 93.8
Epoch: [115][491/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 62.5	Acc@5 93.8
Epoch: [115][501/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 75.0	Acc@5 95.3
Epoch: [115][511/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 64.1	Acc@5 90.6
Epoch: [115][521/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 78.1	Acc@5 98.4
Epoch: [115][531/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 76.6	Acc@5 95.3
Epoch: [115][541/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 67.2	Acc@5 96.9
Epoch: [115][551/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 73.4	Acc@5 87.5
Epoch: [115][561/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 67.2	Acc@5 90.6
Epoch: [115][571/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 64.1	Acc@5 82.8
Epoch: [115][581/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 68.8	Acc@5 89.1
Epoch: [115][591/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 70.3	Acc@5 92.2
Epoch: [115][601/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 71.9	Acc@5 96.9
Epoch: [115][611/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 67.2	Acc@5 92.2
Epoch: [115][621/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 57.8	Acc@5 93.8
Epoch: [115][631/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 65.6	Acc@5 87.5
Epoch: [115][641/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 64.1	Acc@5 95.3
Epoch: [115][651/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 89.1
Epoch: [115][661/704]	Time 0.121	Data 0.001	Loss 3.97	Acc@1 78.1	Acc@5 93.8
Epoch: [115][671/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 73.4	Acc@5 93.8
Epoch: [115][681/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 65.6	Acc@5 90.6
Epoch: [115][691/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 60.9	Acc@5 85.9
Epoch: [115][701/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 60.9	Acc@5 89.1
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 6.8334	Acc@1 62.5000	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.9860	Acc@1 68.7500	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.5290	Acc@1 73.4375	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3415	Acc@1 60.9375	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5465	Acc@1 62.5000	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.2510	Acc@1 60.9375	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 8.5803	Acc@1 50.0000	Acc@5 78.1250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.9122	Acc@1 50.0000	Acc@5 89.0625
 * prec@1 47.280 prec@5 78.580
 * prec@1 53.420 prec@5 83.300
 * prec@1 56.320 prec@5 85.600
 * prec@1 58.140 prec@5 85.560
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_115.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_115.pth.tar'
Epoch: [116][1/704]	Time 0.337	Data 0.170	Loss 4.36	Acc@1 71.9	Acc@5 93.8
Epoch: [116][11/704]	Time 0.140	Data 0.016	Loss 5.20	Acc@1 73.4	Acc@5 98.4
Epoch: [116][21/704]	Time 0.131	Data 0.008	Loss 4.69	Acc@1 75.0	Acc@5 90.6
Epoch: [116][31/704]	Time 0.127	Data 0.006	Loss 6.19	Acc@1 67.2	Acc@5 90.6
Epoch: [116][41/704]	Time 0.126	Data 0.004	Loss 4.52	Acc@1 75.0	Acc@5 98.4
Epoch: [116][51/704]	Time 0.125	Data 0.004	Loss 4.64	Acc@1 70.3	Acc@5 95.3
Epoch: [116][61/704]	Time 0.124	Data 0.003	Loss 4.84	Acc@1 71.9	Acc@5 93.8
Epoch: [116][71/704]	Time 0.123	Data 0.003	Loss 4.31	Acc@1 73.4	Acc@5 93.8
Epoch: [116][81/704]	Time 0.123	Data 0.002	Loss 5.37	Acc@1 67.2	Acc@5 92.2
Epoch: [116][91/704]	Time 0.123	Data 0.002	Loss 4.97	Acc@1 64.1	Acc@5 87.5
Epoch: [116][101/704]	Time 0.122	Data 0.002	Loss 5.28	Acc@1 70.3	Acc@5 92.2
Epoch: [116][111/704]	Time 0.122	Data 0.002	Loss 5.01	Acc@1 78.1	Acc@5 92.2
Epoch: [116][121/704]	Time 0.122	Data 0.002	Loss 4.93	Acc@1 71.9	Acc@5 90.6
Epoch: [116][131/704]	Time 0.122	Data 0.002	Loss 4.90	Acc@1 59.4	Acc@5 93.8
Epoch: [116][141/704]	Time 0.122	Data 0.002	Loss 5.76	Acc@1 60.9	Acc@5 95.3
Epoch: [116][151/704]	Time 0.122	Data 0.001	Loss 5.98	Acc@1 65.6	Acc@5 90.6
Epoch: [116][161/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 60.9	Acc@5 98.4
Epoch: [116][171/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 67.2	Acc@5 90.6
Epoch: [116][181/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 68.8	Acc@5 92.2
Epoch: [116][191/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 68.8	Acc@5 93.8
Epoch: [116][201/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 75.0	Acc@5 95.3
Epoch: [116][211/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 87.5
Epoch: [116][221/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 78.1	Acc@5 96.9
Epoch: [116][231/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 75.0	Acc@5 96.9
Epoch: [116][241/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 65.6	Acc@5 89.1
Epoch: [116][251/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 71.9	Acc@5 92.2
Epoch: [116][261/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 65.6	Acc@5 92.2
Epoch: [116][271/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 71.9	Acc@5 96.9
Epoch: [116][281/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 70.3	Acc@5 90.6
Epoch: [116][291/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 73.4	Acc@5 93.8
Epoch: [116][301/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 68.8	Acc@5 95.3
Epoch: [116][311/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 70.3	Acc@5 92.2
Epoch: [116][321/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 79.7	Acc@5 96.9
Epoch: [116][331/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 70.3	Acc@5 92.2
Epoch: [116][341/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 67.2	Acc@5 95.3
Epoch: [116][351/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 64.1	Acc@5 95.3
Epoch: [116][361/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 73.4	Acc@5 92.2
Epoch: [116][371/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 62.5	Acc@5 92.2
Epoch: [116][381/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 62.5	Acc@5 95.3
Epoch: [116][391/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 60.9	Acc@5 90.6
Epoch: [116][401/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 62.5	Acc@5 92.2
Epoch: [116][411/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 71.9	Acc@5 93.8
Epoch: [116][421/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 70.3	Acc@5 92.2
Epoch: [116][431/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 59.4	Acc@5 93.8
Epoch: [116][441/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 67.2	Acc@5 90.6
Epoch: [116][451/704]	Time 0.121	Data 0.001	Loss 4.08	Acc@1 71.9	Acc@5 95.3
Epoch: [116][461/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 67.2	Acc@5 93.8
Epoch: [116][471/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 67.2	Acc@5 90.6
Epoch: [116][481/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 62.5	Acc@5 92.2
Epoch: [116][491/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 70.3	Acc@5 90.6
Epoch: [116][501/704]	Time 0.121	Data 0.001	Loss 6.30	Acc@1 59.4	Acc@5 90.6
Epoch: [116][511/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 64.1	Acc@5 89.1
Epoch: [116][521/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 59.4	Acc@5 96.9
Epoch: [116][531/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 75.0	Acc@5 90.6
Epoch: [116][541/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 60.9	Acc@5 90.6
Epoch: [116][551/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 62.5	Acc@5 92.2
Epoch: [116][561/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 65.6	Acc@5 93.8
Epoch: [116][571/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 64.1	Acc@5 92.2
Epoch: [116][581/704]	Time 0.121	Data 0.001	Loss 3.53	Acc@1 78.1	Acc@5 98.4
Epoch: [116][591/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 68.8	Acc@5 93.8
Epoch: [116][601/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 93.8
Epoch: [116][611/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 79.7	Acc@5 98.4
Epoch: [116][621/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 76.6	Acc@5 89.1
Epoch: [116][631/704]	Time 0.120	Data 0.001	Loss 5.77	Acc@1 64.1	Acc@5 92.2
Epoch: [116][641/704]	Time 0.120	Data 0.001	Loss 4.53	Acc@1 75.0	Acc@5 96.9
Epoch: [116][651/704]	Time 0.120	Data 0.001	Loss 6.41	Acc@1 59.4	Acc@5 84.4
Epoch: [116][661/704]	Time 0.120	Data 0.001	Loss 5.01	Acc@1 60.9	Acc@5 95.3
Epoch: [116][671/704]	Time 0.120	Data 0.001	Loss 5.53	Acc@1 67.2	Acc@5 92.2
Epoch: [116][681/704]	Time 0.120	Data 0.001	Loss 4.25	Acc@1 75.0	Acc@5 98.4
Epoch: [116][691/704]	Time 0.120	Data 0.001	Loss 4.80	Acc@1 59.4	Acc@5 95.3
Epoch: [116][701/704]	Time 0.120	Data 0.001	Loss 4.16	Acc@1 75.0	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.1965	Acc@1 60.9375	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.9479	Acc@1 65.6250	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.0388	Acc@1 65.6250	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.7479	Acc@1 54.6875	Acc@5 76.5625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9914	Acc@1 60.9375	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.0520	Acc@1 62.5000	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.9340	Acc@1 64.0625	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.3365	Acc@1 51.5625	Acc@5 85.9375
 * prec@1 45.260 prec@5 76.380
 * prec@1 51.780 prec@5 80.620
 * prec@1 55.360 prec@5 83.960
 * prec@1 56.460 prec@5 83.640
Current best validation last_bloc_accuracy 59.3
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_116.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_116.pth.tar'
Epoch: [117][1/704]	Time 0.297	Data 0.130	Loss 4.81	Acc@1 70.3	Acc@5 92.2
Epoch: [117][11/704]	Time 0.136	Data 0.012	Loss 5.35	Acc@1 67.2	Acc@5 95.3
Epoch: [117][21/704]	Time 0.129	Data 0.006	Loss 5.79	Acc@1 65.6	Acc@5 89.1
Epoch: [117][31/704]	Time 0.126	Data 0.004	Loss 4.86	Acc@1 71.9	Acc@5 90.6
Epoch: [117][41/704]	Time 0.125	Data 0.003	Loss 4.73	Acc@1 67.2	Acc@5 95.3
Epoch: [117][51/704]	Time 0.124	Data 0.003	Loss 5.00	Acc@1 71.9	Acc@5 96.9
Epoch: [117][61/704]	Time 0.123	Data 0.002	Loss 4.92	Acc@1 73.4	Acc@5 92.2
Epoch: [117][71/704]	Time 0.123	Data 0.002	Loss 5.06	Acc@1 67.2	Acc@5 92.2
Epoch: [117][81/704]	Time 0.122	Data 0.002	Loss 4.89	Acc@1 65.6	Acc@5 93.8
Epoch: [117][91/704]	Time 0.122	Data 0.002	Loss 5.44	Acc@1 64.1	Acc@5 96.9
Epoch: [117][101/704]	Time 0.122	Data 0.002	Loss 5.01	Acc@1 71.9	Acc@5 90.6
Epoch: [117][111/704]	Time 0.122	Data 0.002	Loss 4.77	Acc@1 78.1	Acc@5 96.9
Epoch: [117][121/704]	Time 0.122	Data 0.001	Loss 4.93	Acc@1 75.0	Acc@5 93.8
Epoch: [117][131/704]	Time 0.122	Data 0.001	Loss 4.78	Acc@1 73.4	Acc@5 90.6
Epoch: [117][141/704]	Time 0.122	Data 0.001	Loss 4.85	Acc@1 70.3	Acc@5 87.5
Epoch: [117][151/704]	Time 0.122	Data 0.001	Loss 4.58	Acc@1 75.0	Acc@5 96.9
Epoch: [117][161/704]	Time 0.122	Data 0.001	Loss 4.62	Acc@1 71.9	Acc@5 96.9
Epoch: [117][171/704]	Time 0.122	Data 0.001	Loss 4.62	Acc@1 65.6	Acc@5 95.3
Epoch: [117][181/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 67.2	Acc@5 92.2
Epoch: [117][191/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 67.2	Acc@5 93.8
Epoch: [117][201/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 68.8	Acc@5 96.9
Epoch: [117][211/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 65.6	Acc@5 89.1
Epoch: [117][221/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 78.1	Acc@5 98.4
Epoch: [117][231/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 68.8	Acc@5 92.2
Epoch: [117][241/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 68.8	Acc@5 95.3
Epoch: [117][251/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 75.0	Acc@5 92.2
Epoch: [117][261/704]	Time 0.121	Data 0.001	Loss 4.01	Acc@1 75.0	Acc@5 93.8
Epoch: [117][271/704]	Time 0.121	Data 0.001	Loss 6.25	Acc@1 59.4	Acc@5 84.4
Epoch: [117][281/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 62.5	Acc@5 93.8
Epoch: [117][291/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 71.9	Acc@5 93.8
Epoch: [117][301/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 54.7	Acc@5 92.2
Epoch: [117][311/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 73.4	Acc@5 96.9
Epoch: [117][321/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 71.9	Acc@5 92.2
Epoch: [117][331/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 68.8	Acc@5 96.9
Epoch: [117][341/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 70.3	Acc@5 92.2
Epoch: [117][351/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 65.6	Acc@5 89.1
Epoch: [117][361/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 62.5	Acc@5 87.5
Epoch: [117][371/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 62.5	Acc@5 93.8
Epoch: [117][381/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 71.9	Acc@5 95.3
Epoch: [117][391/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 65.6	Acc@5 93.8
Epoch: [117][401/704]	Time 0.121	Data 0.001	Loss 4.35	Acc@1 70.3	Acc@5 96.9
Epoch: [117][411/704]	Time 0.121	Data 0.001	Loss 4.28	Acc@1 70.3	Acc@5 96.9
Epoch: [117][421/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 64.1	Acc@5 95.3
Epoch: [117][431/704]	Time 0.121	Data 0.001	Loss 3.60	Acc@1 79.7	Acc@5 98.4
Epoch: [117][441/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 70.3	Acc@5 92.2
Epoch: [117][451/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 64.1	Acc@5 95.3
Epoch: [117][461/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 65.6	Acc@5 96.9
Epoch: [117][471/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 70.3	Acc@5 89.1
Epoch: [117][481/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 70.3	Acc@5 95.3
Epoch: [117][491/704]	Time 0.121	Data 0.001	Loss 6.82	Acc@1 56.2	Acc@5 89.1
Epoch: [117][501/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 67.2	Acc@5 93.8
Epoch: [117][511/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 64.1	Acc@5 92.2
Epoch: [117][521/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 70.3	Acc@5 92.2
Epoch: [117][531/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 73.4	Acc@5 96.9
Epoch: [117][541/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 93.8
Epoch: [117][551/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 67.2	Acc@5 90.6
Epoch: [117][561/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 65.6	Acc@5 93.8
Epoch: [117][571/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 87.5
Epoch: [117][581/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 93.8
Epoch: [117][591/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 65.6	Acc@5 90.6
Epoch: [117][601/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 67.2	Acc@5 96.9
Epoch: [117][611/704]	Time 0.121	Data 0.001	Loss 6.39	Acc@1 73.4	Acc@5 95.3
Epoch: [117][621/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 68.8	Acc@5 93.8
Epoch: [117][631/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 59.4	Acc@5 87.5
Epoch: [117][641/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 67.2	Acc@5 96.9
Epoch: [117][651/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 53.1	Acc@5 89.1
Epoch: [117][661/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 60.9	Acc@5 89.1
Epoch: [117][671/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 73.4	Acc@5 93.8
Epoch: [117][681/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 73.4	Acc@5 89.1
Epoch: [117][691/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 67.2	Acc@5 89.1
Epoch: [117][701/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 70.3	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.8783	Acc@1 73.4375	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.0640	Acc@1 62.5000	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.6295	Acc@1 59.3750	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.2602	Acc@1 60.9375	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.3676	Acc@1 60.9375	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.9820	Acc@1 53.1250	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.7607	Acc@1 60.9375	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1233	Acc@1 65.6250	Acc@5 90.6250
 * prec@1 48.980 prec@5 79.800
 * prec@1 53.280 prec@5 83.260
 * prec@1 57.380 prec@5 86.680
 * prec@1 59.920 prec@5 87.040
New best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_117.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_117.pth.tar'
Epoch: [118][1/704]	Time 0.300	Data 0.132	Loss 4.46	Acc@1 70.3	Acc@5 92.2
Epoch: [118][11/704]	Time 0.137	Data 0.012	Loss 7.11	Acc@1 51.6	Acc@5 90.6
Epoch: [118][21/704]	Time 0.129	Data 0.007	Loss 4.22	Acc@1 73.4	Acc@5 92.2
Epoch: [118][31/704]	Time 0.126	Data 0.005	Loss 5.97	Acc@1 56.2	Acc@5 92.2
Epoch: [118][41/704]	Time 0.125	Data 0.004	Loss 5.88	Acc@1 62.5	Acc@5 93.8
Epoch: [118][51/704]	Time 0.124	Data 0.003	Loss 4.11	Acc@1 81.2	Acc@5 98.4
Epoch: [118][61/704]	Time 0.124	Data 0.002	Loss 6.16	Acc@1 51.6	Acc@5 90.6
Epoch: [118][71/704]	Time 0.124	Data 0.002	Loss 4.85	Acc@1 71.9	Acc@5 93.8
Epoch: [118][81/704]	Time 0.123	Data 0.002	Loss 5.13	Acc@1 68.8	Acc@5 84.4
Epoch: [118][91/704]	Time 0.123	Data 0.002	Loss 4.70	Acc@1 68.8	Acc@5 95.3
Epoch: [118][101/704]	Time 0.123	Data 0.002	Loss 4.60	Acc@1 76.6	Acc@5 96.9
Epoch: [118][111/704]	Time 0.122	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 90.6
Epoch: [118][121/704]	Time 0.122	Data 0.001	Loss 4.32	Acc@1 73.4	Acc@5 90.6
Epoch: [118][131/704]	Time 0.122	Data 0.001	Loss 5.18	Acc@1 59.4	Acc@5 93.8
Epoch: [118][141/704]	Time 0.122	Data 0.001	Loss 5.04	Acc@1 65.6	Acc@5 93.8
Epoch: [118][151/704]	Time 0.122	Data 0.001	Loss 3.72	Acc@1 76.6	Acc@5 93.8
Epoch: [118][161/704]	Time 0.122	Data 0.001	Loss 5.23	Acc@1 59.4	Acc@5 92.2
Epoch: [118][171/704]	Time 0.122	Data 0.001	Loss 5.55	Acc@1 65.6	Acc@5 93.8
Epoch: [118][181/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 67.2	Acc@5 98.4
Epoch: [118][191/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 70.3	Acc@5 98.4
Epoch: [118][201/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 71.9	Acc@5 90.6
Epoch: [118][211/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 93.8
Epoch: [118][221/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 68.8	Acc@5 93.8
Epoch: [118][231/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 73.4	Acc@5 93.8
Epoch: [118][241/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 73.4	Acc@5 92.2
Epoch: [118][251/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 76.6	Acc@5 95.3
Epoch: [118][261/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 76.6	Acc@5 89.1
Epoch: [118][271/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 68.8	Acc@5 90.6
Epoch: [118][281/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 57.8	Acc@5 92.2
Epoch: [118][291/704]	Time 0.121	Data 0.001	Loss 4.19	Acc@1 70.3	Acc@5 93.8
Epoch: [118][301/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 59.4	Acc@5 87.5
Epoch: [118][311/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 73.4	Acc@5 92.2
Epoch: [118][321/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 67.2	Acc@5 92.2
Epoch: [118][331/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 73.4	Acc@5 90.6
Epoch: [118][341/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 70.3	Acc@5 89.1
Epoch: [118][351/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 62.5	Acc@5 93.8
Epoch: [118][361/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 81.2	Acc@5 92.2
Epoch: [118][371/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 78.1	Acc@5 98.4
Epoch: [118][381/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 71.9	Acc@5 96.9
Epoch: [118][391/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 67.2	Acc@5 90.6
Epoch: [118][401/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 60.9	Acc@5 96.9
Epoch: [118][411/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 68.8	Acc@5 95.3
Epoch: [118][421/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 64.1	Acc@5 96.9
Epoch: [118][431/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 65.6	Acc@5 90.6
Epoch: [118][441/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 68.8	Acc@5 95.3
Epoch: [118][451/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 70.3	Acc@5 95.3
Epoch: [118][461/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 75.0	Acc@5 96.9
Epoch: [118][471/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 76.6	Acc@5 95.3
Epoch: [118][481/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 71.9	Acc@5 92.2
Epoch: [118][491/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 79.7	Acc@5 89.1
Epoch: [118][501/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 73.4	Acc@5 89.1
Epoch: [118][511/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 59.4	Acc@5 90.6
Epoch: [118][521/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 81.2	Acc@5 100.0
Epoch: [118][531/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 75.0	Acc@5 93.8
Epoch: [118][541/704]	Time 0.121	Data 0.001	Loss 6.62	Acc@1 64.1	Acc@5 84.4
Epoch: [118][551/704]	Time 0.121	Data 0.001	Loss 3.84	Acc@1 70.3	Acc@5 96.9
Epoch: [118][561/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 65.6	Acc@5 89.1
Epoch: [118][571/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 65.6	Acc@5 92.2
Epoch: [118][581/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 57.8	Acc@5 95.3
Epoch: [118][591/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 75.0	Acc@5 92.2
Epoch: [118][601/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 90.6
Epoch: [118][611/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 62.5	Acc@5 87.5
Epoch: [118][621/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 73.4	Acc@5 98.4
Epoch: [118][631/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 70.3	Acc@5 89.1
Epoch: [118][641/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 60.9	Acc@5 85.9
Epoch: [118][651/704]	Time 0.121	Data 0.001	Loss 6.61	Acc@1 59.4	Acc@5 89.1
Epoch: [118][661/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 64.1	Acc@5 90.6
Epoch: [118][671/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 62.5	Acc@5 93.8
Epoch: [118][681/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 65.6	Acc@5 90.6
Epoch: [118][691/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 70.3	Acc@5 89.1
Epoch: [118][701/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 57.8	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.4102	Acc@1 60.9375	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8812	Acc@1 54.6875	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 9.7884	Acc@1 56.2500	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.0436	Acc@1 64.0625	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2572	Acc@1 64.0625	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.4944	Acc@1 54.6875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.7179	Acc@1 60.9375	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.5499	Acc@1 43.7500	Acc@5 81.2500
 * prec@1 47.920 prec@5 79.020
 * prec@1 53.840 prec@5 83.600
 * prec@1 55.920 prec@5 85.820
 * prec@1 57.400 prec@5 87.040
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_118.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_118.pth.tar'
Epoch: [119][1/704]	Time 0.330	Data 0.164	Loss 4.06	Acc@1 73.4	Acc@5 98.4
Epoch: [119][11/704]	Time 0.139	Data 0.015	Loss 5.17	Acc@1 67.2	Acc@5 93.8
Epoch: [119][21/704]	Time 0.130	Data 0.008	Loss 4.29	Acc@1 78.1	Acc@5 96.9
Epoch: [119][31/704]	Time 0.127	Data 0.006	Loss 5.44	Acc@1 62.5	Acc@5 95.3
Epoch: [119][41/704]	Time 0.125	Data 0.004	Loss 4.68	Acc@1 71.9	Acc@5 90.6
Epoch: [119][51/704]	Time 0.124	Data 0.004	Loss 4.97	Acc@1 71.9	Acc@5 95.3
Epoch: [119][61/704]	Time 0.124	Data 0.003	Loss 4.79	Acc@1 67.2	Acc@5 92.2
Epoch: [119][71/704]	Time 0.123	Data 0.003	Loss 6.40	Acc@1 60.9	Acc@5 84.4
Epoch: [119][81/704]	Time 0.123	Data 0.002	Loss 3.44	Acc@1 76.6	Acc@5 95.3
Epoch: [119][91/704]	Time 0.122	Data 0.002	Loss 4.83	Acc@1 75.0	Acc@5 95.3
Epoch: [119][101/704]	Time 0.122	Data 0.002	Loss 3.94	Acc@1 73.4	Acc@5 98.4
Epoch: [119][111/704]	Time 0.122	Data 0.002	Loss 3.63	Acc@1 78.1	Acc@5 98.4
Epoch: [119][121/704]	Time 0.122	Data 0.002	Loss 4.49	Acc@1 67.2	Acc@5 96.9
Epoch: [119][131/704]	Time 0.122	Data 0.002	Loss 5.42	Acc@1 67.2	Acc@5 90.6
Epoch: [119][141/704]	Time 0.122	Data 0.001	Loss 5.15	Acc@1 71.9	Acc@5 92.2
Epoch: [119][151/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 73.4	Acc@5 95.3
Epoch: [119][161/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 73.4	Acc@5 92.2
Epoch: [119][171/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 57.8	Acc@5 87.5
Epoch: [119][181/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 67.2	Acc@5 89.1
Epoch: [119][191/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 78.1	Acc@5 95.3
Epoch: [119][201/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 70.3	Acc@5 95.3
Epoch: [119][211/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 68.8	Acc@5 92.2
Epoch: [119][221/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 62.5	Acc@5 89.1
Epoch: [119][231/704]	Time 0.121	Data 0.001	Loss 3.75	Acc@1 73.4	Acc@5 93.8
Epoch: [119][241/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 68.8	Acc@5 85.9
Epoch: [119][251/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 76.6	Acc@5 95.3
Epoch: [119][261/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 70.3	Acc@5 93.8
Epoch: [119][271/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 70.3	Acc@5 87.5
Epoch: [119][281/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 67.2	Acc@5 93.8
Epoch: [119][291/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 54.7	Acc@5 93.8
Epoch: [119][301/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 71.9	Acc@5 90.6
Epoch: [119][311/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 64.1	Acc@5 95.3
Epoch: [119][321/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 59.4	Acc@5 89.1
Epoch: [119][331/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 71.9	Acc@5 90.6
Epoch: [119][341/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 76.6	Acc@5 95.3
Epoch: [119][351/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 75.0	Acc@5 96.9
Epoch: [119][361/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 71.9	Acc@5 92.2
Epoch: [119][371/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 71.9	Acc@5 93.8
Epoch: [119][381/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 65.6	Acc@5 93.8
Epoch: [119][391/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 68.8	Acc@5 93.8
Epoch: [119][401/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 79.7	Acc@5 90.6
Epoch: [119][411/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 68.8	Acc@5 93.8
Epoch: [119][421/704]	Time 0.121	Data 0.001	Loss 6.92	Acc@1 56.2	Acc@5 87.5
Epoch: [119][431/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 93.8
Epoch: [119][441/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 75.0	Acc@5 93.8
Epoch: [119][451/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 68.8	Acc@5 87.5
Epoch: [119][461/704]	Time 0.121	Data 0.001	Loss 6.94	Acc@1 59.4	Acc@5 87.5
Epoch: [119][471/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 65.6	Acc@5 84.4
Epoch: [119][481/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 65.6	Acc@5 93.8
Epoch: [119][491/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 68.8	Acc@5 96.9
Epoch: [119][501/704]	Time 0.120	Data 0.001	Loss 6.32	Acc@1 60.9	Acc@5 87.5
Epoch: [119][511/704]	Time 0.120	Data 0.001	Loss 3.99	Acc@1 79.7	Acc@5 98.4
Epoch: [119][521/704]	Time 0.120	Data 0.001	Loss 4.32	Acc@1 71.9	Acc@5 98.4
Epoch: [119][531/704]	Time 0.120	Data 0.001	Loss 5.83	Acc@1 56.2	Acc@5 89.1
Epoch: [119][541/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 65.6	Acc@5 89.1
Epoch: [119][551/704]	Time 0.120	Data 0.001	Loss 4.80	Acc@1 71.9	Acc@5 95.3
Epoch: [119][561/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 64.1	Acc@5 89.1
Epoch: [119][571/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 70.3	Acc@5 92.2
Epoch: [119][581/704]	Time 0.120	Data 0.001	Loss 3.83	Acc@1 70.3	Acc@5 98.4
Epoch: [119][591/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 67.2	Acc@5 93.8
Epoch: [119][601/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 62.5	Acc@5 92.2
Epoch: [119][611/704]	Time 0.120	Data 0.001	Loss 6.96	Acc@1 57.8	Acc@5 90.6
Epoch: [119][621/704]	Time 0.120	Data 0.001	Loss 5.96	Acc@1 65.6	Acc@5 89.1
Epoch: [119][631/704]	Time 0.120	Data 0.001	Loss 5.65	Acc@1 68.8	Acc@5 92.2
Epoch: [119][641/704]	Time 0.120	Data 0.001	Loss 5.11	Acc@1 60.9	Acc@5 95.3
Epoch: [119][651/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 70.3	Acc@5 89.1
Epoch: [119][661/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 64.1	Acc@5 90.6
Epoch: [119][671/704]	Time 0.120	Data 0.001	Loss 4.47	Acc@1 71.9	Acc@5 95.3
Epoch: [119][681/704]	Time 0.120	Data 0.001	Loss 5.87	Acc@1 65.6	Acc@5 90.6
Epoch: [119][691/704]	Time 0.120	Data 0.001	Loss 5.92	Acc@1 64.1	Acc@5 87.5
Epoch: [119][701/704]	Time 0.120	Data 0.001	Loss 5.73	Acc@1 64.1	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.2030	Acc@1 62.5000	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.9002	Acc@1 51.5625	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2810	Acc@1 51.5625	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.1873	Acc@1 48.4375	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.7484	Acc@1 43.7500	Acc@5 76.5625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9445	Acc@1 45.3125	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 8.4804	Acc@1 48.4375	Acc@5 79.6875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.8197	Acc@1 46.8750	Acc@5 82.8125
 * prec@1 47.720 prec@5 78.740
 * prec@1 51.880 prec@5 82.040
 * prec@1 55.560 prec@5 84.360
 * prec@1 56.140 prec@5 86.420
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_119.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_119.pth.tar'
Epoch: [120][1/704]	Time 0.329	Data 0.163	Loss 4.53	Acc@1 71.9	Acc@5 96.9
Epoch: [120][11/704]	Time 0.139	Data 0.015	Loss 4.12	Acc@1 79.7	Acc@5 95.3
Epoch: [120][21/704]	Time 0.130	Data 0.008	Loss 5.37	Acc@1 70.3	Acc@5 90.6
Epoch: [120][31/704]	Time 0.127	Data 0.006	Loss 4.21	Acc@1 67.2	Acc@5 93.8
Epoch: [120][41/704]	Time 0.125	Data 0.004	Loss 5.51	Acc@1 68.8	Acc@5 89.1
Epoch: [120][51/704]	Time 0.124	Data 0.003	Loss 5.57	Acc@1 56.2	Acc@5 89.1
Epoch: [120][61/704]	Time 0.123	Data 0.003	Loss 5.35	Acc@1 60.9	Acc@5 89.1
Epoch: [120][71/704]	Time 0.123	Data 0.003	Loss 4.94	Acc@1 70.3	Acc@5 92.2
Epoch: [120][81/704]	Time 0.123	Data 0.002	Loss 5.41	Acc@1 62.5	Acc@5 95.3
Epoch: [120][91/704]	Time 0.122	Data 0.002	Loss 3.78	Acc@1 78.1	Acc@5 96.9
Epoch: [120][101/704]	Time 0.122	Data 0.002	Loss 4.33	Acc@1 76.6	Acc@5 92.2
Epoch: [120][111/704]	Time 0.122	Data 0.002	Loss 5.97	Acc@1 56.2	Acc@5 87.5
Epoch: [120][121/704]	Time 0.122	Data 0.002	Loss 3.93	Acc@1 79.7	Acc@5 95.3
Epoch: [120][131/704]	Time 0.122	Data 0.002	Loss 5.29	Acc@1 76.6	Acc@5 96.9
Epoch: [120][141/704]	Time 0.122	Data 0.001	Loss 4.14	Acc@1 71.9	Acc@5 95.3
Epoch: [120][151/704]	Time 0.122	Data 0.001	Loss 3.91	Acc@1 71.9	Acc@5 95.3
Epoch: [120][161/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 68.8	Acc@5 95.3
Epoch: [120][171/704]	Time 0.122	Data 0.001	Loss 7.39	Acc@1 59.4	Acc@5 82.8
Epoch: [120][181/704]	Time 0.122	Data 0.001	Loss 5.68	Acc@1 57.8	Acc@5 92.2
Epoch: [120][191/704]	Time 0.121	Data 0.001	Loss 4.25	Acc@1 75.0	Acc@5 92.2
Epoch: [120][201/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 65.6	Acc@5 87.5
Epoch: [120][211/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 71.9	Acc@5 98.4
Epoch: [120][221/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 70.3	Acc@5 100.0
Epoch: [120][231/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 64.1	Acc@5 87.5
Epoch: [120][241/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 75.0	Acc@5 90.6
Epoch: [120][251/704]	Time 0.121	Data 0.001	Loss 3.76	Acc@1 76.6	Acc@5 96.9
Epoch: [120][261/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 67.2	Acc@5 87.5
Epoch: [120][271/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 71.9	Acc@5 92.2
Epoch: [120][281/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 73.4	Acc@5 89.1
Epoch: [120][291/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 70.3	Acc@5 93.8
Epoch: [120][301/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 75.0	Acc@5 92.2
Epoch: [120][311/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 64.1	Acc@5 90.6
Epoch: [120][321/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 65.6	Acc@5 93.8
Epoch: [120][331/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 71.9	Acc@5 89.1
Epoch: [120][341/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 65.6	Acc@5 90.6
Epoch: [120][351/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 64.1	Acc@5 95.3
Epoch: [120][361/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 75.0	Acc@5 93.8
Epoch: [120][371/704]	Time 0.121	Data 0.001	Loss 6.58	Acc@1 56.2	Acc@5 87.5
Epoch: [120][381/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 67.2	Acc@5 90.6
Epoch: [120][391/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 71.9	Acc@5 95.3
Epoch: [120][401/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 68.8	Acc@5 96.9
Epoch: [120][411/704]	Time 0.121	Data 0.001	Loss 6.43	Acc@1 60.9	Acc@5 92.2
Epoch: [120][421/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 71.9	Acc@5 92.2
Epoch: [120][431/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 65.6	Acc@5 92.2
Epoch: [120][441/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 78.1	Acc@5 96.9
Epoch: [120][451/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 96.9
Epoch: [120][461/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 76.6	Acc@5 96.9
Epoch: [120][471/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 60.9	Acc@5 93.8
Epoch: [120][481/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 65.6	Acc@5 87.5
Epoch: [120][491/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 67.2	Acc@5 92.2
Epoch: [120][501/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 60.9	Acc@5 98.4
Epoch: [120][511/704]	Time 0.121	Data 0.001	Loss 4.19	Acc@1 76.6	Acc@5 93.8
Epoch: [120][521/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 68.8	Acc@5 98.4
Epoch: [120][531/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 76.6	Acc@5 93.8
Epoch: [120][541/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 76.6	Acc@5 93.8
Epoch: [120][551/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 64.1	Acc@5 84.4
Epoch: [120][561/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 65.6	Acc@5 93.8
Epoch: [120][571/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 73.4	Acc@5 93.8
Epoch: [120][581/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 65.6	Acc@5 96.9
Epoch: [120][591/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 71.9	Acc@5 93.8
Epoch: [120][601/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 70.3	Acc@5 100.0
Epoch: [120][611/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 64.1	Acc@5 95.3
Epoch: [120][621/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 70.3	Acc@5 89.1
Epoch: [120][631/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 71.9	Acc@5 92.2
Epoch: [120][641/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 62.5	Acc@5 95.3
Epoch: [120][651/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 71.9	Acc@5 90.6
Epoch: [120][661/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 76.6	Acc@5 95.3
Epoch: [120][671/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 68.8	Acc@5 95.3
Epoch: [120][681/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 93.8
Epoch: [120][691/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 68.8	Acc@5 96.9
Epoch: [120][701/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 68.8	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5171	Acc@1 57.8125	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8171	Acc@1 60.9375	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.4472	Acc@1 48.4375	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3165	Acc@1 62.5000	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3148	Acc@1 50.0000	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9247	Acc@1 70.3125	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6884	Acc@1 54.6875	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2831	Acc@1 60.9375	Acc@5 84.3750
 * prec@1 48.860 prec@5 79.060
 * prec@1 53.580 prec@5 83.280
 * prec@1 57.100 prec@5 86.400
 * prec@1 59.600 prec@5 87.180
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_120.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_120.pth.tar'
Epoch: [121][1/704]	Time 0.299	Data 0.132	Loss 4.17	Acc@1 79.7	Acc@5 98.4
Epoch: [121][11/704]	Time 0.137	Data 0.012	Loss 4.08	Acc@1 75.0	Acc@5 98.4
Epoch: [121][21/704]	Time 0.129	Data 0.007	Loss 4.53	Acc@1 71.9	Acc@5 90.6
Epoch: [121][31/704]	Time 0.126	Data 0.005	Loss 4.86	Acc@1 60.9	Acc@5 98.4
Epoch: [121][41/704]	Time 0.125	Data 0.004	Loss 4.60	Acc@1 75.0	Acc@5 93.8
Epoch: [121][51/704]	Time 0.124	Data 0.003	Loss 4.96	Acc@1 78.1	Acc@5 93.8
Epoch: [121][61/704]	Time 0.123	Data 0.002	Loss 4.60	Acc@1 68.8	Acc@5 93.8
Epoch: [121][71/704]	Time 0.123	Data 0.002	Loss 4.22	Acc@1 76.6	Acc@5 95.3
Epoch: [121][81/704]	Time 0.123	Data 0.002	Loss 4.22	Acc@1 76.6	Acc@5 95.3
Epoch: [121][91/704]	Time 0.123	Data 0.002	Loss 5.16	Acc@1 68.8	Acc@5 93.8
Epoch: [121][101/704]	Time 0.123	Data 0.002	Loss 6.46	Acc@1 65.6	Acc@5 92.2
Epoch: [121][111/704]	Time 0.122	Data 0.002	Loss 5.73	Acc@1 57.8	Acc@5 84.4
Epoch: [121][121/704]	Time 0.122	Data 0.001	Loss 4.60	Acc@1 73.4	Acc@5 96.9
Epoch: [121][131/704]	Time 0.122	Data 0.001	Loss 4.01	Acc@1 79.7	Acc@5 95.3
Epoch: [121][141/704]	Time 0.122	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 95.3
Epoch: [121][151/704]	Time 0.122	Data 0.001	Loss 4.18	Acc@1 75.0	Acc@5 93.8
Epoch: [121][161/704]	Time 0.122	Data 0.001	Loss 4.77	Acc@1 71.9	Acc@5 92.2
Epoch: [121][171/704]	Time 0.122	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 95.3
Epoch: [121][181/704]	Time 0.122	Data 0.001	Loss 4.49	Acc@1 70.3	Acc@5 95.3
Epoch: [121][191/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 75.0	Acc@5 95.3
Epoch: [121][201/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 67.2	Acc@5 95.3
Epoch: [121][211/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 67.2	Acc@5 92.2
Epoch: [121][221/704]	Time 0.121	Data 0.001	Loss 4.35	Acc@1 73.4	Acc@5 93.8
Epoch: [121][231/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 75.0	Acc@5 89.1
Epoch: [121][241/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 70.3	Acc@5 93.8
Epoch: [121][251/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 79.7	Acc@5 90.6
Epoch: [121][261/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 68.8	Acc@5 95.3
Epoch: [121][271/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 65.6	Acc@5 92.2
Epoch: [121][281/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 64.1	Acc@5 93.8
Epoch: [121][291/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 68.8	Acc@5 92.2
Epoch: [121][301/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 75.0	Acc@5 95.3
Epoch: [121][311/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 60.9	Acc@5 90.6
Epoch: [121][321/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 65.6	Acc@5 92.2
Epoch: [121][331/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 76.6	Acc@5 98.4
Epoch: [121][341/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 93.8
Epoch: [121][351/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 62.5	Acc@5 95.3
Epoch: [121][361/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 59.4	Acc@5 92.2
Epoch: [121][371/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 92.2
Epoch: [121][381/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 68.8	Acc@5 89.1
Epoch: [121][391/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 59.4	Acc@5 90.6
Epoch: [121][401/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 67.2	Acc@5 90.6
Epoch: [121][411/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 57.8	Acc@5 92.2
Epoch: [121][421/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 67.2	Acc@5 95.3
Epoch: [121][431/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 70.3	Acc@5 90.6
Epoch: [121][441/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 65.6	Acc@5 96.9
Epoch: [121][451/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 67.2	Acc@5 93.8
Epoch: [121][461/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 67.2	Acc@5 90.6
Epoch: [121][471/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 73.4	Acc@5 93.8
Epoch: [121][481/704]	Time 0.121	Data 0.001	Loss 3.72	Acc@1 76.6	Acc@5 96.9
Epoch: [121][491/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 70.3	Acc@5 98.4
Epoch: [121][501/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 57.8	Acc@5 89.1
Epoch: [121][511/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 62.5	Acc@5 92.2
Epoch: [121][521/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 65.6	Acc@5 95.3
Epoch: [121][531/704]	Time 0.121	Data 0.001	Loss 6.21	Acc@1 64.1	Acc@5 89.1
Epoch: [121][541/704]	Time 0.121	Data 0.001	Loss 6.27	Acc@1 64.1	Acc@5 98.4
Epoch: [121][551/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 93.8
Epoch: [121][561/704]	Time 0.121	Data 0.001	Loss 4.07	Acc@1 73.4	Acc@5 95.3
Epoch: [121][571/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 71.9	Acc@5 93.8
Epoch: [121][581/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 65.6	Acc@5 90.6
Epoch: [121][591/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 65.6	Acc@5 92.2
Epoch: [121][601/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 57.8	Acc@5 98.4
Epoch: [121][611/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 62.5	Acc@5 93.8
Epoch: [121][621/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 73.4	Acc@5 87.5
Epoch: [121][631/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 64.1	Acc@5 92.2
Epoch: [121][641/704]	Time 0.121	Data 0.001	Loss 6.12	Acc@1 60.9	Acc@5 92.2
Epoch: [121][651/704]	Time 0.121	Data 0.001	Loss 4.22	Acc@1 78.1	Acc@5 95.3
Epoch: [121][661/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 75.0	Acc@5 98.4
Epoch: [121][671/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 65.6	Acc@5 90.6
Epoch: [121][681/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 65.6	Acc@5 93.8
Epoch: [121][691/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 67.2	Acc@5 93.8
Epoch: [121][701/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 62.5	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 9.0726	Acc@1 42.1875	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.8130	Acc@1 65.6250	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.5200	Acc@1 51.5625	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.6153	Acc@1 53.1250	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.8880	Acc@1 60.9375	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.3093	Acc@1 53.1250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.6835	Acc@1 62.5000	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.1500	Acc@1 48.4375	Acc@5 81.2500
 * prec@1 49.100 prec@5 79.480
 * prec@1 52.080 prec@5 81.760
 * prec@1 56.840 prec@5 85.360
 * prec@1 56.920 prec@5 85.420
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_121.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_121.pth.tar'
Epoch: [122][1/704]	Time 0.300	Data 0.132	Loss 4.78	Acc@1 67.2	Acc@5 98.4
Epoch: [122][11/704]	Time 0.140	Data 0.012	Loss 7.04	Acc@1 56.2	Acc@5 85.9
Epoch: [122][21/704]	Time 0.131	Data 0.007	Loss 4.32	Acc@1 70.3	Acc@5 93.8
Epoch: [122][31/704]	Time 0.127	Data 0.005	Loss 3.89	Acc@1 73.4	Acc@5 96.9
Epoch: [122][41/704]	Time 0.125	Data 0.004	Loss 4.18	Acc@1 81.2	Acc@5 96.9
Epoch: [122][51/704]	Time 0.124	Data 0.003	Loss 4.91	Acc@1 70.3	Acc@5 95.3
Epoch: [122][61/704]	Time 0.124	Data 0.003	Loss 5.50	Acc@1 64.1	Acc@5 90.6
Epoch: [122][71/704]	Time 0.123	Data 0.002	Loss 7.25	Acc@1 56.2	Acc@5 85.9
Epoch: [122][81/704]	Time 0.123	Data 0.002	Loss 3.71	Acc@1 78.1	Acc@5 95.3
Epoch: [122][91/704]	Time 0.123	Data 0.002	Loss 4.89	Acc@1 76.6	Acc@5 93.8
Epoch: [122][101/704]	Time 0.122	Data 0.002	Loss 5.81	Acc@1 67.2	Acc@5 93.8
Epoch: [122][111/704]	Time 0.122	Data 0.002	Loss 5.35	Acc@1 70.3	Acc@5 90.6
Epoch: [122][121/704]	Time 0.122	Data 0.002	Loss 5.20	Acc@1 68.8	Acc@5 96.9
Epoch: [122][131/704]	Time 0.122	Data 0.001	Loss 5.48	Acc@1 60.9	Acc@5 93.8
Epoch: [122][141/704]	Time 0.122	Data 0.001	Loss 5.97	Acc@1 71.9	Acc@5 89.1
Epoch: [122][151/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 65.6	Acc@5 93.8
Epoch: [122][161/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 59.4	Acc@5 95.3
Epoch: [122][171/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 64.1	Acc@5 92.2
Epoch: [122][181/704]	Time 0.121	Data 0.001	Loss 3.78	Acc@1 76.6	Acc@5 96.9
Epoch: [122][191/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 68.8	Acc@5 87.5
Epoch: [122][201/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 78.1	Acc@5 98.4
Epoch: [122][211/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 67.2	Acc@5 93.8
Epoch: [122][221/704]	Time 0.121	Data 0.001	Loss 6.49	Acc@1 62.5	Acc@5 93.8
Epoch: [122][231/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 60.9	Acc@5 89.1
Epoch: [122][241/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 68.8	Acc@5 92.2
Epoch: [122][251/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 82.8	Acc@5 96.9
Epoch: [122][261/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 71.9	Acc@5 98.4
Epoch: [122][271/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 57.8	Acc@5 92.2
Epoch: [122][281/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 68.8	Acc@5 92.2
Epoch: [122][291/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 64.1	Acc@5 95.3
Epoch: [122][301/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 75.0	Acc@5 95.3
Epoch: [122][311/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 67.2	Acc@5 93.8
Epoch: [122][321/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 67.2	Acc@5 92.2
Epoch: [122][331/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 71.9	Acc@5 92.2
Epoch: [122][341/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 75.0	Acc@5 95.3
Epoch: [122][351/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 65.6	Acc@5 93.8
Epoch: [122][361/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 64.1	Acc@5 95.3
Epoch: [122][371/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 71.9	Acc@5 92.2
Epoch: [122][381/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 60.9	Acc@5 95.3
Epoch: [122][391/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 75.0	Acc@5 96.9
Epoch: [122][401/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 73.4	Acc@5 90.6
Epoch: [122][411/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 79.7	Acc@5 92.2
Epoch: [122][421/704]	Time 0.121	Data 0.001	Loss 6.40	Acc@1 57.8	Acc@5 96.9
Epoch: [122][431/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 71.9	Acc@5 93.8
Epoch: [122][441/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 79.7	Acc@5 98.4
Epoch: [122][451/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 93.8
Epoch: [122][461/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 73.4	Acc@5 95.3
Epoch: [122][471/704]	Time 0.120	Data 0.001	Loss 4.66	Acc@1 67.2	Acc@5 89.1
Epoch: [122][481/704]	Time 0.120	Data 0.001	Loss 4.02	Acc@1 78.1	Acc@5 93.8
Epoch: [122][491/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 56.2	Acc@5 90.6
Epoch: [122][501/704]	Time 0.120	Data 0.001	Loss 5.30	Acc@1 64.1	Acc@5 90.6
Epoch: [122][511/704]	Time 0.120	Data 0.001	Loss 4.24	Acc@1 79.7	Acc@5 93.8
Epoch: [122][521/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 76.6	Acc@5 93.8
Epoch: [122][531/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 67.2	Acc@5 89.1
Epoch: [122][541/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 90.6
Epoch: [122][551/704]	Time 0.120	Data 0.001	Loss 4.02	Acc@1 75.0	Acc@5 93.8
Epoch: [122][561/704]	Time 0.120	Data 0.001	Loss 5.05	Acc@1 75.0	Acc@5 92.2
Epoch: [122][571/704]	Time 0.120	Data 0.001	Loss 5.72	Acc@1 67.2	Acc@5 89.1
Epoch: [122][581/704]	Time 0.120	Data 0.001	Loss 4.48	Acc@1 76.6	Acc@5 93.8
Epoch: [122][591/704]	Time 0.120	Data 0.001	Loss 4.44	Acc@1 70.3	Acc@5 93.8
Epoch: [122][601/704]	Time 0.120	Data 0.001	Loss 5.49	Acc@1 70.3	Acc@5 90.6
Epoch: [122][611/704]	Time 0.120	Data 0.001	Loss 4.68	Acc@1 65.6	Acc@5 95.3
Epoch: [122][621/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 68.8	Acc@5 90.6
Epoch: [122][631/704]	Time 0.120	Data 0.001	Loss 3.66	Acc@1 79.7	Acc@5 96.9
Epoch: [122][641/704]	Time 0.120	Data 0.001	Loss 4.67	Acc@1 64.1	Acc@5 92.2
Epoch: [122][651/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 71.9	Acc@5 95.3
Epoch: [122][661/704]	Time 0.120	Data 0.001	Loss 5.98	Acc@1 67.2	Acc@5 89.1
Epoch: [122][671/704]	Time 0.120	Data 0.001	Loss 5.06	Acc@1 65.6	Acc@5 95.3
Epoch: [122][681/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 59.4	Acc@5 90.6
Epoch: [122][691/704]	Time 0.120	Data 0.001	Loss 5.51	Acc@1 65.6	Acc@5 89.1
Epoch: [122][701/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 64.1	Acc@5 89.1
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.3469	Acc@1 60.9375	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.3470	Acc@1 45.3125	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2018	Acc@1 54.6875	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.9069	Acc@1 51.5625	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.8305	Acc@1 67.1875	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.6134	Acc@1 51.5625	Acc@5 79.6875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.7210	Acc@1 59.3750	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2381	Acc@1 59.3750	Acc@5 92.1875
 * prec@1 48.400 prec@5 79.580
 * prec@1 51.620 prec@5 81.880
 * prec@1 55.840 prec@5 84.600
 * prec@1 56.600 prec@5 84.860
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_122.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_122.pth.tar'
Epoch: [123][1/704]	Time 0.330	Data 0.164	Loss 4.32	Acc@1 76.6	Acc@5 93.8
Epoch: [123][11/704]	Time 0.139	Data 0.015	Loss 5.62	Acc@1 62.5	Acc@5 87.5
Epoch: [123][21/704]	Time 0.130	Data 0.008	Loss 3.88	Acc@1 82.8	Acc@5 96.9
Epoch: [123][31/704]	Time 0.127	Data 0.006	Loss 6.06	Acc@1 56.2	Acc@5 93.8
Epoch: [123][41/704]	Time 0.125	Data 0.004	Loss 4.62	Acc@1 75.0	Acc@5 93.8
Epoch: [123][51/704]	Time 0.124	Data 0.004	Loss 4.89	Acc@1 70.3	Acc@5 89.1
Epoch: [123][61/704]	Time 0.123	Data 0.003	Loss 5.25	Acc@1 70.3	Acc@5 92.2
Epoch: [123][71/704]	Time 0.123	Data 0.003	Loss 4.51	Acc@1 76.6	Acc@5 92.2
Epoch: [123][81/704]	Time 0.123	Data 0.002	Loss 5.41	Acc@1 64.1	Acc@5 90.6
Epoch: [123][91/704]	Time 0.122	Data 0.002	Loss 6.41	Acc@1 59.4	Acc@5 89.1
Epoch: [123][101/704]	Time 0.122	Data 0.002	Loss 4.55	Acc@1 70.3	Acc@5 92.2
Epoch: [123][111/704]	Time 0.122	Data 0.002	Loss 4.30	Acc@1 79.7	Acc@5 95.3
Epoch: [123][121/704]	Time 0.122	Data 0.002	Loss 4.09	Acc@1 73.4	Acc@5 93.8
Epoch: [123][131/704]	Time 0.122	Data 0.002	Loss 5.47	Acc@1 64.1	Acc@5 90.6
Epoch: [123][141/704]	Time 0.122	Data 0.002	Loss 4.36	Acc@1 71.9	Acc@5 96.9
Epoch: [123][151/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 67.2	Acc@5 90.6
Epoch: [123][161/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 70.3	Acc@5 96.9
Epoch: [123][171/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 70.3	Acc@5 93.8
Epoch: [123][181/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 71.9	Acc@5 95.3
Epoch: [123][191/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 70.3	Acc@5 92.2
Epoch: [123][201/704]	Time 0.121	Data 0.001	Loss 4.21	Acc@1 84.4	Acc@5 96.9
Epoch: [123][211/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 70.3	Acc@5 92.2
Epoch: [123][221/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 71.9	Acc@5 100.0
Epoch: [123][231/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 75.0	Acc@5 93.8
Epoch: [123][241/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 67.2	Acc@5 93.8
Epoch: [123][251/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 67.2	Acc@5 93.8
Epoch: [123][261/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 70.3	Acc@5 93.8
Epoch: [123][271/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 75.0	Acc@5 95.3
Epoch: [123][281/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 65.6	Acc@5 89.1
Epoch: [123][291/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 68.8	Acc@5 98.4
Epoch: [123][301/704]	Time 0.121	Data 0.001	Loss 6.58	Acc@1 59.4	Acc@5 79.7
Epoch: [123][311/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 64.1	Acc@5 87.5
Epoch: [123][321/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 68.8	Acc@5 92.2
Epoch: [123][331/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 60.9	Acc@5 85.9
Epoch: [123][341/704]	Time 0.121	Data 0.001	Loss 3.90	Acc@1 71.9	Acc@5 93.8
Epoch: [123][351/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 60.9	Acc@5 95.3
Epoch: [123][361/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 75.0	Acc@5 87.5
Epoch: [123][371/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 68.8	Acc@5 93.8
Epoch: [123][381/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 67.2	Acc@5 92.2
Epoch: [123][391/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 68.8	Acc@5 92.2
Epoch: [123][401/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 75.0	Acc@5 98.4
Epoch: [123][411/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 71.9	Acc@5 92.2
Epoch: [123][421/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 68.8	Acc@5 90.6
Epoch: [123][431/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 78.1	Acc@5 95.3
Epoch: [123][441/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 93.8
Epoch: [123][451/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 54.7	Acc@5 92.2
Epoch: [123][461/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 68.8	Acc@5 96.9
Epoch: [123][471/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 62.5	Acc@5 93.8
Epoch: [123][481/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 64.1	Acc@5 85.9
Epoch: [123][491/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 67.2	Acc@5 96.9
Epoch: [123][501/704]	Time 0.121	Data 0.001	Loss 6.99	Acc@1 48.4	Acc@5 90.6
Epoch: [123][511/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 65.6	Acc@5 93.8
Epoch: [123][521/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 64.1	Acc@5 92.2
Epoch: [123][531/704]	Time 0.120	Data 0.001	Loss 5.31	Acc@1 60.9	Acc@5 96.9
Epoch: [123][541/704]	Time 0.120	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 95.3
Epoch: [123][551/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 68.8	Acc@5 100.0
Epoch: [123][561/704]	Time 0.120	Data 0.001	Loss 4.14	Acc@1 78.1	Acc@5 93.8
Epoch: [123][571/704]	Time 0.120	Data 0.001	Loss 5.09	Acc@1 73.4	Acc@5 90.6
Epoch: [123][581/704]	Time 0.120	Data 0.001	Loss 4.30	Acc@1 70.3	Acc@5 92.2
Epoch: [123][591/704]	Time 0.120	Data 0.001	Loss 6.34	Acc@1 65.6	Acc@5 89.1
Epoch: [123][601/704]	Time 0.120	Data 0.001	Loss 4.03	Acc@1 76.6	Acc@5 93.8
Epoch: [123][611/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 65.6	Acc@5 90.6
Epoch: [123][621/704]	Time 0.120	Data 0.001	Loss 4.87	Acc@1 62.5	Acc@5 93.8
Epoch: [123][631/704]	Time 0.120	Data 0.001	Loss 4.25	Acc@1 73.4	Acc@5 95.3
Epoch: [123][641/704]	Time 0.120	Data 0.001	Loss 5.22	Acc@1 71.9	Acc@5 89.1
Epoch: [123][651/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 67.2	Acc@5 92.2
Epoch: [123][661/704]	Time 0.120	Data 0.001	Loss 5.90	Acc@1 73.4	Acc@5 89.1
Epoch: [123][671/704]	Time 0.120	Data 0.001	Loss 3.66	Acc@1 85.9	Acc@5 96.9
Epoch: [123][681/704]	Time 0.120	Data 0.001	Loss 4.13	Acc@1 75.0	Acc@5 90.6
Epoch: [123][691/704]	Time 0.120	Data 0.001	Loss 5.70	Acc@1 64.1	Acc@5 92.2
Epoch: [123][701/704]	Time 0.120	Data 0.001	Loss 5.45	Acc@1 65.6	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.4119	Acc@1 62.5000	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.3611	Acc@1 60.9375	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.0932	Acc@1 62.5000	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.6427	Acc@1 64.0625	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.0862	Acc@1 68.7500	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1448	Acc@1 65.6250	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.8430	Acc@1 51.5625	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1004	Acc@1 60.9375	Acc@5 90.6250
 * prec@1 48.060 prec@5 78.440
 * prec@1 52.360 prec@5 82.260
 * prec@1 56.740 prec@5 85.200
 * prec@1 58.460 prec@5 85.580
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_123.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_123.pth.tar'
Epoch: [124][1/704]	Time 0.302	Data 0.134	Loss 3.41	Acc@1 81.2	Acc@5 100.0
Epoch: [124][11/704]	Time 0.137	Data 0.012	Loss 4.78	Acc@1 68.8	Acc@5 95.3
Epoch: [124][21/704]	Time 0.129	Data 0.007	Loss 4.11	Acc@1 78.1	Acc@5 93.8
Epoch: [124][31/704]	Time 0.126	Data 0.005	Loss 4.37	Acc@1 76.6	Acc@5 93.8
Epoch: [124][41/704]	Time 0.125	Data 0.004	Loss 4.74	Acc@1 75.0	Acc@5 89.1
Epoch: [124][51/704]	Time 0.124	Data 0.003	Loss 4.68	Acc@1 68.8	Acc@5 95.3
Epoch: [124][61/704]	Time 0.123	Data 0.003	Loss 3.51	Acc@1 70.3	Acc@5 96.9
Epoch: [124][71/704]	Time 0.123	Data 0.002	Loss 5.28	Acc@1 67.2	Acc@5 96.9
Epoch: [124][81/704]	Time 0.123	Data 0.002	Loss 4.37	Acc@1 73.4	Acc@5 96.9
Epoch: [124][91/704]	Time 0.123	Data 0.002	Loss 4.05	Acc@1 78.1	Acc@5 100.0
Epoch: [124][101/704]	Time 0.122	Data 0.002	Loss 4.72	Acc@1 67.2	Acc@5 93.8
Epoch: [124][111/704]	Time 0.122	Data 0.002	Loss 3.79	Acc@1 67.2	Acc@5 98.4
Epoch: [124][121/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 65.6	Acc@5 95.3
Epoch: [124][131/704]	Time 0.122	Data 0.001	Loss 4.72	Acc@1 76.6	Acc@5 92.2
Epoch: [124][141/704]	Time 0.122	Data 0.001	Loss 6.49	Acc@1 57.8	Acc@5 89.1
Epoch: [124][151/704]	Time 0.122	Data 0.001	Loss 4.97	Acc@1 65.6	Acc@5 89.1
Epoch: [124][161/704]	Time 0.122	Data 0.001	Loss 5.31	Acc@1 70.3	Acc@5 95.3
Epoch: [124][171/704]	Time 0.122	Data 0.001	Loss 6.54	Acc@1 57.8	Acc@5 92.2
Epoch: [124][181/704]	Time 0.122	Data 0.001	Loss 5.77	Acc@1 62.5	Acc@5 92.2
Epoch: [124][191/704]	Time 0.122	Data 0.001	Loss 5.19	Acc@1 67.2	Acc@5 89.1
Epoch: [124][201/704]	Time 0.122	Data 0.001	Loss 7.08	Acc@1 60.9	Acc@5 90.6
Epoch: [124][211/704]	Time 0.122	Data 0.001	Loss 4.79	Acc@1 64.1	Acc@5 95.3
Epoch: [124][221/704]	Time 0.122	Data 0.001	Loss 3.27	Acc@1 76.6	Acc@5 98.4
Epoch: [124][231/704]	Time 0.122	Data 0.001	Loss 3.10	Acc@1 81.2	Acc@5 96.9
Epoch: [124][241/704]	Time 0.122	Data 0.001	Loss 5.55	Acc@1 65.6	Acc@5 95.3
Epoch: [124][251/704]	Time 0.122	Data 0.001	Loss 5.11	Acc@1 67.2	Acc@5 89.1
Epoch: [124][261/704]	Time 0.122	Data 0.001	Loss 4.71	Acc@1 78.1	Acc@5 96.9
Epoch: [124][271/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 75.0	Acc@5 96.9
Epoch: [124][281/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 65.6	Acc@5 95.3
Epoch: [124][291/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 71.9	Acc@5 92.2
Epoch: [124][301/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 75.0	Acc@5 95.3
Epoch: [124][311/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 73.4	Acc@5 93.8
Epoch: [124][321/704]	Time 0.121	Data 0.001	Loss 6.73	Acc@1 59.4	Acc@5 90.6
Epoch: [124][331/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 76.6	Acc@5 96.9
Epoch: [124][341/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 67.2	Acc@5 89.1
Epoch: [124][351/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 70.3	Acc@5 92.2
Epoch: [124][361/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 70.3	Acc@5 87.5
Epoch: [124][371/704]	Time 0.121	Data 0.001	Loss 6.49	Acc@1 59.4	Acc@5 82.8
Epoch: [124][381/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 70.3	Acc@5 90.6
Epoch: [124][391/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 62.5	Acc@5 89.1
Epoch: [124][401/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 67.2	Acc@5 87.5
Epoch: [124][411/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 64.1	Acc@5 96.9
Epoch: [124][421/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 65.6	Acc@5 93.8
Epoch: [124][431/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 76.6	Acc@5 89.1
Epoch: [124][441/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 73.4	Acc@5 96.9
Epoch: [124][451/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 60.9	Acc@5 98.4
Epoch: [124][461/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 64.1	Acc@5 90.6
Epoch: [124][471/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 68.8	Acc@5 96.9
Epoch: [124][481/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 60.9	Acc@5 92.2
Epoch: [124][491/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 73.4	Acc@5 92.2
Epoch: [124][501/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 59.4	Acc@5 93.8
Epoch: [124][511/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 78.1	Acc@5 92.2
Epoch: [124][521/704]	Time 0.121	Data 0.001	Loss 6.24	Acc@1 64.1	Acc@5 90.6
Epoch: [124][531/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 65.6	Acc@5 93.8
Epoch: [124][541/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 60.9	Acc@5 93.8
Epoch: [124][551/704]	Time 0.121	Data 0.001	Loss 3.78	Acc@1 70.3	Acc@5 89.1
Epoch: [124][561/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 71.9	Acc@5 93.8
Epoch: [124][571/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 96.9
Epoch: [124][581/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 75.0	Acc@5 96.9
Epoch: [124][591/704]	Time 0.121	Data 0.001	Loss 6.59	Acc@1 53.1	Acc@5 87.5
Epoch: [124][601/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 65.6	Acc@5 95.3
Epoch: [124][611/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 89.1
Epoch: [124][621/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 62.5	Acc@5 89.1
Epoch: [124][631/704]	Time 0.121	Data 0.001	Loss 6.65	Acc@1 59.4	Acc@5 87.5
Epoch: [124][641/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 62.5	Acc@5 96.9
Epoch: [124][651/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 75.0	Acc@5 93.8
Epoch: [124][661/704]	Time 0.121	Data 0.001	Loss 7.13	Acc@1 57.8	Acc@5 85.9
Epoch: [124][671/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 70.3	Acc@5 96.9
Epoch: [124][681/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 71.9	Acc@5 92.2
Epoch: [124][691/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 68.8	Acc@5 90.6
Epoch: [124][701/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 60.9	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.6085	Acc@1 59.3750	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.9093	Acc@1 56.2500	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.1602	Acc@1 51.5625	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.1922	Acc@1 71.8750	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.5293	Acc@1 65.6250	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.9515	Acc@1 50.0000	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7704	Acc@1 56.2500	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.8157	Acc@1 56.2500	Acc@5 79.6875
 * prec@1 48.040 prec@5 78.780
 * prec@1 53.580 prec@5 83.420
 * prec@1 57.380 prec@5 85.600
 * prec@1 57.840 prec@5 86.720
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_124.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_124.pth.tar'
Epoch: [125][1/704]	Time 0.305	Data 0.137	Loss 3.38	Acc@1 73.4	Acc@5 96.9
Epoch: [125][11/704]	Time 0.137	Data 0.013	Loss 5.47	Acc@1 73.4	Acc@5 92.2
Epoch: [125][21/704]	Time 0.129	Data 0.007	Loss 4.63	Acc@1 70.3	Acc@5 93.8
Epoch: [125][31/704]	Time 0.126	Data 0.005	Loss 4.18	Acc@1 73.4	Acc@5 93.8
Epoch: [125][41/704]	Time 0.125	Data 0.004	Loss 4.75	Acc@1 78.1	Acc@5 92.2
Epoch: [125][51/704]	Time 0.124	Data 0.003	Loss 5.61	Acc@1 67.2	Acc@5 87.5
Epoch: [125][61/704]	Time 0.124	Data 0.003	Loss 4.77	Acc@1 65.6	Acc@5 92.2
Epoch: [125][71/704]	Time 0.124	Data 0.002	Loss 3.74	Acc@1 71.9	Acc@5 98.4
Epoch: [125][81/704]	Time 0.123	Data 0.002	Loss 5.35	Acc@1 59.4	Acc@5 93.8
Epoch: [125][91/704]	Time 0.123	Data 0.002	Loss 5.21	Acc@1 68.8	Acc@5 92.2
Epoch: [125][101/704]	Time 0.123	Data 0.002	Loss 4.78	Acc@1 75.0	Acc@5 89.1
Epoch: [125][111/704]	Time 0.122	Data 0.002	Loss 3.86	Acc@1 85.9	Acc@5 96.9
Epoch: [125][121/704]	Time 0.122	Data 0.001	Loss 4.81	Acc@1 73.4	Acc@5 95.3
Epoch: [125][131/704]	Time 0.122	Data 0.001	Loss 4.62	Acc@1 71.9	Acc@5 92.2
Epoch: [125][141/704]	Time 0.122	Data 0.001	Loss 4.65	Acc@1 73.4	Acc@5 93.8
Epoch: [125][151/704]	Time 0.122	Data 0.001	Loss 4.60	Acc@1 71.9	Acc@5 96.9
Epoch: [125][161/704]	Time 0.122	Data 0.001	Loss 6.66	Acc@1 62.5	Acc@5 87.5
Epoch: [125][171/704]	Time 0.122	Data 0.001	Loss 3.62	Acc@1 81.2	Acc@5 93.8
Epoch: [125][181/704]	Time 0.122	Data 0.001	Loss 4.78	Acc@1 70.3	Acc@5 95.3
Epoch: [125][191/704]	Time 0.122	Data 0.001	Loss 4.11	Acc@1 75.0	Acc@5 96.9
Epoch: [125][201/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 67.2	Acc@5 95.3
Epoch: [125][211/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 60.9	Acc@5 95.3
Epoch: [125][221/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 56.2	Acc@5 92.2
Epoch: [125][231/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 78.1	Acc@5 93.8
Epoch: [125][241/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 71.9	Acc@5 95.3
Epoch: [125][251/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 79.7	Acc@5 95.3
Epoch: [125][261/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 75.0	Acc@5 90.6
Epoch: [125][271/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 57.8	Acc@5 92.2
Epoch: [125][281/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 71.9	Acc@5 95.3
Epoch: [125][291/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 73.4	Acc@5 98.4
Epoch: [125][301/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 75.0	Acc@5 95.3
Epoch: [125][311/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 73.4	Acc@5 92.2
Epoch: [125][321/704]	Time 0.121	Data 0.001	Loss 3.83	Acc@1 75.0	Acc@5 92.2
Epoch: [125][331/704]	Time 0.121	Data 0.001	Loss 4.22	Acc@1 71.9	Acc@5 95.3
Epoch: [125][341/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 64.1	Acc@5 90.6
Epoch: [125][351/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 70.3	Acc@5 90.6
Epoch: [125][361/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 92.2
Epoch: [125][371/704]	Time 0.121	Data 0.001	Loss 4.25	Acc@1 73.4	Acc@5 96.9
Epoch: [125][381/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 70.3	Acc@5 89.1
Epoch: [125][391/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 70.3	Acc@5 95.3
Epoch: [125][401/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 75.0	Acc@5 93.8
Epoch: [125][411/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 75.0	Acc@5 92.2
Epoch: [125][421/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 70.3	Acc@5 93.8
Epoch: [125][431/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 70.3	Acc@5 93.8
Epoch: [125][441/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 73.4	Acc@5 95.3
Epoch: [125][451/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 65.6	Acc@5 95.3
Epoch: [125][461/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 71.9	Acc@5 93.8
Epoch: [125][471/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 53.1	Acc@5 89.1
Epoch: [125][481/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 65.6	Acc@5 98.4
Epoch: [125][491/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 75.0	Acc@5 93.8
Epoch: [125][501/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 65.6	Acc@5 93.8
Epoch: [125][511/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 95.3
Epoch: [125][521/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 73.4	Acc@5 92.2
Epoch: [125][531/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 96.9
Epoch: [125][541/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 78.1	Acc@5 89.1
Epoch: [125][551/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 70.3	Acc@5 89.1
Epoch: [125][561/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 59.4	Acc@5 93.8
Epoch: [125][571/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 73.4	Acc@5 93.8
Epoch: [125][581/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 70.3	Acc@5 95.3
Epoch: [125][591/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 70.3	Acc@5 89.1
Epoch: [125][601/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 70.3	Acc@5 95.3
Epoch: [125][611/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 71.9	Acc@5 89.1
Epoch: [125][621/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 59.4	Acc@5 98.4
Epoch: [125][631/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 67.2	Acc@5 89.1
Epoch: [125][641/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 57.8	Acc@5 89.1
Epoch: [125][651/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 68.8	Acc@5 93.8
Epoch: [125][661/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 76.6	Acc@5 93.8
Epoch: [125][671/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 73.4	Acc@5 93.8
Epoch: [125][681/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 65.6	Acc@5 93.8
Epoch: [125][691/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 68.8	Acc@5 93.8
Epoch: [125][701/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 73.4	Acc@5 95.3
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.9441	Acc@1 70.3125	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.4991	Acc@1 57.8125	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.5652	Acc@1 45.3125	Acc@5 81.2500
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 6.0463	Acc@1 60.9375	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4685	Acc@1 60.9375	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.1376	Acc@1 68.7500	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.9384	Acc@1 70.3125	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.1796	Acc@1 59.3750	Acc@5 85.9375
 * prec@1 46.120 prec@5 77.560
 * prec@1 52.560 prec@5 82.240
 * prec@1 54.940 prec@5 84.260
 * prec@1 57.160 prec@5 84.820
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_125.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_125.pth.tar'
Epoch: [126][1/704]	Time 0.332	Data 0.166	Loss 5.66	Acc@1 71.9	Acc@5 93.8
Epoch: [126][11/704]	Time 0.140	Data 0.015	Loss 6.37	Acc@1 65.6	Acc@5 87.5
Epoch: [126][21/704]	Time 0.131	Data 0.008	Loss 5.42	Acc@1 65.6	Acc@5 90.6
Epoch: [126][31/704]	Time 0.127	Data 0.006	Loss 4.79	Acc@1 73.4	Acc@5 95.3
Epoch: [126][41/704]	Time 0.126	Data 0.004	Loss 5.06	Acc@1 68.8	Acc@5 92.2
Epoch: [126][51/704]	Time 0.125	Data 0.004	Loss 4.31	Acc@1 75.0	Acc@5 92.2
Epoch: [126][61/704]	Time 0.124	Data 0.003	Loss 5.48	Acc@1 65.6	Acc@5 95.3
Epoch: [126][71/704]	Time 0.124	Data 0.003	Loss 4.64	Acc@1 64.1	Acc@5 95.3
Epoch: [126][81/704]	Time 0.123	Data 0.002	Loss 4.47	Acc@1 70.3	Acc@5 95.3
Epoch: [126][91/704]	Time 0.123	Data 0.002	Loss 4.76	Acc@1 70.3	Acc@5 95.3
Epoch: [126][101/704]	Time 0.123	Data 0.002	Loss 6.01	Acc@1 62.5	Acc@5 89.1
Epoch: [126][111/704]	Time 0.123	Data 0.002	Loss 4.35	Acc@1 73.4	Acc@5 95.3
Epoch: [126][121/704]	Time 0.122	Data 0.002	Loss 5.34	Acc@1 62.5	Acc@5 95.3
Epoch: [126][131/704]	Time 0.122	Data 0.002	Loss 4.74	Acc@1 68.8	Acc@5 92.2
Epoch: [126][141/704]	Time 0.122	Data 0.002	Loss 4.71	Acc@1 65.6	Acc@5 93.8
Epoch: [126][151/704]	Time 0.122	Data 0.001	Loss 4.85	Acc@1 78.1	Acc@5 92.2
Epoch: [126][161/704]	Time 0.122	Data 0.001	Loss 4.25	Acc@1 78.1	Acc@5 92.2
Epoch: [126][171/704]	Time 0.122	Data 0.001	Loss 5.33	Acc@1 65.6	Acc@5 87.5
Epoch: [126][181/704]	Time 0.122	Data 0.001	Loss 3.96	Acc@1 75.0	Acc@5 95.3
Epoch: [126][191/704]	Time 0.122	Data 0.001	Loss 4.36	Acc@1 76.6	Acc@5 95.3
Epoch: [126][201/704]	Time 0.122	Data 0.001	Loss 4.89	Acc@1 75.0	Acc@5 95.3
Epoch: [126][211/704]	Time 0.122	Data 0.001	Loss 4.67	Acc@1 65.6	Acc@5 95.3
Epoch: [126][221/704]	Time 0.122	Data 0.001	Loss 5.48	Acc@1 64.1	Acc@5 87.5
Epoch: [126][231/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 70.3	Acc@5 92.2
Epoch: [126][241/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 64.1	Acc@5 89.1
Epoch: [126][251/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 60.9	Acc@5 92.2
Epoch: [126][261/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 70.3	Acc@5 92.2
Epoch: [126][271/704]	Time 0.121	Data 0.001	Loss 3.78	Acc@1 81.2	Acc@5 93.8
Epoch: [126][281/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 73.4	Acc@5 93.8
Epoch: [126][291/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 65.6	Acc@5 90.6
Epoch: [126][301/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 67.2	Acc@5 90.6
Epoch: [126][311/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 92.2
Epoch: [126][321/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 64.1	Acc@5 87.5
Epoch: [126][331/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 71.9	Acc@5 90.6
Epoch: [126][341/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 71.9	Acc@5 95.3
Epoch: [126][351/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 64.1	Acc@5 95.3
Epoch: [126][361/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 67.2	Acc@5 85.9
Epoch: [126][371/704]	Time 0.121	Data 0.001	Loss 6.49	Acc@1 64.1	Acc@5 87.5
Epoch: [126][381/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 68.8	Acc@5 95.3
Epoch: [126][391/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 62.5	Acc@5 92.2
Epoch: [126][401/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 57.8	Acc@5 96.9
Epoch: [126][411/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 59.4	Acc@5 92.2
Epoch: [126][421/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 73.4	Acc@5 98.4
Epoch: [126][431/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 62.5	Acc@5 95.3
Epoch: [126][441/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 54.7	Acc@5 89.1
Epoch: [126][451/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 71.9	Acc@5 93.8
Epoch: [126][461/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 75.0	Acc@5 95.3
Epoch: [126][471/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 60.9	Acc@5 87.5
Epoch: [126][481/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 73.4	Acc@5 92.2
Epoch: [126][491/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 71.9	Acc@5 90.6
Epoch: [126][501/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 92.2
Epoch: [126][511/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 56.2	Acc@5 90.6
Epoch: [126][521/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 68.8	Acc@5 96.9
Epoch: [126][531/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 65.6	Acc@5 95.3
Epoch: [126][541/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 68.8	Acc@5 89.1
Epoch: [126][551/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 64.1	Acc@5 90.6
Epoch: [126][561/704]	Time 0.121	Data 0.001	Loss 6.47	Acc@1 57.8	Acc@5 84.4
Epoch: [126][571/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 70.3	Acc@5 98.4
Epoch: [126][581/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 70.3	Acc@5 96.9
Epoch: [126][591/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 64.1	Acc@5 87.5
Epoch: [126][601/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 57.8	Acc@5 90.6
Epoch: [126][611/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 78.1	Acc@5 90.6
Epoch: [126][621/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 64.1	Acc@5 92.2
Epoch: [126][631/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 62.5	Acc@5 92.2
Epoch: [126][641/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 70.3	Acc@5 87.5
Epoch: [126][651/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 75.0	Acc@5 96.9
Epoch: [126][661/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 68.8	Acc@5 79.7
Epoch: [126][671/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 75.0	Acc@5 93.8
Epoch: [126][681/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 71.9	Acc@5 92.2
Epoch: [126][691/704]	Time 0.121	Data 0.001	Loss 3.56	Acc@1 79.7	Acc@5 96.9
Epoch: [126][701/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 62.5	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.7451	Acc@1 71.8750	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1892	Acc@1 54.6875	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0416	Acc@1 48.4375	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.4940	Acc@1 57.8125	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2536	Acc@1 60.9375	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.8274	Acc@1 54.6875	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6156	Acc@1 53.1250	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.8392	Acc@1 56.2500	Acc@5 85.9375
 * prec@1 49.560 prec@5 79.160
 * prec@1 52.640 prec@5 82.440
 * prec@1 57.320 prec@5 85.860
 * prec@1 58.860 prec@5 86.940
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_126.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_126.pth.tar'
Epoch: [127][1/704]	Time 0.330	Data 0.163	Loss 3.28	Acc@1 84.4	Acc@5 98.4
Epoch: [127][11/704]	Time 0.139	Data 0.015	Loss 4.56	Acc@1 65.6	Acc@5 92.2
Epoch: [127][21/704]	Time 0.130	Data 0.008	Loss 4.26	Acc@1 71.9	Acc@5 95.3
Epoch: [127][31/704]	Time 0.127	Data 0.006	Loss 5.10	Acc@1 68.8	Acc@5 95.3
Epoch: [127][41/704]	Time 0.125	Data 0.004	Loss 4.65	Acc@1 65.6	Acc@5 92.2
Epoch: [127][51/704]	Time 0.124	Data 0.004	Loss 4.54	Acc@1 78.1	Acc@5 95.3
Epoch: [127][61/704]	Time 0.124	Data 0.003	Loss 4.57	Acc@1 71.9	Acc@5 98.4
Epoch: [127][71/704]	Time 0.123	Data 0.003	Loss 4.03	Acc@1 68.8	Acc@5 98.4
Epoch: [127][81/704]	Time 0.123	Data 0.002	Loss 6.37	Acc@1 59.4	Acc@5 92.2
Epoch: [127][91/704]	Time 0.123	Data 0.002	Loss 3.80	Acc@1 78.1	Acc@5 92.2
Epoch: [127][101/704]	Time 0.122	Data 0.002	Loss 6.26	Acc@1 59.4	Acc@5 92.2
Epoch: [127][111/704]	Time 0.122	Data 0.002	Loss 5.34	Acc@1 67.2	Acc@5 92.2
Epoch: [127][121/704]	Time 0.122	Data 0.002	Loss 4.08	Acc@1 73.4	Acc@5 92.2
Epoch: [127][131/704]	Time 0.122	Data 0.002	Loss 4.70	Acc@1 73.4	Acc@5 92.2
Epoch: [127][141/704]	Time 0.122	Data 0.002	Loss 4.97	Acc@1 67.2	Acc@5 95.3
Epoch: [127][151/704]	Time 0.122	Data 0.001	Loss 5.65	Acc@1 60.9	Acc@5 89.1
Epoch: [127][161/704]	Time 0.122	Data 0.001	Loss 5.65	Acc@1 70.3	Acc@5 89.1
Epoch: [127][171/704]	Time 0.122	Data 0.001	Loss 5.38	Acc@1 59.4	Acc@5 93.8
Epoch: [127][181/704]	Time 0.122	Data 0.001	Loss 6.16	Acc@1 64.1	Acc@5 84.4
Epoch: [127][191/704]	Time 0.122	Data 0.001	Loss 6.59	Acc@1 59.4	Acc@5 89.1
Epoch: [127][201/704]	Time 0.122	Data 0.001	Loss 5.10	Acc@1 68.8	Acc@5 93.8
Epoch: [127][211/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 96.9
Epoch: [127][221/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 60.9	Acc@5 93.8
Epoch: [127][231/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 78.1	Acc@5 95.3
Epoch: [127][241/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 65.6	Acc@5 93.8
Epoch: [127][251/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 79.7	Acc@5 98.4
Epoch: [127][261/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 70.3	Acc@5 95.3
Epoch: [127][271/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 89.1
Epoch: [127][281/704]	Time 0.121	Data 0.001	Loss 4.01	Acc@1 75.0	Acc@5 96.9
Epoch: [127][291/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 60.9	Acc@5 90.6
Epoch: [127][301/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 95.3
Epoch: [127][311/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 68.8	Acc@5 90.6
Epoch: [127][321/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 68.8	Acc@5 95.3
Epoch: [127][331/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 67.2	Acc@5 95.3
Epoch: [127][341/704]	Time 0.121	Data 0.001	Loss 6.35	Acc@1 60.9	Acc@5 92.2
Epoch: [127][351/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 70.3	Acc@5 89.1
Epoch: [127][361/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 76.6	Acc@5 95.3
Epoch: [127][371/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 76.6	Acc@5 93.8
Epoch: [127][381/704]	Time 0.121	Data 0.001	Loss 4.07	Acc@1 78.1	Acc@5 96.9
Epoch: [127][391/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 68.8	Acc@5 95.3
Epoch: [127][401/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 68.8	Acc@5 92.2
Epoch: [127][411/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 65.6	Acc@5 89.1
Epoch: [127][421/704]	Time 0.121	Data 0.001	Loss 3.34	Acc@1 78.1	Acc@5 96.9
Epoch: [127][431/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 62.5	Acc@5 89.1
Epoch: [127][441/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 76.6	Acc@5 98.4
Epoch: [127][451/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 62.5	Acc@5 96.9
Epoch: [127][461/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 62.5	Acc@5 89.1
Epoch: [127][471/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 64.1	Acc@5 89.1
Epoch: [127][481/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 62.5	Acc@5 96.9
Epoch: [127][491/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 60.9	Acc@5 95.3
Epoch: [127][501/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 73.4	Acc@5 93.8
Epoch: [127][511/704]	Time 0.121	Data 0.001	Loss 6.80	Acc@1 60.9	Acc@5 90.6
Epoch: [127][521/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 67.2	Acc@5 93.8
Epoch: [127][531/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 64.1	Acc@5 92.2
Epoch: [127][541/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 68.8	Acc@5 100.0
Epoch: [127][551/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 92.2
Epoch: [127][561/704]	Time 0.121	Data 0.001	Loss 6.61	Acc@1 62.5	Acc@5 87.5
Epoch: [127][571/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 65.6	Acc@5 89.1
Epoch: [127][581/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 68.8	Acc@5 90.6
Epoch: [127][591/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 68.8	Acc@5 95.3
Epoch: [127][601/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 70.3	Acc@5 90.6
Epoch: [127][611/704]	Time 0.121	Data 0.001	Loss 3.88	Acc@1 73.4	Acc@5 98.4
Epoch: [127][621/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 60.9	Acc@5 93.8
Epoch: [127][631/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 70.3	Acc@5 87.5
Epoch: [127][641/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 65.6	Acc@5 87.5
Epoch: [127][651/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 64.1	Acc@5 90.6
Epoch: [127][661/704]	Time 0.121	Data 0.001	Loss 3.74	Acc@1 81.2	Acc@5 96.9
Epoch: [127][671/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 67.2	Acc@5 90.6
Epoch: [127][681/704]	Time 0.121	Data 0.001	Loss 3.82	Acc@1 73.4	Acc@5 98.4
Epoch: [127][691/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 71.9	Acc@5 95.3
Epoch: [127][701/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 67.2	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 7.8915	Acc@1 51.5625	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.4830	Acc@1 68.7500	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.4049	Acc@1 54.6875	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3542	Acc@1 54.6875	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5212	Acc@1 57.8125	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.3977	Acc@1 53.1250	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.3915	Acc@1 60.9375	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.2840	Acc@1 53.1250	Acc@5 84.3750
 * prec@1 48.660 prec@5 79.700
 * prec@1 52.220 prec@5 82.960
 * prec@1 55.220 prec@5 84.520
 * prec@1 58.160 prec@5 85.740
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_127.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_127.pth.tar'
Epoch: [128][1/704]	Time 0.299	Data 0.131	Loss 5.32	Acc@1 64.1	Acc@5 93.8
Epoch: [128][11/704]	Time 0.137	Data 0.012	Loss 5.20	Acc@1 67.2	Acc@5 87.5
Epoch: [128][21/704]	Time 0.129	Data 0.007	Loss 5.02	Acc@1 67.2	Acc@5 92.2
Epoch: [128][31/704]	Time 0.126	Data 0.005	Loss 5.62	Acc@1 70.3	Acc@5 93.8
Epoch: [128][41/704]	Time 0.125	Data 0.004	Loss 4.75	Acc@1 73.4	Acc@5 95.3
Epoch: [128][51/704]	Time 0.124	Data 0.003	Loss 3.70	Acc@1 73.4	Acc@5 96.9
Epoch: [128][61/704]	Time 0.123	Data 0.003	Loss 4.36	Acc@1 71.9	Acc@5 95.3
Epoch: [128][71/704]	Time 0.123	Data 0.002	Loss 4.38	Acc@1 68.8	Acc@5 95.3
Epoch: [128][81/704]	Time 0.122	Data 0.002	Loss 3.88	Acc@1 65.6	Acc@5 96.9
Epoch: [128][91/704]	Time 0.123	Data 0.002	Loss 4.83	Acc@1 79.7	Acc@5 93.8
Epoch: [128][101/704]	Time 0.123	Data 0.002	Loss 5.13	Acc@1 67.2	Acc@5 93.8
Epoch: [128][111/704]	Time 0.122	Data 0.002	Loss 4.91	Acc@1 71.9	Acc@5 93.8
Epoch: [128][121/704]	Time 0.122	Data 0.001	Loss 4.55	Acc@1 71.9	Acc@5 98.4
Epoch: [128][131/704]	Time 0.122	Data 0.001	Loss 4.88	Acc@1 73.4	Acc@5 95.3
Epoch: [128][141/704]	Time 0.122	Data 0.001	Loss 4.20	Acc@1 79.7	Acc@5 98.4
Epoch: [128][151/704]	Time 0.122	Data 0.001	Loss 4.78	Acc@1 67.2	Acc@5 93.8
Epoch: [128][161/704]	Time 0.122	Data 0.001	Loss 5.80	Acc@1 67.2	Acc@5 89.1
Epoch: [128][171/704]	Time 0.122	Data 0.001	Loss 5.66	Acc@1 70.3	Acc@5 89.1
Epoch: [128][181/704]	Time 0.122	Data 0.001	Loss 5.46	Acc@1 70.3	Acc@5 92.2
Epoch: [128][191/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 75.0	Acc@5 93.8
Epoch: [128][201/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 60.9	Acc@5 90.6
Epoch: [128][211/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 75.0	Acc@5 96.9
Epoch: [128][221/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 68.8	Acc@5 92.2
Epoch: [128][231/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 71.9	Acc@5 98.4
Epoch: [128][241/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 62.5	Acc@5 92.2
Epoch: [128][251/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 68.8	Acc@5 96.9
Epoch: [128][261/704]	Time 0.121	Data 0.001	Loss 6.48	Acc@1 51.6	Acc@5 89.1
Epoch: [128][271/704]	Time 0.121	Data 0.001	Loss 6.58	Acc@1 60.9	Acc@5 82.8
Epoch: [128][281/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 71.9	Acc@5 95.3
Epoch: [128][291/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 71.9	Acc@5 92.2
Epoch: [128][301/704]	Time 0.121	Data 0.001	Loss 7.36	Acc@1 48.4	Acc@5 82.8
Epoch: [128][311/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 75.0	Acc@5 90.6
Epoch: [128][321/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 64.1	Acc@5 89.1
Epoch: [128][331/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 75.0	Acc@5 95.3
Epoch: [128][341/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 73.4	Acc@5 95.3
Epoch: [128][351/704]	Time 0.121	Data 0.001	Loss 3.79	Acc@1 71.9	Acc@5 98.4
Epoch: [128][361/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 65.6	Acc@5 90.6
Epoch: [128][371/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 57.8	Acc@5 89.1
Epoch: [128][381/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 65.6	Acc@5 93.8
Epoch: [128][391/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 57.8	Acc@5 90.6
Epoch: [128][401/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 70.3	Acc@5 96.9
Epoch: [128][411/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 62.5	Acc@5 89.1
Epoch: [128][421/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 68.8	Acc@5 92.2
Epoch: [128][431/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 68.8	Acc@5 93.8
Epoch: [128][441/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 70.3	Acc@5 89.1
Epoch: [128][451/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 78.1	Acc@5 92.2
Epoch: [128][461/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 71.9	Acc@5 92.2
Epoch: [128][471/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 92.2
Epoch: [128][481/704]	Time 0.121	Data 0.001	Loss 6.65	Acc@1 59.4	Acc@5 90.6
Epoch: [128][491/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 60.9	Acc@5 92.2
Epoch: [128][501/704]	Time 0.121	Data 0.001	Loss 6.36	Acc@1 60.9	Acc@5 89.1
Epoch: [128][511/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 70.3	Acc@5 92.2
Epoch: [128][521/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 71.9	Acc@5 90.6
Epoch: [128][531/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 68.8	Acc@5 96.9
Epoch: [128][541/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 60.9	Acc@5 89.1
Epoch: [128][551/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 75.0	Acc@5 95.3
Epoch: [128][561/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 67.2	Acc@5 93.8
Epoch: [128][571/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 73.4	Acc@5 90.6
Epoch: [128][581/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 76.6	Acc@5 90.6
Epoch: [128][591/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 75.0	Acc@5 87.5
Epoch: [128][601/704]	Time 0.121	Data 0.001	Loss 3.84	Acc@1 79.7	Acc@5 98.4
Epoch: [128][611/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 67.2	Acc@5 93.8
Epoch: [128][621/704]	Time 0.121	Data 0.001	Loss 4.08	Acc@1 71.9	Acc@5 98.4
Epoch: [128][631/704]	Time 0.121	Data 0.001	Loss 5.98	Acc@1 59.4	Acc@5 85.9
Epoch: [128][641/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 75.0	Acc@5 93.8
Epoch: [128][651/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 57.8	Acc@5 90.6
Epoch: [128][661/704]	Time 0.121	Data 0.001	Loss 6.24	Acc@1 62.5	Acc@5 90.6
Epoch: [128][671/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 73.4	Acc@5 98.4
Epoch: [128][681/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 75.0	Acc@5 90.6
Epoch: [128][691/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 75.0	Acc@5 95.3
Epoch: [128][701/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 67.2	Acc@5 93.8
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.7227	Acc@1 60.9375	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.3520	Acc@1 57.8125	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.1674	Acc@1 67.1875	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3613	Acc@1 64.0625	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9137	Acc@1 53.1250	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.4656	Acc@1 67.1875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.3026	Acc@1 64.0625	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3745	Acc@1 64.0625	Acc@5 89.0625
 * prec@1 46.400 prec@5 77.420
 * prec@1 51.780 prec@5 81.620
 * prec@1 55.580 prec@5 85.320
 * prec@1 57.860 prec@5 86.080
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_128.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_128.pth.tar'
Epoch: [129][1/704]	Time 0.300	Data 0.132	Loss 4.50	Acc@1 70.3	Acc@5 95.3
Epoch: [129][11/704]	Time 0.141	Data 0.012	Loss 5.87	Acc@1 73.4	Acc@5 89.1
Epoch: [129][21/704]	Time 0.131	Data 0.007	Loss 6.56	Acc@1 64.1	Acc@5 87.5
Epoch: [129][31/704]	Time 0.128	Data 0.005	Loss 4.06	Acc@1 73.4	Acc@5 96.9
Epoch: [129][41/704]	Time 0.126	Data 0.004	Loss 4.46	Acc@1 68.8	Acc@5 93.8
Epoch: [129][51/704]	Time 0.125	Data 0.003	Loss 5.06	Acc@1 76.6	Acc@5 95.3
Epoch: [129][61/704]	Time 0.124	Data 0.003	Loss 5.12	Acc@1 60.9	Acc@5 95.3
Epoch: [129][71/704]	Time 0.124	Data 0.002	Loss 6.68	Acc@1 59.4	Acc@5 87.5
Epoch: [129][81/704]	Time 0.123	Data 0.002	Loss 5.30	Acc@1 62.5	Acc@5 92.2
Epoch: [129][91/704]	Time 0.123	Data 0.002	Loss 4.52	Acc@1 70.3	Acc@5 93.8
Epoch: [129][101/704]	Time 0.123	Data 0.002	Loss 5.11	Acc@1 71.9	Acc@5 93.8
Epoch: [129][111/704]	Time 0.122	Data 0.002	Loss 5.56	Acc@1 68.8	Acc@5 96.9
Epoch: [129][121/704]	Time 0.122	Data 0.001	Loss 5.42	Acc@1 71.9	Acc@5 92.2
Epoch: [129][131/704]	Time 0.122	Data 0.001	Loss 6.63	Acc@1 67.2	Acc@5 89.1
Epoch: [129][141/704]	Time 0.122	Data 0.001	Loss 3.51	Acc@1 82.8	Acc@5 100.0
Epoch: [129][151/704]	Time 0.122	Data 0.001	Loss 5.81	Acc@1 64.1	Acc@5 96.9
Epoch: [129][161/704]	Time 0.122	Data 0.001	Loss 5.47	Acc@1 60.9	Acc@5 89.1
Epoch: [129][171/704]	Time 0.122	Data 0.001	Loss 4.78	Acc@1 76.6	Acc@5 90.6
Epoch: [129][181/704]	Time 0.122	Data 0.001	Loss 3.77	Acc@1 76.6	Acc@5 96.9
Epoch: [129][191/704]	Time 0.122	Data 0.001	Loss 4.70	Acc@1 68.8	Acc@5 93.8
Epoch: [129][201/704]	Time 0.122	Data 0.001	Loss 4.17	Acc@1 73.4	Acc@5 96.9
Epoch: [129][211/704]	Time 0.122	Data 0.001	Loss 5.11	Acc@1 68.8	Acc@5 95.3
Epoch: [129][221/704]	Time 0.122	Data 0.001	Loss 4.72	Acc@1 68.8	Acc@5 92.2
Epoch: [129][231/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 76.6	Acc@5 93.8
Epoch: [129][241/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 71.9	Acc@5 92.2
Epoch: [129][251/704]	Time 0.121	Data 0.001	Loss 4.35	Acc@1 73.4	Acc@5 96.9
Epoch: [129][261/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 71.9	Acc@5 96.9
Epoch: [129][271/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 56.2	Acc@5 93.8
Epoch: [129][281/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 75.0	Acc@5 96.9
Epoch: [129][291/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 60.9	Acc@5 95.3
Epoch: [129][301/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 65.6	Acc@5 90.6
Epoch: [129][311/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 60.9	Acc@5 95.3
Epoch: [129][321/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 75.0	Acc@5 95.3
Epoch: [129][331/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 64.1	Acc@5 93.8
Epoch: [129][341/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 67.2	Acc@5 96.9
Epoch: [129][351/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 68.8	Acc@5 90.6
Epoch: [129][361/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 65.6	Acc@5 92.2
Epoch: [129][371/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 67.2	Acc@5 90.6
Epoch: [129][381/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 71.9	Acc@5 96.9
Epoch: [129][391/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 65.6	Acc@5 93.8
Epoch: [129][401/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 96.9
Epoch: [129][411/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 68.8	Acc@5 95.3
Epoch: [129][421/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 68.8	Acc@5 89.1
Epoch: [129][431/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 68.8	Acc@5 96.9
Epoch: [129][441/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 71.9	Acc@5 92.2
Epoch: [129][451/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 68.8	Acc@5 90.6
Epoch: [129][461/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 64.1	Acc@5 98.4
Epoch: [129][471/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 60.9	Acc@5 89.1
Epoch: [129][481/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 64.1	Acc@5 90.6
Epoch: [129][491/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 70.3	Acc@5 98.4
Epoch: [129][501/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 87.5	Acc@5 98.4
Epoch: [129][511/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 95.3
Epoch: [129][521/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 75.0	Acc@5 93.8
Epoch: [129][531/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 65.6	Acc@5 92.2
Epoch: [129][541/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 76.6	Acc@5 90.6
Epoch: [129][551/704]	Time 0.121	Data 0.001	Loss 6.23	Acc@1 59.4	Acc@5 85.9
Epoch: [129][561/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 98.4
Epoch: [129][571/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 59.4	Acc@5 93.8
Epoch: [129][581/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 67.2	Acc@5 89.1
Epoch: [129][591/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 75.0	Acc@5 89.1
Epoch: [129][601/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 65.6	Acc@5 96.9
Epoch: [129][611/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 64.1	Acc@5 95.3
Epoch: [129][621/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 70.3	Acc@5 92.2
Epoch: [129][631/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 81.2	Acc@5 93.8
Epoch: [129][641/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 79.7	Acc@5 93.8
Epoch: [129][651/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 65.6	Acc@5 95.3
Epoch: [129][661/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 68.8	Acc@5 93.8
Epoch: [129][671/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 73.4	Acc@5 90.6
Epoch: [129][681/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 59.4	Acc@5 92.2
Epoch: [129][691/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 96.9
Epoch: [129][701/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 71.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.8828	Acc@1 67.1875	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.4152	Acc@1 62.5000	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2541	Acc@1 57.8125	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.0724	Acc@1 64.0625	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.1362	Acc@1 54.6875	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1793	Acc@1 71.8750	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.0202	Acc@1 51.5625	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.9221	Acc@1 53.1250	Acc@5 87.5000
 * prec@1 45.900 prec@5 76.260
 * prec@1 51.620 prec@5 82.540
 * prec@1 56.340 prec@5 85.580
 * prec@1 56.820 prec@5 85.960
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_129.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_129.pth.tar'
Epoch: [130][1/704]	Time 0.326	Data 0.159	Loss 5.16	Acc@1 68.8	Acc@5 96.9
Epoch: [130][11/704]	Time 0.139	Data 0.015	Loss 4.06	Acc@1 71.9	Acc@5 95.3
Epoch: [130][21/704]	Time 0.130	Data 0.008	Loss 4.38	Acc@1 76.6	Acc@5 96.9
Epoch: [130][31/704]	Time 0.127	Data 0.006	Loss 4.79	Acc@1 73.4	Acc@5 95.3
Epoch: [130][41/704]	Time 0.125	Data 0.004	Loss 3.68	Acc@1 78.1	Acc@5 96.9
Epoch: [130][51/704]	Time 0.124	Data 0.004	Loss 4.87	Acc@1 70.3	Acc@5 95.3
Epoch: [130][61/704]	Time 0.124	Data 0.003	Loss 4.35	Acc@1 70.3	Acc@5 92.2
Epoch: [130][71/704]	Time 0.123	Data 0.003	Loss 3.92	Acc@1 79.7	Acc@5 98.4
Epoch: [130][81/704]	Time 0.123	Data 0.002	Loss 4.74	Acc@1 70.3	Acc@5 93.8
Epoch: [130][91/704]	Time 0.123	Data 0.002	Loss 4.93	Acc@1 71.9	Acc@5 96.9
Epoch: [130][101/704]	Time 0.122	Data 0.002	Loss 4.33	Acc@1 68.8	Acc@5 95.3
Epoch: [130][111/704]	Time 0.122	Data 0.002	Loss 4.99	Acc@1 70.3	Acc@5 95.3
Epoch: [130][121/704]	Time 0.122	Data 0.002	Loss 5.51	Acc@1 68.8	Acc@5 92.2
Epoch: [130][131/704]	Time 0.122	Data 0.002	Loss 4.55	Acc@1 68.8	Acc@5 96.9
Epoch: [130][141/704]	Time 0.122	Data 0.001	Loss 5.95	Acc@1 59.4	Acc@5 90.6
Epoch: [130][151/704]	Time 0.122	Data 0.001	Loss 4.83	Acc@1 65.6	Acc@5 96.9
Epoch: [130][161/704]	Time 0.122	Data 0.001	Loss 3.85	Acc@1 70.3	Acc@5 98.4
Epoch: [130][171/704]	Time 0.122	Data 0.001	Loss 4.37	Acc@1 73.4	Acc@5 95.3
Epoch: [130][181/704]	Time 0.122	Data 0.001	Loss 4.68	Acc@1 70.3	Acc@5 96.9
Epoch: [130][191/704]	Time 0.122	Data 0.001	Loss 5.92	Acc@1 57.8	Acc@5 92.2
Epoch: [130][201/704]	Time 0.122	Data 0.001	Loss 4.04	Acc@1 76.6	Acc@5 95.3
Epoch: [130][211/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 65.6	Acc@5 95.3
Epoch: [130][221/704]	Time 0.122	Data 0.001	Loss 4.52	Acc@1 71.9	Acc@5 93.8
Epoch: [130][231/704]	Time 0.122	Data 0.001	Loss 4.57	Acc@1 71.9	Acc@5 95.3
Epoch: [130][241/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 90.6
Epoch: [130][251/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 67.2	Acc@5 85.9
Epoch: [130][261/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 64.1	Acc@5 93.8
Epoch: [130][271/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 75.0	Acc@5 96.9
Epoch: [130][281/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 67.2	Acc@5 93.8
Epoch: [130][291/704]	Time 0.121	Data 0.001	Loss 4.19	Acc@1 78.1	Acc@5 98.4
Epoch: [130][301/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 92.2
Epoch: [130][311/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 78.1	Acc@5 95.3
Epoch: [130][321/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 71.9	Acc@5 96.9
Epoch: [130][331/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 96.9
Epoch: [130][341/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 78.1	Acc@5 95.3
Epoch: [130][351/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 64.1	Acc@5 90.6
Epoch: [130][361/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 93.8
Epoch: [130][371/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 67.2	Acc@5 92.2
Epoch: [130][381/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 78.1	Acc@5 89.1
Epoch: [130][391/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 71.9	Acc@5 92.2
Epoch: [130][401/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 62.5	Acc@5 92.2
Epoch: [130][411/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 78.1	Acc@5 96.9
Epoch: [130][421/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 78.1	Acc@5 93.8
Epoch: [130][431/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 67.2	Acc@5 93.8
Epoch: [130][441/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 65.6	Acc@5 95.3
Epoch: [130][451/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 71.9	Acc@5 90.6
Epoch: [130][461/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 68.8	Acc@5 93.8
Epoch: [130][471/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 70.3	Acc@5 89.1
Epoch: [130][481/704]	Time 0.121	Data 0.001	Loss 3.63	Acc@1 78.1	Acc@5 98.4
Epoch: [130][491/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 68.8	Acc@5 92.2
Epoch: [130][501/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 73.4	Acc@5 96.9
Epoch: [130][511/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 67.2	Acc@5 89.1
Epoch: [130][521/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 68.8	Acc@5 92.2
Epoch: [130][531/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 71.9	Acc@5 95.3
Epoch: [130][541/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 78.1	Acc@5 98.4
Epoch: [130][551/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 67.2	Acc@5 92.2
Epoch: [130][561/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 71.9	Acc@5 95.3
Epoch: [130][571/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 68.8	Acc@5 98.4
Epoch: [130][581/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 60.9	Acc@5 87.5
Epoch: [130][591/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 62.5	Acc@5 93.8
Epoch: [130][601/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 70.3	Acc@5 93.8
Epoch: [130][611/704]	Time 0.121	Data 0.001	Loss 6.33	Acc@1 67.2	Acc@5 85.9
Epoch: [130][621/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 64.1	Acc@5 90.6
Epoch: [130][631/704]	Time 0.121	Data 0.001	Loss 4.18	Acc@1 75.0	Acc@5 96.9
Epoch: [130][641/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 70.3	Acc@5 95.3
Epoch: [130][651/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 79.7	Acc@5 95.3
Epoch: [130][661/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 59.4	Acc@5 87.5
Epoch: [130][671/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 76.6	Acc@5 89.1
Epoch: [130][681/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 70.3	Acc@5 96.9
Epoch: [130][691/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 62.5	Acc@5 90.6
Epoch: [130][701/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 53.1	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.7525	Acc@1 68.7500	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.8747	Acc@1 50.0000	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0915	Acc@1 56.2500	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.2926	Acc@1 67.1875	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.1638	Acc@1 56.2500	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.0466	Acc@1 51.5625	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.2430	Acc@1 50.0000	Acc@5 71.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9494	Acc@1 57.8125	Acc@5 90.6250
 * prec@1 47.620 prec@5 78.600
 * prec@1 53.480 prec@5 82.920
 * prec@1 55.780 prec@5 84.820
 * prec@1 57.000 prec@5 85.860
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_130.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_130.pth.tar'
Epoch: [131][1/704]	Time 0.300	Data 0.132	Loss 4.23	Acc@1 70.3	Acc@5 95.3
Epoch: [131][11/704]	Time 0.137	Data 0.012	Loss 4.84	Acc@1 70.3	Acc@5 90.6
Epoch: [131][21/704]	Time 0.129	Data 0.007	Loss 5.35	Acc@1 60.9	Acc@5 90.6
Epoch: [131][31/704]	Time 0.126	Data 0.005	Loss 5.44	Acc@1 65.6	Acc@5 90.6
Epoch: [131][41/704]	Time 0.125	Data 0.004	Loss 5.80	Acc@1 67.2	Acc@5 93.8
Epoch: [131][51/704]	Time 0.124	Data 0.003	Loss 4.19	Acc@1 78.1	Acc@5 96.9
Epoch: [131][61/704]	Time 0.123	Data 0.003	Loss 4.48	Acc@1 65.6	Acc@5 96.9
Epoch: [131][71/704]	Time 0.123	Data 0.002	Loss 3.85	Acc@1 82.8	Acc@5 98.4
Epoch: [131][81/704]	Time 0.122	Data 0.002	Loss 5.00	Acc@1 64.1	Acc@5 96.9
Epoch: [131][91/704]	Time 0.122	Data 0.002	Loss 4.31	Acc@1 75.0	Acc@5 96.9
Epoch: [131][101/704]	Time 0.122	Data 0.002	Loss 3.81	Acc@1 78.1	Acc@5 98.4
Epoch: [131][111/704]	Time 0.122	Data 0.002	Loss 4.44	Acc@1 71.9	Acc@5 93.8
Epoch: [131][121/704]	Time 0.122	Data 0.001	Loss 3.43	Acc@1 82.8	Acc@5 98.4
Epoch: [131][131/704]	Time 0.122	Data 0.001	Loss 4.53	Acc@1 75.0	Acc@5 92.2
Epoch: [131][141/704]	Time 0.122	Data 0.001	Loss 6.00	Acc@1 65.6	Acc@5 98.4
Epoch: [131][151/704]	Time 0.122	Data 0.001	Loss 4.35	Acc@1 70.3	Acc@5 95.3
Epoch: [131][161/704]	Time 0.122	Data 0.001	Loss 6.10	Acc@1 70.3	Acc@5 90.6
Epoch: [131][171/704]	Time 0.122	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 92.2
Epoch: [131][181/704]	Time 0.122	Data 0.001	Loss 4.33	Acc@1 73.4	Acc@5 89.1
Epoch: [131][191/704]	Time 0.122	Data 0.001	Loss 3.94	Acc@1 73.4	Acc@5 93.8
Epoch: [131][201/704]	Time 0.122	Data 0.001	Loss 5.32	Acc@1 68.8	Acc@5 92.2
Epoch: [131][211/704]	Time 0.122	Data 0.001	Loss 5.09	Acc@1 65.6	Acc@5 93.8
Epoch: [131][221/704]	Time 0.122	Data 0.001	Loss 2.91	Acc@1 82.8	Acc@5 98.4
Epoch: [131][231/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 70.3	Acc@5 95.3
Epoch: [131][241/704]	Time 0.121	Data 0.001	Loss 3.80	Acc@1 79.7	Acc@5 96.9
Epoch: [131][251/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 64.1	Acc@5 96.9
Epoch: [131][261/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 64.1	Acc@5 93.8
Epoch: [131][271/704]	Time 0.121	Data 0.001	Loss 3.80	Acc@1 76.6	Acc@5 96.9
Epoch: [131][281/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 64.1	Acc@5 90.6
Epoch: [131][291/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 70.3	Acc@5 89.1
Epoch: [131][301/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 76.6	Acc@5 92.2
Epoch: [131][311/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 76.6	Acc@5 95.3
Epoch: [131][321/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 68.8	Acc@5 96.9
Epoch: [131][331/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 62.5	Acc@5 90.6
Epoch: [131][341/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 73.4	Acc@5 92.2
Epoch: [131][351/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 70.3	Acc@5 95.3
Epoch: [131][361/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 67.2	Acc@5 87.5
Epoch: [131][371/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 79.7	Acc@5 95.3
Epoch: [131][381/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 60.9	Acc@5 92.2
Epoch: [131][391/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 60.9	Acc@5 92.2
Epoch: [131][401/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 75.0	Acc@5 92.2
Epoch: [131][411/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 62.5	Acc@5 96.9
Epoch: [131][421/704]	Time 0.121	Data 0.001	Loss 5.65	Acc@1 67.2	Acc@5 90.6
Epoch: [131][431/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 92.2
Epoch: [131][441/704]	Time 0.121	Data 0.001	Loss 6.70	Acc@1 62.5	Acc@5 84.4
Epoch: [131][451/704]	Time 0.121	Data 0.001	Loss 6.50	Acc@1 57.8	Acc@5 85.9
Epoch: [131][461/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 67.2	Acc@5 95.3
Epoch: [131][471/704]	Time 0.121	Data 0.001	Loss 4.19	Acc@1 68.8	Acc@5 93.8
Epoch: [131][481/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 54.7	Acc@5 92.2
Epoch: [131][491/704]	Time 0.121	Data 0.001	Loss 6.50	Acc@1 60.9	Acc@5 87.5
Epoch: [131][501/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 68.8	Acc@5 96.9
Epoch: [131][511/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 67.2	Acc@5 92.2
Epoch: [131][521/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 73.4	Acc@5 92.2
Epoch: [131][531/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 62.5	Acc@5 92.2
Epoch: [131][541/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 71.9	Acc@5 93.8
Epoch: [131][551/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 70.3	Acc@5 93.8
Epoch: [131][561/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 75.0	Acc@5 92.2
Epoch: [131][571/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 90.6
Epoch: [131][581/704]	Time 0.121	Data 0.001	Loss 3.95	Acc@1 81.2	Acc@5 96.9
Epoch: [131][591/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 60.9	Acc@5 93.8
Epoch: [131][601/704]	Time 0.121	Data 0.001	Loss 4.94	Acc@1 70.3	Acc@5 93.8
Epoch: [131][611/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 73.4	Acc@5 96.9
Epoch: [131][621/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 81.2	Acc@5 96.9
Epoch: [131][631/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 65.6	Acc@5 89.1
Epoch: [131][641/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 64.1	Acc@5 93.8
Epoch: [131][651/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 59.4	Acc@5 93.8
Epoch: [131][661/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 68.8	Acc@5 92.2
Epoch: [131][671/704]	Time 0.121	Data 0.001	Loss 6.35	Acc@1 56.2	Acc@5 89.1
Epoch: [131][681/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 67.2	Acc@5 96.9
Epoch: [131][691/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 68.8	Acc@5 93.8
Epoch: [131][701/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 68.8	Acc@5 92.2
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.2780	Acc@1 57.8125	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7326	Acc@1 56.2500	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.1812	Acc@1 51.5625	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7128	Acc@1 62.5000	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9855	Acc@1 65.6250	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2829	Acc@1 53.1250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.1674	Acc@1 70.3125	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9263	Acc@1 54.6875	Acc@5 85.9375
 * prec@1 49.220 prec@5 79.600
 * prec@1 53.140 prec@5 82.520
 * prec@1 57.380 prec@5 85.740
 * prec@1 59.300 prec@5 87.200
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_131.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_131.pth.tar'
Epoch: [132][1/704]	Time 0.295	Data 0.127	Loss 5.41	Acc@1 64.1	Acc@5 92.2
Epoch: [132][11/704]	Time 0.136	Data 0.012	Loss 5.89	Acc@1 59.4	Acc@5 93.8
Epoch: [132][21/704]	Time 0.128	Data 0.006	Loss 5.09	Acc@1 65.6	Acc@5 93.8
Epoch: [132][31/704]	Time 0.126	Data 0.004	Loss 4.67	Acc@1 70.3	Acc@5 92.2
Epoch: [132][41/704]	Time 0.124	Data 0.003	Loss 4.87	Acc@1 71.9	Acc@5 98.4
Epoch: [132][51/704]	Time 0.123	Data 0.003	Loss 4.56	Acc@1 76.6	Acc@5 93.8
Epoch: [132][61/704]	Time 0.123	Data 0.002	Loss 4.39	Acc@1 75.0	Acc@5 95.3
Epoch: [132][71/704]	Time 0.123	Data 0.002	Loss 4.86	Acc@1 70.3	Acc@5 93.8
Epoch: [132][81/704]	Time 0.123	Data 0.002	Loss 3.89	Acc@1 78.1	Acc@5 92.2
Epoch: [132][91/704]	Time 0.122	Data 0.002	Loss 6.25	Acc@1 59.4	Acc@5 85.9
Epoch: [132][101/704]	Time 0.122	Data 0.002	Loss 4.01	Acc@1 71.9	Acc@5 95.3
Epoch: [132][111/704]	Time 0.122	Data 0.002	Loss 4.18	Acc@1 79.7	Acc@5 93.8
Epoch: [132][121/704]	Time 0.122	Data 0.001	Loss 5.25	Acc@1 64.1	Acc@5 92.2
Epoch: [132][131/704]	Time 0.122	Data 0.001	Loss 5.08	Acc@1 70.3	Acc@5 90.6
Epoch: [132][141/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 71.9	Acc@5 89.1
Epoch: [132][151/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 90.6
Epoch: [132][161/704]	Time 0.121	Data 0.001	Loss 5.64	Acc@1 68.8	Acc@5 92.2
Epoch: [132][171/704]	Time 0.121	Data 0.001	Loss 3.45	Acc@1 78.1	Acc@5 98.4
Epoch: [132][181/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 60.9	Acc@5 90.6
Epoch: [132][191/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 67.2	Acc@5 93.8
Epoch: [132][201/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 70.3	Acc@5 89.1
Epoch: [132][211/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 70.3	Acc@5 93.8
Epoch: [132][221/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 68.8	Acc@5 92.2
Epoch: [132][231/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 70.3	Acc@5 89.1
Epoch: [132][241/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 75.0	Acc@5 95.3
Epoch: [132][251/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 73.4	Acc@5 96.9
Epoch: [132][261/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 73.4	Acc@5 87.5
Epoch: [132][271/704]	Time 0.121	Data 0.001	Loss 3.90	Acc@1 81.2	Acc@5 93.8
Epoch: [132][281/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 64.1	Acc@5 93.8
Epoch: [132][291/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 67.2	Acc@5 96.9
Epoch: [132][301/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 75.0	Acc@5 90.6
Epoch: [132][311/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 78.1	Acc@5 95.3
Epoch: [132][321/704]	Time 0.121	Data 0.001	Loss 6.18	Acc@1 57.8	Acc@5 87.5
Epoch: [132][331/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 76.6	Acc@5 93.8
Epoch: [132][341/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 75.0	Acc@5 92.2
Epoch: [132][351/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 70.3	Acc@5 93.8
Epoch: [132][361/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 75.0	Acc@5 96.9
Epoch: [132][371/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 71.9	Acc@5 93.8
Epoch: [132][381/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 68.8	Acc@5 90.6
Epoch: [132][391/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 73.4	Acc@5 92.2
Epoch: [132][401/704]	Time 0.120	Data 0.001	Loss 5.54	Acc@1 70.3	Acc@5 92.2
Epoch: [132][411/704]	Time 0.120	Data 0.001	Loss 5.62	Acc@1 67.2	Acc@5 93.8
Epoch: [132][421/704]	Time 0.120	Data 0.001	Loss 4.79	Acc@1 70.3	Acc@5 90.6
Epoch: [132][431/704]	Time 0.120	Data 0.001	Loss 4.58	Acc@1 75.0	Acc@5 93.8
Epoch: [132][441/704]	Time 0.120	Data 0.001	Loss 5.29	Acc@1 70.3	Acc@5 93.8
Epoch: [132][451/704]	Time 0.120	Data 0.001	Loss 4.83	Acc@1 75.0	Acc@5 98.4
Epoch: [132][461/704]	Time 0.120	Data 0.001	Loss 4.37	Acc@1 76.6	Acc@5 93.8
Epoch: [132][471/704]	Time 0.120	Data 0.001	Loss 4.80	Acc@1 78.1	Acc@5 95.3
Epoch: [132][481/704]	Time 0.120	Data 0.001	Loss 4.92	Acc@1 71.9	Acc@5 92.2
Epoch: [132][491/704]	Time 0.120	Data 0.001	Loss 4.91	Acc@1 68.8	Acc@5 93.8
Epoch: [132][501/704]	Time 0.120	Data 0.001	Loss 4.99	Acc@1 70.3	Acc@5 93.8
Epoch: [132][511/704]	Time 0.120	Data 0.001	Loss 3.82	Acc@1 73.4	Acc@5 98.4
Epoch: [132][521/704]	Time 0.120	Data 0.001	Loss 4.13	Acc@1 68.8	Acc@5 96.9
Epoch: [132][531/704]	Time 0.120	Data 0.001	Loss 3.79	Acc@1 68.8	Acc@5 96.9
Epoch: [132][541/704]	Time 0.120	Data 0.001	Loss 6.58	Acc@1 56.2	Acc@5 90.6
Epoch: [132][551/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 65.6	Acc@5 93.8
Epoch: [132][561/704]	Time 0.120	Data 0.001	Loss 5.49	Acc@1 68.8	Acc@5 92.2
Epoch: [132][571/704]	Time 0.120	Data 0.001	Loss 5.09	Acc@1 68.8	Acc@5 95.3
Epoch: [132][581/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 68.8	Acc@5 92.2
Epoch: [132][591/704]	Time 0.120	Data 0.001	Loss 5.00	Acc@1 71.9	Acc@5 89.1
Epoch: [132][601/704]	Time 0.120	Data 0.001	Loss 6.43	Acc@1 67.2	Acc@5 85.9
Epoch: [132][611/704]	Time 0.120	Data 0.001	Loss 4.42	Acc@1 73.4	Acc@5 92.2
Epoch: [132][621/704]	Time 0.120	Data 0.001	Loss 4.61	Acc@1 70.3	Acc@5 95.3
Epoch: [132][631/704]	Time 0.120	Data 0.001	Loss 4.68	Acc@1 75.0	Acc@5 92.2
Epoch: [132][641/704]	Time 0.120	Data 0.001	Loss 4.53	Acc@1 71.9	Acc@5 95.3
Epoch: [132][651/704]	Time 0.120	Data 0.001	Loss 6.18	Acc@1 60.9	Acc@5 85.9
Epoch: [132][661/704]	Time 0.120	Data 0.001	Loss 5.84	Acc@1 64.1	Acc@5 92.2
Epoch: [132][671/704]	Time 0.120	Data 0.001	Loss 4.43	Acc@1 73.4	Acc@5 95.3
Epoch: [132][681/704]	Time 0.120	Data 0.001	Loss 5.99	Acc@1 64.1	Acc@5 90.6
Epoch: [132][691/704]	Time 0.120	Data 0.001	Loss 4.93	Acc@1 65.6	Acc@5 95.3
Epoch: [132][701/704]	Time 0.120	Data 0.001	Loss 4.76	Acc@1 71.9	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 7.9332	Acc@1 53.1250	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.1910	Acc@1 64.0625	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.1896	Acc@1 60.9375	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3311	Acc@1 56.2500	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4583	Acc@1 54.6875	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.1790	Acc@1 56.2500	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4450	Acc@1 56.2500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.7893	Acc@1 50.0000	Acc@5 76.5625
 * prec@1 47.180 prec@5 78.000
 * prec@1 53.460 prec@5 82.400
 * prec@1 55.200 prec@5 84.600
 * prec@1 57.520 prec@5 85.780
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_132.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_132.pth.tar'
Epoch: [133][1/704]	Time 0.333	Data 0.167	Loss 4.91	Acc@1 76.6	Acc@5 87.5
Epoch: [133][11/704]	Time 0.140	Data 0.015	Loss 5.65	Acc@1 68.8	Acc@5 95.3
Epoch: [133][21/704]	Time 0.131	Data 0.008	Loss 4.68	Acc@1 76.6	Acc@5 96.9
Epoch: [133][31/704]	Time 0.127	Data 0.006	Loss 5.17	Acc@1 78.1	Acc@5 93.8
Epoch: [133][41/704]	Time 0.126	Data 0.004	Loss 4.82	Acc@1 68.8	Acc@5 95.3
Epoch: [133][51/704]	Time 0.124	Data 0.004	Loss 3.88	Acc@1 79.7	Acc@5 90.6
Epoch: [133][61/704]	Time 0.124	Data 0.003	Loss 5.96	Acc@1 53.1	Acc@5 82.8
Epoch: [133][71/704]	Time 0.123	Data 0.003	Loss 4.42	Acc@1 65.6	Acc@5 93.8
Epoch: [133][81/704]	Time 0.123	Data 0.002	Loss 5.26	Acc@1 71.9	Acc@5 90.6
Epoch: [133][91/704]	Time 0.123	Data 0.002	Loss 4.49	Acc@1 73.4	Acc@5 96.9
Epoch: [133][101/704]	Time 0.122	Data 0.002	Loss 4.84	Acc@1 65.6	Acc@5 90.6
Epoch: [133][111/704]	Time 0.122	Data 0.002	Loss 4.57	Acc@1 71.9	Acc@5 96.9
Epoch: [133][121/704]	Time 0.122	Data 0.002	Loss 4.73	Acc@1 75.0	Acc@5 89.1
Epoch: [133][131/704]	Time 0.122	Data 0.002	Loss 4.29	Acc@1 78.1	Acc@5 98.4
Epoch: [133][141/704]	Time 0.122	Data 0.002	Loss 4.64	Acc@1 70.3	Acc@5 96.9
Epoch: [133][151/704]	Time 0.122	Data 0.001	Loss 4.81	Acc@1 71.9	Acc@5 96.9
Epoch: [133][161/704]	Time 0.122	Data 0.001	Loss 5.16	Acc@1 70.3	Acc@5 92.2
Epoch: [133][171/704]	Time 0.122	Data 0.001	Loss 4.49	Acc@1 70.3	Acc@5 96.9
Epoch: [133][181/704]	Time 0.122	Data 0.001	Loss 4.64	Acc@1 67.2	Acc@5 93.8
Epoch: [133][191/704]	Time 0.121	Data 0.001	Loss 6.23	Acc@1 64.1	Acc@5 90.6
Epoch: [133][201/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 71.9	Acc@5 95.3
Epoch: [133][211/704]	Time 0.121	Data 0.001	Loss 3.76	Acc@1 73.4	Acc@5 98.4
Epoch: [133][221/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 67.2	Acc@5 93.8
Epoch: [133][231/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 75.0	Acc@5 95.3
Epoch: [133][241/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 56.2	Acc@5 90.6
Epoch: [133][251/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 76.6	Acc@5 90.6
Epoch: [133][261/704]	Time 0.121	Data 0.001	Loss 6.03	Acc@1 70.3	Acc@5 93.8
Epoch: [133][271/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 67.2	Acc@5 92.2
Epoch: [133][281/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 71.9	Acc@5 96.9
Epoch: [133][291/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 73.4	Acc@5 90.6
Epoch: [133][301/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 76.6	Acc@5 90.6
Epoch: [133][311/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 75.0	Acc@5 90.6
Epoch: [133][321/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 76.6	Acc@5 92.2
Epoch: [133][331/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 73.4	Acc@5 92.2
Epoch: [133][341/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 73.4	Acc@5 95.3
Epoch: [133][351/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 78.1	Acc@5 96.9
Epoch: [133][361/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 65.6	Acc@5 90.6
Epoch: [133][371/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 96.9
Epoch: [133][381/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 75.0	Acc@5 95.3
Epoch: [133][391/704]	Time 0.121	Data 0.001	Loss 3.88	Acc@1 78.1	Acc@5 95.3
Epoch: [133][401/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 65.6	Acc@5 90.6
Epoch: [133][411/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 67.2	Acc@5 92.2
Epoch: [133][421/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 65.6	Acc@5 93.8
Epoch: [133][431/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 64.1	Acc@5 93.8
Epoch: [133][441/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 93.8
Epoch: [133][451/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 65.6	Acc@5 93.8
Epoch: [133][461/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 67.2	Acc@5 93.8
Epoch: [133][471/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 96.9
Epoch: [133][481/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 68.8	Acc@5 93.8
Epoch: [133][491/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 75.0	Acc@5 95.3
Epoch: [133][501/704]	Time 0.121	Data 0.001	Loss 6.64	Acc@1 59.4	Acc@5 85.9
Epoch: [133][511/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 70.3	Acc@5 96.9
Epoch: [133][521/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 76.6	Acc@5 96.9
Epoch: [133][531/704]	Time 0.121	Data 0.001	Loss 5.96	Acc@1 59.4	Acc@5 92.2
Epoch: [133][541/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 68.8	Acc@5 89.1
Epoch: [133][551/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 68.8	Acc@5 93.8
Epoch: [133][561/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 62.5	Acc@5 95.3
Epoch: [133][571/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 65.6	Acc@5 93.8
Epoch: [133][581/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 64.1	Acc@5 95.3
Epoch: [133][591/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 78.1	Acc@5 96.9
Epoch: [133][601/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 64.1	Acc@5 90.6
Epoch: [133][611/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 71.9	Acc@5 92.2
Epoch: [133][621/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 70.3	Acc@5 92.2
Epoch: [133][631/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 68.8	Acc@5 92.2
Epoch: [133][641/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 73.4	Acc@5 93.8
Epoch: [133][651/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 59.4	Acc@5 87.5
Epoch: [133][661/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 68.8	Acc@5 92.2
Epoch: [133][671/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 89.1
Epoch: [133][681/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 62.5	Acc@5 89.1
Epoch: [133][691/704]	Time 0.121	Data 0.001	Loss 6.54	Acc@1 64.1	Acc@5 89.1
Epoch: [133][701/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 64.1	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 6.1552	Acc@1 62.5000	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.8265	Acc@1 60.9375	Acc@5 98.4375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8226	Acc@1 62.5000	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.4406	Acc@1 60.9375	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4832	Acc@1 56.2500	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.0300	Acc@1 59.3750	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7396	Acc@1 56.2500	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.0643	Acc@1 71.8750	Acc@5 90.6250
 * prec@1 47.900 prec@5 78.720
 * prec@1 52.020 prec@5 82.680
 * prec@1 56.460 prec@5 84.800
 * prec@1 57.860 prec@5 85.980
Current best validation last_bloc_accuracy 59.92
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_133.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_133.pth.tar'
Epoch: [134][1/704]	Time 0.328	Data 0.162	Loss 4.22	Acc@1 78.1	Acc@5 89.1
Epoch: [134][11/704]	Time 0.141	Data 0.015	Loss 4.23	Acc@1 71.9	Acc@5 93.8
Epoch: [134][21/704]	Time 0.131	Data 0.008	Loss 5.03	Acc@1 65.6	Acc@5 96.9
Epoch: [134][31/704]	Time 0.127	Data 0.006	Loss 5.01	Acc@1 68.8	Acc@5 93.8
Epoch: [134][41/704]	Time 0.126	Data 0.004	Loss 3.62	Acc@1 75.0	Acc@5 95.3
Epoch: [134][51/704]	Time 0.124	Data 0.004	Loss 4.14	Acc@1 73.4	Acc@5 96.9
Epoch: [134][61/704]	Time 0.124	Data 0.003	Loss 5.75	Acc@1 65.6	Acc@5 92.2
Epoch: [134][71/704]	Time 0.123	Data 0.003	Loss 4.61	Acc@1 76.6	Acc@5 92.2
Epoch: [134][81/704]	Time 0.123	Data 0.002	Loss 4.70	Acc@1 71.9	Acc@5 96.9
Epoch: [134][91/704]	Time 0.122	Data 0.002	Loss 5.85	Acc@1 67.2	Acc@5 90.6
Epoch: [134][101/704]	Time 0.122	Data 0.002	Loss 4.31	Acc@1 75.0	Acc@5 89.1
Epoch: [134][111/704]	Time 0.122	Data 0.002	Loss 5.16	Acc@1 70.3	Acc@5 90.6
Epoch: [134][121/704]	Time 0.122	Data 0.002	Loss 5.35	Acc@1 67.2	Acc@5 96.9
Epoch: [134][131/704]	Time 0.122	Data 0.002	Loss 4.22	Acc@1 82.8	Acc@5 96.9
Epoch: [134][141/704]	Time 0.122	Data 0.002	Loss 4.57	Acc@1 70.3	Acc@5 95.3
Epoch: [134][151/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 73.4	Acc@5 85.9
Epoch: [134][161/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 67.2	Acc@5 87.5
Epoch: [134][171/704]	Time 0.122	Data 0.001	Loss 6.32	Acc@1 59.4	Acc@5 89.1
Epoch: [134][181/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 67.2	Acc@5 96.9
Epoch: [134][191/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 67.2	Acc@5 90.6
Epoch: [134][201/704]	Time 0.121	Data 0.001	Loss 6.28	Acc@1 62.5	Acc@5 87.5
Epoch: [134][211/704]	Time 0.121	Data 0.001	Loss 4.23	Acc@1 70.3	Acc@5 90.6
Epoch: [134][221/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 68.8	Acc@5 92.2
Epoch: [134][231/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 71.9	Acc@5 93.8
Epoch: [134][241/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 68.8	Acc@5 93.8
Epoch: [134][251/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 78.1	Acc@5 93.8
Epoch: [134][261/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 64.1	Acc@5 93.8
Epoch: [134][271/704]	Time 0.121	Data 0.001	Loss 4.21	Acc@1 73.4	Acc@5 96.9
Epoch: [134][281/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 75.0	Acc@5 96.9
Epoch: [134][291/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 95.3
Epoch: [134][301/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 68.8	Acc@5 90.6
Epoch: [134][311/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 71.9	Acc@5 89.1
Epoch: [134][321/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 59.4	Acc@5 93.8
Epoch: [134][331/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 73.4	Acc@5 95.3
Epoch: [134][341/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 68.8	Acc@5 90.6
Epoch: [134][351/704]	Time 0.121	Data 0.001	Loss 4.18	Acc@1 73.4	Acc@5 96.9
Epoch: [134][361/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 67.2	Acc@5 93.8
Epoch: [134][371/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 67.2	Acc@5 93.8
Epoch: [134][381/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 60.9	Acc@5 85.9
Epoch: [134][391/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 75.0	Acc@5 90.6
Epoch: [134][401/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 62.5	Acc@5 89.1
Epoch: [134][411/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 70.3	Acc@5 98.4
Epoch: [134][421/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 64.1	Acc@5 92.2
Epoch: [134][431/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 70.3	Acc@5 89.1
Epoch: [134][441/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 60.9	Acc@5 92.2
Epoch: [134][451/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 64.1	Acc@5 87.5
Epoch: [134][461/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 73.4	Acc@5 95.3
Epoch: [134][471/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 70.3	Acc@5 98.4
Epoch: [134][481/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 67.2	Acc@5 93.8
Epoch: [134][491/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 82.8	Acc@5 96.9
Epoch: [134][501/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 78.1	Acc@5 89.1
Epoch: [134][511/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 71.9	Acc@5 98.4
Epoch: [134][521/704]	Time 0.121	Data 0.001	Loss 5.52	Acc@1 59.4	Acc@5 95.3
Epoch: [134][531/704]	Time 0.120	Data 0.001	Loss 4.37	Acc@1 75.0	Acc@5 92.2
Epoch: [134][541/704]	Time 0.120	Data 0.001	Loss 4.45	Acc@1 75.0	Acc@5 92.2
Epoch: [134][551/704]	Time 0.120	Data 0.001	Loss 4.30	Acc@1 75.0	Acc@5 95.3
Epoch: [134][561/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 71.9	Acc@5 93.8
Epoch: [134][571/704]	Time 0.120	Data 0.001	Loss 4.59	Acc@1 76.6	Acc@5 92.2
Epoch: [134][581/704]	Time 0.120	Data 0.001	Loss 6.26	Acc@1 65.6	Acc@5 90.6
Epoch: [134][591/704]	Time 0.120	Data 0.001	Loss 5.71	Acc@1 68.8	Acc@5 93.8
Epoch: [134][601/704]	Time 0.120	Data 0.001	Loss 5.47	Acc@1 70.3	Acc@5 89.1
Epoch: [134][611/704]	Time 0.120	Data 0.001	Loss 6.24	Acc@1 59.4	Acc@5 92.2
Epoch: [134][621/704]	Time 0.120	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 90.6
Epoch: [134][631/704]	Time 0.120	Data 0.001	Loss 5.03	Acc@1 68.8	Acc@5 87.5
Epoch: [134][641/704]	Time 0.120	Data 0.001	Loss 4.88	Acc@1 73.4	Acc@5 89.1
Epoch: [134][651/704]	Time 0.120	Data 0.001	Loss 4.74	Acc@1 68.8	Acc@5 95.3
Epoch: [134][661/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 62.5	Acc@5 93.8
Epoch: [134][671/704]	Time 0.120	Data 0.001	Loss 4.56	Acc@1 76.6	Acc@5 92.2
Epoch: [134][681/704]	Time 0.120	Data 0.001	Loss 5.94	Acc@1 57.8	Acc@5 90.6
Epoch: [134][691/704]	Time 0.120	Data 0.001	Loss 4.73	Acc@1 68.8	Acc@5 93.8
Epoch: [134][701/704]	Time 0.120	Data 0.001	Loss 5.35	Acc@1 71.9	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.3699	Acc@1 56.2500	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.6664	Acc@1 53.1250	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.1734	Acc@1 48.4375	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 9.7951	Acc@1 42.1875	Acc@5 78.1250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2338	Acc@1 62.5000	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.5907	Acc@1 65.6250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.8009	Acc@1 62.5000	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.4722	Acc@1 64.0625	Acc@5 87.5000
 * prec@1 49.140 prec@5 79.060
 * prec@1 54.200 prec@5 83.360
 * prec@1 58.060 prec@5 86.160
 * prec@1 60.000 prec@5 86.760
New best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_134.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_134.pth.tar'
Epoch: [135][1/704]	Time 0.299	Data 0.132	Loss 5.30	Acc@1 67.2	Acc@5 92.2
Epoch: [135][11/704]	Time 0.137	Data 0.012	Loss 5.80	Acc@1 68.8	Acc@5 92.2
Epoch: [135][21/704]	Time 0.129	Data 0.007	Loss 3.89	Acc@1 79.7	Acc@5 93.8
Epoch: [135][31/704]	Time 0.126	Data 0.005	Loss 4.68	Acc@1 76.6	Acc@5 90.6
Epoch: [135][41/704]	Time 0.124	Data 0.004	Loss 4.47	Acc@1 76.6	Acc@5 96.9
Epoch: [135][51/704]	Time 0.124	Data 0.003	Loss 4.98	Acc@1 70.3	Acc@5 95.3
Epoch: [135][61/704]	Time 0.123	Data 0.003	Loss 5.28	Acc@1 64.1	Acc@5 89.1
Epoch: [135][71/704]	Time 0.123	Data 0.002	Loss 6.04	Acc@1 59.4	Acc@5 87.5
Epoch: [135][81/704]	Time 0.122	Data 0.002	Loss 4.54	Acc@1 71.9	Acc@5 92.2
Epoch: [135][91/704]	Time 0.122	Data 0.002	Loss 5.51	Acc@1 65.6	Acc@5 95.3
Epoch: [135][101/704]	Time 0.122	Data 0.002	Loss 3.65	Acc@1 82.8	Acc@5 98.4
Epoch: [135][111/704]	Time 0.122	Data 0.002	Loss 4.29	Acc@1 76.6	Acc@5 87.5
Epoch: [135][121/704]	Time 0.122	Data 0.001	Loss 6.00	Acc@1 64.1	Acc@5 87.5
Epoch: [135][131/704]	Time 0.122	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 93.8
Epoch: [135][141/704]	Time 0.122	Data 0.001	Loss 5.60	Acc@1 67.2	Acc@5 87.5
Epoch: [135][151/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 79.7	Acc@5 95.3
Epoch: [135][161/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 78.1	Acc@5 93.8
Epoch: [135][171/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 92.2
Epoch: [135][181/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 70.3	Acc@5 90.6
Epoch: [135][191/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 64.1	Acc@5 92.2
Epoch: [135][201/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 71.9	Acc@5 96.9
Epoch: [135][211/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 68.8	Acc@5 93.8
Epoch: [135][221/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 79.7	Acc@5 100.0
Epoch: [135][231/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 59.4	Acc@5 92.2
Epoch: [135][241/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 76.6	Acc@5 93.8
Epoch: [135][251/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 73.4	Acc@5 93.8
Epoch: [135][261/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 67.2	Acc@5 96.9
Epoch: [135][271/704]	Time 0.121	Data 0.001	Loss 4.22	Acc@1 71.9	Acc@5 96.9
Epoch: [135][281/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 93.8
Epoch: [135][291/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 68.8	Acc@5 89.1
Epoch: [135][301/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 62.5	Acc@5 93.8
Epoch: [135][311/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 68.8	Acc@5 95.3
Epoch: [135][321/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 62.5	Acc@5 93.8
Epoch: [135][331/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 81.2	Acc@5 100.0
Epoch: [135][341/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 60.9	Acc@5 90.6
Epoch: [135][351/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 76.6	Acc@5 95.3
Epoch: [135][361/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 71.9	Acc@5 92.2
Epoch: [135][371/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 65.6	Acc@5 84.4
Epoch: [135][381/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 76.6	Acc@5 93.8
Epoch: [135][391/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 71.9	Acc@5 98.4
Epoch: [135][401/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 59.4	Acc@5 89.1
Epoch: [135][411/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 70.3	Acc@5 96.9
Epoch: [135][421/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 65.6	Acc@5 95.3
Epoch: [135][431/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 75.0	Acc@5 98.4
Epoch: [135][441/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 76.6	Acc@5 92.2
Epoch: [135][451/704]	Time 0.121	Data 0.001	Loss 6.41	Acc@1 64.1	Acc@5 85.9
Epoch: [135][461/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 70.3	Acc@5 93.8
Epoch: [135][471/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 79.7	Acc@5 96.9
Epoch: [135][481/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 64.1	Acc@5 93.8
Epoch: [135][491/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 76.6	Acc@5 93.8
Epoch: [135][501/704]	Time 0.120	Data 0.001	Loss 4.51	Acc@1 67.2	Acc@5 95.3
Epoch: [135][511/704]	Time 0.120	Data 0.001	Loss 5.28	Acc@1 64.1	Acc@5 87.5
Epoch: [135][521/704]	Time 0.120	Data 0.001	Loss 4.24	Acc@1 76.6	Acc@5 90.6
Epoch: [135][531/704]	Time 0.120	Data 0.001	Loss 5.33	Acc@1 65.6	Acc@5 95.3
Epoch: [135][541/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 64.1	Acc@5 92.2
Epoch: [135][551/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 73.4	Acc@5 93.8
Epoch: [135][561/704]	Time 0.120	Data 0.001	Loss 5.36	Acc@1 70.3	Acc@5 90.6
Epoch: [135][571/704]	Time 0.120	Data 0.001	Loss 5.18	Acc@1 62.5	Acc@5 93.8
Epoch: [135][581/704]	Time 0.120	Data 0.001	Loss 4.73	Acc@1 68.8	Acc@5 87.5
Epoch: [135][591/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 68.8	Acc@5 92.2
Epoch: [135][601/704]	Time 0.121	Data 0.001	Loss 5.83	Acc@1 54.7	Acc@5 93.8
Epoch: [135][611/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 64.1	Acc@5 93.8
Epoch: [135][621/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 73.4	Acc@5 93.8
Epoch: [135][631/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 64.1	Acc@5 93.8
Epoch: [135][641/704]	Time 0.121	Data 0.001	Loss 5.74	Acc@1 62.5	Acc@5 95.3
Epoch: [135][651/704]	Time 0.120	Data 0.001	Loss 5.82	Acc@1 64.1	Acc@5 92.2
Epoch: [135][661/704]	Time 0.120	Data 0.001	Loss 5.40	Acc@1 68.8	Acc@5 96.9
Epoch: [135][671/704]	Time 0.120	Data 0.001	Loss 7.42	Acc@1 56.2	Acc@5 92.2
Epoch: [135][681/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 62.5	Acc@5 92.2
Epoch: [135][691/704]	Time 0.120	Data 0.001	Loss 4.50	Acc@1 71.9	Acc@5 98.4
Epoch: [135][701/704]	Time 0.120	Data 0.001	Loss 4.57	Acc@1 73.4	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.0888	Acc@1 56.2500	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.8106	Acc@1 56.2500	Acc@5 73.4375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8828	Acc@1 62.5000	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.0084	Acc@1 56.2500	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5954	Acc@1 62.5000	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.8947	Acc@1 64.0625	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.8857	Acc@1 59.3750	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.2515	Acc@1 65.6250	Acc@5 90.6250
 * prec@1 48.960 prec@5 79.720
 * prec@1 53.580 prec@5 83.200
 * prec@1 55.520 prec@5 85.300
 * prec@1 57.240 prec@5 85.660
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_135.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_135.pth.tar'
Epoch: [136][1/704]	Time 0.301	Data 0.131	Loss 3.85	Acc@1 82.8	Acc@5 96.9
Epoch: [136][11/704]	Time 0.141	Data 0.012	Loss 4.37	Acc@1 71.9	Acc@5 93.8
Epoch: [136][21/704]	Time 0.131	Data 0.007	Loss 4.28	Acc@1 81.2	Acc@5 95.3
Epoch: [136][31/704]	Time 0.128	Data 0.005	Loss 4.77	Acc@1 75.0	Acc@5 95.3
Epoch: [136][41/704]	Time 0.126	Data 0.004	Loss 4.30	Acc@1 73.4	Acc@5 96.9
Epoch: [136][51/704]	Time 0.125	Data 0.003	Loss 4.27	Acc@1 73.4	Acc@5 92.2
Epoch: [136][61/704]	Time 0.124	Data 0.003	Loss 4.05	Acc@1 71.9	Acc@5 98.4
Epoch: [136][71/704]	Time 0.124	Data 0.002	Loss 4.82	Acc@1 71.9	Acc@5 92.2
Epoch: [136][81/704]	Time 0.123	Data 0.002	Loss 5.31	Acc@1 70.3	Acc@5 93.8
Epoch: [136][91/704]	Time 0.123	Data 0.002	Loss 4.85	Acc@1 73.4	Acc@5 93.8
Epoch: [136][101/704]	Time 0.123	Data 0.002	Loss 5.12	Acc@1 68.8	Acc@5 93.8
Epoch: [136][111/704]	Time 0.123	Data 0.002	Loss 4.38	Acc@1 71.9	Acc@5 96.9
Epoch: [136][121/704]	Time 0.123	Data 0.001	Loss 4.42	Acc@1 70.3	Acc@5 95.3
Epoch: [136][131/704]	Time 0.122	Data 0.001	Loss 5.10	Acc@1 71.9	Acc@5 93.8
Epoch: [136][141/704]	Time 0.122	Data 0.001	Loss 4.99	Acc@1 71.9	Acc@5 92.2
Epoch: [136][151/704]	Time 0.122	Data 0.001	Loss 4.41	Acc@1 70.3	Acc@5 95.3
Epoch: [136][161/704]	Time 0.122	Data 0.001	Loss 3.84	Acc@1 76.6	Acc@5 95.3
Epoch: [136][171/704]	Time 0.122	Data 0.001	Loss 4.25	Acc@1 68.8	Acc@5 92.2
Epoch: [136][181/704]	Time 0.122	Data 0.001	Loss 4.40	Acc@1 76.6	Acc@5 96.9
Epoch: [136][191/704]	Time 0.122	Data 0.001	Loss 4.32	Acc@1 71.9	Acc@5 95.3
Epoch: [136][201/704]	Time 0.122	Data 0.001	Loss 5.33	Acc@1 71.9	Acc@5 89.1
Epoch: [136][211/704]	Time 0.122	Data 0.001	Loss 4.54	Acc@1 68.8	Acc@5 95.3
Epoch: [136][221/704]	Time 0.122	Data 0.001	Loss 5.71	Acc@1 71.9	Acc@5 92.2
Epoch: [136][231/704]	Time 0.122	Data 0.001	Loss 4.73	Acc@1 75.0	Acc@5 93.8
Epoch: [136][241/704]	Time 0.122	Data 0.001	Loss 4.70	Acc@1 75.0	Acc@5 93.8
Epoch: [136][251/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 57.8	Acc@5 93.8
Epoch: [136][261/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 67.2	Acc@5 89.1
Epoch: [136][271/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 65.6	Acc@5 90.6
Epoch: [136][281/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 62.5	Acc@5 96.9
Epoch: [136][291/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 71.9	Acc@5 93.8
Epoch: [136][301/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 65.6	Acc@5 89.1
Epoch: [136][311/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 96.9
Epoch: [136][321/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 71.9	Acc@5 95.3
Epoch: [136][331/704]	Time 0.121	Data 0.001	Loss 3.90	Acc@1 76.6	Acc@5 95.3
Epoch: [136][341/704]	Time 0.121	Data 0.001	Loss 5.69	Acc@1 62.5	Acc@5 92.2
Epoch: [136][351/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 68.8	Acc@5 89.1
Epoch: [136][361/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 62.5	Acc@5 93.8
Epoch: [136][371/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 65.6	Acc@5 92.2
Epoch: [136][381/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 75.0	Acc@5 90.6
Epoch: [136][391/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 96.9
Epoch: [136][401/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 68.8	Acc@5 96.9
Epoch: [136][411/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 71.9	Acc@5 95.3
Epoch: [136][421/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 59.4	Acc@5 93.8
Epoch: [136][431/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 62.5	Acc@5 92.2
Epoch: [136][441/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 65.6	Acc@5 90.6
Epoch: [136][451/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 73.4	Acc@5 96.9
Epoch: [136][461/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 70.3	Acc@5 90.6
Epoch: [136][471/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 64.1	Acc@5 92.2
Epoch: [136][481/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 68.8	Acc@5 96.9
Epoch: [136][491/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 65.6	Acc@5 92.2
Epoch: [136][501/704]	Time 0.121	Data 0.001	Loss 3.95	Acc@1 76.6	Acc@5 95.3
Epoch: [136][511/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 73.4	Acc@5 90.6
Epoch: [136][521/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 68.8	Acc@5 90.6
Epoch: [136][531/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 75.0	Acc@5 92.2
Epoch: [136][541/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 62.5	Acc@5 92.2
Epoch: [136][551/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 65.6	Acc@5 90.6
Epoch: [136][561/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 68.8	Acc@5 95.3
Epoch: [136][571/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 73.4	Acc@5 92.2
Epoch: [136][581/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 65.6	Acc@5 95.3
Epoch: [136][591/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 71.9	Acc@5 87.5
Epoch: [136][601/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 68.8	Acc@5 93.8
Epoch: [136][611/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 71.9	Acc@5 93.8
Epoch: [136][621/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 62.5	Acc@5 89.1
Epoch: [136][631/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 60.9	Acc@5 93.8
Epoch: [136][641/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 70.3	Acc@5 98.4
Epoch: [136][651/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 79.7	Acc@5 92.2
Epoch: [136][661/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 71.9	Acc@5 96.9
Epoch: [136][671/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 70.3	Acc@5 89.1
Epoch: [136][681/704]	Time 0.121	Data 0.001	Loss 4.28	Acc@1 68.8	Acc@5 93.8
Epoch: [136][691/704]	Time 0.121	Data 0.001	Loss 6.19	Acc@1 64.1	Acc@5 90.6
Epoch: [136][701/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 60.9	Acc@5 89.1
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.0910	Acc@1 57.8125	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7657	Acc@1 65.6250	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2480	Acc@1 57.8125	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6825	Acc@1 56.2500	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4443	Acc@1 59.3750	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.3878	Acc@1 54.6875	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.2363	Acc@1 59.3750	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.6400	Acc@1 62.5000	Acc@5 85.9375
 * prec@1 46.820 prec@5 76.580
 * prec@1 52.080 prec@5 82.300
 * prec@1 56.500 prec@5 85.460
 * prec@1 58.780 prec@5 86.640
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_136.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_136.pth.tar'
Epoch: [137][1/704]	Time 0.328	Data 0.162	Loss 4.25	Acc@1 75.0	Acc@5 92.2
Epoch: [137][11/704]	Time 0.139	Data 0.015	Loss 5.12	Acc@1 65.6	Acc@5 96.9
Epoch: [137][21/704]	Time 0.130	Data 0.008	Loss 5.33	Acc@1 67.2	Acc@5 90.6
Epoch: [137][31/704]	Time 0.127	Data 0.006	Loss 4.46	Acc@1 70.3	Acc@5 92.2
Epoch: [137][41/704]	Time 0.125	Data 0.004	Loss 4.43	Acc@1 70.3	Acc@5 95.3
Epoch: [137][51/704]	Time 0.124	Data 0.004	Loss 4.11	Acc@1 79.7	Acc@5 93.8
Epoch: [137][61/704]	Time 0.123	Data 0.003	Loss 5.48	Acc@1 67.2	Acc@5 90.6
Epoch: [137][71/704]	Time 0.123	Data 0.003	Loss 5.39	Acc@1 71.9	Acc@5 89.1
Epoch: [137][81/704]	Time 0.123	Data 0.002	Loss 5.07	Acc@1 73.4	Acc@5 90.6
Epoch: [137][91/704]	Time 0.122	Data 0.002	Loss 3.38	Acc@1 67.2	Acc@5 98.4
Epoch: [137][101/704]	Time 0.122	Data 0.002	Loss 4.70	Acc@1 71.9	Acc@5 96.9
Epoch: [137][111/704]	Time 0.122	Data 0.002	Loss 5.11	Acc@1 62.5	Acc@5 95.3
Epoch: [137][121/704]	Time 0.122	Data 0.002	Loss 5.95	Acc@1 64.1	Acc@5 95.3
Epoch: [137][131/704]	Time 0.122	Data 0.002	Loss 5.81	Acc@1 57.8	Acc@5 89.1
Epoch: [137][141/704]	Time 0.122	Data 0.002	Loss 3.57	Acc@1 81.2	Acc@5 93.8
Epoch: [137][151/704]	Time 0.121	Data 0.001	Loss 3.80	Acc@1 79.7	Acc@5 95.3
Epoch: [137][161/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 64.1	Acc@5 90.6
Epoch: [137][171/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 75.0	Acc@5 89.1
Epoch: [137][181/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 76.6	Acc@5 92.2
Epoch: [137][191/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 67.2	Acc@5 90.6
Epoch: [137][201/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 75.0	Acc@5 93.8
Epoch: [137][211/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 81.2	Acc@5 96.9
Epoch: [137][221/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 67.2	Acc@5 93.8
Epoch: [137][231/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 78.1	Acc@5 96.9
Epoch: [137][241/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 71.9	Acc@5 90.6
Epoch: [137][251/704]	Time 0.121	Data 0.001	Loss 5.77	Acc@1 64.1	Acc@5 89.1
Epoch: [137][261/704]	Time 0.121	Data 0.001	Loss 6.45	Acc@1 50.0	Acc@5 92.2
Epoch: [137][271/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 65.6	Acc@5 93.8
Epoch: [137][281/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 70.3	Acc@5 89.1
Epoch: [137][291/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 78.1	Acc@5 90.6
Epoch: [137][301/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 65.6	Acc@5 92.2
Epoch: [137][311/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 76.6	Acc@5 93.8
Epoch: [137][321/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 62.5	Acc@5 92.2
Epoch: [137][331/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 68.8	Acc@5 90.6
Epoch: [137][341/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 96.9
Epoch: [137][351/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 70.3	Acc@5 95.3
Epoch: [137][361/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 68.8	Acc@5 93.8
Epoch: [137][371/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 71.9	Acc@5 90.6
Epoch: [137][381/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 57.8	Acc@5 89.1
Epoch: [137][391/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 75.0	Acc@5 92.2
Epoch: [137][401/704]	Time 0.121	Data 0.001	Loss 6.84	Acc@1 64.1	Acc@5 84.4
Epoch: [137][411/704]	Time 0.121	Data 0.001	Loss 6.11	Acc@1 54.7	Acc@5 87.5
Epoch: [137][421/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 67.2	Acc@5 95.3
Epoch: [137][431/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 93.8
Epoch: [137][441/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 65.6	Acc@5 89.1
Epoch: [137][451/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 64.1	Acc@5 89.1
Epoch: [137][461/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 68.8	Acc@5 93.8
Epoch: [137][471/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 76.6	Acc@5 95.3
Epoch: [137][481/704]	Time 0.120	Data 0.001	Loss 5.37	Acc@1 60.9	Acc@5 90.6
Epoch: [137][491/704]	Time 0.120	Data 0.001	Loss 4.64	Acc@1 71.9	Acc@5 93.8
Epoch: [137][501/704]	Time 0.120	Data 0.001	Loss 5.32	Acc@1 70.3	Acc@5 89.1
Epoch: [137][511/704]	Time 0.120	Data 0.001	Loss 4.32	Acc@1 75.0	Acc@5 93.8
Epoch: [137][521/704]	Time 0.120	Data 0.001	Loss 4.56	Acc@1 76.6	Acc@5 92.2
Epoch: [137][531/704]	Time 0.120	Data 0.001	Loss 4.52	Acc@1 70.3	Acc@5 90.6
Epoch: [137][541/704]	Time 0.120	Data 0.001	Loss 5.06	Acc@1 70.3	Acc@5 95.3
Epoch: [137][551/704]	Time 0.120	Data 0.001	Loss 4.51	Acc@1 73.4	Acc@5 92.2
Epoch: [137][561/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 67.2	Acc@5 90.6
Epoch: [137][571/704]	Time 0.120	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 87.5
Epoch: [137][581/704]	Time 0.120	Data 0.001	Loss 5.58	Acc@1 65.6	Acc@5 92.2
Epoch: [137][591/704]	Time 0.120	Data 0.001	Loss 4.90	Acc@1 70.3	Acc@5 95.3
Epoch: [137][601/704]	Time 0.120	Data 0.001	Loss 4.94	Acc@1 70.3	Acc@5 93.8
Epoch: [137][611/704]	Time 0.120	Data 0.001	Loss 4.16	Acc@1 73.4	Acc@5 96.9
Epoch: [137][621/704]	Time 0.120	Data 0.001	Loss 4.08	Acc@1 73.4	Acc@5 98.4
Epoch: [137][631/704]	Time 0.120	Data 0.001	Loss 4.28	Acc@1 65.6	Acc@5 98.4
Epoch: [137][641/704]	Time 0.120	Data 0.001	Loss 5.57	Acc@1 60.9	Acc@5 87.5
Epoch: [137][651/704]	Time 0.120	Data 0.001	Loss 5.26	Acc@1 65.6	Acc@5 92.2
Epoch: [137][661/704]	Time 0.120	Data 0.001	Loss 4.22	Acc@1 76.6	Acc@5 96.9
Epoch: [137][671/704]	Time 0.120	Data 0.001	Loss 4.35	Acc@1 76.6	Acc@5 89.1
Epoch: [137][681/704]	Time 0.120	Data 0.001	Loss 5.34	Acc@1 75.0	Acc@5 92.2
Epoch: [137][691/704]	Time 0.120	Data 0.001	Loss 5.27	Acc@1 62.5	Acc@5 93.8
Epoch: [137][701/704]	Time 0.120	Data 0.001	Loss 4.66	Acc@1 70.3	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.1715	Acc@1 50.0000	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.4608	Acc@1 59.3750	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.3324	Acc@1 45.3125	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4777	Acc@1 60.9375	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6210	Acc@1 64.0625	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.3953	Acc@1 59.3750	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.6875	Acc@1 64.0625	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.4882	Acc@1 60.9375	Acc@5 92.1875
 * prec@1 49.900 prec@5 80.440
 * prec@1 53.700 prec@5 83.620
 * prec@1 57.320 prec@5 85.500
 * prec@1 59.360 prec@5 86.120
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_137.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_137.pth.tar'
Epoch: [138][1/704]	Time 0.300	Data 0.132	Loss 3.88	Acc@1 82.8	Acc@5 93.8
Epoch: [138][11/704]	Time 0.137	Data 0.012	Loss 3.91	Acc@1 67.2	Acc@5 95.3
Epoch: [138][21/704]	Time 0.129	Data 0.007	Loss 5.41	Acc@1 62.5	Acc@5 96.9
Epoch: [138][31/704]	Time 0.126	Data 0.005	Loss 5.12	Acc@1 62.5	Acc@5 92.2
Epoch: [138][41/704]	Time 0.124	Data 0.004	Loss 5.52	Acc@1 65.6	Acc@5 92.2
Epoch: [138][51/704]	Time 0.124	Data 0.003	Loss 4.47	Acc@1 81.2	Acc@5 96.9
Epoch: [138][61/704]	Time 0.123	Data 0.003	Loss 5.09	Acc@1 64.1	Acc@5 93.8
Epoch: [138][71/704]	Time 0.123	Data 0.002	Loss 4.83	Acc@1 73.4	Acc@5 98.4
Epoch: [138][81/704]	Time 0.122	Data 0.002	Loss 4.93	Acc@1 73.4	Acc@5 93.8
Epoch: [138][91/704]	Time 0.122	Data 0.002	Loss 4.71	Acc@1 65.6	Acc@5 96.9
Epoch: [138][101/704]	Time 0.122	Data 0.002	Loss 6.18	Acc@1 68.8	Acc@5 92.2
Epoch: [138][111/704]	Time 0.122	Data 0.002	Loss 4.31	Acc@1 73.4	Acc@5 95.3
Epoch: [138][121/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 75.0	Acc@5 95.3
Epoch: [138][131/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 76.6	Acc@5 92.2
Epoch: [138][141/704]	Time 0.122	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 93.8
Epoch: [138][151/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 68.8	Acc@5 96.9
Epoch: [138][161/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 78.1	Acc@5 93.8
Epoch: [138][171/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 65.6	Acc@5 87.5
Epoch: [138][181/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 70.3	Acc@5 93.8
Epoch: [138][191/704]	Time 0.121	Data 0.001	Loss 4.30	Acc@1 70.3	Acc@5 95.3
Epoch: [138][201/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 76.6	Acc@5 92.2
Epoch: [138][211/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 78.1	Acc@5 95.3
Epoch: [138][221/704]	Time 0.121	Data 0.001	Loss 3.86	Acc@1 81.2	Acc@5 98.4
Epoch: [138][231/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 65.6	Acc@5 90.6
Epoch: [138][241/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 71.9	Acc@5 90.6
Epoch: [138][251/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 75.0	Acc@5 98.4
Epoch: [138][261/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 70.3	Acc@5 93.8
Epoch: [138][271/704]	Time 0.121	Data 0.001	Loss 3.77	Acc@1 79.7	Acc@5 98.4
Epoch: [138][281/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 64.1	Acc@5 84.4
Epoch: [138][291/704]	Time 0.121	Data 0.001	Loss 5.55	Acc@1 59.4	Acc@5 85.9
Epoch: [138][301/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 57.8	Acc@5 92.2
Epoch: [138][311/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 70.3	Acc@5 90.6
Epoch: [138][321/704]	Time 0.121	Data 0.001	Loss 3.62	Acc@1 82.8	Acc@5 98.4
Epoch: [138][331/704]	Time 0.121	Data 0.001	Loss 3.57	Acc@1 73.4	Acc@5 96.9
Epoch: [138][341/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 75.0	Acc@5 95.3
Epoch: [138][351/704]	Time 0.121	Data 0.001	Loss 4.21	Acc@1 78.1	Acc@5 96.9
Epoch: [138][361/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 75.0	Acc@5 93.8
Epoch: [138][371/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 68.8	Acc@5 95.3
Epoch: [138][381/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 64.1	Acc@5 89.1
Epoch: [138][391/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 67.2	Acc@5 92.2
Epoch: [138][401/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 76.6	Acc@5 95.3
Epoch: [138][411/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 67.2	Acc@5 93.8
Epoch: [138][421/704]	Time 0.121	Data 0.001	Loss 7.25	Acc@1 56.2	Acc@5 85.9
Epoch: [138][431/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 71.9	Acc@5 90.6
Epoch: [138][441/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 59.4	Acc@5 93.8
Epoch: [138][451/704]	Time 0.121	Data 0.001	Loss 5.57	Acc@1 67.2	Acc@5 93.8
Epoch: [138][461/704]	Time 0.121	Data 0.001	Loss 4.61	Acc@1 68.8	Acc@5 89.1
Epoch: [138][471/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 62.5	Acc@5 95.3
Epoch: [138][481/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 76.6	Acc@5 93.8
Epoch: [138][491/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 71.9	Acc@5 92.2
Epoch: [138][501/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 76.6	Acc@5 90.6
Epoch: [138][511/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 60.9	Acc@5 92.2
Epoch: [138][521/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 65.6	Acc@5 92.2
Epoch: [138][531/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 70.3	Acc@5 95.3
Epoch: [138][541/704]	Time 0.121	Data 0.001	Loss 4.39	Acc@1 67.2	Acc@5 93.8
Epoch: [138][551/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 73.4	Acc@5 95.3
Epoch: [138][561/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 68.8	Acc@5 89.1
Epoch: [138][571/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 75.0	Acc@5 90.6
Epoch: [138][581/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 75.0	Acc@5 95.3
Epoch: [138][591/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 93.8
Epoch: [138][601/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 62.5	Acc@5 90.6
Epoch: [138][611/704]	Time 0.120	Data 0.001	Loss 5.01	Acc@1 64.1	Acc@5 92.2
Epoch: [138][621/704]	Time 0.120	Data 0.001	Loss 4.84	Acc@1 59.4	Acc@5 93.8
Epoch: [138][631/704]	Time 0.120	Data 0.001	Loss 6.62	Acc@1 59.4	Acc@5 90.6
Epoch: [138][641/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 65.6	Acc@5 93.8
Epoch: [138][651/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 70.3	Acc@5 95.3
Epoch: [138][661/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 71.9	Acc@5 96.9
Epoch: [138][671/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 68.8	Acc@5 87.5
Epoch: [138][681/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 68.8	Acc@5 92.2
Epoch: [138][691/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 57.8	Acc@5 95.3
Epoch: [138][701/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 71.9	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.2517	Acc@1 64.0625	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 8.2883	Acc@1 53.1250	Acc@5 78.1250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2053	Acc@1 75.0000	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.0470	Acc@1 59.3750	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.3911	Acc@1 59.3750	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.1125	Acc@1 50.0000	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.6616	Acc@1 56.2500	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.2983	Acc@1 45.3125	Acc@5 79.6875
 * prec@1 47.640 prec@5 78.440
 * prec@1 53.740 prec@5 83.420
 * prec@1 58.280 prec@5 86.140
 * prec@1 57.720 prec@5 86.540
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_138.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_138.pth.tar'
Epoch: [139][1/704]	Time 0.298	Data 0.131	Loss 4.81	Acc@1 67.2	Acc@5 95.3
Epoch: [139][11/704]	Time 0.136	Data 0.012	Loss 4.19	Acc@1 67.2	Acc@5 98.4
Epoch: [139][21/704]	Time 0.129	Data 0.006	Loss 4.70	Acc@1 67.2	Acc@5 95.3
Epoch: [139][31/704]	Time 0.126	Data 0.004	Loss 4.69	Acc@1 67.2	Acc@5 92.2
Epoch: [139][41/704]	Time 0.124	Data 0.003	Loss 5.06	Acc@1 70.3	Acc@5 93.8
Epoch: [139][51/704]	Time 0.123	Data 0.003	Loss 3.93	Acc@1 82.8	Acc@5 96.9
Epoch: [139][61/704]	Time 0.124	Data 0.002	Loss 5.41	Acc@1 64.1	Acc@5 92.2
Epoch: [139][71/704]	Time 0.123	Data 0.002	Loss 4.84	Acc@1 71.9	Acc@5 90.6
Epoch: [139][81/704]	Time 0.123	Data 0.002	Loss 4.41	Acc@1 75.0	Acc@5 93.8
Epoch: [139][91/704]	Time 0.122	Data 0.002	Loss 3.95	Acc@1 68.8	Acc@5 95.3
Epoch: [139][101/704]	Time 0.122	Data 0.002	Loss 4.21	Acc@1 73.4	Acc@5 93.8
Epoch: [139][111/704]	Time 0.122	Data 0.001	Loss 4.61	Acc@1 67.2	Acc@5 93.8
Epoch: [139][121/704]	Time 0.122	Data 0.001	Loss 4.68	Acc@1 67.2	Acc@5 93.8
Epoch: [139][131/704]	Time 0.122	Data 0.001	Loss 5.62	Acc@1 60.9	Acc@5 90.6
Epoch: [139][141/704]	Time 0.122	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 93.8
Epoch: [139][151/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 57.8	Acc@5 89.1
Epoch: [139][161/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 71.9	Acc@5 92.2
Epoch: [139][171/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 76.6	Acc@5 98.4
Epoch: [139][181/704]	Time 0.121	Data 0.001	Loss 3.99	Acc@1 81.2	Acc@5 96.9
Epoch: [139][191/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 68.8	Acc@5 92.2
Epoch: [139][201/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 73.4	Acc@5 96.9
Epoch: [139][211/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 68.8	Acc@5 93.8
Epoch: [139][221/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 71.9	Acc@5 96.9
Epoch: [139][231/704]	Time 0.121	Data 0.001	Loss 3.99	Acc@1 73.4	Acc@5 95.3
Epoch: [139][241/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 65.6	Acc@5 90.6
Epoch: [139][251/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 70.3	Acc@5 90.6
Epoch: [139][261/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 79.7	Acc@5 92.2
Epoch: [139][271/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 60.9	Acc@5 93.8
Epoch: [139][281/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 76.6	Acc@5 96.9
Epoch: [139][291/704]	Time 0.121	Data 0.001	Loss 5.10	Acc@1 64.1	Acc@5 93.8
Epoch: [139][301/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 76.6	Acc@5 96.9
Epoch: [139][311/704]	Time 0.121	Data 0.001	Loss 5.90	Acc@1 67.2	Acc@5 89.1
Epoch: [139][321/704]	Time 0.121	Data 0.001	Loss 6.16	Acc@1 67.2	Acc@5 93.8
Epoch: [139][331/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 68.8	Acc@5 96.9
Epoch: [139][341/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 78.1	Acc@5 95.3
Epoch: [139][351/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 71.9	Acc@5 95.3
Epoch: [139][361/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 67.2	Acc@5 93.8
Epoch: [139][371/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 76.6	Acc@5 96.9
Epoch: [139][381/704]	Time 0.121	Data 0.001	Loss 4.62	Acc@1 64.1	Acc@5 93.8
Epoch: [139][391/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 70.3	Acc@5 98.4
Epoch: [139][401/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 68.8	Acc@5 93.8
Epoch: [139][411/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 64.1	Acc@5 95.3
Epoch: [139][421/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 71.9	Acc@5 89.1
Epoch: [139][431/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 71.9	Acc@5 95.3
Epoch: [139][441/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 68.8	Acc@5 98.4
Epoch: [139][451/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 68.8	Acc@5 95.3
Epoch: [139][461/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 70.3	Acc@5 93.8
Epoch: [139][471/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 65.6	Acc@5 96.9
Epoch: [139][481/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 71.9	Acc@5 93.8
Epoch: [139][491/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 70.3	Acc@5 92.2
Epoch: [139][501/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 75.0	Acc@5 89.1
Epoch: [139][511/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 62.5	Acc@5 92.2
Epoch: [139][521/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 68.8	Acc@5 93.8
Epoch: [139][531/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 70.3	Acc@5 90.6
Epoch: [139][541/704]	Time 0.121	Data 0.001	Loss 6.22	Acc@1 59.4	Acc@5 90.6
Epoch: [139][551/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 65.6	Acc@5 87.5
Epoch: [139][561/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 64.1	Acc@5 87.5
Epoch: [139][571/704]	Time 0.121	Data 0.001	Loss 6.50	Acc@1 57.8	Acc@5 85.9
Epoch: [139][581/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 67.2	Acc@5 98.4
Epoch: [139][591/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 62.5	Acc@5 95.3
Epoch: [139][601/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 68.8	Acc@5 96.9
Epoch: [139][611/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 68.8	Acc@5 95.3
Epoch: [139][621/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 62.5	Acc@5 92.2
Epoch: [139][631/704]	Time 0.120	Data 0.001	Loss 4.68	Acc@1 71.9	Acc@5 92.2
Epoch: [139][641/704]	Time 0.120	Data 0.001	Loss 5.55	Acc@1 60.9	Acc@5 92.2
Epoch: [139][651/704]	Time 0.120	Data 0.001	Loss 5.04	Acc@1 68.8	Acc@5 93.8
Epoch: [139][661/704]	Time 0.120	Data 0.001	Loss 5.17	Acc@1 67.2	Acc@5 95.3
Epoch: [139][671/704]	Time 0.120	Data 0.001	Loss 5.19	Acc@1 65.6	Acc@5 89.1
Epoch: [139][681/704]	Time 0.120	Data 0.001	Loss 5.74	Acc@1 65.6	Acc@5 92.2
Epoch: [139][691/704]	Time 0.120	Data 0.001	Loss 5.24	Acc@1 71.9	Acc@5 92.2
Epoch: [139][701/704]	Time 0.120	Data 0.001	Loss 5.13	Acc@1 75.0	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.6890	Acc@1 50.0000	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 8.0911	Acc@1 48.4375	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.4106	Acc@1 59.3750	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3118	Acc@1 59.3750	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6980	Acc@1 56.2500	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.8766	Acc@1 59.3750	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7252	Acc@1 54.6875	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.6272	Acc@1 59.3750	Acc@5 79.6875
 * prec@1 48.280 prec@5 78.580
 * prec@1 53.060 prec@5 83.140
 * prec@1 56.300 prec@5 85.400
 * prec@1 57.260 prec@5 85.960
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_139.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_139.pth.tar'
Epoch: [140][1/704]	Time 0.331	Data 0.165	Loss 4.19	Acc@1 71.9	Acc@5 92.2
Epoch: [140][11/704]	Time 0.139	Data 0.015	Loss 5.24	Acc@1 64.1	Acc@5 87.5
Epoch: [140][21/704]	Time 0.130	Data 0.008	Loss 4.79	Acc@1 70.3	Acc@5 92.2
Epoch: [140][31/704]	Time 0.127	Data 0.006	Loss 4.60	Acc@1 68.8	Acc@5 95.3
Epoch: [140][41/704]	Time 0.125	Data 0.004	Loss 3.88	Acc@1 79.7	Acc@5 96.9
Epoch: [140][51/704]	Time 0.124	Data 0.004	Loss 5.06	Acc@1 67.2	Acc@5 95.3
Epoch: [140][61/704]	Time 0.123	Data 0.003	Loss 5.69	Acc@1 62.5	Acc@5 90.6
Epoch: [140][71/704]	Time 0.123	Data 0.003	Loss 4.83	Acc@1 65.6	Acc@5 93.8
Epoch: [140][81/704]	Time 0.122	Data 0.002	Loss 4.04	Acc@1 75.0	Acc@5 96.9
Epoch: [140][91/704]	Time 0.122	Data 0.002	Loss 5.90	Acc@1 64.1	Acc@5 92.2
Epoch: [140][101/704]	Time 0.122	Data 0.002	Loss 5.09	Acc@1 70.3	Acc@5 93.8
Epoch: [140][111/704]	Time 0.122	Data 0.002	Loss 4.95	Acc@1 70.3	Acc@5 90.6
Epoch: [140][121/704]	Time 0.121	Data 0.002	Loss 4.72	Acc@1 71.9	Acc@5 96.9
Epoch: [140][131/704]	Time 0.121	Data 0.002	Loss 4.49	Acc@1 64.1	Acc@5 93.8
Epoch: [140][141/704]	Time 0.121	Data 0.002	Loss 4.07	Acc@1 73.4	Acc@5 96.9
Epoch: [140][151/704]	Time 0.121	Data 0.001	Loss 6.70	Acc@1 60.9	Acc@5 90.6
Epoch: [140][161/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 70.3	Acc@5 95.3
Epoch: [140][171/704]	Time 0.121	Data 0.001	Loss 6.01	Acc@1 65.6	Acc@5 89.1
Epoch: [140][181/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 73.4	Acc@5 92.2
Epoch: [140][191/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 68.8	Acc@5 92.2
Epoch: [140][201/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 71.9	Acc@5 92.2
Epoch: [140][211/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 73.4	Acc@5 93.8
Epoch: [140][221/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 93.8
Epoch: [140][231/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 62.5	Acc@5 90.6
Epoch: [140][241/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 59.4	Acc@5 89.1
Epoch: [140][251/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 75.0	Acc@5 92.2
Epoch: [140][261/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 76.6	Acc@5 93.8
Epoch: [140][271/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 71.9	Acc@5 93.8
Epoch: [140][281/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 64.1	Acc@5 89.1
Epoch: [140][291/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 73.4	Acc@5 92.2
Epoch: [140][301/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 67.2	Acc@5 92.2
Epoch: [140][311/704]	Time 0.121	Data 0.001	Loss 6.05	Acc@1 65.6	Acc@5 89.1
Epoch: [140][321/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 76.6	Acc@5 92.2
Epoch: [140][331/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 70.3	Acc@5 93.8
Epoch: [140][341/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 68.8	Acc@5 92.2
Epoch: [140][351/704]	Time 0.121	Data 0.001	Loss 4.15	Acc@1 76.6	Acc@5 95.3
Epoch: [140][361/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 70.3	Acc@5 93.8
Epoch: [140][371/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 68.8	Acc@5 95.3
Epoch: [140][381/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 70.3	Acc@5 93.8
Epoch: [140][391/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 70.3	Acc@5 96.9
Epoch: [140][401/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 71.9	Acc@5 93.8
Epoch: [140][411/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 73.4	Acc@5 93.8
Epoch: [140][421/704]	Time 0.121	Data 0.001	Loss 4.99	Acc@1 65.6	Acc@5 96.9
Epoch: [140][431/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 65.6	Acc@5 96.9
Epoch: [140][441/704]	Time 0.121	Data 0.001	Loss 6.00	Acc@1 64.1	Acc@5 93.8
Epoch: [140][451/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 71.9	Acc@5 93.8
Epoch: [140][461/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 65.6	Acc@5 89.1
Epoch: [140][471/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 70.3	Acc@5 92.2
Epoch: [140][481/704]	Time 0.121	Data 0.001	Loss 6.29	Acc@1 68.8	Acc@5 87.5
Epoch: [140][491/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 70.3	Acc@5 93.8
Epoch: [140][501/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 60.9	Acc@5 95.3
Epoch: [140][511/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 60.9	Acc@5 93.8
Epoch: [140][521/704]	Time 0.121	Data 0.001	Loss 5.66	Acc@1 65.6	Acc@5 93.8
Epoch: [140][531/704]	Time 0.121	Data 0.001	Loss 3.59	Acc@1 71.9	Acc@5 96.9
Epoch: [140][541/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 92.2
Epoch: [140][551/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 62.5	Acc@5 90.6
Epoch: [140][561/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 93.8
Epoch: [140][571/704]	Time 0.121	Data 0.001	Loss 6.36	Acc@1 62.5	Acc@5 81.2
Epoch: [140][581/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 64.1	Acc@5 93.8
Epoch: [140][591/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 78.1	Acc@5 95.3
Epoch: [140][601/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 65.6	Acc@5 93.8
Epoch: [140][611/704]	Time 0.121	Data 0.001	Loss 6.10	Acc@1 60.9	Acc@5 79.7
Epoch: [140][621/704]	Time 0.121	Data 0.001	Loss 5.93	Acc@1 65.6	Acc@5 95.3
Epoch: [140][631/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 68.8	Acc@5 93.8
Epoch: [140][641/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 70.3	Acc@5 93.8
Epoch: [140][651/704]	Time 0.120	Data 0.001	Loss 5.43	Acc@1 70.3	Acc@5 93.8
Epoch: [140][661/704]	Time 0.120	Data 0.001	Loss 4.69	Acc@1 70.3	Acc@5 92.2
Epoch: [140][671/704]	Time 0.120	Data 0.001	Loss 4.38	Acc@1 76.6	Acc@5 90.6
Epoch: [140][681/704]	Time 0.120	Data 0.001	Loss 5.14	Acc@1 67.2	Acc@5 93.8
Epoch: [140][691/704]	Time 0.120	Data 0.001	Loss 4.78	Acc@1 71.9	Acc@5 93.8
Epoch: [140][701/704]	Time 0.120	Data 0.001	Loss 4.38	Acc@1 68.8	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 8.9768	Acc@1 46.8750	Acc@5 73.4375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.1160	Acc@1 48.4375	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.9800	Acc@1 57.8125	Acc@5 79.6875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.1014	Acc@1 42.1875	Acc@5 78.1250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7341	Acc@1 54.6875	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 9.9041	Acc@1 42.1875	Acc@5 76.5625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.8873	Acc@1 50.0000	Acc@5 78.1250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.8446	Acc@1 56.2500	Acc@5 81.2500
 * prec@1 48.080 prec@5 78.500
 * prec@1 51.340 prec@5 81.060
 * prec@1 53.700 prec@5 82.980
 * prec@1 55.460 prec@5 84.560
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_140.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_140.pth.tar'
Epoch: [141][1/704]	Time 0.329	Data 0.162	Loss 5.12	Acc@1 68.8	Acc@5 95.3
Epoch: [141][11/704]	Time 0.140	Data 0.015	Loss 4.72	Acc@1 64.1	Acc@5 96.9
Epoch: [141][21/704]	Time 0.130	Data 0.008	Loss 4.06	Acc@1 78.1	Acc@5 95.3
Epoch: [141][31/704]	Time 0.127	Data 0.006	Loss 4.56	Acc@1 70.3	Acc@5 96.9
Epoch: [141][41/704]	Time 0.125	Data 0.004	Loss 4.73	Acc@1 68.8	Acc@5 96.9
Epoch: [141][51/704]	Time 0.124	Data 0.003	Loss 4.74	Acc@1 65.6	Acc@5 87.5
Epoch: [141][61/704]	Time 0.124	Data 0.003	Loss 4.40	Acc@1 75.0	Acc@5 95.3
Epoch: [141][71/704]	Time 0.123	Data 0.003	Loss 4.46	Acc@1 71.9	Acc@5 95.3
Epoch: [141][81/704]	Time 0.123	Data 0.002	Loss 4.57	Acc@1 73.4	Acc@5 93.8
Epoch: [141][91/704]	Time 0.123	Data 0.002	Loss 4.35	Acc@1 68.8	Acc@5 96.9
Epoch: [141][101/704]	Time 0.122	Data 0.002	Loss 3.57	Acc@1 82.8	Acc@5 95.3
Epoch: [141][111/704]	Time 0.122	Data 0.002	Loss 4.96	Acc@1 71.9	Acc@5 92.2
Epoch: [141][121/704]	Time 0.122	Data 0.002	Loss 4.13	Acc@1 76.6	Acc@5 96.9
Epoch: [141][131/704]	Time 0.122	Data 0.002	Loss 5.66	Acc@1 68.8	Acc@5 90.6
Epoch: [141][141/704]	Time 0.122	Data 0.001	Loss 4.72	Acc@1 67.2	Acc@5 92.2
Epoch: [141][151/704]	Time 0.122	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 93.8
Epoch: [141][161/704]	Time 0.122	Data 0.001	Loss 4.24	Acc@1 81.2	Acc@5 96.9
Epoch: [141][171/704]	Time 0.122	Data 0.001	Loss 4.48	Acc@1 59.4	Acc@5 96.9
Epoch: [141][181/704]	Time 0.122	Data 0.001	Loss 5.63	Acc@1 62.5	Acc@5 87.5
Epoch: [141][191/704]	Time 0.122	Data 0.001	Loss 4.82	Acc@1 71.9	Acc@5 95.3
Epoch: [141][201/704]	Time 0.122	Data 0.001	Loss 5.21	Acc@1 65.6	Acc@5 93.8
Epoch: [141][211/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 67.2	Acc@5 92.2
Epoch: [141][221/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 78.1	Acc@5 95.3
Epoch: [141][231/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 70.3	Acc@5 92.2
Epoch: [141][241/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 68.8	Acc@5 93.8
Epoch: [141][251/704]	Time 0.121	Data 0.001	Loss 5.75	Acc@1 64.1	Acc@5 95.3
Epoch: [141][261/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 67.2	Acc@5 95.3
Epoch: [141][271/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 68.8	Acc@5 96.9
Epoch: [141][281/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 62.5	Acc@5 95.3
Epoch: [141][291/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 70.3	Acc@5 92.2
Epoch: [141][301/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 64.1	Acc@5 92.2
Epoch: [141][311/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 65.6	Acc@5 92.2
Epoch: [141][321/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 70.3	Acc@5 95.3
Epoch: [141][331/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 71.9	Acc@5 92.2
Epoch: [141][341/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 68.8	Acc@5 95.3
Epoch: [141][351/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 68.8	Acc@5 92.2
Epoch: [141][361/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 68.8	Acc@5 96.9
Epoch: [141][371/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 78.1	Acc@5 89.1
Epoch: [141][381/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 70.3	Acc@5 93.8
Epoch: [141][391/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 73.4	Acc@5 90.6
Epoch: [141][401/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 65.6	Acc@5 95.3
Epoch: [141][411/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 65.6	Acc@5 90.6
Epoch: [141][421/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 68.8	Acc@5 92.2
Epoch: [141][431/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 64.1	Acc@5 87.5
Epoch: [141][441/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 60.9	Acc@5 89.1
Epoch: [141][451/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 68.8	Acc@5 90.6
Epoch: [141][461/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 64.1	Acc@5 93.8
Epoch: [141][471/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 67.2	Acc@5 92.2
Epoch: [141][481/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 73.4	Acc@5 92.2
Epoch: [141][491/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 78.1	Acc@5 100.0
Epoch: [141][501/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 76.6	Acc@5 93.8
Epoch: [141][511/704]	Time 0.121	Data 0.001	Loss 5.53	Acc@1 65.6	Acc@5 90.6
Epoch: [141][521/704]	Time 0.121	Data 0.001	Loss 3.51	Acc@1 78.1	Acc@5 96.9
Epoch: [141][531/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 62.5	Acc@5 89.1
Epoch: [141][541/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 75.0	Acc@5 95.3
Epoch: [141][551/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 75.0	Acc@5 90.6
Epoch: [141][561/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 67.2	Acc@5 95.3
Epoch: [141][571/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 73.4	Acc@5 95.3
Epoch: [141][581/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 67.2	Acc@5 95.3
Epoch: [141][591/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 64.1	Acc@5 92.2
Epoch: [141][601/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 64.1	Acc@5 92.2
Epoch: [141][611/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 71.9	Acc@5 93.8
Epoch: [141][621/704]	Time 0.121	Data 0.001	Loss 6.32	Acc@1 62.5	Acc@5 89.1
Epoch: [141][631/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 64.1	Acc@5 95.3
Epoch: [141][641/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 75.0	Acc@5 98.4
Epoch: [141][651/704]	Time 0.121	Data 0.001	Loss 4.28	Acc@1 73.4	Acc@5 95.3
Epoch: [141][661/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 70.3	Acc@5 95.3
Epoch: [141][671/704]	Time 0.121	Data 0.001	Loss 5.81	Acc@1 60.9	Acc@5 93.8
Epoch: [141][681/704]	Time 0.121	Data 0.001	Loss 4.59	Acc@1 71.9	Acc@5 95.3
Epoch: [141][691/704]	Time 0.121	Data 0.001	Loss 3.76	Acc@1 76.6	Acc@5 95.3
Epoch: [141][701/704]	Time 0.121	Data 0.001	Loss 5.15	Acc@1 60.9	Acc@5 92.2
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 9.1228	Acc@1 50.0000	Acc@5 76.5625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7522	Acc@1 57.8125	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8390	Acc@1 64.0625	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.4561	Acc@1 51.5625	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4298	Acc@1 60.9375	Acc@5 84.3750
Epoch: [51/79]	Time 0.019	Data 0.006	Loss 7.0337	Acc@1 53.1250	Acc@5 89.0625
Epoch: [61/79]	Time 0.019	Data 0.006	Loss 6.7545	Acc@1 54.6875	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 8.0206	Acc@1 46.8750	Acc@5 79.6875
 * prec@1 47.460 prec@5 78.960
 * prec@1 51.440 prec@5 81.940
 * prec@1 55.720 prec@5 84.760
 * prec@1 56.420 prec@5 85.480
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_141.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_141.pth.tar'
Epoch: [142][1/704]	Time 0.301	Data 0.133	Loss 3.62	Acc@1 81.2	Acc@5 96.9
Epoch: [142][11/704]	Time 0.137	Data 0.012	Loss 4.91	Acc@1 71.9	Acc@5 95.3
Epoch: [142][21/704]	Time 0.129	Data 0.007	Loss 4.01	Acc@1 71.9	Acc@5 100.0
Epoch: [142][31/704]	Time 0.127	Data 0.005	Loss 4.49	Acc@1 73.4	Acc@5 90.6
Epoch: [142][41/704]	Time 0.125	Data 0.004	Loss 5.24	Acc@1 67.2	Acc@5 93.8
Epoch: [142][51/704]	Time 0.124	Data 0.003	Loss 4.24	Acc@1 68.8	Acc@5 96.9
Epoch: [142][61/704]	Time 0.124	Data 0.002	Loss 4.60	Acc@1 73.4	Acc@5 95.3
Epoch: [142][71/704]	Time 0.123	Data 0.002	Loss 4.04	Acc@1 82.8	Acc@5 96.9
Epoch: [142][81/704]	Time 0.123	Data 0.002	Loss 4.39	Acc@1 78.1	Acc@5 92.2
Epoch: [142][91/704]	Time 0.123	Data 0.002	Loss 5.37	Acc@1 65.6	Acc@5 93.8
Epoch: [142][101/704]	Time 0.123	Data 0.002	Loss 4.29	Acc@1 67.2	Acc@5 96.9
Epoch: [142][111/704]	Time 0.122	Data 0.002	Loss 5.12	Acc@1 68.8	Acc@5 92.2
Epoch: [142][121/704]	Time 0.122	Data 0.001	Loss 4.33	Acc@1 81.2	Acc@5 95.3
Epoch: [142][131/704]	Time 0.122	Data 0.001	Loss 4.51	Acc@1 65.6	Acc@5 93.8
Epoch: [142][141/704]	Time 0.122	Data 0.001	Loss 4.56	Acc@1 71.9	Acc@5 96.9
Epoch: [142][151/704]	Time 0.122	Data 0.001	Loss 4.60	Acc@1 71.9	Acc@5 92.2
Epoch: [142][161/704]	Time 0.122	Data 0.001	Loss 4.42	Acc@1 75.0	Acc@5 95.3
Epoch: [142][171/704]	Time 0.122	Data 0.001	Loss 4.82	Acc@1 65.6	Acc@5 90.6
Epoch: [142][181/704]	Time 0.122	Data 0.001	Loss 3.68	Acc@1 79.7	Acc@5 96.9
Epoch: [142][191/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 71.9	Acc@5 93.8
Epoch: [142][201/704]	Time 0.121	Data 0.001	Loss 4.92	Acc@1 71.9	Acc@5 95.3
Epoch: [142][211/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 65.6	Acc@5 85.9
Epoch: [142][221/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 65.6	Acc@5 93.8
Epoch: [142][231/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 71.9	Acc@5 95.3
Epoch: [142][241/704]	Time 0.121	Data 0.001	Loss 4.32	Acc@1 68.8	Acc@5 96.9
Epoch: [142][251/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 64.1	Acc@5 90.6
Epoch: [142][261/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 67.2	Acc@5 93.8
Epoch: [142][271/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 78.1	Acc@5 95.3
Epoch: [142][281/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 73.4	Acc@5 92.2
Epoch: [142][291/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 78.1	Acc@5 93.8
Epoch: [142][301/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 64.1	Acc@5 95.3
Epoch: [142][311/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 64.1	Acc@5 87.5
Epoch: [142][321/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 76.6	Acc@5 93.8
Epoch: [142][331/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 71.9	Acc@5 95.3
Epoch: [142][341/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 71.9	Acc@5 90.6
Epoch: [142][351/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 73.4	Acc@5 92.2
Epoch: [142][361/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 78.1	Acc@5 93.8
Epoch: [142][371/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 79.7	Acc@5 89.1
Epoch: [142][381/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 64.1	Acc@5 96.9
Epoch: [142][391/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 60.9	Acc@5 89.1
Epoch: [142][401/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 73.4	Acc@5 93.8
Epoch: [142][411/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 67.2	Acc@5 90.6
Epoch: [142][421/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 75.0	Acc@5 92.2
Epoch: [142][431/704]	Time 0.121	Data 0.001	Loss 3.86	Acc@1 70.3	Acc@5 96.9
Epoch: [142][441/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 75.0	Acc@5 95.3
Epoch: [142][451/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 70.3	Acc@5 98.4
Epoch: [142][461/704]	Time 0.121	Data 0.001	Loss 3.81	Acc@1 76.6	Acc@5 100.0
Epoch: [142][471/704]	Time 0.121	Data 0.001	Loss 5.60	Acc@1 64.1	Acc@5 92.2
Epoch: [142][481/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 76.6	Acc@5 92.2
Epoch: [142][491/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 64.1	Acc@5 89.1
Epoch: [142][501/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 67.2	Acc@5 98.4
Epoch: [142][511/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 62.5	Acc@5 92.2
Epoch: [142][521/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 73.4	Acc@5 90.6
Epoch: [142][531/704]	Time 0.121	Data 0.001	Loss 4.25	Acc@1 64.1	Acc@5 95.3
Epoch: [142][541/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 67.2	Acc@5 93.8
Epoch: [142][551/704]	Time 0.121	Data 0.001	Loss 6.15	Acc@1 65.6	Acc@5 85.9
Epoch: [142][561/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 67.2	Acc@5 90.6
Epoch: [142][571/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 68.8	Acc@5 93.8
Epoch: [142][581/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 75.0	Acc@5 93.8
Epoch: [142][591/704]	Time 0.121	Data 0.001	Loss 6.09	Acc@1 57.8	Acc@5 85.9
Epoch: [142][601/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 70.3	Acc@5 95.3
Epoch: [142][611/704]	Time 0.121	Data 0.001	Loss 6.52	Acc@1 56.2	Acc@5 85.9
Epoch: [142][621/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 62.5	Acc@5 92.2
Epoch: [142][631/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 68.8	Acc@5 92.2
Epoch: [142][641/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 85.9
Epoch: [142][651/704]	Time 0.121	Data 0.001	Loss 6.67	Acc@1 54.7	Acc@5 89.1
Epoch: [142][661/704]	Time 0.121	Data 0.001	Loss 6.31	Acc@1 64.1	Acc@5 89.1
Epoch: [142][671/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 57.8	Acc@5 90.6
Epoch: [142][681/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 71.9	Acc@5 84.4
Epoch: [142][691/704]	Time 0.121	Data 0.001	Loss 4.69	Acc@1 65.6	Acc@5 93.8
Epoch: [142][701/704]	Time 0.121	Data 0.001	Loss 4.60	Acc@1 75.0	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.7459	Acc@1 60.9375	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.0128	Acc@1 53.1250	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0094	Acc@1 57.8125	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.1729	Acc@1 56.2500	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.0802	Acc@1 46.8750	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7307	Acc@1 54.6875	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 9.4414	Acc@1 40.6250	Acc@5 75.0000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2421	Acc@1 65.6250	Acc@5 93.7500
 * prec@1 44.060 prec@5 74.480
 * prec@1 49.960 prec@5 80.500
 * prec@1 54.580 prec@5 83.820
 * prec@1 56.900 prec@5 85.560
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_142.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_142.pth.tar'
Epoch: [143][1/704]	Time 0.300	Data 0.131	Loss 3.98	Acc@1 68.8	Acc@5 93.8
Epoch: [143][11/704]	Time 0.141	Data 0.012	Loss 5.09	Acc@1 67.2	Acc@5 93.8
Epoch: [143][21/704]	Time 0.132	Data 0.007	Loss 4.87	Acc@1 57.8	Acc@5 90.6
Epoch: [143][31/704]	Time 0.128	Data 0.005	Loss 4.91	Acc@1 64.1	Acc@5 95.3
Epoch: [143][41/704]	Time 0.126	Data 0.004	Loss 6.54	Acc@1 60.9	Acc@5 90.6
Epoch: [143][51/704]	Time 0.125	Data 0.003	Loss 4.68	Acc@1 68.8	Acc@5 92.2
Epoch: [143][61/704]	Time 0.124	Data 0.002	Loss 3.14	Acc@1 73.4	Acc@5 95.3
Epoch: [143][71/704]	Time 0.124	Data 0.002	Loss 5.24	Acc@1 68.8	Acc@5 92.2
Epoch: [143][81/704]	Time 0.124	Data 0.002	Loss 4.39	Acc@1 65.6	Acc@5 98.4
Epoch: [143][91/704]	Time 0.123	Data 0.002	Loss 3.81	Acc@1 76.6	Acc@5 98.4
Epoch: [143][101/704]	Time 0.123	Data 0.002	Loss 5.67	Acc@1 70.3	Acc@5 95.3
Epoch: [143][111/704]	Time 0.123	Data 0.002	Loss 5.07	Acc@1 73.4	Acc@5 93.8
Epoch: [143][121/704]	Time 0.123	Data 0.001	Loss 3.86	Acc@1 71.9	Acc@5 95.3
Epoch: [143][131/704]	Time 0.122	Data 0.001	Loss 4.80	Acc@1 70.3	Acc@5 92.2
Epoch: [143][141/704]	Time 0.122	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 90.6
Epoch: [143][151/704]	Time 0.122	Data 0.001	Loss 4.40	Acc@1 75.0	Acc@5 98.4
Epoch: [143][161/704]	Time 0.122	Data 0.001	Loss 4.55	Acc@1 78.1	Acc@5 92.2
Epoch: [143][171/704]	Time 0.122	Data 0.001	Loss 5.29	Acc@1 65.6	Acc@5 92.2
Epoch: [143][181/704]	Time 0.122	Data 0.001	Loss 4.17	Acc@1 71.9	Acc@5 95.3
Epoch: [143][191/704]	Time 0.122	Data 0.001	Loss 5.22	Acc@1 67.2	Acc@5 95.3
Epoch: [143][201/704]	Time 0.122	Data 0.001	Loss 4.96	Acc@1 71.9	Acc@5 95.3
Epoch: [143][211/704]	Time 0.122	Data 0.001	Loss 4.60	Acc@1 70.3	Acc@5 93.8
Epoch: [143][221/704]	Time 0.122	Data 0.001	Loss 4.27	Acc@1 71.9	Acc@5 95.3
Epoch: [143][231/704]	Time 0.122	Data 0.001	Loss 4.91	Acc@1 68.8	Acc@5 95.3
Epoch: [143][241/704]	Time 0.122	Data 0.001	Loss 4.50	Acc@1 67.2	Acc@5 96.9
Epoch: [143][251/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 76.6	Acc@5 96.9
Epoch: [143][261/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 60.9	Acc@5 93.8
Epoch: [143][271/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 75.0	Acc@5 95.3
Epoch: [143][281/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 70.3	Acc@5 93.8
Epoch: [143][291/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 70.3	Acc@5 96.9
Epoch: [143][301/704]	Time 0.121	Data 0.001	Loss 5.26	Acc@1 67.2	Acc@5 89.1
Epoch: [143][311/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 75.0	Acc@5 92.2
Epoch: [143][321/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 62.5	Acc@5 90.6
Epoch: [143][331/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 75.0	Acc@5 93.8
Epoch: [143][341/704]	Time 0.121	Data 0.001	Loss 6.07	Acc@1 67.2	Acc@5 90.6
Epoch: [143][351/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 67.2	Acc@5 92.2
Epoch: [143][361/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 73.4	Acc@5 95.3
Epoch: [143][371/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 64.1	Acc@5 93.8
Epoch: [143][381/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 76.6	Acc@5 96.9
Epoch: [143][391/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 67.2	Acc@5 92.2
Epoch: [143][401/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 68.8	Acc@5 95.3
Epoch: [143][411/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 76.6	Acc@5 92.2
Epoch: [143][421/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 64.1	Acc@5 93.8
Epoch: [143][431/704]	Time 0.121	Data 0.001	Loss 6.04	Acc@1 62.5	Acc@5 85.9
Epoch: [143][441/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 92.2
Epoch: [143][451/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 73.4	Acc@5 96.9
Epoch: [143][461/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 73.4	Acc@5 93.8
Epoch: [143][471/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 70.3	Acc@5 93.8
Epoch: [143][481/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 65.6	Acc@5 87.5
Epoch: [143][491/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 68.8	Acc@5 92.2
Epoch: [143][501/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 68.8	Acc@5 90.6
Epoch: [143][511/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 64.1	Acc@5 90.6
Epoch: [143][521/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 64.1	Acc@5 90.6
Epoch: [143][531/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 76.6	Acc@5 96.9
Epoch: [143][541/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 68.8	Acc@5 89.1
Epoch: [143][551/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 68.8	Acc@5 87.5
Epoch: [143][561/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 68.8	Acc@5 96.9
Epoch: [143][571/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 76.6	Acc@5 93.8
Epoch: [143][581/704]	Time 0.121	Data 0.001	Loss 4.71	Acc@1 65.6	Acc@5 96.9
Epoch: [143][591/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 65.6	Acc@5 90.6
Epoch: [143][601/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 73.4	Acc@5 93.8
Epoch: [143][611/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 70.3	Acc@5 92.2
Epoch: [143][621/704]	Time 0.121	Data 0.001	Loss 5.73	Acc@1 59.4	Acc@5 84.4
Epoch: [143][631/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 73.4	Acc@5 96.9
Epoch: [143][641/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 71.9	Acc@5 93.8
Epoch: [143][651/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 67.2	Acc@5 92.2
Epoch: [143][661/704]	Time 0.121	Data 0.001	Loss 5.89	Acc@1 60.9	Acc@5 90.6
Epoch: [143][671/704]	Time 0.121	Data 0.000	Loss 4.20	Acc@1 71.9	Acc@5 96.9
Epoch: [143][681/704]	Time 0.121	Data 0.000	Loss 6.25	Acc@1 62.5	Acc@5 90.6
Epoch: [143][691/704]	Time 0.121	Data 0.000	Loss 5.36	Acc@1 70.3	Acc@5 92.2
Epoch: [143][701/704]	Time 0.121	Data 0.000	Loss 6.16	Acc@1 54.7	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 8.0067	Acc@1 54.6875	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.3181	Acc@1 59.3750	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.6773	Acc@1 54.6875	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.9851	Acc@1 53.1250	Acc@5 78.1250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.8547	Acc@1 50.0000	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.2953	Acc@1 50.0000	Acc@5 81.2500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.1140	Acc@1 62.5000	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.1135	Acc@1 56.2500	Acc@5 79.6875
 * prec@1 49.260 prec@5 79.240
 * prec@1 51.880 prec@5 82.300
 * prec@1 56.800 prec@5 85.860
 * prec@1 59.100 prec@5 86.600
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_143.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_143.pth.tar'
Epoch: [144][1/704]	Time 0.326	Data 0.160	Loss 5.84	Acc@1 75.0	Acc@5 92.2
Epoch: [144][11/704]	Time 0.139	Data 0.015	Loss 3.91	Acc@1 76.6	Acc@5 100.0
Epoch: [144][21/704]	Time 0.130	Data 0.008	Loss 4.55	Acc@1 75.0	Acc@5 93.8
Epoch: [144][31/704]	Time 0.127	Data 0.005	Loss 4.24	Acc@1 70.3	Acc@5 95.3
Epoch: [144][41/704]	Time 0.125	Data 0.004	Loss 4.31	Acc@1 75.0	Acc@5 95.3
Epoch: [144][51/704]	Time 0.125	Data 0.003	Loss 4.39	Acc@1 70.3	Acc@5 95.3
Epoch: [144][61/704]	Time 0.124	Data 0.003	Loss 5.75	Acc@1 68.8	Acc@5 93.8
Epoch: [144][71/704]	Time 0.124	Data 0.003	Loss 3.92	Acc@1 78.1	Acc@5 93.8
Epoch: [144][81/704]	Time 0.123	Data 0.002	Loss 4.15	Acc@1 68.8	Acc@5 100.0
Epoch: [144][91/704]	Time 0.123	Data 0.002	Loss 4.17	Acc@1 78.1	Acc@5 98.4
Epoch: [144][101/704]	Time 0.123	Data 0.002	Loss 6.36	Acc@1 59.4	Acc@5 90.6
Epoch: [144][111/704]	Time 0.122	Data 0.002	Loss 4.72	Acc@1 73.4	Acc@5 93.8
Epoch: [144][121/704]	Time 0.122	Data 0.002	Loss 5.32	Acc@1 67.2	Acc@5 93.8
Epoch: [144][131/704]	Time 0.122	Data 0.001	Loss 5.47	Acc@1 65.6	Acc@5 92.2
Epoch: [144][141/704]	Time 0.122	Data 0.001	Loss 5.03	Acc@1 64.1	Acc@5 92.2
Epoch: [144][151/704]	Time 0.122	Data 0.001	Loss 5.32	Acc@1 73.4	Acc@5 90.6
Epoch: [144][161/704]	Time 0.122	Data 0.001	Loss 4.34	Acc@1 70.3	Acc@5 96.9
Epoch: [144][171/704]	Time 0.122	Data 0.001	Loss 4.40	Acc@1 70.3	Acc@5 96.9
Epoch: [144][181/704]	Time 0.122	Data 0.001	Loss 5.39	Acc@1 67.2	Acc@5 90.6
Epoch: [144][191/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 75.0	Acc@5 92.2
Epoch: [144][201/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 68.8	Acc@5 95.3
Epoch: [144][211/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 68.8	Acc@5 95.3
Epoch: [144][221/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 65.6	Acc@5 92.2
Epoch: [144][231/704]	Time 0.121	Data 0.001	Loss 6.82	Acc@1 57.8	Acc@5 89.1
Epoch: [144][241/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 70.3	Acc@5 95.3
Epoch: [144][251/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 67.2	Acc@5 89.1
Epoch: [144][261/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 73.4	Acc@5 92.2
Epoch: [144][271/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 79.7	Acc@5 95.3
Epoch: [144][281/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 71.9	Acc@5 96.9
Epoch: [144][291/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 73.4	Acc@5 93.8
Epoch: [144][301/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 71.9	Acc@5 93.8
Epoch: [144][311/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 71.9	Acc@5 95.3
Epoch: [144][321/704]	Time 0.121	Data 0.001	Loss 6.13	Acc@1 62.5	Acc@5 90.6
Epoch: [144][331/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 71.9	Acc@5 93.8
Epoch: [144][341/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 75.0	Acc@5 93.8
Epoch: [144][351/704]	Time 0.121	Data 0.001	Loss 6.17	Acc@1 70.3	Acc@5 95.3
Epoch: [144][361/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 71.9	Acc@5 90.6
Epoch: [144][371/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 81.2	Acc@5 96.9
Epoch: [144][381/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 65.6	Acc@5 89.1
Epoch: [144][391/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 65.6	Acc@5 95.3
Epoch: [144][401/704]	Time 0.121	Data 0.001	Loss 5.36	Acc@1 60.9	Acc@5 92.2
Epoch: [144][411/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 67.2	Acc@5 95.3
Epoch: [144][421/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 73.4	Acc@5 92.2
Epoch: [144][431/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 60.9	Acc@5 90.6
Epoch: [144][441/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 71.9	Acc@5 92.2
Epoch: [144][451/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 75.0	Acc@5 93.8
Epoch: [144][461/704]	Time 0.121	Data 0.001	Loss 5.88	Acc@1 68.8	Acc@5 89.1
Epoch: [144][471/704]	Time 0.121	Data 0.001	Loss 5.68	Acc@1 64.1	Acc@5 92.2
Epoch: [144][481/704]	Time 0.121	Data 0.001	Loss 5.40	Acc@1 71.9	Acc@5 96.9
Epoch: [144][491/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 67.2	Acc@5 89.1
Epoch: [144][501/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 71.9	Acc@5 93.8
Epoch: [144][511/704]	Time 0.121	Data 0.001	Loss 5.46	Acc@1 60.9	Acc@5 95.3
Epoch: [144][521/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 62.5	Acc@5 89.1
Epoch: [144][531/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 60.9	Acc@5 89.1
Epoch: [144][541/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 73.4	Acc@5 95.3
Epoch: [144][551/704]	Time 0.121	Data 0.001	Loss 5.28	Acc@1 64.1	Acc@5 93.8
Epoch: [144][561/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 73.4	Acc@5 87.5
Epoch: [144][571/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 68.8	Acc@5 85.9
Epoch: [144][581/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 70.3	Acc@5 92.2
Epoch: [144][591/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 68.8	Acc@5 93.8
Epoch: [144][601/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 68.8	Acc@5 96.9
Epoch: [144][611/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 73.4	Acc@5 93.8
Epoch: [144][621/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 93.8
Epoch: [144][631/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 93.8
Epoch: [144][641/704]	Time 0.121	Data 0.001	Loss 5.91	Acc@1 67.2	Acc@5 85.9
Epoch: [144][651/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 57.8	Acc@5 92.2
Epoch: [144][661/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 70.3	Acc@5 93.8
Epoch: [144][671/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 67.2	Acc@5 90.6
Epoch: [144][681/704]	Time 0.121	Data 0.000	Loss 4.77	Acc@1 73.4	Acc@5 92.2
Epoch: [144][691/704]	Time 0.121	Data 0.000	Loss 5.65	Acc@1 67.2	Acc@5 89.1
Epoch: [144][701/704]	Time 0.121	Data 0.000	Loss 4.24	Acc@1 78.1	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.1292	Acc@1 56.2500	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.9027	Acc@1 43.7500	Acc@5 81.2500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.4911	Acc@1 65.6250	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.6947	Acc@1 50.0000	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.4082	Acc@1 56.2500	Acc@5 79.6875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.6453	Acc@1 53.1250	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.5521	Acc@1 51.5625	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.1094	Acc@1 59.3750	Acc@5 79.6875
 * prec@1 48.900 prec@5 78.760
 * prec@1 53.240 prec@5 82.920
 * prec@1 56.580 prec@5 85.620
 * prec@1 57.120 prec@5 86.240
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_144.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_144.pth.tar'
Epoch: [145][1/704]	Time 0.301	Data 0.133	Loss 4.33	Acc@1 68.8	Acc@5 90.6
Epoch: [145][11/704]	Time 0.137	Data 0.012	Loss 5.92	Acc@1 70.3	Acc@5 90.6
Epoch: [145][21/704]	Time 0.129	Data 0.007	Loss 6.27	Acc@1 62.5	Acc@5 95.3
Epoch: [145][31/704]	Time 0.126	Data 0.005	Loss 5.76	Acc@1 68.8	Acc@5 85.9
Epoch: [145][41/704]	Time 0.125	Data 0.004	Loss 4.70	Acc@1 73.4	Acc@5 93.8
Epoch: [145][51/704]	Time 0.124	Data 0.003	Loss 4.68	Acc@1 67.2	Acc@5 100.0
Epoch: [145][61/704]	Time 0.123	Data 0.003	Loss 5.61	Acc@1 67.2	Acc@5 84.4
Epoch: [145][71/704]	Time 0.123	Data 0.002	Loss 5.09	Acc@1 71.9	Acc@5 96.9
Epoch: [145][81/704]	Time 0.123	Data 0.002	Loss 4.42	Acc@1 68.8	Acc@5 93.8
Epoch: [145][91/704]	Time 0.122	Data 0.002	Loss 5.60	Acc@1 64.1	Acc@5 96.9
Epoch: [145][101/704]	Time 0.122	Data 0.002	Loss 4.41	Acc@1 75.0	Acc@5 93.8
Epoch: [145][111/704]	Time 0.122	Data 0.002	Loss 5.14	Acc@1 62.5	Acc@5 89.1
Epoch: [145][121/704]	Time 0.122	Data 0.001	Loss 5.72	Acc@1 65.6	Acc@5 87.5
Epoch: [145][131/704]	Time 0.122	Data 0.001	Loss 5.86	Acc@1 60.9	Acc@5 90.6
Epoch: [145][141/704]	Time 0.122	Data 0.001	Loss 6.01	Acc@1 64.1	Acc@5 85.9
Epoch: [145][151/704]	Time 0.122	Data 0.001	Loss 4.62	Acc@1 73.4	Acc@5 98.4
Epoch: [145][161/704]	Time 0.122	Data 0.001	Loss 3.45	Acc@1 82.8	Acc@5 96.9
Epoch: [145][171/704]	Time 0.122	Data 0.001	Loss 4.36	Acc@1 70.3	Acc@5 90.6
Epoch: [145][181/704]	Time 0.122	Data 0.001	Loss 4.20	Acc@1 62.5	Acc@5 98.4
Epoch: [145][191/704]	Time 0.121	Data 0.001	Loss 5.35	Acc@1 57.8	Acc@5 92.2
Epoch: [145][201/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 71.9	Acc@5 92.2
Epoch: [145][211/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 64.1	Acc@5 89.1
Epoch: [145][221/704]	Time 0.121	Data 0.001	Loss 4.58	Acc@1 68.8	Acc@5 95.3
Epoch: [145][231/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 70.3	Acc@5 96.9
Epoch: [145][241/704]	Time 0.121	Data 0.001	Loss 5.92	Acc@1 60.9	Acc@5 89.1
Epoch: [145][251/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 71.9	Acc@5 93.8
Epoch: [145][261/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 75.0	Acc@5 92.2
Epoch: [145][271/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 71.9	Acc@5 93.8
Epoch: [145][281/704]	Time 0.121	Data 0.001	Loss 4.47	Acc@1 75.0	Acc@5 93.8
Epoch: [145][291/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 71.9	Acc@5 98.4
Epoch: [145][301/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 67.2	Acc@5 93.8
Epoch: [145][311/704]	Time 0.121	Data 0.001	Loss 3.20	Acc@1 87.5	Acc@5 98.4
Epoch: [145][321/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 93.8
Epoch: [145][331/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 71.9	Acc@5 95.3
Epoch: [145][341/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 73.4	Acc@5 93.8
Epoch: [145][351/704]	Time 0.121	Data 0.001	Loss 4.33	Acc@1 71.9	Acc@5 92.2
Epoch: [145][361/704]	Time 0.121	Data 0.001	Loss 5.41	Acc@1 68.8	Acc@5 96.9
Epoch: [145][371/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 70.3	Acc@5 98.4
Epoch: [145][381/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 65.6	Acc@5 90.6
Epoch: [145][391/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 67.2	Acc@5 95.3
Epoch: [145][401/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 67.2	Acc@5 87.5
Epoch: [145][411/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 73.4	Acc@5 90.6
Epoch: [145][421/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 64.1	Acc@5 95.3
Epoch: [145][431/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 71.9	Acc@5 95.3
Epoch: [145][441/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 62.5	Acc@5 93.8
Epoch: [145][451/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 68.8	Acc@5 92.2
Epoch: [145][461/704]	Time 0.121	Data 0.001	Loss 4.68	Acc@1 67.2	Acc@5 98.4
Epoch: [145][471/704]	Time 0.121	Data 0.001	Loss 5.02	Acc@1 68.8	Acc@5 93.8
Epoch: [145][481/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 75.0	Acc@5 89.1
Epoch: [145][491/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 90.6
Epoch: [145][501/704]	Time 0.121	Data 0.001	Loss 5.54	Acc@1 67.2	Acc@5 90.6
Epoch: [145][511/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 85.9	Acc@5 93.8
Epoch: [145][521/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 67.2	Acc@5 92.2
Epoch: [145][531/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 68.8	Acc@5 93.8
Epoch: [145][541/704]	Time 0.121	Data 0.001	Loss 4.75	Acc@1 64.1	Acc@5 90.6
Epoch: [145][551/704]	Time 0.121	Data 0.001	Loss 4.44	Acc@1 71.9	Acc@5 93.8
Epoch: [145][561/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 64.1	Acc@5 93.8
Epoch: [145][571/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 65.6	Acc@5 89.1
Epoch: [145][581/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 76.6	Acc@5 92.2
Epoch: [145][591/704]	Time 0.121	Data 0.001	Loss 4.25	Acc@1 76.6	Acc@5 98.4
Epoch: [145][601/704]	Time 0.121	Data 0.001	Loss 4.65	Acc@1 78.1	Acc@5 96.9
Epoch: [145][611/704]	Time 0.121	Data 0.001	Loss 4.87	Acc@1 71.9	Acc@5 95.3
Epoch: [145][621/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 67.2	Acc@5 87.5
Epoch: [145][631/704]	Time 0.121	Data 0.001	Loss 4.37	Acc@1 76.6	Acc@5 93.8
Epoch: [145][641/704]	Time 0.121	Data 0.001	Loss 5.06	Acc@1 65.6	Acc@5 96.9
Epoch: [145][651/704]	Time 0.121	Data 0.001	Loss 5.59	Acc@1 68.8	Acc@5 90.6
Epoch: [145][661/704]	Time 0.121	Data 0.001	Loss 5.16	Acc@1 65.6	Acc@5 95.3
Epoch: [145][671/704]	Time 0.121	Data 0.001	Loss 5.67	Acc@1 64.1	Acc@5 82.8
Epoch: [145][681/704]	Time 0.121	Data 0.001	Loss 3.60	Acc@1 79.7	Acc@5 100.0
Epoch: [145][691/704]	Time 0.121	Data 0.001	Loss 5.94	Acc@1 57.8	Acc@5 92.2
Epoch: [145][701/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 62.5	Acc@5 93.8
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.9310	Acc@1 53.1250	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.2231	Acc@1 48.4375	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.6826	Acc@1 48.4375	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.2770	Acc@1 60.9375	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.8251	Acc@1 57.8125	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.3864	Acc@1 57.8125	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.5983	Acc@1 62.5000	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3614	Acc@1 53.1250	Acc@5 89.0625
 * prec@1 49.200 prec@5 79.500
 * prec@1 53.340 prec@5 82.880
 * prec@1 57.660 prec@5 85.980
 * prec@1 58.420 prec@5 86.180
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_145.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_145.pth.tar'
Epoch: [146][1/704]	Time 0.299	Data 0.131	Loss 6.08	Acc@1 57.8	Acc@5 85.9
Epoch: [146][11/704]	Time 0.137	Data 0.012	Loss 4.25	Acc@1 76.6	Acc@5 96.9
Epoch: [146][21/704]	Time 0.129	Data 0.007	Loss 4.88	Acc@1 75.0	Acc@5 92.2
Epoch: [146][31/704]	Time 0.126	Data 0.005	Loss 4.60	Acc@1 71.9	Acc@5 95.3
Epoch: [146][41/704]	Time 0.125	Data 0.004	Loss 4.77	Acc@1 70.3	Acc@5 89.1
Epoch: [146][51/704]	Time 0.124	Data 0.003	Loss 4.09	Acc@1 76.6	Acc@5 92.2
Epoch: [146][61/704]	Time 0.124	Data 0.003	Loss 4.38	Acc@1 68.8	Acc@5 95.3
Epoch: [146][71/704]	Time 0.124	Data 0.002	Loss 5.87	Acc@1 64.1	Acc@5 89.1
Epoch: [146][81/704]	Time 0.123	Data 0.002	Loss 5.14	Acc@1 70.3	Acc@5 95.3
Epoch: [146][91/704]	Time 0.123	Data 0.002	Loss 5.58	Acc@1 51.6	Acc@5 89.1
Epoch: [146][101/704]	Time 0.123	Data 0.002	Loss 5.06	Acc@1 65.6	Acc@5 95.3
Epoch: [146][111/704]	Time 0.123	Data 0.002	Loss 4.95	Acc@1 65.6	Acc@5 95.3
Epoch: [146][121/704]	Time 0.122	Data 0.001	Loss 5.26	Acc@1 68.8	Acc@5 92.2
Epoch: [146][131/704]	Time 0.122	Data 0.001	Loss 5.58	Acc@1 56.2	Acc@5 92.2
Epoch: [146][141/704]	Time 0.122	Data 0.001	Loss 3.37	Acc@1 73.4	Acc@5 100.0
Epoch: [146][151/704]	Time 0.122	Data 0.001	Loss 4.81	Acc@1 75.0	Acc@5 93.8
Epoch: [146][161/704]	Time 0.122	Data 0.001	Loss 4.89	Acc@1 71.9	Acc@5 96.9
Epoch: [146][171/704]	Time 0.122	Data 0.001	Loss 4.32	Acc@1 75.0	Acc@5 93.8
Epoch: [146][181/704]	Time 0.122	Data 0.001	Loss 4.13	Acc@1 82.8	Acc@5 96.9
Epoch: [146][191/704]	Time 0.122	Data 0.001	Loss 5.08	Acc@1 70.3	Acc@5 93.8
Epoch: [146][201/704]	Time 0.122	Data 0.001	Loss 4.75	Acc@1 68.8	Acc@5 93.8
Epoch: [146][211/704]	Time 0.122	Data 0.001	Loss 5.41	Acc@1 67.2	Acc@5 93.8
Epoch: [146][221/704]	Time 0.122	Data 0.001	Loss 4.16	Acc@1 76.6	Acc@5 96.9
Epoch: [146][231/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 71.9	Acc@5 92.2
Epoch: [146][241/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 71.9	Acc@5 93.8
Epoch: [146][251/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 59.4	Acc@5 95.3
Epoch: [146][261/704]	Time 0.121	Data 0.001	Loss 5.34	Acc@1 60.9	Acc@5 89.1
Epoch: [146][271/704]	Time 0.121	Data 0.001	Loss 4.93	Acc@1 76.6	Acc@5 93.8
Epoch: [146][281/704]	Time 0.121	Data 0.001	Loss 3.68	Acc@1 78.1	Acc@5 98.4
Epoch: [146][291/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 68.8	Acc@5 93.8
Epoch: [146][301/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 70.3	Acc@5 92.2
Epoch: [146][311/704]	Time 0.121	Data 0.001	Loss 5.29	Acc@1 70.3	Acc@5 96.9
Epoch: [146][321/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 73.4	Acc@5 98.4
Epoch: [146][331/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 75.0	Acc@5 95.3
Epoch: [146][341/704]	Time 0.121	Data 0.001	Loss 5.62	Acc@1 60.9	Acc@5 95.3
Epoch: [146][351/704]	Time 0.121	Data 0.001	Loss 4.88	Acc@1 67.2	Acc@5 93.8
Epoch: [146][361/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 62.5	Acc@5 93.8
Epoch: [146][371/704]	Time 0.121	Data 0.001	Loss 6.06	Acc@1 59.4	Acc@5 87.5
Epoch: [146][381/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 71.9	Acc@5 95.3
Epoch: [146][391/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 68.8	Acc@5 93.8
Epoch: [146][401/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 65.6	Acc@5 95.3
Epoch: [146][411/704]	Time 0.121	Data 0.001	Loss 5.61	Acc@1 71.9	Acc@5 95.3
Epoch: [146][421/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 75.0	Acc@5 93.8
Epoch: [146][431/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 62.5	Acc@5 89.1
Epoch: [146][441/704]	Time 0.121	Data 0.001	Loss 5.79	Acc@1 56.2	Acc@5 87.5
Epoch: [146][451/704]	Time 0.121	Data 0.001	Loss 4.89	Acc@1 67.2	Acc@5 93.8
Epoch: [146][461/704]	Time 0.121	Data 0.001	Loss 5.70	Acc@1 71.9	Acc@5 90.6
Epoch: [146][471/704]	Time 0.121	Data 0.001	Loss 5.80	Acc@1 65.6	Acc@5 90.6
Epoch: [146][481/704]	Time 0.121	Data 0.001	Loss 6.95	Acc@1 56.2	Acc@5 89.1
Epoch: [146][491/704]	Time 0.121	Data 0.001	Loss 5.45	Acc@1 68.8	Acc@5 92.2
Epoch: [146][501/704]	Time 0.121	Data 0.001	Loss 4.74	Acc@1 67.2	Acc@5 95.3
Epoch: [146][511/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 75.0	Acc@5 89.1
Epoch: [146][521/704]	Time 0.121	Data 0.001	Loss 6.75	Acc@1 65.6	Acc@5 89.1
Epoch: [146][531/704]	Time 0.121	Data 0.001	Loss 4.19	Acc@1 78.1	Acc@5 93.8
Epoch: [146][541/704]	Time 0.121	Data 0.001	Loss 8.18	Acc@1 40.6	Acc@5 84.4
Epoch: [146][551/704]	Time 0.121	Data 0.001	Loss 3.63	Acc@1 79.7	Acc@5 93.8
Epoch: [146][561/704]	Time 0.121	Data 0.001	Loss 4.63	Acc@1 68.8	Acc@5 95.3
Epoch: [146][571/704]	Time 0.121	Data 0.001	Loss 4.52	Acc@1 71.9	Acc@5 95.3
Epoch: [146][581/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 70.3	Acc@5 93.8
Epoch: [146][591/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 59.4	Acc@5 98.4
Epoch: [146][601/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 75.0	Acc@5 96.9
Epoch: [146][611/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 65.6	Acc@5 93.8
Epoch: [146][621/704]	Time 0.121	Data 0.001	Loss 6.20	Acc@1 59.4	Acc@5 93.8
Epoch: [146][631/704]	Time 0.121	Data 0.001	Loss 7.57	Acc@1 62.5	Acc@5 76.6
Epoch: [146][641/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 76.6	Acc@5 95.3
Epoch: [146][651/704]	Time 0.121	Data 0.001	Loss 5.18	Acc@1 75.0	Acc@5 95.3
Epoch: [146][661/704]	Time 0.121	Data 0.001	Loss 5.01	Acc@1 75.0	Acc@5 92.2
Epoch: [146][671/704]	Time 0.121	Data 0.001	Loss 6.63	Acc@1 60.9	Acc@5 84.4
Epoch: [146][681/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 79.7	Acc@5 93.8
Epoch: [146][691/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 76.6	Acc@5 95.3
Epoch: [146][701/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 62.5	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.9117	Acc@1 54.6875	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.3530	Acc@1 56.2500	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.7588	Acc@1 51.5625	Acc@5 82.8125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.6302	Acc@1 65.6250	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9489	Acc@1 68.7500	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.0930	Acc@1 56.2500	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4801	Acc@1 57.8125	Acc@5 79.6875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.9664	Acc@1 59.3750	Acc@5 87.5000
 * prec@1 47.880 prec@5 79.380
 * prec@1 52.960 prec@5 82.500
 * prec@1 56.740 prec@5 86.140
 * prec@1 58.160 prec@5 86.260
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_146.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_146.pth.tar'
Epoch: [147][1/704]	Time 0.328	Data 0.161	Loss 3.87	Acc@1 76.6	Acc@5 93.8
Epoch: [147][11/704]	Time 0.139	Data 0.015	Loss 5.19	Acc@1 71.9	Acc@5 95.3
Epoch: [147][21/704]	Time 0.130	Data 0.008	Loss 5.07	Acc@1 75.0	Acc@5 90.6
Epoch: [147][31/704]	Time 0.127	Data 0.005	Loss 3.96	Acc@1 73.4	Acc@5 93.8
Epoch: [147][41/704]	Time 0.125	Data 0.004	Loss 5.11	Acc@1 68.8	Acc@5 93.8
Epoch: [147][51/704]	Time 0.124	Data 0.003	Loss 5.13	Acc@1 67.2	Acc@5 93.8
Epoch: [147][61/704]	Time 0.124	Data 0.003	Loss 4.27	Acc@1 65.6	Acc@5 89.1
Epoch: [147][71/704]	Time 0.123	Data 0.003	Loss 4.63	Acc@1 68.8	Acc@5 93.8
Epoch: [147][81/704]	Time 0.123	Data 0.002	Loss 4.32	Acc@1 65.6	Acc@5 95.3
Epoch: [147][91/704]	Time 0.122	Data 0.002	Loss 4.25	Acc@1 65.6	Acc@5 100.0
Epoch: [147][101/704]	Time 0.122	Data 0.002	Loss 4.74	Acc@1 67.2	Acc@5 98.4
Epoch: [147][111/704]	Time 0.122	Data 0.002	Loss 4.51	Acc@1 71.9	Acc@5 96.9
Epoch: [147][121/704]	Time 0.122	Data 0.002	Loss 5.33	Acc@1 76.6	Acc@5 90.6
Epoch: [147][131/704]	Time 0.122	Data 0.002	Loss 4.21	Acc@1 73.4	Acc@5 92.2
Epoch: [147][141/704]	Time 0.122	Data 0.001	Loss 4.50	Acc@1 73.4	Acc@5 95.3
Epoch: [147][151/704]	Time 0.122	Data 0.001	Loss 5.14	Acc@1 64.1	Acc@5 87.5
Epoch: [147][161/704]	Time 0.121	Data 0.001	Loss 5.12	Acc@1 75.0	Acc@5 93.8
Epoch: [147][171/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 73.4	Acc@5 93.8
Epoch: [147][181/704]	Time 0.121	Data 0.001	Loss 4.70	Acc@1 64.1	Acc@5 93.8
Epoch: [147][191/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 75.0	Acc@5 98.4
Epoch: [147][201/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 64.1	Acc@5 90.6
Epoch: [147][211/704]	Time 0.121	Data 0.001	Loss 4.22	Acc@1 71.9	Acc@5 96.9
Epoch: [147][221/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 64.1	Acc@5 96.9
Epoch: [147][231/704]	Time 0.121	Data 0.001	Loss 5.87	Acc@1 62.5	Acc@5 93.8
Epoch: [147][241/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 64.1	Acc@5 89.1
Epoch: [147][251/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 71.9	Acc@5 92.2
Epoch: [147][261/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 67.2	Acc@5 93.8
Epoch: [147][271/704]	Time 0.121	Data 0.001	Loss 3.93	Acc@1 76.6	Acc@5 100.0
Epoch: [147][281/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 79.7	Acc@5 96.9
Epoch: [147][291/704]	Time 0.121	Data 0.001	Loss 5.99	Acc@1 67.2	Acc@5 87.5
Epoch: [147][301/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 62.5	Acc@5 87.5
Epoch: [147][311/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 70.3	Acc@5 98.4
Epoch: [147][321/704]	Time 0.121	Data 0.001	Loss 5.84	Acc@1 64.1	Acc@5 92.2
Epoch: [147][331/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 75.0	Acc@5 92.2
Epoch: [147][341/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 76.6	Acc@5 92.2
Epoch: [147][351/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 64.1	Acc@5 93.8
Epoch: [147][361/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 78.1	Acc@5 95.3
Epoch: [147][371/704]	Time 0.121	Data 0.001	Loss 3.60	Acc@1 82.8	Acc@5 96.9
Epoch: [147][381/704]	Time 0.121	Data 0.001	Loss 5.13	Acc@1 70.3	Acc@5 92.2
Epoch: [147][391/704]	Time 0.121	Data 0.001	Loss 6.14	Acc@1 67.2	Acc@5 92.2
Epoch: [147][401/704]	Time 0.121	Data 0.001	Loss 5.72	Acc@1 67.2	Acc@5 89.1
Epoch: [147][411/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 67.2	Acc@5 92.2
Epoch: [147][421/704]	Time 0.121	Data 0.001	Loss 3.50	Acc@1 76.6	Acc@5 98.4
Epoch: [147][431/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 57.8	Acc@5 93.8
Epoch: [147][441/704]	Time 0.121	Data 0.001	Loss 4.25	Acc@1 68.8	Acc@5 90.6
Epoch: [147][451/704]	Time 0.121	Data 0.001	Loss 5.86	Acc@1 70.3	Acc@5 85.9
Epoch: [147][461/704]	Time 0.121	Data 0.001	Loss 5.78	Acc@1 59.4	Acc@5 92.2
Epoch: [147][471/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 70.3	Acc@5 93.8
Epoch: [147][481/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 71.9	Acc@5 93.8
Epoch: [147][491/704]	Time 0.121	Data 0.001	Loss 4.27	Acc@1 64.1	Acc@5 93.8
Epoch: [147][501/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 70.3	Acc@5 96.9
Epoch: [147][511/704]	Time 0.121	Data 0.001	Loss 4.54	Acc@1 73.4	Acc@5 92.2
Epoch: [147][521/704]	Time 0.121	Data 0.001	Loss 5.51	Acc@1 60.9	Acc@5 90.6
Epoch: [147][531/704]	Time 0.121	Data 0.001	Loss 5.04	Acc@1 67.2	Acc@5 89.1
Epoch: [147][541/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 75.0	Acc@5 95.3
Epoch: [147][551/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 76.6	Acc@5 93.8
Epoch: [147][561/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 68.8	Acc@5 85.9
Epoch: [147][571/704]	Time 0.121	Data 0.001	Loss 5.63	Acc@1 64.1	Acc@5 90.6
Epoch: [147][581/704]	Time 0.121	Data 0.001	Loss 5.37	Acc@1 65.6	Acc@5 95.3
Epoch: [147][591/704]	Time 0.121	Data 0.001	Loss 5.14	Acc@1 65.6	Acc@5 95.3
Epoch: [147][601/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 70.3	Acc@5 93.8
Epoch: [147][611/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 68.8	Acc@5 90.6
Epoch: [147][621/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 65.6	Acc@5 92.2
Epoch: [147][631/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 73.4	Acc@5 93.8
Epoch: [147][641/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 64.1	Acc@5 92.2
Epoch: [147][651/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 95.3
Epoch: [147][661/704]	Time 0.121	Data 0.001	Loss 4.51	Acc@1 81.2	Acc@5 92.2
Epoch: [147][671/704]	Time 0.121	Data 0.001	Loss 5.43	Acc@1 67.2	Acc@5 90.6
Epoch: [147][681/704]	Time 0.121	Data 0.001	Loss 4.72	Acc@1 71.9	Acc@5 92.2
Epoch: [147][691/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 70.3	Acc@5 95.3
Epoch: [147][701/704]	Time 0.121	Data 0.001	Loss 6.34	Acc@1 60.9	Acc@5 79.7
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.6831	Acc@1 51.5625	Acc@5 76.5625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0073	Acc@1 50.0000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.7000	Acc@1 50.0000	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4189	Acc@1 53.1250	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.1608	Acc@1 62.5000	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.2578	Acc@1 60.9375	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.2413	Acc@1 51.5625	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9767	Acc@1 59.3750	Acc@5 82.8125
 * prec@1 47.560 prec@5 78.460
 * prec@1 53.760 prec@5 83.580
 * prec@1 55.100 prec@5 85.480
 * prec@1 56.300 prec@5 85.660
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_147.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_147.pth.tar'
Epoch: [148][1/704]	Time 0.326	Data 0.159	Loss 3.86	Acc@1 76.6	Acc@5 95.3
Epoch: [148][11/704]	Time 0.139	Data 0.015	Loss 4.34	Acc@1 78.1	Acc@5 95.3
Epoch: [148][21/704]	Time 0.130	Data 0.008	Loss 4.26	Acc@1 71.9	Acc@5 93.8
Epoch: [148][31/704]	Time 0.127	Data 0.005	Loss 6.76	Acc@1 60.9	Acc@5 89.1
Epoch: [148][41/704]	Time 0.125	Data 0.004	Loss 5.08	Acc@1 64.1	Acc@5 90.6
Epoch: [148][51/704]	Time 0.124	Data 0.003	Loss 5.71	Acc@1 65.6	Acc@5 89.1
Epoch: [148][61/704]	Time 0.124	Data 0.003	Loss 4.05	Acc@1 73.4	Acc@5 96.9
Epoch: [148][71/704]	Time 0.123	Data 0.003	Loss 4.84	Acc@1 64.1	Acc@5 95.3
Epoch: [148][81/704]	Time 0.123	Data 0.002	Loss 4.41	Acc@1 71.9	Acc@5 95.3
Epoch: [148][91/704]	Time 0.122	Data 0.002	Loss 4.61	Acc@1 68.8	Acc@5 96.9
Epoch: [148][101/704]	Time 0.122	Data 0.002	Loss 4.50	Acc@1 75.0	Acc@5 98.4
Epoch: [148][111/704]	Time 0.122	Data 0.002	Loss 4.89	Acc@1 70.3	Acc@5 93.8
Epoch: [148][121/704]	Time 0.122	Data 0.002	Loss 6.42	Acc@1 51.6	Acc@5 92.2
Epoch: [148][131/704]	Time 0.122	Data 0.002	Loss 4.24	Acc@1 68.8	Acc@5 92.2
Epoch: [148][141/704]	Time 0.122	Data 0.001	Loss 4.19	Acc@1 75.0	Acc@5 92.2
Epoch: [148][151/704]	Time 0.122	Data 0.001	Loss 5.13	Acc@1 65.6	Acc@5 93.8
Epoch: [148][161/704]	Time 0.121	Data 0.001	Loss 4.85	Acc@1 70.3	Acc@5 100.0
Epoch: [148][171/704]	Time 0.122	Data 0.001	Loss 5.38	Acc@1 60.9	Acc@5 90.6
Epoch: [148][181/704]	Time 0.121	Data 0.001	Loss 3.98	Acc@1 75.0	Acc@5 95.3
Epoch: [148][191/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 67.2	Acc@5 98.4
Epoch: [148][201/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 75.0	Acc@5 96.9
Epoch: [148][211/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 65.6	Acc@5 95.3
Epoch: [148][221/704]	Time 0.121	Data 0.001	Loss 5.44	Acc@1 75.0	Acc@5 95.3
Epoch: [148][231/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 62.5	Acc@5 96.9
Epoch: [148][241/704]	Time 0.121	Data 0.001	Loss 4.41	Acc@1 75.0	Acc@5 93.8
Epoch: [148][251/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 76.6	Acc@5 92.2
Epoch: [148][261/704]	Time 0.121	Data 0.001	Loss 5.20	Acc@1 60.9	Acc@5 96.9
Epoch: [148][271/704]	Time 0.121	Data 0.001	Loss 4.40	Acc@1 68.8	Acc@5 96.9
Epoch: [148][281/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 64.1	Acc@5 90.6
Epoch: [148][291/704]	Time 0.121	Data 0.001	Loss 6.24	Acc@1 64.1	Acc@5 90.6
Epoch: [148][301/704]	Time 0.121	Data 0.001	Loss 4.66	Acc@1 73.4	Acc@5 96.9
Epoch: [148][311/704]	Time 0.121	Data 0.001	Loss 4.10	Acc@1 79.7	Acc@5 93.8
Epoch: [148][321/704]	Time 0.121	Data 0.001	Loss 3.77	Acc@1 73.4	Acc@5 95.3
Epoch: [148][331/704]	Time 0.121	Data 0.001	Loss 3.62	Acc@1 71.9	Acc@5 95.3
Epoch: [148][341/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 73.4	Acc@5 92.2
Epoch: [148][351/704]	Time 0.121	Data 0.001	Loss 3.98	Acc@1 68.8	Acc@5 95.3
Epoch: [148][361/704]	Time 0.121	Data 0.001	Loss 3.72	Acc@1 73.4	Acc@5 98.4
Epoch: [148][371/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 73.4	Acc@5 93.8
Epoch: [148][381/704]	Time 0.121	Data 0.001	Loss 4.45	Acc@1 68.8	Acc@5 95.3
Epoch: [148][391/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 75.0	Acc@5 96.9
Epoch: [148][401/704]	Time 0.121	Data 0.001	Loss 4.83	Acc@1 75.0	Acc@5 95.3
Epoch: [148][411/704]	Time 0.121	Data 0.001	Loss 5.03	Acc@1 62.5	Acc@5 87.5
Epoch: [148][421/704]	Time 0.121	Data 0.001	Loss 6.08	Acc@1 65.6	Acc@5 92.2
Epoch: [148][431/704]	Time 0.121	Data 0.001	Loss 4.09	Acc@1 73.4	Acc@5 95.3
Epoch: [148][441/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 68.8	Acc@5 95.3
Epoch: [148][451/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 70.3	Acc@5 93.8
Epoch: [148][461/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 62.5	Acc@5 96.9
Epoch: [148][471/704]	Time 0.121	Data 0.001	Loss 5.39	Acc@1 64.1	Acc@5 89.1
Epoch: [148][481/704]	Time 0.121	Data 0.001	Loss 5.27	Acc@1 71.9	Acc@5 92.2
Epoch: [148][491/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 75.0	Acc@5 93.8
Epoch: [148][501/704]	Time 0.121	Data 0.001	Loss 4.50	Acc@1 68.8	Acc@5 95.3
Epoch: [148][511/704]	Time 0.121	Data 0.001	Loss 5.31	Acc@1 68.8	Acc@5 95.3
Epoch: [148][521/704]	Time 0.121	Data 0.001	Loss 3.80	Acc@1 76.6	Acc@5 93.8
Epoch: [148][531/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 79.7	Acc@5 95.3
Epoch: [148][541/704]	Time 0.121	Data 0.001	Loss 5.71	Acc@1 64.1	Acc@5 90.6
Epoch: [148][551/704]	Time 0.121	Data 0.001	Loss 5.23	Acc@1 65.6	Acc@5 93.8
Epoch: [148][561/704]	Time 0.121	Data 0.001	Loss 5.85	Acc@1 59.4	Acc@5 92.2
Epoch: [148][571/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 79.7	Acc@5 98.4
Epoch: [148][581/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 81.2	Acc@5 93.8
Epoch: [148][591/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 68.8	Acc@5 90.6
Epoch: [148][601/704]	Time 0.121	Data 0.001	Loss 5.33	Acc@1 59.4	Acc@5 92.2
Epoch: [148][611/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 65.6	Acc@5 95.3
Epoch: [148][621/704]	Time 0.121	Data 0.001	Loss 5.09	Acc@1 59.4	Acc@5 95.3
Epoch: [148][631/704]	Time 0.121	Data 0.001	Loss 5.11	Acc@1 64.1	Acc@5 92.2
Epoch: [148][641/704]	Time 0.121	Data 0.001	Loss 4.95	Acc@1 57.8	Acc@5 93.8
Epoch: [148][651/704]	Time 0.121	Data 0.001	Loss 4.80	Acc@1 75.0	Acc@5 95.3
Epoch: [148][661/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 64.1	Acc@5 92.2
Epoch: [148][671/704]	Time 0.121	Data 0.001	Loss 5.42	Acc@1 62.5	Acc@5 92.2
Epoch: [148][681/704]	Time 0.121	Data 0.001	Loss 5.82	Acc@1 62.5	Acc@5 92.2
Epoch: [148][691/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 65.6	Acc@5 98.4
Epoch: [148][701/704]	Time 0.121	Data 0.001	Loss 4.64	Acc@1 70.3	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.8441	Acc@1 50.0000	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.9792	Acc@1 60.9375	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7787	Acc@1 62.5000	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.2200	Acc@1 53.1250	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.9849	Acc@1 48.4375	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.3392	Acc@1 60.9375	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.5441	Acc@1 54.6875	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.3041	Acc@1 65.6250	Acc@5 96.8750
 * prec@1 48.600 prec@5 79.520
 * prec@1 52.780 prec@5 83.360
 * prec@1 57.540 prec@5 86.880
 * prec@1 58.200 prec@5 86.460
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_148.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_148.pth.tar'
Epoch: [149][1/704]	Time 0.298	Data 0.131	Loss 4.04	Acc@1 79.7	Acc@5 98.4
Epoch: [149][11/704]	Time 0.137	Data 0.012	Loss 4.74	Acc@1 68.8	Acc@5 92.2
Epoch: [149][21/704]	Time 0.129	Data 0.007	Loss 4.14	Acc@1 79.7	Acc@5 95.3
Epoch: [149][31/704]	Time 0.126	Data 0.005	Loss 4.46	Acc@1 68.8	Acc@5 92.2
Epoch: [149][41/704]	Time 0.125	Data 0.004	Loss 4.53	Acc@1 62.5	Acc@5 96.9
Epoch: [149][51/704]	Time 0.124	Data 0.003	Loss 5.38	Acc@1 75.0	Acc@5 89.1
Epoch: [149][61/704]	Time 0.123	Data 0.003	Loss 4.02	Acc@1 76.6	Acc@5 95.3
Epoch: [149][71/704]	Time 0.123	Data 0.002	Loss 4.16	Acc@1 73.4	Acc@5 95.3
Epoch: [149][81/704]	Time 0.122	Data 0.002	Loss 4.73	Acc@1 75.0	Acc@5 92.2
Epoch: [149][91/704]	Time 0.123	Data 0.002	Loss 5.55	Acc@1 65.6	Acc@5 92.2
Epoch: [149][101/704]	Time 0.122	Data 0.002	Loss 5.79	Acc@1 68.8	Acc@5 90.6
Epoch: [149][111/704]	Time 0.122	Data 0.002	Loss 4.62	Acc@1 67.2	Acc@5 95.3
Epoch: [149][121/704]	Time 0.122	Data 0.001	Loss 6.09	Acc@1 60.9	Acc@5 90.6
Epoch: [149][131/704]	Time 0.122	Data 0.001	Loss 5.58	Acc@1 68.8	Acc@5 96.9
Epoch: [149][141/704]	Time 0.122	Data 0.001	Loss 4.43	Acc@1 71.9	Acc@5 93.8
Epoch: [149][151/704]	Time 0.122	Data 0.001	Loss 5.45	Acc@1 64.1	Acc@5 89.1
Epoch: [149][161/704]	Time 0.122	Data 0.001	Loss 4.36	Acc@1 71.9	Acc@5 92.2
Epoch: [149][171/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 78.1	Acc@5 98.4
Epoch: [149][181/704]	Time 0.121	Data 0.001	Loss 4.97	Acc@1 67.2	Acc@5 93.8
Epoch: [149][191/704]	Time 0.121	Data 0.001	Loss 4.53	Acc@1 70.3	Acc@5 92.2
Epoch: [149][201/704]	Time 0.121	Data 0.001	Loss 3.71	Acc@1 78.1	Acc@5 98.4
Epoch: [149][211/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 67.2	Acc@5 92.2
Epoch: [149][221/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 62.5	Acc@5 92.2
Epoch: [149][231/704]	Time 0.121	Data 0.001	Loss 4.73	Acc@1 71.9	Acc@5 93.8
Epoch: [149][241/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 78.1	Acc@5 92.2
Epoch: [149][251/704]	Time 0.121	Data 0.001	Loss 5.08	Acc@1 73.4	Acc@5 95.3
Epoch: [149][261/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 73.4	Acc@5 93.8
Epoch: [149][271/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 73.4	Acc@5 96.9
Epoch: [149][281/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 67.2	Acc@5 93.8
Epoch: [149][291/704]	Time 0.121	Data 0.001	Loss 5.58	Acc@1 76.6	Acc@5 93.8
Epoch: [149][301/704]	Time 0.121	Data 0.001	Loss 5.38	Acc@1 65.6	Acc@5 95.3
Epoch: [149][311/704]	Time 0.121	Data 0.001	Loss 5.07	Acc@1 67.2	Acc@5 98.4
Epoch: [149][321/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 76.6	Acc@5 93.8
Epoch: [149][331/704]	Time 0.121	Data 0.001	Loss 3.68	Acc@1 82.8	Acc@5 98.4
Epoch: [149][341/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 64.1	Acc@5 95.3
Epoch: [149][351/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 68.8	Acc@5 95.3
Epoch: [149][361/704]	Time 0.121	Data 0.001	Loss 4.77	Acc@1 68.8	Acc@5 90.6
Epoch: [149][371/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 64.1	Acc@5 89.1
Epoch: [149][381/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 68.8	Acc@5 93.8
Epoch: [149][391/704]	Time 0.121	Data 0.001	Loss 4.81	Acc@1 76.6	Acc@5 93.8
Epoch: [149][401/704]	Time 0.121	Data 0.001	Loss 5.49	Acc@1 70.3	Acc@5 90.6
Epoch: [149][411/704]	Time 0.121	Data 0.001	Loss 5.32	Acc@1 62.5	Acc@5 90.6
Epoch: [149][421/704]	Time 0.121	Data 0.001	Loss 5.56	Acc@1 67.2	Acc@5 92.2
Epoch: [149][431/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 70.3	Acc@5 95.3
Epoch: [149][441/704]	Time 0.121	Data 0.001	Loss 4.86	Acc@1 70.3	Acc@5 93.8
Epoch: [149][451/704]	Time 0.121	Data 0.001	Loss 4.98	Acc@1 73.4	Acc@5 93.8
Epoch: [149][461/704]	Time 0.121	Data 0.001	Loss 4.67	Acc@1 71.9	Acc@5 92.2
Epoch: [149][471/704]	Time 0.121	Data 0.001	Loss 4.84	Acc@1 71.9	Acc@5 96.9
Epoch: [149][481/704]	Time 0.121	Data 0.001	Loss 5.48	Acc@1 67.2	Acc@5 90.6
Epoch: [149][491/704]	Time 0.121	Data 0.001	Loss 4.42	Acc@1 68.8	Acc@5 93.8
Epoch: [149][501/704]	Time 0.121	Data 0.001	Loss 5.97	Acc@1 60.9	Acc@5 87.5
Epoch: [149][511/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 73.4	Acc@5 95.3
Epoch: [149][521/704]	Time 0.121	Data 0.001	Loss 5.24	Acc@1 59.4	Acc@5 92.2
Epoch: [149][531/704]	Time 0.121	Data 0.001	Loss 5.22	Acc@1 70.3	Acc@5 90.6
Epoch: [149][541/704]	Time 0.121	Data 0.001	Loss 5.19	Acc@1 70.3	Acc@5 89.1
Epoch: [149][551/704]	Time 0.121	Data 0.001	Loss 5.17	Acc@1 64.1	Acc@5 92.2
Epoch: [149][561/704]	Time 0.121	Data 0.001	Loss 4.79	Acc@1 75.0	Acc@5 95.3
Epoch: [149][571/704]	Time 0.121	Data 0.001	Loss 4.96	Acc@1 68.8	Acc@5 93.8
Epoch: [149][581/704]	Time 0.121	Data 0.001	Loss 4.57	Acc@1 65.6	Acc@5 90.6
Epoch: [149][591/704]	Time 0.121	Data 0.001	Loss 5.50	Acc@1 60.9	Acc@5 85.9
Epoch: [149][601/704]	Time 0.121	Data 0.001	Loss 4.91	Acc@1 57.8	Acc@5 90.6
Epoch: [149][611/704]	Time 0.121	Data 0.001	Loss 5.21	Acc@1 64.1	Acc@5 93.8
Epoch: [149][621/704]	Time 0.121	Data 0.001	Loss 5.47	Acc@1 57.8	Acc@5 96.9
Epoch: [149][631/704]	Time 0.121	Data 0.001	Loss 5.25	Acc@1 68.8	Acc@5 93.8
Epoch: [149][641/704]	Time 0.121	Data 0.001	Loss 4.56	Acc@1 73.4	Acc@5 93.8
Epoch: [149][651/704]	Time 0.121	Data 0.001	Loss 5.00	Acc@1 71.9	Acc@5 95.3
Epoch: [149][661/704]	Time 0.121	Data 0.001	Loss 5.05	Acc@1 64.1	Acc@5 93.8
Epoch: [149][671/704]	Time 0.121	Data 0.001	Loss 5.30	Acc@1 67.2	Acc@5 93.8
Epoch: [149][681/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 67.2	Acc@5 92.2
Epoch: [149][691/704]	Time 0.121	Data 0.001	Loss 4.31	Acc@1 79.7	Acc@5 96.9
Epoch: [149][701/704]	Time 0.121	Data 0.001	Loss 5.76	Acc@1 71.9	Acc@5 90.6
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.4725	Acc@1 60.9375	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.3961	Acc@1 73.4375	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.5822	Acc@1 60.9375	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3801	Acc@1 57.8125	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.2910	Acc@1 48.4375	Acc@5 76.5625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2652	Acc@1 57.8125	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7224	Acc@1 64.0625	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.9771	Acc@1 64.0625	Acc@5 93.7500
 * prec@1 48.060 prec@5 79.060
 * prec@1 54.540 prec@5 83.000
 * prec@1 57.220 prec@5 85.780
 * prec@1 59.260 prec@5 86.920
Current best validation last_bloc_accuracy 60.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_149.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_149.pth.tar'
Epoch: [150][1/704]	Time 0.301	Data 0.132	Loss 5.09	Acc@1 73.4	Acc@5 92.2
Epoch: [150][11/704]	Time 0.141	Data 0.012	Loss 4.06	Acc@1 68.8	Acc@5 98.4
Epoch: [150][21/704]	Time 0.131	Data 0.007	Loss 4.22	Acc@1 75.0	Acc@5 92.2
Epoch: [150][31/704]	Time 0.128	Data 0.005	Loss 3.97	Acc@1 73.4	Acc@5 93.8
Epoch: [150][41/704]	Time 0.126	Data 0.004	Loss 4.12	Acc@1 70.3	Acc@5 96.9
Epoch: [150][51/704]	Time 0.125	Data 0.003	Loss 4.15	Acc@1 75.0	Acc@5 95.3
Epoch: [150][61/704]	Time 0.124	Data 0.002	Loss 4.15	Acc@1 75.0	Acc@5 96.9
Epoch: [150][71/704]	Time 0.123	Data 0.002	Loss 3.63	Acc@1 76.6	Acc@5 98.4
Epoch: [150][81/704]	Time 0.123	Data 0.002	Loss 4.47	Acc@1 68.8	Acc@5 96.9
Epoch: [150][91/704]	Time 0.123	Data 0.002	Loss 4.07	Acc@1 79.7	Acc@5 100.0
Epoch: [150][101/704]	Time 0.123	Data 0.002	Loss 3.66	Acc@1 78.1	Acc@5 98.4
Epoch: [150][111/704]	Time 0.122	Data 0.001	Loss 4.26	Acc@1 75.0	Acc@5 96.9
Epoch: [150][121/704]	Time 0.122	Data 0.001	Loss 4.49	Acc@1 75.0	Acc@5 96.9
Epoch: [150][131/704]	Time 0.122	Data 0.001	Loss 5.18	Acc@1 73.4	Acc@5 90.6
Epoch: [150][141/704]	Time 0.122	Data 0.001	Loss 4.80	Acc@1 78.1	Acc@5 96.9
Epoch: [150][151/704]	Time 0.122	Data 0.001	Loss 4.19	Acc@1 70.3	Acc@5 95.3
Epoch: [150][161/704]	Time 0.122	Data 0.001	Loss 3.57	Acc@1 79.7	Acc@5 98.4
Epoch: [150][171/704]	Time 0.122	Data 0.001	Loss 4.42	Acc@1 81.2	Acc@5 95.3
Epoch: [150][181/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 85.9	Acc@5 98.4
Epoch: [150][191/704]	Time 0.121	Data 0.001	Loss 4.01	Acc@1 79.7	Acc@5 95.3
Epoch: [150][201/704]	Time 0.121	Data 0.001	Loss 4.24	Acc@1 78.1	Acc@5 96.9
Epoch: [150][211/704]	Time 0.121	Data 0.001	Loss 4.82	Acc@1 67.2	Acc@5 95.3
Epoch: [150][221/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 85.9	Acc@5 96.9
Epoch: [150][231/704]	Time 0.121	Data 0.001	Loss 3.75	Acc@1 82.8	Acc@5 93.8
Epoch: [150][241/704]	Time 0.121	Data 0.001	Loss 4.48	Acc@1 73.4	Acc@5 93.8
Epoch: [150][251/704]	Time 0.121	Data 0.001	Loss 3.08	Acc@1 81.2	Acc@5 100.0
Epoch: [150][261/704]	Time 0.121	Data 0.001	Loss 3.66	Acc@1 82.8	Acc@5 98.4
Epoch: [150][271/704]	Time 0.121	Data 0.001	Loss 4.55	Acc@1 68.8	Acc@5 95.3
Epoch: [150][281/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 82.8	Acc@5 95.3
Epoch: [150][291/704]	Time 0.121	Data 0.001	Loss 3.83	Acc@1 78.1	Acc@5 93.8
Epoch: [150][301/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 75.0	Acc@5 98.4
Epoch: [150][311/704]	Time 0.121	Data 0.001	Loss 3.47	Acc@1 79.7	Acc@5 100.0
Epoch: [150][321/704]	Time 0.121	Data 0.001	Loss 4.49	Acc@1 76.6	Acc@5 92.2
Epoch: [150][331/704]	Time 0.121	Data 0.001	Loss 3.56	Acc@1 78.1	Acc@5 96.9
Epoch: [150][341/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 84.4	Acc@5 96.9
Epoch: [150][351/704]	Time 0.121	Data 0.001	Loss 4.34	Acc@1 79.7	Acc@5 95.3
Epoch: [150][361/704]	Time 0.121	Data 0.001	Loss 4.90	Acc@1 76.6	Acc@5 95.3
Epoch: [150][371/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 85.9	Acc@5 95.3
Epoch: [150][381/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 78.1	Acc@5 96.9
Epoch: [150][391/704]	Time 0.121	Data 0.001	Loss 3.43	Acc@1 78.1	Acc@5 96.9
Epoch: [150][401/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 81.2	Acc@5 96.9
Epoch: [150][411/704]	Time 0.121	Data 0.001	Loss 3.83	Acc@1 79.7	Acc@5 93.8
Epoch: [150][421/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 85.9	Acc@5 100.0
Epoch: [150][431/704]	Time 0.121	Data 0.001	Loss 3.91	Acc@1 81.2	Acc@5 96.9
Epoch: [150][441/704]	Time 0.121	Data 0.001	Loss 4.46	Acc@1 70.3	Acc@5 95.3
Epoch: [150][451/704]	Time 0.121	Data 0.001	Loss 3.93	Acc@1 82.8	Acc@5 93.8
Epoch: [150][461/704]	Time 0.121	Data 0.001	Loss 3.66	Acc@1 81.2	Acc@5 95.3
Epoch: [150][471/704]	Time 0.121	Data 0.001	Loss 3.74	Acc@1 75.0	Acc@5 95.3
Epoch: [150][481/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 85.9	Acc@5 100.0
Epoch: [150][491/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 84.4	Acc@5 96.9
Epoch: [150][501/704]	Time 0.121	Data 0.001	Loss 3.82	Acc@1 76.6	Acc@5 96.9
Epoch: [150][511/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 85.9	Acc@5 98.4
Epoch: [150][521/704]	Time 0.121	Data 0.001	Loss 3.62	Acc@1 82.8	Acc@5 100.0
Epoch: [150][531/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 85.9	Acc@5 98.4
Epoch: [150][541/704]	Time 0.121	Data 0.001	Loss 3.27	Acc@1 81.2	Acc@5 96.9
Epoch: [150][551/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 81.2	Acc@5 98.4
Epoch: [150][561/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 85.9	Acc@5 100.0
Epoch: [150][571/704]	Time 0.121	Data 0.001	Loss 4.38	Acc@1 70.3	Acc@5 92.2
Epoch: [150][581/704]	Time 0.121	Data 0.001	Loss 3.86	Acc@1 79.7	Acc@5 95.3
Epoch: [150][591/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 85.9	Acc@5 100.0
Epoch: [150][601/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 84.4	Acc@5 96.9
Epoch: [150][611/704]	Time 0.121	Data 0.001	Loss 3.18	Acc@1 76.6	Acc@5 96.9
Epoch: [150][621/704]	Time 0.121	Data 0.001	Loss 3.63	Acc@1 82.8	Acc@5 98.4
Epoch: [150][631/704]	Time 0.121	Data 0.001	Loss 3.13	Acc@1 82.8	Acc@5 98.4
Epoch: [150][641/704]	Time 0.121	Data 0.001	Loss 3.86	Acc@1 82.8	Acc@5 98.4
Epoch: [150][651/704]	Time 0.121	Data 0.001	Loss 4.16	Acc@1 76.6	Acc@5 98.4
Epoch: [150][661/704]	Time 0.121	Data 0.001	Loss 4.43	Acc@1 78.1	Acc@5 90.6
Epoch: [150][671/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 84.4	Acc@5 100.0
Epoch: [150][681/704]	Time 0.121	Data 0.001	Loss 3.62	Acc@1 84.4	Acc@5 93.8
Epoch: [150][691/704]	Time 0.121	Data 0.001	Loss 4.21	Acc@1 79.7	Acc@5 92.2
Epoch: [150][701/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 78.1	Acc@5 96.9
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.3251	Acc@1 62.5000	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.2688	Acc@1 70.3125	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.9667	Acc@1 73.4375	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.1199	Acc@1 64.0625	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.9942	Acc@1 65.6250	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.5991	Acc@1 59.3750	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.1075	Acc@1 68.7500	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7342	Acc@1 60.9375	Acc@5 85.9375
 * prec@1 55.820 prec@5 84.380
 * prec@1 60.620 prec@5 87.440
 * prec@1 65.040 prec@5 90.860
 * prec@1 67.340 prec@5 91.100
New best validation last_bloc_accuracy 67.34
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_150.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_150.pth.tar'
Epoch: [151][1/704]	Time 0.329	Data 0.163	Loss 3.82	Acc@1 79.7	Acc@5 95.3
Epoch: [151][11/704]	Time 0.139	Data 0.015	Loss 3.08	Acc@1 82.8	Acc@5 95.3
Epoch: [151][21/704]	Time 0.130	Data 0.008	Loss 4.15	Acc@1 81.2	Acc@5 95.3
Epoch: [151][31/704]	Time 0.127	Data 0.006	Loss 3.21	Acc@1 87.5	Acc@5 100.0
Epoch: [151][41/704]	Time 0.125	Data 0.004	Loss 4.13	Acc@1 73.4	Acc@5 95.3
Epoch: [151][51/704]	Time 0.124	Data 0.003	Loss 3.55	Acc@1 81.2	Acc@5 100.0
Epoch: [151][61/704]	Time 0.124	Data 0.003	Loss 3.55	Acc@1 81.2	Acc@5 100.0
Epoch: [151][71/704]	Time 0.123	Data 0.003	Loss 3.69	Acc@1 84.4	Acc@5 96.9
Epoch: [151][81/704]	Time 0.123	Data 0.002	Loss 3.02	Acc@1 84.4	Acc@5 98.4
Epoch: [151][91/704]	Time 0.122	Data 0.002	Loss 2.46	Acc@1 87.5	Acc@5 98.4
Epoch: [151][101/704]	Time 0.122	Data 0.002	Loss 2.68	Acc@1 85.9	Acc@5 98.4
Epoch: [151][111/704]	Time 0.122	Data 0.002	Loss 2.49	Acc@1 92.2	Acc@5 100.0
Epoch: [151][121/704]	Time 0.122	Data 0.002	Loss 3.21	Acc@1 79.7	Acc@5 96.9
Epoch: [151][131/704]	Time 0.122	Data 0.002	Loss 3.42	Acc@1 87.5	Acc@5 96.9
Epoch: [151][141/704]	Time 0.122	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [151][151/704]	Time 0.121	Data 0.001	Loss 4.29	Acc@1 71.9	Acc@5 95.3
Epoch: [151][161/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 87.5	Acc@5 96.9
Epoch: [151][171/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 81.2	Acc@5 100.0
Epoch: [151][181/704]	Time 0.121	Data 0.001	Loss 3.59	Acc@1 79.7	Acc@5 96.9
Epoch: [151][191/704]	Time 0.121	Data 0.001	Loss 3.47	Acc@1 87.5	Acc@5 98.4
Epoch: [151][201/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 78.1	Acc@5 98.4
Epoch: [151][211/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 78.1	Acc@5 95.3
Epoch: [151][221/704]	Time 0.121	Data 0.001	Loss 4.19	Acc@1 73.4	Acc@5 95.3
Epoch: [151][231/704]	Time 0.121	Data 0.001	Loss 3.23	Acc@1 84.4	Acc@5 96.9
Epoch: [151][241/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 87.5	Acc@5 98.4
Epoch: [151][251/704]	Time 0.121	Data 0.001	Loss 3.20	Acc@1 78.1	Acc@5 100.0
Epoch: [151][261/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 96.9	Acc@5 100.0
Epoch: [151][271/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 81.2	Acc@5 98.4
Epoch: [151][281/704]	Time 0.121	Data 0.001	Loss 4.12	Acc@1 70.3	Acc@5 96.9
Epoch: [151][291/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 84.4	Acc@5 98.4
Epoch: [151][301/704]	Time 0.121	Data 0.001	Loss 3.72	Acc@1 78.1	Acc@5 96.9
Epoch: [151][311/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 84.4	Acc@5 100.0
Epoch: [151][321/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 84.4	Acc@5 95.3
Epoch: [151][331/704]	Time 0.121	Data 0.001	Loss 3.83	Acc@1 81.2	Acc@5 92.2
Epoch: [151][341/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 78.1	Acc@5 100.0
Epoch: [151][351/704]	Time 0.121	Data 0.001	Loss 3.63	Acc@1 84.4	Acc@5 98.4
Epoch: [151][361/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 81.2	Acc@5 98.4
Epoch: [151][371/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 89.1	Acc@5 98.4
Epoch: [151][381/704]	Time 0.121	Data 0.001	Loss 3.18	Acc@1 75.0	Acc@5 96.9
Epoch: [151][391/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 100.0
Epoch: [151][401/704]	Time 0.121	Data 0.001	Loss 3.79	Acc@1 84.4	Acc@5 98.4
Epoch: [151][411/704]	Time 0.121	Data 0.001	Loss 3.73	Acc@1 81.2	Acc@5 98.4
Epoch: [151][421/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 85.9	Acc@5 100.0
Epoch: [151][431/704]	Time 0.121	Data 0.001	Loss 3.34	Acc@1 79.7	Acc@5 98.4
Epoch: [151][441/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 75.0	Acc@5 95.3
Epoch: [151][451/704]	Time 0.121	Data 0.001	Loss 3.37	Acc@1 79.7	Acc@5 95.3
Epoch: [151][461/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 82.8	Acc@5 95.3
Epoch: [151][471/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 76.6	Acc@5 98.4
Epoch: [151][481/704]	Time 0.121	Data 0.001	Loss 3.67	Acc@1 79.7	Acc@5 96.9
Epoch: [151][491/704]	Time 0.121	Data 0.001	Loss 3.90	Acc@1 73.4	Acc@5 96.9
Epoch: [151][501/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 89.1	Acc@5 100.0
Epoch: [151][511/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 82.8	Acc@5 100.0
Epoch: [151][521/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 87.5	Acc@5 98.4
Epoch: [151][531/704]	Time 0.121	Data 0.001	Loss 4.08	Acc@1 87.5	Acc@5 96.9
Epoch: [151][541/704]	Time 0.121	Data 0.001	Loss 4.08	Acc@1 73.4	Acc@5 95.3
Epoch: [151][551/704]	Time 0.121	Data 0.001	Loss 3.18	Acc@1 87.5	Acc@5 100.0
Epoch: [151][561/704]	Time 0.121	Data 0.001	Loss 3.29	Acc@1 84.4	Acc@5 95.3
Epoch: [151][571/704]	Time 0.121	Data 0.001	Loss 3.91	Acc@1 76.6	Acc@5 93.8
Epoch: [151][581/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 79.7	Acc@5 98.4
Epoch: [151][591/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 78.1	Acc@5 95.3
Epoch: [151][601/704]	Time 0.120	Data 0.001	Loss 4.18	Acc@1 75.0	Acc@5 95.3
Epoch: [151][611/704]	Time 0.120	Data 0.001	Loss 3.48	Acc@1 84.4	Acc@5 96.9
Epoch: [151][621/704]	Time 0.120	Data 0.001	Loss 3.30	Acc@1 81.2	Acc@5 98.4
Epoch: [151][631/704]	Time 0.120	Data 0.001	Loss 3.95	Acc@1 73.4	Acc@5 98.4
Epoch: [151][641/704]	Time 0.120	Data 0.001	Loss 3.36	Acc@1 78.1	Acc@5 96.9
Epoch: [151][651/704]	Time 0.120	Data 0.001	Loss 3.45	Acc@1 79.7	Acc@5 96.9
Epoch: [151][661/704]	Time 0.120	Data 0.001	Loss 3.57	Acc@1 75.0	Acc@5 96.9
Epoch: [151][671/704]	Time 0.120	Data 0.001	Loss 3.30	Acc@1 82.8	Acc@5 93.8
Epoch: [151][681/704]	Time 0.120	Data 0.001	Loss 3.42	Acc@1 81.2	Acc@5 98.4
Epoch: [151][691/704]	Time 0.120	Data 0.001	Loss 3.43	Acc@1 79.7	Acc@5 98.4
Epoch: [151][701/704]	Time 0.120	Data 0.001	Loss 3.21	Acc@1 84.4	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.3535	Acc@1 71.8750	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.8189	Acc@1 65.6250	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5776	Acc@1 76.5625	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.4214	Acc@1 68.7500	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.4004	Acc@1 75.0000	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.3195	Acc@1 75.0000	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.4511	Acc@1 62.5000	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.5826	Acc@1 71.8750	Acc@5 89.0625
 * prec@1 56.580 prec@5 84.940
 * prec@1 61.320 prec@5 88.040
 * prec@1 66.320 prec@5 91.140
 * prec@1 68.580 prec@5 91.580
New best validation last_bloc_accuracy 68.58
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_151.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_151.pth.tar'
Epoch: [152][1/704]	Time 0.301	Data 0.133	Loss 3.90	Acc@1 81.2	Acc@5 96.9
Epoch: [152][11/704]	Time 0.137	Data 0.012	Loss 3.09	Acc@1 82.8	Acc@5 98.4
Epoch: [152][21/704]	Time 0.129	Data 0.007	Loss 2.82	Acc@1 92.2	Acc@5 98.4
Epoch: [152][31/704]	Time 0.127	Data 0.005	Loss 3.28	Acc@1 89.1	Acc@5 100.0
Epoch: [152][41/704]	Time 0.125	Data 0.004	Loss 3.51	Acc@1 85.9	Acc@5 96.9
Epoch: [152][51/704]	Time 0.124	Data 0.003	Loss 3.63	Acc@1 76.6	Acc@5 93.8
Epoch: [152][61/704]	Time 0.124	Data 0.002	Loss 3.64	Acc@1 82.8	Acc@5 98.4
Epoch: [152][71/704]	Time 0.123	Data 0.002	Loss 3.18	Acc@1 73.4	Acc@5 96.9
Epoch: [152][81/704]	Time 0.123	Data 0.002	Loss 2.45	Acc@1 85.9	Acc@5 100.0
Epoch: [152][91/704]	Time 0.123	Data 0.002	Loss 2.82	Acc@1 87.5	Acc@5 98.4
Epoch: [152][101/704]	Time 0.122	Data 0.002	Loss 2.95	Acc@1 85.9	Acc@5 98.4
Epoch: [152][111/704]	Time 0.122	Data 0.001	Loss 3.12	Acc@1 89.1	Acc@5 98.4
Epoch: [152][121/704]	Time 0.122	Data 0.001	Loss 3.62	Acc@1 84.4	Acc@5 98.4
Epoch: [152][131/704]	Time 0.122	Data 0.001	Loss 3.78	Acc@1 84.4	Acc@5 95.3
Epoch: [152][141/704]	Time 0.122	Data 0.001	Loss 3.35	Acc@1 82.8	Acc@5 98.4
Epoch: [152][151/704]	Time 0.122	Data 0.001	Loss 2.98	Acc@1 87.5	Acc@5 96.9
Epoch: [152][161/704]	Time 0.122	Data 0.001	Loss 2.41	Acc@1 85.9	Acc@5 98.4
Epoch: [152][171/704]	Time 0.122	Data 0.001	Loss 2.73	Acc@1 90.6	Acc@5 98.4
Epoch: [152][181/704]	Time 0.122	Data 0.001	Loss 3.81	Acc@1 76.6	Acc@5 95.3
Epoch: [152][191/704]	Time 0.122	Data 0.001	Loss 3.31	Acc@1 84.4	Acc@5 96.9
Epoch: [152][201/704]	Time 0.122	Data 0.001	Loss 3.20	Acc@1 85.9	Acc@5 96.9
Epoch: [152][211/704]	Time 0.121	Data 0.001	Loss 4.20	Acc@1 78.1	Acc@5 96.9
Epoch: [152][221/704]	Time 0.121	Data 0.001	Loss 4.05	Acc@1 78.1	Acc@5 98.4
Epoch: [152][231/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 85.9	Acc@5 96.9
Epoch: [152][241/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 84.4	Acc@5 98.4
Epoch: [152][251/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 87.5	Acc@5 95.3
Epoch: [152][261/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 87.5	Acc@5 95.3
Epoch: [152][271/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 81.2	Acc@5 100.0
Epoch: [152][281/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 82.8	Acc@5 98.4
Epoch: [152][291/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 92.2	Acc@5 100.0
Epoch: [152][301/704]	Time 0.121	Data 0.001	Loss 3.39	Acc@1 81.2	Acc@5 93.8
Epoch: [152][311/704]	Time 0.121	Data 0.001	Loss 3.28	Acc@1 79.7	Acc@5 98.4
Epoch: [152][321/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 85.9	Acc@5 98.4
Epoch: [152][331/704]	Time 0.121	Data 0.001	Loss 3.05	Acc@1 82.8	Acc@5 98.4
Epoch: [152][341/704]	Time 0.121	Data 0.001	Loss 3.70	Acc@1 79.7	Acc@5 100.0
Epoch: [152][351/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 82.8	Acc@5 100.0
Epoch: [152][361/704]	Time 0.121	Data 0.001	Loss 3.74	Acc@1 89.1	Acc@5 98.4
Epoch: [152][371/704]	Time 0.121	Data 0.001	Loss 3.50	Acc@1 81.2	Acc@5 96.9
Epoch: [152][381/704]	Time 0.121	Data 0.001	Loss 3.34	Acc@1 79.7	Acc@5 96.9
Epoch: [152][391/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 85.9	Acc@5 98.4
Epoch: [152][401/704]	Time 0.121	Data 0.001	Loss 3.60	Acc@1 82.8	Acc@5 98.4
Epoch: [152][411/704]	Time 0.121	Data 0.001	Loss 3.84	Acc@1 84.4	Acc@5 98.4
Epoch: [152][421/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 85.9	Acc@5 98.4
Epoch: [152][431/704]	Time 0.121	Data 0.001	Loss 3.81	Acc@1 82.8	Acc@5 96.9
Epoch: [152][441/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 84.4	Acc@5 98.4
Epoch: [152][451/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 87.5	Acc@5 95.3
Epoch: [152][461/704]	Time 0.121	Data 0.001	Loss 3.49	Acc@1 79.7	Acc@5 95.3
Epoch: [152][471/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 100.0
Epoch: [152][481/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 90.6	Acc@5 95.3
Epoch: [152][491/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 85.9	Acc@5 96.9
Epoch: [152][501/704]	Time 0.121	Data 0.001	Loss 4.07	Acc@1 78.1	Acc@5 96.9
Epoch: [152][511/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 84.4	Acc@5 100.0
Epoch: [152][521/704]	Time 0.121	Data 0.001	Loss 3.69	Acc@1 78.1	Acc@5 95.3
Epoch: [152][531/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 89.1	Acc@5 98.4
Epoch: [152][541/704]	Time 0.121	Data 0.001	Loss 3.85	Acc@1 76.6	Acc@5 98.4
Epoch: [152][551/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 92.2	Acc@5 100.0
Epoch: [152][561/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 78.1	Acc@5 98.4
Epoch: [152][571/704]	Time 0.121	Data 0.001	Loss 4.36	Acc@1 73.4	Acc@5 92.2
Epoch: [152][581/704]	Time 0.121	Data 0.001	Loss 4.03	Acc@1 71.9	Acc@5 96.9
Epoch: [152][591/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 82.8	Acc@5 96.9
Epoch: [152][601/704]	Time 0.121	Data 0.001	Loss 3.40	Acc@1 81.2	Acc@5 95.3
Epoch: [152][611/704]	Time 0.121	Data 0.001	Loss 3.35	Acc@1 79.7	Acc@5 96.9
Epoch: [152][621/704]	Time 0.121	Data 0.001	Loss 3.00	Acc@1 84.4	Acc@5 96.9
Epoch: [152][631/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 84.4	Acc@5 96.9
Epoch: [152][641/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 78.1	Acc@5 98.4
Epoch: [152][651/704]	Time 0.121	Data 0.001	Loss 3.19	Acc@1 84.4	Acc@5 100.0
Epoch: [152][661/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 82.8	Acc@5 100.0
Epoch: [152][671/704]	Time 0.121	Data 0.001	Loss 3.27	Acc@1 81.2	Acc@5 96.9
Epoch: [152][681/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 81.2	Acc@5 95.3
Epoch: [152][691/704]	Time 0.121	Data 0.001	Loss 3.57	Acc@1 82.8	Acc@5 96.9
Epoch: [152][701/704]	Time 0.121	Data 0.001	Loss 4.14	Acc@1 87.5	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.0958	Acc@1 71.8750	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.4022	Acc@1 68.7500	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.4170	Acc@1 75.0000	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.0917	Acc@1 67.1875	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2988	Acc@1 71.8750	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.2847	Acc@1 76.5625	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.0333	Acc@1 67.1875	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.0735	Acc@1 68.7500	Acc@5 96.8750
 * prec@1 56.700 prec@5 84.280
 * prec@1 61.260 prec@5 88.200
 * prec@1 65.980 prec@5 90.980
 * prec@1 68.780 prec@5 91.500
New best validation last_bloc_accuracy 68.78
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_152.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_152.pth.tar'
Epoch: [153][1/704]	Time 0.299	Data 0.132	Loss 3.46	Acc@1 79.7	Acc@5 100.0
Epoch: [153][11/704]	Time 0.136	Data 0.012	Loss 3.91	Acc@1 76.6	Acc@5 93.8
Epoch: [153][21/704]	Time 0.128	Data 0.007	Loss 2.63	Acc@1 89.1	Acc@5 100.0
Epoch: [153][31/704]	Time 0.125	Data 0.005	Loss 2.75	Acc@1 84.4	Acc@5 98.4
Epoch: [153][41/704]	Time 0.124	Data 0.003	Loss 2.89	Acc@1 78.1	Acc@5 100.0
Epoch: [153][51/704]	Time 0.123	Data 0.003	Loss 2.56	Acc@1 84.4	Acc@5 98.4
Epoch: [153][61/704]	Time 0.123	Data 0.002	Loss 3.36	Acc@1 79.7	Acc@5 96.9
Epoch: [153][71/704]	Time 0.123	Data 0.002	Loss 3.24	Acc@1 87.5	Acc@5 96.9
Epoch: [153][81/704]	Time 0.123	Data 0.002	Loss 2.59	Acc@1 85.9	Acc@5 100.0
Epoch: [153][91/704]	Time 0.122	Data 0.002	Loss 3.39	Acc@1 84.4	Acc@5 96.9
Epoch: [153][101/704]	Time 0.122	Data 0.002	Loss 3.12	Acc@1 85.9	Acc@5 98.4
Epoch: [153][111/704]	Time 0.122	Data 0.001	Loss 3.64	Acc@1 78.1	Acc@5 95.3
Epoch: [153][121/704]	Time 0.122	Data 0.001	Loss 2.83	Acc@1 84.4	Acc@5 96.9
Epoch: [153][131/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 84.4	Acc@5 96.9
Epoch: [153][141/704]	Time 0.121	Data 0.001	Loss 3.55	Acc@1 78.1	Acc@5 96.9
Epoch: [153][151/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 81.2	Acc@5 98.4
Epoch: [153][161/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 84.4	Acc@5 100.0
Epoch: [153][171/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 87.5	Acc@5 98.4
Epoch: [153][181/704]	Time 0.121	Data 0.001	Loss 3.28	Acc@1 79.7	Acc@5 98.4
Epoch: [153][191/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 84.4	Acc@5 96.9
Epoch: [153][201/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 87.5	Acc@5 98.4
Epoch: [153][211/704]	Time 0.121	Data 0.001	Loss 3.96	Acc@1 82.8	Acc@5 96.9
Epoch: [153][221/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 87.5	Acc@5 98.4
Epoch: [153][231/704]	Time 0.121	Data 0.001	Loss 3.79	Acc@1 82.8	Acc@5 93.8
Epoch: [153][241/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 87.5	Acc@5 98.4
Epoch: [153][251/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 84.4	Acc@5 96.9
Epoch: [153][261/704]	Time 0.121	Data 0.001	Loss 3.53	Acc@1 78.1	Acc@5 96.9
Epoch: [153][271/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 79.7	Acc@5 96.9
Epoch: [153][281/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 81.2	Acc@5 98.4
Epoch: [153][291/704]	Time 0.120	Data 0.001	Loss 3.35	Acc@1 87.5	Acc@5 93.8
Epoch: [153][301/704]	Time 0.120	Data 0.001	Loss 3.54	Acc@1 84.4	Acc@5 96.9
Epoch: [153][311/704]	Time 0.120	Data 0.001	Loss 3.60	Acc@1 89.1	Acc@5 95.3
Epoch: [153][321/704]	Time 0.120	Data 0.001	Loss 3.86	Acc@1 76.6	Acc@5 98.4
Epoch: [153][331/704]	Time 0.120	Data 0.001	Loss 3.88	Acc@1 76.6	Acc@5 95.3
Epoch: [153][341/704]	Time 0.120	Data 0.001	Loss 3.45	Acc@1 75.0	Acc@5 96.9
Epoch: [153][351/704]	Time 0.120	Data 0.001	Loss 3.22	Acc@1 84.4	Acc@5 96.9
Epoch: [153][361/704]	Time 0.120	Data 0.001	Loss 2.93	Acc@1 84.4	Acc@5 98.4
Epoch: [153][371/704]	Time 0.120	Data 0.001	Loss 4.29	Acc@1 78.1	Acc@5 93.8
Epoch: [153][381/704]	Time 0.120	Data 0.001	Loss 3.44	Acc@1 82.8	Acc@5 95.3
Epoch: [153][391/704]	Time 0.120	Data 0.001	Loss 3.02	Acc@1 85.9	Acc@5 100.0
Epoch: [153][401/704]	Time 0.120	Data 0.001	Loss 2.95	Acc@1 87.5	Acc@5 95.3
Epoch: [153][411/704]	Time 0.120	Data 0.001	Loss 2.23	Acc@1 89.1	Acc@5 98.4
Epoch: [153][421/704]	Time 0.120	Data 0.001	Loss 2.59	Acc@1 76.6	Acc@5 98.4
Epoch: [153][431/704]	Time 0.120	Data 0.001	Loss 3.16	Acc@1 82.8	Acc@5 100.0
Epoch: [153][441/704]	Time 0.120	Data 0.001	Loss 3.40	Acc@1 85.9	Acc@5 95.3
Epoch: [153][451/704]	Time 0.120	Data 0.001	Loss 3.34	Acc@1 78.1	Acc@5 100.0
Epoch: [153][461/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 90.6	Acc@5 96.9
Epoch: [153][471/704]	Time 0.120	Data 0.001	Loss 2.62	Acc@1 84.4	Acc@5 98.4
Epoch: [153][481/704]	Time 0.120	Data 0.001	Loss 3.52	Acc@1 81.2	Acc@5 98.4
Epoch: [153][491/704]	Time 0.120	Data 0.001	Loss 3.53	Acc@1 81.2	Acc@5 96.9
Epoch: [153][501/704]	Time 0.120	Data 0.001	Loss 2.77	Acc@1 90.6	Acc@5 100.0
Epoch: [153][511/704]	Time 0.120	Data 0.001	Loss 3.65	Acc@1 84.4	Acc@5 95.3
Epoch: [153][521/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 90.6	Acc@5 100.0
Epoch: [153][531/704]	Time 0.120	Data 0.001	Loss 2.70	Acc@1 89.1	Acc@5 98.4
Epoch: [153][541/704]	Time 0.120	Data 0.001	Loss 2.61	Acc@1 87.5	Acc@5 98.4
Epoch: [153][551/704]	Time 0.120	Data 0.001	Loss 3.43	Acc@1 76.6	Acc@5 96.9
Epoch: [153][561/704]	Time 0.120	Data 0.001	Loss 4.24	Acc@1 73.4	Acc@5 96.9
Epoch: [153][571/704]	Time 0.120	Data 0.001	Loss 3.13	Acc@1 82.8	Acc@5 100.0
Epoch: [153][581/704]	Time 0.120	Data 0.001	Loss 3.55	Acc@1 79.7	Acc@5 100.0
Epoch: [153][591/704]	Time 0.120	Data 0.001	Loss 4.06	Acc@1 76.6	Acc@5 96.9
Epoch: [153][601/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 79.7	Acc@5 98.4
Epoch: [153][611/704]	Time 0.120	Data 0.001	Loss 4.00	Acc@1 84.4	Acc@5 95.3
Epoch: [153][621/704]	Time 0.120	Data 0.001	Loss 3.82	Acc@1 75.0	Acc@5 98.4
Epoch: [153][631/704]	Time 0.120	Data 0.001	Loss 3.61	Acc@1 81.2	Acc@5 98.4
Epoch: [153][641/704]	Time 0.120	Data 0.001	Loss 2.78	Acc@1 89.1	Acc@5 100.0
Epoch: [153][651/704]	Time 0.120	Data 0.001	Loss 3.15	Acc@1 82.8	Acc@5 100.0
Epoch: [153][661/704]	Time 0.120	Data 0.001	Loss 2.67	Acc@1 89.1	Acc@5 98.4
Epoch: [153][671/704]	Time 0.120	Data 0.001	Loss 2.77	Acc@1 87.5	Acc@5 96.9
Epoch: [153][681/704]	Time 0.120	Data 0.001	Loss 3.26	Acc@1 82.8	Acc@5 96.9
Epoch: [153][691/704]	Time 0.120	Data 0.001	Loss 3.32	Acc@1 82.8	Acc@5 98.4
Epoch: [153][701/704]	Time 0.120	Data 0.001	Loss 2.66	Acc@1 85.9	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.0273	Acc@1 65.6250	Acc@5 96.8750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.8472	Acc@1 70.3125	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.4420	Acc@1 70.3125	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4048	Acc@1 71.8750	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.7545	Acc@1 73.4375	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8030	Acc@1 70.3125	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.6730	Acc@1 78.1250	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.3023	Acc@1 70.3125	Acc@5 90.6250
 * prec@1 57.160 prec@5 84.880
 * prec@1 61.980 prec@5 87.900
 * prec@1 66.020 prec@5 91.200
 * prec@1 69.060 prec@5 91.680
New best validation last_bloc_accuracy 69.06
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_153.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_153.pth.tar'
Epoch: [154][1/704]	Time 0.332	Data 0.166	Loss 2.72	Acc@1 93.8	Acc@5 100.0
Epoch: [154][11/704]	Time 0.139	Data 0.015	Loss 3.50	Acc@1 84.4	Acc@5 96.9
Epoch: [154][21/704]	Time 0.130	Data 0.008	Loss 3.07	Acc@1 84.4	Acc@5 96.9
Epoch: [154][31/704]	Time 0.127	Data 0.006	Loss 2.75	Acc@1 84.4	Acc@5 98.4
Epoch: [154][41/704]	Time 0.125	Data 0.004	Loss 3.71	Acc@1 79.7	Acc@5 98.4
Epoch: [154][51/704]	Time 0.124	Data 0.004	Loss 2.33	Acc@1 87.5	Acc@5 100.0
Epoch: [154][61/704]	Time 0.123	Data 0.003	Loss 3.39	Acc@1 76.6	Acc@5 96.9
Epoch: [154][71/704]	Time 0.123	Data 0.003	Loss 2.86	Acc@1 79.7	Acc@5 96.9
Epoch: [154][81/704]	Time 0.122	Data 0.002	Loss 3.09	Acc@1 82.8	Acc@5 98.4
Epoch: [154][91/704]	Time 0.122	Data 0.002	Loss 4.42	Acc@1 71.9	Acc@5 95.3
Epoch: [154][101/704]	Time 0.122	Data 0.002	Loss 2.55	Acc@1 90.6	Acc@5 98.4
Epoch: [154][111/704]	Time 0.122	Data 0.002	Loss 3.34	Acc@1 79.7	Acc@5 98.4
Epoch: [154][121/704]	Time 0.122	Data 0.002	Loss 3.84	Acc@1 73.4	Acc@5 96.9
Epoch: [154][131/704]	Time 0.121	Data 0.002	Loss 3.18	Acc@1 82.8	Acc@5 100.0
Epoch: [154][141/704]	Time 0.121	Data 0.001	Loss 3.73	Acc@1 78.1	Acc@5 98.4
Epoch: [154][151/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 79.7	Acc@5 96.9
Epoch: [154][161/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 81.2	Acc@5 95.3
Epoch: [154][171/704]	Time 0.121	Data 0.001	Loss 3.05	Acc@1 81.2	Acc@5 100.0
Epoch: [154][181/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 82.8	Acc@5 98.4
Epoch: [154][191/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 78.1	Acc@5 100.0
Epoch: [154][201/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [154][211/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 84.4	Acc@5 96.9
Epoch: [154][221/704]	Time 0.121	Data 0.001	Loss 4.11	Acc@1 81.2	Acc@5 95.3
Epoch: [154][231/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 84.4	Acc@5 98.4
Epoch: [154][241/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 87.5	Acc@5 98.4
Epoch: [154][251/704]	Time 0.121	Data 0.001	Loss 3.13	Acc@1 90.6	Acc@5 95.3
Epoch: [154][261/704]	Time 0.121	Data 0.001	Loss 3.81	Acc@1 81.2	Acc@5 98.4
Epoch: [154][271/704]	Time 0.121	Data 0.001	Loss 4.21	Acc@1 71.9	Acc@5 98.4
Epoch: [154][281/704]	Time 0.121	Data 0.001	Loss 3.46	Acc@1 78.1	Acc@5 93.8
Epoch: [154][291/704]	Time 0.120	Data 0.001	Loss 3.94	Acc@1 79.7	Acc@5 96.9
Epoch: [154][301/704]	Time 0.120	Data 0.001	Loss 3.28	Acc@1 82.8	Acc@5 98.4
Epoch: [154][311/704]	Time 0.120	Data 0.001	Loss 3.66	Acc@1 79.7	Acc@5 92.2
Epoch: [154][321/704]	Time 0.120	Data 0.001	Loss 3.05	Acc@1 87.5	Acc@5 98.4
Epoch: [154][331/704]	Time 0.120	Data 0.001	Loss 2.76	Acc@1 87.5	Acc@5 98.4
Epoch: [154][341/704]	Time 0.120	Data 0.001	Loss 2.60	Acc@1 92.2	Acc@5 100.0
Epoch: [154][351/704]	Time 0.120	Data 0.001	Loss 3.31	Acc@1 82.8	Acc@5 95.3
Epoch: [154][361/704]	Time 0.120	Data 0.001	Loss 3.78	Acc@1 85.9	Acc@5 98.4
Epoch: [154][371/704]	Time 0.120	Data 0.001	Loss 2.63	Acc@1 87.5	Acc@5 96.9
Epoch: [154][381/704]	Time 0.120	Data 0.001	Loss 3.15	Acc@1 85.9	Acc@5 98.4
Epoch: [154][391/704]	Time 0.120	Data 0.001	Loss 3.79	Acc@1 78.1	Acc@5 95.3
Epoch: [154][401/704]	Time 0.120	Data 0.001	Loss 3.52	Acc@1 85.9	Acc@5 96.9
Epoch: [154][411/704]	Time 0.120	Data 0.001	Loss 2.91	Acc@1 84.4	Acc@5 100.0
Epoch: [154][421/704]	Time 0.120	Data 0.001	Loss 3.31	Acc@1 78.1	Acc@5 96.9
Epoch: [154][431/704]	Time 0.120	Data 0.001	Loss 2.91	Acc@1 85.9	Acc@5 96.9
Epoch: [154][441/704]	Time 0.120	Data 0.001	Loss 2.92	Acc@1 81.2	Acc@5 98.4
Epoch: [154][451/704]	Time 0.120	Data 0.001	Loss 4.06	Acc@1 76.6	Acc@5 98.4
Epoch: [154][461/704]	Time 0.120	Data 0.001	Loss 3.79	Acc@1 78.1	Acc@5 98.4
Epoch: [154][471/704]	Time 0.120	Data 0.001	Loss 4.10	Acc@1 81.2	Acc@5 95.3
Epoch: [154][481/704]	Time 0.120	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 100.0
Epoch: [154][491/704]	Time 0.120	Data 0.001	Loss 3.78	Acc@1 79.7	Acc@5 98.4
Epoch: [154][501/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [154][511/704]	Time 0.120	Data 0.001	Loss 3.44	Acc@1 78.1	Acc@5 100.0
Epoch: [154][521/704]	Time 0.120	Data 0.001	Loss 3.36	Acc@1 82.8	Acc@5 98.4
Epoch: [154][531/704]	Time 0.120	Data 0.001	Loss 2.73	Acc@1 85.9	Acc@5 98.4
Epoch: [154][541/704]	Time 0.120	Data 0.001	Loss 2.52	Acc@1 84.4	Acc@5 98.4
Epoch: [154][551/704]	Time 0.120	Data 0.001	Loss 2.67	Acc@1 84.4	Acc@5 98.4
Epoch: [154][561/704]	Time 0.120	Data 0.001	Loss 2.98	Acc@1 90.6	Acc@5 96.9
Epoch: [154][571/704]	Time 0.120	Data 0.001	Loss 3.11	Acc@1 81.2	Acc@5 96.9
Epoch: [154][581/704]	Time 0.120	Data 0.001	Loss 3.23	Acc@1 90.6	Acc@5 98.4
Epoch: [154][591/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 87.5	Acc@5 100.0
Epoch: [154][601/704]	Time 0.120	Data 0.001	Loss 3.93	Acc@1 78.1	Acc@5 95.3
Epoch: [154][611/704]	Time 0.120	Data 0.001	Loss 3.65	Acc@1 82.8	Acc@5 98.4
Epoch: [154][621/704]	Time 0.120	Data 0.001	Loss 2.63	Acc@1 92.2	Acc@5 100.0
Epoch: [154][631/704]	Time 0.120	Data 0.001	Loss 3.22	Acc@1 78.1	Acc@5 100.0
Epoch: [154][641/704]	Time 0.120	Data 0.001	Loss 2.86	Acc@1 87.5	Acc@5 100.0
Epoch: [154][651/704]	Time 0.120	Data 0.001	Loss 2.92	Acc@1 89.1	Acc@5 100.0
Epoch: [154][661/704]	Time 0.120	Data 0.001	Loss 3.16	Acc@1 84.4	Acc@5 96.9
Epoch: [154][671/704]	Time 0.120	Data 0.001	Loss 3.32	Acc@1 73.4	Acc@5 96.9
Epoch: [154][681/704]	Time 0.120	Data 0.001	Loss 3.31	Acc@1 85.9	Acc@5 96.9
Epoch: [154][691/704]	Time 0.120	Data 0.001	Loss 3.02	Acc@1 89.1	Acc@5 100.0
Epoch: [154][701/704]	Time 0.120	Data 0.001	Loss 3.33	Acc@1 78.1	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.1923	Acc@1 71.8750	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 4.7686	Acc@1 81.2500	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.6516	Acc@1 68.7500	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.4179	Acc@1 70.3125	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.0180	Acc@1 67.1875	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.7255	Acc@1 68.7500	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.3878	Acc@1 59.3750	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.6828	Acc@1 75.0000	Acc@5 95.3125
 * prec@1 56.560 prec@5 84.980
 * prec@1 61.760 prec@5 88.640
 * prec@1 66.840 prec@5 90.960
 * prec@1 68.380 prec@5 91.280
Current best validation last_bloc_accuracy 69.06
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_154.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_154.pth.tar'
Epoch: [155][1/704]	Time 0.335	Data 0.168	Loss 3.32	Acc@1 84.4	Acc@5 98.4
Epoch: [155][11/704]	Time 0.140	Data 0.016	Loss 3.19	Acc@1 82.8	Acc@5 100.0
Epoch: [155][21/704]	Time 0.131	Data 0.008	Loss 3.38	Acc@1 84.4	Acc@5 98.4
Epoch: [155][31/704]	Time 0.127	Data 0.006	Loss 2.76	Acc@1 85.9	Acc@5 98.4
Epoch: [155][41/704]	Time 0.126	Data 0.004	Loss 3.07	Acc@1 89.1	Acc@5 100.0
Epoch: [155][51/704]	Time 0.125	Data 0.004	Loss 2.90	Acc@1 84.4	Acc@5 100.0
Epoch: [155][61/704]	Time 0.124	Data 0.003	Loss 2.86	Acc@1 85.9	Acc@5 96.9
Epoch: [155][71/704]	Time 0.123	Data 0.003	Loss 3.64	Acc@1 75.0	Acc@5 93.8
Epoch: [155][81/704]	Time 0.123	Data 0.002	Loss 3.19	Acc@1 82.8	Acc@5 100.0
Epoch: [155][91/704]	Time 0.123	Data 0.002	Loss 3.03	Acc@1 76.6	Acc@5 96.9
Epoch: [155][101/704]	Time 0.123	Data 0.002	Loss 3.40	Acc@1 84.4	Acc@5 96.9
Epoch: [155][111/704]	Time 0.122	Data 0.002	Loss 3.13	Acc@1 85.9	Acc@5 98.4
Epoch: [155][121/704]	Time 0.122	Data 0.002	Loss 4.12	Acc@1 79.7	Acc@5 98.4
Epoch: [155][131/704]	Time 0.122	Data 0.002	Loss 3.90	Acc@1 79.7	Acc@5 98.4
Epoch: [155][141/704]	Time 0.122	Data 0.001	Loss 2.98	Acc@1 82.8	Acc@5 98.4
Epoch: [155][151/704]	Time 0.122	Data 0.001	Loss 3.27	Acc@1 79.7	Acc@5 96.9
Epoch: [155][161/704]	Time 0.122	Data 0.001	Loss 2.83	Acc@1 85.9	Acc@5 98.4
Epoch: [155][171/704]	Time 0.122	Data 0.001	Loss 4.18	Acc@1 75.0	Acc@5 96.9
Epoch: [155][181/704]	Time 0.122	Data 0.001	Loss 2.66	Acc@1 82.8	Acc@5 96.9
Epoch: [155][191/704]	Time 0.122	Data 0.001	Loss 3.49	Acc@1 85.9	Acc@5 100.0
Epoch: [155][201/704]	Time 0.122	Data 0.001	Loss 2.99	Acc@1 90.6	Acc@5 95.3
Epoch: [155][211/704]	Time 0.122	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [155][221/704]	Time 0.122	Data 0.001	Loss 3.16	Acc@1 75.0	Acc@5 98.4
Epoch: [155][231/704]	Time 0.121	Data 0.001	Loss 3.61	Acc@1 78.1	Acc@5 96.9
Epoch: [155][241/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 89.1	Acc@5 98.4
Epoch: [155][251/704]	Time 0.121	Data 0.001	Loss 3.50	Acc@1 85.9	Acc@5 95.3
Epoch: [155][261/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 84.4	Acc@5 95.3
Epoch: [155][271/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 84.4	Acc@5 100.0
Epoch: [155][281/704]	Time 0.121	Data 0.001	Loss 3.70	Acc@1 75.0	Acc@5 100.0
Epoch: [155][291/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 76.6	Acc@5 92.2
Epoch: [155][301/704]	Time 0.121	Data 0.001	Loss 3.34	Acc@1 84.4	Acc@5 95.3
Epoch: [155][311/704]	Time 0.121	Data 0.001	Loss 3.18	Acc@1 81.2	Acc@5 100.0
Epoch: [155][321/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 90.6	Acc@5 98.4
Epoch: [155][331/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 82.8	Acc@5 98.4
Epoch: [155][341/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 82.8	Acc@5 96.9
Epoch: [155][351/704]	Time 0.121	Data 0.001	Loss 3.70	Acc@1 90.6	Acc@5 96.9
Epoch: [155][361/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 78.1	Acc@5 100.0
Epoch: [155][371/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 85.9	Acc@5 100.0
Epoch: [155][381/704]	Time 0.121	Data 0.001	Loss 3.55	Acc@1 79.7	Acc@5 95.3
Epoch: [155][391/704]	Time 0.121	Data 0.001	Loss 3.46	Acc@1 82.8	Acc@5 93.8
Epoch: [155][401/704]	Time 0.121	Data 0.001	Loss 3.13	Acc@1 87.5	Acc@5 96.9
Epoch: [155][411/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 82.8	Acc@5 100.0
Epoch: [155][421/704]	Time 0.121	Data 0.001	Loss 3.59	Acc@1 78.1	Acc@5 98.4
Epoch: [155][431/704]	Time 0.121	Data 0.001	Loss 3.70	Acc@1 85.9	Acc@5 95.3
Epoch: [155][441/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 76.6	Acc@5 98.4
Epoch: [155][451/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 87.5	Acc@5 96.9
Epoch: [155][461/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 85.9	Acc@5 100.0
Epoch: [155][471/704]	Time 0.121	Data 0.001	Loss 3.57	Acc@1 78.1	Acc@5 92.2
Epoch: [155][481/704]	Time 0.121	Data 0.001	Loss 3.51	Acc@1 81.2	Acc@5 98.4
Epoch: [155][491/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 82.8	Acc@5 100.0
Epoch: [155][501/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 84.4	Acc@5 96.9
Epoch: [155][511/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 85.9	Acc@5 96.9
Epoch: [155][521/704]	Time 0.121	Data 0.001	Loss 4.78	Acc@1 75.0	Acc@5 98.4
Epoch: [155][531/704]	Time 0.121	Data 0.001	Loss 3.84	Acc@1 79.7	Acc@5 93.8
Epoch: [155][541/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 82.8	Acc@5 100.0
Epoch: [155][551/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 90.6	Acc@5 98.4
Epoch: [155][561/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 87.5	Acc@5 98.4
Epoch: [155][571/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 73.4	Acc@5 95.3
Epoch: [155][581/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 82.8	Acc@5 98.4
Epoch: [155][591/704]	Time 0.121	Data 0.001	Loss 3.67	Acc@1 78.1	Acc@5 95.3
Epoch: [155][601/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 87.5	Acc@5 100.0
Epoch: [155][611/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 87.5	Acc@5 96.9
Epoch: [155][621/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 90.6	Acc@5 100.0
Epoch: [155][631/704]	Time 0.121	Data 0.001	Loss 3.61	Acc@1 78.1	Acc@5 98.4
Epoch: [155][641/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 90.6	Acc@5 98.4
Epoch: [155][651/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 85.9	Acc@5 98.4
Epoch: [155][661/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 87.5	Acc@5 100.0
Epoch: [155][671/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 82.8	Acc@5 100.0
Epoch: [155][681/704]	Time 0.121	Data 0.001	Loss 3.39	Acc@1 81.2	Acc@5 95.3
Epoch: [155][691/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 78.1	Acc@5 98.4
Epoch: [155][701/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 85.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.3347	Acc@1 67.1875	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.7418	Acc@1 68.7500	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.9313	Acc@1 70.3125	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.5605	Acc@1 67.1875	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.0016	Acc@1 71.8750	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.7170	Acc@1 73.4375	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.9662	Acc@1 71.8750	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.9787	Acc@1 68.7500	Acc@5 90.6250
 * prec@1 56.920 prec@5 84.560
 * prec@1 61.720 prec@5 88.460
 * prec@1 66.280 prec@5 90.740
 * prec@1 69.420 prec@5 91.820
New best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_155.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_155.pth.tar'
Epoch: [156][1/704]	Time 0.301	Data 0.133	Loss 3.57	Acc@1 75.0	Acc@5 98.4
Epoch: [156][11/704]	Time 0.137	Data 0.012	Loss 3.15	Acc@1 81.2	Acc@5 100.0
Epoch: [156][21/704]	Time 0.129	Data 0.007	Loss 2.97	Acc@1 85.9	Acc@5 96.9
Epoch: [156][31/704]	Time 0.126	Data 0.005	Loss 3.27	Acc@1 81.2	Acc@5 96.9
Epoch: [156][41/704]	Time 0.125	Data 0.004	Loss 2.99	Acc@1 82.8	Acc@5 100.0
Epoch: [156][51/704]	Time 0.124	Data 0.003	Loss 2.40	Acc@1 92.2	Acc@5 98.4
Epoch: [156][61/704]	Time 0.124	Data 0.003	Loss 3.29	Acc@1 87.5	Acc@5 96.9
Epoch: [156][71/704]	Time 0.123	Data 0.002	Loss 2.16	Acc@1 84.4	Acc@5 98.4
Epoch: [156][81/704]	Time 0.123	Data 0.002	Loss 2.24	Acc@1 85.9	Acc@5 98.4
Epoch: [156][91/704]	Time 0.123	Data 0.002	Loss 3.12	Acc@1 82.8	Acc@5 98.4
Epoch: [156][101/704]	Time 0.123	Data 0.002	Loss 3.75	Acc@1 76.6	Acc@5 98.4
Epoch: [156][111/704]	Time 0.123	Data 0.002	Loss 2.84	Acc@1 82.8	Acc@5 100.0
Epoch: [156][121/704]	Time 0.122	Data 0.002	Loss 2.62	Acc@1 89.1	Acc@5 98.4
Epoch: [156][131/704]	Time 0.122	Data 0.001	Loss 2.40	Acc@1 84.4	Acc@5 100.0
Epoch: [156][141/704]	Time 0.122	Data 0.001	Loss 3.23	Acc@1 82.8	Acc@5 98.4
Epoch: [156][151/704]	Time 0.122	Data 0.001	Loss 3.47	Acc@1 78.1	Acc@5 98.4
Epoch: [156][161/704]	Time 0.122	Data 0.001	Loss 3.30	Acc@1 84.4	Acc@5 98.4
Epoch: [156][171/704]	Time 0.122	Data 0.001	Loss 2.52	Acc@1 87.5	Acc@5 100.0
Epoch: [156][181/704]	Time 0.122	Data 0.001	Loss 2.86	Acc@1 87.5	Acc@5 98.4
Epoch: [156][191/704]	Time 0.122	Data 0.001	Loss 2.34	Acc@1 93.8	Acc@5 95.3
Epoch: [156][201/704]	Time 0.122	Data 0.001	Loss 2.83	Acc@1 87.5	Acc@5 98.4
Epoch: [156][211/704]	Time 0.122	Data 0.001	Loss 2.73	Acc@1 82.8	Acc@5 96.9
Epoch: [156][221/704]	Time 0.122	Data 0.001	Loss 3.23	Acc@1 84.4	Acc@5 100.0
Epoch: [156][231/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 84.4	Acc@5 96.9
Epoch: [156][241/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 85.9	Acc@5 100.0
Epoch: [156][251/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 75.0	Acc@5 98.4
Epoch: [156][261/704]	Time 0.121	Data 0.001	Loss 3.86	Acc@1 75.0	Acc@5 96.9
Epoch: [156][271/704]	Time 0.121	Data 0.001	Loss 3.85	Acc@1 79.7	Acc@5 96.9
Epoch: [156][281/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 82.8	Acc@5 98.4
Epoch: [156][291/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 85.9	Acc@5 100.0
Epoch: [156][301/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 93.8	Acc@5 98.4
Epoch: [156][311/704]	Time 0.121	Data 0.001	Loss 3.21	Acc@1 78.1	Acc@5 96.9
Epoch: [156][321/704]	Time 0.121	Data 0.001	Loss 4.06	Acc@1 75.0	Acc@5 98.4
Epoch: [156][331/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 87.5	Acc@5 98.4
Epoch: [156][341/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 82.8	Acc@5 98.4
Epoch: [156][351/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 79.7	Acc@5 96.9
Epoch: [156][361/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 85.9	Acc@5 96.9
Epoch: [156][371/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 85.9	Acc@5 100.0
Epoch: [156][381/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 93.8	Acc@5 100.0
Epoch: [156][391/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 87.5	Acc@5 100.0
Epoch: [156][401/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 79.7	Acc@5 100.0
Epoch: [156][411/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [156][421/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 90.6	Acc@5 96.9
Epoch: [156][431/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 84.4	Acc@5 92.2
Epoch: [156][441/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 85.9	Acc@5 100.0
Epoch: [156][451/704]	Time 0.121	Data 0.001	Loss 3.70	Acc@1 82.8	Acc@5 93.8
Epoch: [156][461/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 84.4	Acc@5 95.3
Epoch: [156][471/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 82.8	Acc@5 100.0
Epoch: [156][481/704]	Time 0.121	Data 0.001	Loss 3.00	Acc@1 79.7	Acc@5 100.0
Epoch: [156][491/704]	Time 0.121	Data 0.001	Loss 3.72	Acc@1 84.4	Acc@5 96.9
Epoch: [156][501/704]	Time 0.121	Data 0.001	Loss 3.44	Acc@1 81.2	Acc@5 100.0
Epoch: [156][511/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 78.1	Acc@5 95.3
Epoch: [156][521/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 82.8	Acc@5 98.4
Epoch: [156][531/704]	Time 0.121	Data 0.001	Loss 3.27	Acc@1 85.9	Acc@5 98.4
Epoch: [156][541/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 79.7	Acc@5 98.4
Epoch: [156][551/704]	Time 0.121	Data 0.001	Loss 3.43	Acc@1 82.8	Acc@5 96.9
Epoch: [156][561/704]	Time 0.121	Data 0.001	Loss 4.17	Acc@1 78.1	Acc@5 93.8
Epoch: [156][571/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 87.5	Acc@5 98.4
Epoch: [156][581/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [156][591/704]	Time 0.121	Data 0.001	Loss 3.49	Acc@1 79.7	Acc@5 98.4
Epoch: [156][601/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 87.5	Acc@5 96.9
Epoch: [156][611/704]	Time 0.121	Data 0.001	Loss 3.89	Acc@1 79.7	Acc@5 96.9
Epoch: [156][621/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 84.4	Acc@5 98.4
Epoch: [156][631/704]	Time 0.121	Data 0.001	Loss 4.19	Acc@1 79.7	Acc@5 100.0
Epoch: [156][641/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 81.2	Acc@5 98.4
Epoch: [156][651/704]	Time 0.121	Data 0.001	Loss 3.23	Acc@1 85.9	Acc@5 95.3
Epoch: [156][661/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 81.2	Acc@5 96.9
Epoch: [156][671/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 96.9
Epoch: [156][681/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 87.5	Acc@5 100.0
Epoch: [156][691/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 100.0
Epoch: [156][701/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 81.2	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.0989	Acc@1 60.9375	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.5069	Acc@1 67.1875	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2328	Acc@1 68.7500	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.3747	Acc@1 67.1875	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6183	Acc@1 64.0625	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.8111	Acc@1 73.4375	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.2325	Acc@1 65.6250	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.5363	Acc@1 70.3125	Acc@5 92.1875
 * prec@1 57.320 prec@5 85.120
 * prec@1 62.380 prec@5 88.360
 * prec@1 66.680 prec@5 91.660
 * prec@1 68.480 prec@5 91.480
Current best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_156.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_156.pth.tar'
Epoch: [157][1/704]	Time 0.299	Data 0.131	Loss 2.81	Acc@1 84.4	Acc@5 98.4
Epoch: [157][11/704]	Time 0.140	Data 0.012	Loss 3.28	Acc@1 79.7	Acc@5 95.3
Epoch: [157][21/704]	Time 0.130	Data 0.007	Loss 2.94	Acc@1 89.1	Acc@5 100.0
Epoch: [157][31/704]	Time 0.127	Data 0.005	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [157][41/704]	Time 0.125	Data 0.004	Loss 2.25	Acc@1 90.6	Acc@5 98.4
Epoch: [157][51/704]	Time 0.124	Data 0.003	Loss 2.94	Acc@1 85.9	Acc@5 98.4
Epoch: [157][61/704]	Time 0.123	Data 0.002	Loss 2.75	Acc@1 85.9	Acc@5 93.8
Epoch: [157][71/704]	Time 0.123	Data 0.002	Loss 2.78	Acc@1 84.4	Acc@5 98.4
Epoch: [157][81/704]	Time 0.123	Data 0.002	Loss 3.05	Acc@1 82.8	Acc@5 96.9
Epoch: [157][91/704]	Time 0.122	Data 0.002	Loss 3.02	Acc@1 85.9	Acc@5 96.9
Epoch: [157][101/704]	Time 0.122	Data 0.002	Loss 2.61	Acc@1 85.9	Acc@5 93.8
Epoch: [157][111/704]	Time 0.122	Data 0.002	Loss 2.68	Acc@1 92.2	Acc@5 96.9
Epoch: [157][121/704]	Time 0.122	Data 0.001	Loss 3.47	Acc@1 84.4	Acc@5 95.3
Epoch: [157][131/704]	Time 0.122	Data 0.001	Loss 2.58	Acc@1 84.4	Acc@5 98.4
Epoch: [157][141/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 92.2	Acc@5 100.0
Epoch: [157][151/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 89.1	Acc@5 95.3
Epoch: [157][161/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 87.5	Acc@5 100.0
Epoch: [157][171/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 92.2	Acc@5 98.4
Epoch: [157][181/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 82.8	Acc@5 96.9
Epoch: [157][191/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 95.3	Acc@5 100.0
Epoch: [157][201/704]	Time 0.121	Data 0.001	Loss 3.54	Acc@1 79.7	Acc@5 98.4
Epoch: [157][211/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 76.6	Acc@5 98.4
Epoch: [157][221/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [157][231/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 84.4	Acc@5 100.0
Epoch: [157][241/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 85.9	Acc@5 98.4
Epoch: [157][251/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 93.8	Acc@5 98.4
Epoch: [157][261/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 89.1	Acc@5 100.0
Epoch: [157][271/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 82.8	Acc@5 98.4
Epoch: [157][281/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 84.4	Acc@5 98.4
Epoch: [157][291/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 100.0
Epoch: [157][301/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [157][311/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 81.2	Acc@5 96.9
Epoch: [157][321/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 81.2	Acc@5 93.8
Epoch: [157][331/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 87.5	Acc@5 98.4
Epoch: [157][341/704]	Time 0.120	Data 0.001	Loss 2.49	Acc@1 90.6	Acc@5 100.0
Epoch: [157][351/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 100.0
Epoch: [157][361/704]	Time 0.120	Data 0.001	Loss 3.27	Acc@1 84.4	Acc@5 98.4
Epoch: [157][371/704]	Time 0.120	Data 0.001	Loss 2.77	Acc@1 82.8	Acc@5 98.4
Epoch: [157][381/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 92.2	Acc@5 100.0
Epoch: [157][391/704]	Time 0.120	Data 0.001	Loss 2.25	Acc@1 92.2	Acc@5 100.0
Epoch: [157][401/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 85.9	Acc@5 100.0
Epoch: [157][411/704]	Time 0.120	Data 0.001	Loss 3.35	Acc@1 82.8	Acc@5 96.9
Epoch: [157][421/704]	Time 0.120	Data 0.001	Loss 4.20	Acc@1 79.7	Acc@5 95.3
Epoch: [157][431/704]	Time 0.120	Data 0.001	Loss 3.14	Acc@1 82.8	Acc@5 98.4
Epoch: [157][441/704]	Time 0.120	Data 0.001	Loss 3.57	Acc@1 71.9	Acc@5 96.9
Epoch: [157][451/704]	Time 0.120	Data 0.001	Loss 3.43	Acc@1 87.5	Acc@5 95.3
Epoch: [157][461/704]	Time 0.120	Data 0.001	Loss 3.09	Acc@1 87.5	Acc@5 96.9
Epoch: [157][471/704]	Time 0.120	Data 0.001	Loss 3.28	Acc@1 78.1	Acc@5 100.0
Epoch: [157][481/704]	Time 0.120	Data 0.001	Loss 2.96	Acc@1 84.4	Acc@5 100.0
Epoch: [157][491/704]	Time 0.120	Data 0.001	Loss 2.85	Acc@1 87.5	Acc@5 98.4
Epoch: [157][501/704]	Time 0.120	Data 0.001	Loss 3.38	Acc@1 81.2	Acc@5 96.9
Epoch: [157][511/704]	Time 0.120	Data 0.001	Loss 2.97	Acc@1 82.8	Acc@5 100.0
Epoch: [157][521/704]	Time 0.120	Data 0.001	Loss 2.85	Acc@1 89.1	Acc@5 100.0
Epoch: [157][531/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [157][541/704]	Time 0.120	Data 0.001	Loss 3.96	Acc@1 84.4	Acc@5 95.3
Epoch: [157][551/704]	Time 0.120	Data 0.001	Loss 2.66	Acc@1 89.1	Acc@5 98.4
Epoch: [157][561/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 85.9	Acc@5 100.0
Epoch: [157][571/704]	Time 0.120	Data 0.001	Loss 2.80	Acc@1 82.8	Acc@5 95.3
Epoch: [157][581/704]	Time 0.120	Data 0.001	Loss 3.20	Acc@1 79.7	Acc@5 96.9
Epoch: [157][591/704]	Time 0.120	Data 0.001	Loss 2.82	Acc@1 87.5	Acc@5 98.4
Epoch: [157][601/704]	Time 0.120	Data 0.001	Loss 2.93	Acc@1 85.9	Acc@5 98.4
Epoch: [157][611/704]	Time 0.120	Data 0.001	Loss 3.44	Acc@1 81.2	Acc@5 98.4
Epoch: [157][621/704]	Time 0.120	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [157][631/704]	Time 0.120	Data 0.001	Loss 3.38	Acc@1 81.2	Acc@5 96.9
Epoch: [157][641/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 87.5	Acc@5 98.4
Epoch: [157][651/704]	Time 0.120	Data 0.001	Loss 3.16	Acc@1 84.4	Acc@5 96.9
Epoch: [157][661/704]	Time 0.120	Data 0.001	Loss 3.81	Acc@1 76.6	Acc@5 95.3
Epoch: [157][671/704]	Time 0.120	Data 0.001	Loss 3.01	Acc@1 81.2	Acc@5 95.3
Epoch: [157][681/704]	Time 0.120	Data 0.001	Loss 3.09	Acc@1 87.5	Acc@5 96.9
Epoch: [157][691/704]	Time 0.120	Data 0.001	Loss 2.91	Acc@1 73.4	Acc@5 100.0
Epoch: [157][701/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.1633	Acc@1 64.0625	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.2119	Acc@1 67.1875	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.3416	Acc@1 78.1250	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.9958	Acc@1 60.9375	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.1978	Acc@1 62.5000	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.1116	Acc@1 65.6250	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.3530	Acc@1 75.0000	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.0542	Acc@1 65.6250	Acc@5 98.4375
 * prec@1 57.700 prec@5 84.700
 * prec@1 61.460 prec@5 88.260
 * prec@1 67.220 prec@5 91.020
 * prec@1 68.880 prec@5 91.760
Current best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_157.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_157.pth.tar'
Epoch: [158][1/704]	Time 0.329	Data 0.163	Loss 3.22	Acc@1 78.1	Acc@5 96.9
Epoch: [158][11/704]	Time 0.139	Data 0.015	Loss 3.48	Acc@1 87.5	Acc@5 100.0
Epoch: [158][21/704]	Time 0.130	Data 0.008	Loss 1.91	Acc@1 89.1	Acc@5 100.0
Epoch: [158][31/704]	Time 0.127	Data 0.006	Loss 2.75	Acc@1 85.9	Acc@5 98.4
Epoch: [158][41/704]	Time 0.125	Data 0.004	Loss 2.45	Acc@1 90.6	Acc@5 98.4
Epoch: [158][51/704]	Time 0.124	Data 0.004	Loss 2.56	Acc@1 89.1	Acc@5 100.0
Epoch: [158][61/704]	Time 0.123	Data 0.003	Loss 2.47	Acc@1 92.2	Acc@5 100.0
Epoch: [158][71/704]	Time 0.123	Data 0.003	Loss 2.36	Acc@1 85.9	Acc@5 100.0
Epoch: [158][81/704]	Time 0.122	Data 0.002	Loss 2.41	Acc@1 90.6	Acc@5 100.0
Epoch: [158][91/704]	Time 0.122	Data 0.002	Loss 2.02	Acc@1 87.5	Acc@5 98.4
Epoch: [158][101/704]	Time 0.122	Data 0.002	Loss 2.21	Acc@1 84.4	Acc@5 98.4
Epoch: [158][111/704]	Time 0.122	Data 0.002	Loss 3.27	Acc@1 84.4	Acc@5 96.9
Epoch: [158][121/704]	Time 0.122	Data 0.002	Loss 2.57	Acc@1 82.8	Acc@5 100.0
Epoch: [158][131/704]	Time 0.121	Data 0.002	Loss 1.70	Acc@1 98.4	Acc@5 100.0
Epoch: [158][141/704]	Time 0.121	Data 0.002	Loss 3.21	Acc@1 79.7	Acc@5 98.4
Epoch: [158][151/704]	Time 0.121	Data 0.002	Loss 2.84	Acc@1 89.1	Acc@5 98.4
Epoch: [158][161/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 89.1	Acc@5 100.0
Epoch: [158][171/704]	Time 0.121	Data 0.001	Loss 3.58	Acc@1 82.8	Acc@5 93.8
Epoch: [158][181/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 89.1	Acc@5 100.0
Epoch: [158][191/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 85.9	Acc@5 98.4
Epoch: [158][201/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 89.1	Acc@5 98.4
Epoch: [158][211/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 81.2	Acc@5 96.9
Epoch: [158][221/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 90.6	Acc@5 96.9
Epoch: [158][231/704]	Time 0.121	Data 0.001	Loss 3.00	Acc@1 85.9	Acc@5 98.4
Epoch: [158][241/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 87.5	Acc@5 96.9
Epoch: [158][251/704]	Time 0.121	Data 0.001	Loss 3.21	Acc@1 82.8	Acc@5 96.9
Epoch: [158][261/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 85.9	Acc@5 95.3
Epoch: [158][271/704]	Time 0.121	Data 0.001	Loss 3.76	Acc@1 78.1	Acc@5 93.8
Epoch: [158][281/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 78.1	Acc@5 100.0
Epoch: [158][291/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 90.6	Acc@5 98.4
Epoch: [158][301/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 82.8	Acc@5 96.9
Epoch: [158][311/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 87.5	Acc@5 98.4
Epoch: [158][321/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 78.1	Acc@5 95.3
Epoch: [158][331/704]	Time 0.121	Data 0.001	Loss 3.60	Acc@1 79.7	Acc@5 100.0
Epoch: [158][341/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 92.2	Acc@5 96.9
Epoch: [158][351/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 84.4	Acc@5 98.4
Epoch: [158][361/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 84.4	Acc@5 96.9
Epoch: [158][371/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [158][381/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 89.1	Acc@5 100.0
Epoch: [158][391/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 87.5	Acc@5 96.9
Epoch: [158][401/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 89.1	Acc@5 100.0
Epoch: [158][411/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 82.8	Acc@5 96.9
Epoch: [158][421/704]	Time 0.121	Data 0.001	Loss 4.04	Acc@1 81.2	Acc@5 96.9
Epoch: [158][431/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 81.2	Acc@5 100.0
Epoch: [158][441/704]	Time 0.120	Data 0.001	Loss 3.26	Acc@1 82.8	Acc@5 98.4
Epoch: [158][451/704]	Time 0.120	Data 0.001	Loss 3.45	Acc@1 87.5	Acc@5 98.4
Epoch: [158][461/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [158][471/704]	Time 0.120	Data 0.001	Loss 2.89	Acc@1 82.8	Acc@5 100.0
Epoch: [158][481/704]	Time 0.120	Data 0.001	Loss 3.27	Acc@1 85.9	Acc@5 96.9
Epoch: [158][491/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 85.9	Acc@5 100.0
Epoch: [158][501/704]	Time 0.120	Data 0.001	Loss 3.19	Acc@1 82.8	Acc@5 100.0
Epoch: [158][511/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 87.5	Acc@5 100.0
Epoch: [158][521/704]	Time 0.120	Data 0.001	Loss 3.17	Acc@1 81.2	Acc@5 100.0
Epoch: [158][531/704]	Time 0.120	Data 0.001	Loss 2.82	Acc@1 89.1	Acc@5 96.9
Epoch: [158][541/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 87.5	Acc@5 96.9
Epoch: [158][551/704]	Time 0.120	Data 0.001	Loss 3.01	Acc@1 90.6	Acc@5 100.0
Epoch: [158][561/704]	Time 0.120	Data 0.001	Loss 2.81	Acc@1 84.4	Acc@5 100.0
Epoch: [158][571/704]	Time 0.120	Data 0.001	Loss 2.65	Acc@1 85.9	Acc@5 100.0
Epoch: [158][581/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [158][591/704]	Time 0.120	Data 0.001	Loss 3.27	Acc@1 81.2	Acc@5 93.8
Epoch: [158][601/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 87.5	Acc@5 96.9
Epoch: [158][611/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 89.1	Acc@5 96.9
Epoch: [158][621/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 90.6	Acc@5 98.4
Epoch: [158][631/704]	Time 0.120	Data 0.001	Loss 3.41	Acc@1 82.8	Acc@5 96.9
Epoch: [158][641/704]	Time 0.120	Data 0.001	Loss 2.81	Acc@1 89.1	Acc@5 98.4
Epoch: [158][651/704]	Time 0.120	Data 0.001	Loss 2.48	Acc@1 90.6	Acc@5 98.4
Epoch: [158][661/704]	Time 0.120	Data 0.001	Loss 3.18	Acc@1 84.4	Acc@5 96.9
Epoch: [158][671/704]	Time 0.120	Data 0.001	Loss 3.40	Acc@1 81.2	Acc@5 100.0
Epoch: [158][681/704]	Time 0.120	Data 0.001	Loss 3.16	Acc@1 81.2	Acc@5 96.9
Epoch: [158][691/704]	Time 0.120	Data 0.001	Loss 3.05	Acc@1 85.9	Acc@5 100.0
Epoch: [158][701/704]	Time 0.120	Data 0.001	Loss 2.52	Acc@1 85.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.4080	Acc@1 60.9375	Acc@5 82.8125
Epoch: [11/79]	Time 0.027	Data 0.014	Loss 4.5704	Acc@1 78.1250	Acc@5 93.7500
Epoch: [21/79]	Time 0.022	Data 0.010	Loss 5.0396	Acc@1 68.7500	Acc@5 93.7500
Epoch: [31/79]	Time 0.020	Data 0.008	Loss 5.6622	Acc@1 70.3125	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.007	Loss 4.8021	Acc@1 67.1875	Acc@5 93.7500
Epoch: [51/79]	Time 0.019	Data 0.006	Loss 7.2927	Acc@1 64.0625	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.6499	Acc@1 65.6250	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.8425	Acc@1 64.0625	Acc@5 95.3125
 * prec@1 57.760 prec@5 85.280
 * prec@1 62.260 prec@5 88.140
 * prec@1 66.500 prec@5 91.300
 * prec@1 69.320 prec@5 91.860
Current best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_158.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_158.pth.tar'
Epoch: [159][1/704]	Time 0.301	Data 0.133	Loss 2.58	Acc@1 87.5	Acc@5 95.3
Epoch: [159][11/704]	Time 0.137	Data 0.012	Loss 2.62	Acc@1 89.1	Acc@5 98.4
Epoch: [159][21/704]	Time 0.129	Data 0.007	Loss 2.82	Acc@1 84.4	Acc@5 98.4
Epoch: [159][31/704]	Time 0.126	Data 0.005	Loss 3.27	Acc@1 78.1	Acc@5 93.8
Epoch: [159][41/704]	Time 0.125	Data 0.004	Loss 2.33	Acc@1 84.4	Acc@5 100.0
Epoch: [159][51/704]	Time 0.124	Data 0.003	Loss 2.64	Acc@1 90.6	Acc@5 98.4
Epoch: [159][61/704]	Time 0.123	Data 0.002	Loss 2.79	Acc@1 89.1	Acc@5 98.4
Epoch: [159][71/704]	Time 0.123	Data 0.002	Loss 3.65	Acc@1 84.4	Acc@5 98.4
Epoch: [159][81/704]	Time 0.123	Data 0.002	Loss 3.42	Acc@1 84.4	Acc@5 96.9
Epoch: [159][91/704]	Time 0.122	Data 0.002	Loss 2.89	Acc@1 90.6	Acc@5 100.0
Epoch: [159][101/704]	Time 0.122	Data 0.002	Loss 2.66	Acc@1 84.4	Acc@5 98.4
Epoch: [159][111/704]	Time 0.122	Data 0.002	Loss 2.61	Acc@1 90.6	Acc@5 98.4
Epoch: [159][121/704]	Time 0.122	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 100.0
Epoch: [159][131/704]	Time 0.122	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [159][141/704]	Time 0.122	Data 0.001	Loss 2.39	Acc@1 82.8	Acc@5 98.4
Epoch: [159][151/704]	Time 0.122	Data 0.001	Loss 3.46	Acc@1 85.9	Acc@5 96.9
Epoch: [159][161/704]	Time 0.122	Data 0.001	Loss 3.45	Acc@1 85.9	Acc@5 98.4
Epoch: [159][171/704]	Time 0.122	Data 0.001	Loss 1.82	Acc@1 85.9	Acc@5 98.4
Epoch: [159][181/704]	Time 0.122	Data 0.001	Loss 3.07	Acc@1 79.7	Acc@5 98.4
Epoch: [159][191/704]	Time 0.122	Data 0.001	Loss 3.42	Acc@1 89.1	Acc@5 98.4
Epoch: [159][201/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 81.2	Acc@5 98.4
Epoch: [159][211/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 81.2	Acc@5 100.0
Epoch: [159][221/704]	Time 0.121	Data 0.001	Loss 3.29	Acc@1 87.5	Acc@5 98.4
Epoch: [159][231/704]	Time 0.121	Data 0.001	Loss 3.37	Acc@1 79.7	Acc@5 96.9
Epoch: [159][241/704]	Time 0.121	Data 0.001	Loss 4.13	Acc@1 70.3	Acc@5 95.3
Epoch: [159][251/704]	Time 0.121	Data 0.001	Loss 3.32	Acc@1 87.5	Acc@5 96.9
Epoch: [159][261/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 78.1	Acc@5 100.0
Epoch: [159][271/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 87.5	Acc@5 98.4
Epoch: [159][281/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 79.7	Acc@5 100.0
Epoch: [159][291/704]	Time 0.121	Data 0.001	Loss 3.46	Acc@1 87.5	Acc@5 96.9
Epoch: [159][301/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 87.5	Acc@5 100.0
Epoch: [159][311/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 84.4	Acc@5 100.0
Epoch: [159][321/704]	Time 0.121	Data 0.001	Loss 2.97	Acc@1 82.8	Acc@5 100.0
Epoch: [159][331/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 81.2	Acc@5 98.4
Epoch: [159][341/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 89.1	Acc@5 98.4
Epoch: [159][351/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 89.1	Acc@5 98.4
Epoch: [159][361/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 96.9
Epoch: [159][371/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 89.1	Acc@5 96.9
Epoch: [159][381/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 84.4	Acc@5 100.0
Epoch: [159][391/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 90.6	Acc@5 100.0
Epoch: [159][401/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 84.4	Acc@5 98.4
Epoch: [159][411/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 93.8	Acc@5 100.0
Epoch: [159][421/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 90.6	Acc@5 100.0
Epoch: [159][431/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 89.1	Acc@5 96.9
Epoch: [159][441/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 93.8	Acc@5 98.4
Epoch: [159][451/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 87.5	Acc@5 100.0
Epoch: [159][461/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 84.4	Acc@5 98.4
Epoch: [159][471/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 79.7	Acc@5 98.4
Epoch: [159][481/704]	Time 0.121	Data 0.001	Loss 3.33	Acc@1 81.2	Acc@5 98.4
Epoch: [159][491/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 81.2	Acc@5 100.0
Epoch: [159][501/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 87.5	Acc@5 100.0
Epoch: [159][511/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 85.9	Acc@5 98.4
Epoch: [159][521/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 89.1	Acc@5 98.4
Epoch: [159][531/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 87.5	Acc@5 98.4
Epoch: [159][541/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 82.8	Acc@5 100.0
Epoch: [159][551/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 93.8	Acc@5 100.0
Epoch: [159][561/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 84.4	Acc@5 98.4
Epoch: [159][571/704]	Time 0.121	Data 0.001	Loss 3.39	Acc@1 81.2	Acc@5 98.4
Epoch: [159][581/704]	Time 0.121	Data 0.001	Loss 3.00	Acc@1 78.1	Acc@5 100.0
Epoch: [159][591/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 82.8	Acc@5 98.4
Epoch: [159][601/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 87.5	Acc@5 100.0
Epoch: [159][611/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 89.1	Acc@5 100.0
Epoch: [159][621/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 92.2	Acc@5 98.4
Epoch: [159][631/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 89.1	Acc@5 98.4
Epoch: [159][641/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 85.9	Acc@5 98.4
Epoch: [159][651/704]	Time 0.121	Data 0.001	Loss 3.55	Acc@1 82.8	Acc@5 93.8
Epoch: [159][661/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 92.2	Acc@5 100.0
Epoch: [159][671/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 78.1	Acc@5 96.9
Epoch: [159][681/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 79.7	Acc@5 100.0
Epoch: [159][691/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 85.9	Acc@5 98.4
Epoch: [159][701/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 90.6	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.2307	Acc@1 67.1875	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 4.7343	Acc@1 68.7500	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.9009	Acc@1 79.6875	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.7232	Acc@1 54.6875	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9880	Acc@1 59.3750	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.8384	Acc@1 68.7500	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.0545	Acc@1 71.8750	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.6098	Acc@1 65.6250	Acc@5 96.8750
 * prec@1 57.500 prec@5 85.160
 * prec@1 62.420 prec@5 88.580
 * prec@1 67.120 prec@5 91.000
 * prec@1 68.840 prec@5 91.640
Current best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_159.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_159.pth.tar'
Epoch: [160][1/704]	Time 0.294	Data 0.127	Loss 2.94	Acc@1 81.2	Acc@5 98.4
Epoch: [160][11/704]	Time 0.136	Data 0.012	Loss 2.81	Acc@1 81.2	Acc@5 98.4
Epoch: [160][21/704]	Time 0.128	Data 0.006	Loss 3.26	Acc@1 85.9	Acc@5 98.4
Epoch: [160][31/704]	Time 0.126	Data 0.004	Loss 3.27	Acc@1 85.9	Acc@5 98.4
Epoch: [160][41/704]	Time 0.124	Data 0.003	Loss 2.36	Acc@1 84.4	Acc@5 100.0
Epoch: [160][51/704]	Time 0.123	Data 0.003	Loss 3.14	Acc@1 84.4	Acc@5 98.4
Epoch: [160][61/704]	Time 0.124	Data 0.002	Loss 2.26	Acc@1 92.2	Acc@5 98.4
Epoch: [160][71/704]	Time 0.123	Data 0.002	Loss 3.36	Acc@1 79.7	Acc@5 98.4
Epoch: [160][81/704]	Time 0.123	Data 0.002	Loss 3.77	Acc@1 82.8	Acc@5 96.9
Epoch: [160][91/704]	Time 0.122	Data 0.002	Loss 2.78	Acc@1 89.1	Acc@5 96.9
Epoch: [160][101/704]	Time 0.122	Data 0.002	Loss 2.11	Acc@1 89.1	Acc@5 100.0
Epoch: [160][111/704]	Time 0.122	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 100.0
Epoch: [160][121/704]	Time 0.122	Data 0.001	Loss 2.85	Acc@1 87.5	Acc@5 93.8
Epoch: [160][131/704]	Time 0.122	Data 0.001	Loss 2.85	Acc@1 87.5	Acc@5 96.9
Epoch: [160][141/704]	Time 0.122	Data 0.001	Loss 2.28	Acc@1 89.1	Acc@5 100.0
Epoch: [160][151/704]	Time 0.121	Data 0.001	Loss 3.10	Acc@1 84.4	Acc@5 96.9
Epoch: [160][161/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 96.9	Acc@5 100.0
Epoch: [160][171/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 81.2	Acc@5 100.0
Epoch: [160][181/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 98.4
Epoch: [160][191/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [160][201/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 90.6	Acc@5 98.4
Epoch: [160][211/704]	Time 0.121	Data 0.001	Loss 3.40	Acc@1 81.2	Acc@5 98.4
Epoch: [160][221/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 84.4	Acc@5 98.4
Epoch: [160][231/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 96.9
Epoch: [160][241/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 79.7	Acc@5 98.4
Epoch: [160][251/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 84.4	Acc@5 96.9
Epoch: [160][261/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 92.2	Acc@5 100.0
Epoch: [160][271/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 87.5	Acc@5 100.0
Epoch: [160][281/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 85.9	Acc@5 100.0
Epoch: [160][291/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 90.6	Acc@5 98.4
Epoch: [160][301/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 89.1	Acc@5 98.4
Epoch: [160][311/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 81.2	Acc@5 100.0
Epoch: [160][321/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 79.7	Acc@5 100.0
Epoch: [160][331/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 85.9	Acc@5 96.9
Epoch: [160][341/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 82.8	Acc@5 98.4
Epoch: [160][351/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 85.9	Acc@5 96.9
Epoch: [160][361/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 89.1	Acc@5 96.9
Epoch: [160][371/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 81.2	Acc@5 98.4
Epoch: [160][381/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 78.1	Acc@5 98.4
Epoch: [160][391/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 81.2	Acc@5 100.0
Epoch: [160][401/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 87.5	Acc@5 100.0
Epoch: [160][411/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 79.7	Acc@5 98.4
Epoch: [160][421/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 85.9	Acc@5 96.9
Epoch: [160][431/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 89.1	Acc@5 96.9
Epoch: [160][441/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 85.9	Acc@5 100.0
Epoch: [160][451/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 82.8	Acc@5 96.9
Epoch: [160][461/704]	Time 0.121	Data 0.001	Loss 4.00	Acc@1 82.8	Acc@5 95.3
Epoch: [160][471/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 89.1	Acc@5 100.0
Epoch: [160][481/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 90.6	Acc@5 100.0
Epoch: [160][491/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 92.2	Acc@5 96.9
Epoch: [160][501/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 87.5	Acc@5 98.4
Epoch: [160][511/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [160][521/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 76.6	Acc@5 98.4
Epoch: [160][531/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 85.9	Acc@5 100.0
Epoch: [160][541/704]	Time 0.120	Data 0.001	Loss 3.08	Acc@1 82.8	Acc@5 96.9
Epoch: [160][551/704]	Time 0.120	Data 0.001	Loss 3.07	Acc@1 82.8	Acc@5 96.9
Epoch: [160][561/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 90.6	Acc@5 98.4
Epoch: [160][571/704]	Time 0.121	Data 0.001	Loss 3.39	Acc@1 84.4	Acc@5 98.4
Epoch: [160][581/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 89.1	Acc@5 98.4
Epoch: [160][591/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 85.9	Acc@5 100.0
Epoch: [160][601/704]	Time 0.120	Data 0.001	Loss 2.59	Acc@1 84.4	Acc@5 100.0
Epoch: [160][611/704]	Time 0.120	Data 0.001	Loss 3.04	Acc@1 84.4	Acc@5 96.9
Epoch: [160][621/704]	Time 0.120	Data 0.001	Loss 3.77	Acc@1 81.2	Acc@5 96.9
Epoch: [160][631/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 89.1	Acc@5 98.4
Epoch: [160][641/704]	Time 0.120	Data 0.001	Loss 2.73	Acc@1 89.1	Acc@5 98.4
Epoch: [160][651/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 84.4	Acc@5 98.4
Epoch: [160][661/704]	Time 0.120	Data 0.001	Loss 2.78	Acc@1 84.4	Acc@5 96.9
Epoch: [160][671/704]	Time 0.120	Data 0.001	Loss 3.68	Acc@1 81.2	Acc@5 96.9
Epoch: [160][681/704]	Time 0.120	Data 0.001	Loss 3.24	Acc@1 84.4	Acc@5 100.0
Epoch: [160][691/704]	Time 0.120	Data 0.001	Loss 2.87	Acc@1 87.5	Acc@5 98.4
Epoch: [160][701/704]	Time 0.120	Data 0.001	Loss 3.89	Acc@1 76.6	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 4.1825	Acc@1 82.8125	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4091	Acc@1 62.5000	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5254	Acc@1 76.5625	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6500	Acc@1 60.9375	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.7115	Acc@1 68.7500	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.3380	Acc@1 59.3750	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.9619	Acc@1 68.7500	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.3207	Acc@1 76.5625	Acc@5 96.8750
 * prec@1 56.960 prec@5 84.860
 * prec@1 62.720 prec@5 87.960
 * prec@1 65.920 prec@5 90.960
 * prec@1 68.240 prec@5 91.860
Current best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_160.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_160.pth.tar'
Epoch: [161][1/704]	Time 0.333	Data 0.166	Loss 1.82	Acc@1 92.2	Acc@5 98.4
Epoch: [161][11/704]	Time 0.140	Data 0.015	Loss 3.28	Acc@1 84.4	Acc@5 96.9
Epoch: [161][21/704]	Time 0.131	Data 0.008	Loss 2.79	Acc@1 81.2	Acc@5 98.4
Epoch: [161][31/704]	Time 0.127	Data 0.006	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [161][41/704]	Time 0.126	Data 0.004	Loss 2.74	Acc@1 85.9	Acc@5 100.0
Epoch: [161][51/704]	Time 0.125	Data 0.004	Loss 3.07	Acc@1 81.2	Acc@5 100.0
Epoch: [161][61/704]	Time 0.124	Data 0.003	Loss 2.77	Acc@1 82.8	Acc@5 100.0
Epoch: [161][71/704]	Time 0.123	Data 0.003	Loss 2.76	Acc@1 84.4	Acc@5 98.4
Epoch: [161][81/704]	Time 0.123	Data 0.002	Loss 2.26	Acc@1 87.5	Acc@5 100.0
Epoch: [161][91/704]	Time 0.123	Data 0.002	Loss 3.33	Acc@1 87.5	Acc@5 100.0
Epoch: [161][101/704]	Time 0.123	Data 0.002	Loss 3.43	Acc@1 84.4	Acc@5 98.4
Epoch: [161][111/704]	Time 0.122	Data 0.002	Loss 2.72	Acc@1 87.5	Acc@5 100.0
Epoch: [161][121/704]	Time 0.122	Data 0.002	Loss 2.60	Acc@1 84.4	Acc@5 100.0
Epoch: [161][131/704]	Time 0.122	Data 0.002	Loss 2.63	Acc@1 84.4	Acc@5 100.0
Epoch: [161][141/704]	Time 0.122	Data 0.001	Loss 2.70	Acc@1 89.1	Acc@5 96.9
Epoch: [161][151/704]	Time 0.122	Data 0.001	Loss 3.30	Acc@1 89.1	Acc@5 96.9
Epoch: [161][161/704]	Time 0.122	Data 0.001	Loss 2.77	Acc@1 82.8	Acc@5 98.4
Epoch: [161][171/704]	Time 0.122	Data 0.001	Loss 3.78	Acc@1 81.2	Acc@5 96.9
Epoch: [161][181/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 84.4	Acc@5 98.4
Epoch: [161][191/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 96.9	Acc@5 98.4
Epoch: [161][201/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [161][211/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 82.8	Acc@5 96.9
Epoch: [161][221/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 82.8	Acc@5 96.9
Epoch: [161][231/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [161][241/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [161][251/704]	Time 0.121	Data 0.001	Loss 3.57	Acc@1 82.8	Acc@5 93.8
Epoch: [161][261/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 82.8	Acc@5 98.4
Epoch: [161][271/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 84.4	Acc@5 100.0
Epoch: [161][281/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 76.6	Acc@5 98.4
Epoch: [161][291/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 89.1	Acc@5 98.4
Epoch: [161][301/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 100.0
Epoch: [161][311/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 87.5	Acc@5 96.9
Epoch: [161][321/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 98.4
Epoch: [161][331/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 89.1	Acc@5 96.9
Epoch: [161][341/704]	Time 0.121	Data 0.001	Loss 3.67	Acc@1 82.8	Acc@5 98.4
Epoch: [161][351/704]	Time 0.121	Data 0.001	Loss 3.23	Acc@1 81.2	Acc@5 98.4
Epoch: [161][361/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 84.4	Acc@5 100.0
Epoch: [161][371/704]	Time 0.121	Data 0.001	Loss 3.13	Acc@1 87.5	Acc@5 96.9
Epoch: [161][381/704]	Time 0.121	Data 0.001	Loss 3.08	Acc@1 87.5	Acc@5 98.4
Epoch: [161][391/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 82.8	Acc@5 100.0
Epoch: [161][401/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 87.5	Acc@5 100.0
Epoch: [161][411/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 84.4	Acc@5 96.9
Epoch: [161][421/704]	Time 0.121	Data 0.001	Loss 3.54	Acc@1 81.2	Acc@5 98.4
Epoch: [161][431/704]	Time 0.121	Data 0.001	Loss 3.83	Acc@1 78.1	Acc@5 96.9
Epoch: [161][441/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 89.1	Acc@5 100.0
Epoch: [161][451/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 85.9	Acc@5 100.0
Epoch: [161][461/704]	Time 0.121	Data 0.001	Loss 3.19	Acc@1 78.1	Acc@5 98.4
Epoch: [161][471/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 87.5	Acc@5 100.0
Epoch: [161][481/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 87.5	Acc@5 98.4
Epoch: [161][491/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 89.1	Acc@5 100.0
Epoch: [161][501/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 84.4	Acc@5 95.3
Epoch: [161][511/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 85.9	Acc@5 98.4
Epoch: [161][521/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 85.9	Acc@5 98.4
Epoch: [161][531/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 85.9	Acc@5 98.4
Epoch: [161][541/704]	Time 0.121	Data 0.001	Loss 3.13	Acc@1 85.9	Acc@5 98.4
Epoch: [161][551/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [161][561/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 92.2	Acc@5 98.4
Epoch: [161][571/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 85.9	Acc@5 100.0
Epoch: [161][581/704]	Time 0.121	Data 0.001	Loss 3.54	Acc@1 78.1	Acc@5 98.4
Epoch: [161][591/704]	Time 0.121	Data 0.001	Loss 3.61	Acc@1 79.7	Acc@5 96.9
Epoch: [161][601/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 85.9	Acc@5 100.0
Epoch: [161][611/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 79.7	Acc@5 98.4
Epoch: [161][621/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 84.4	Acc@5 96.9
Epoch: [161][631/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 90.6	Acc@5 100.0
Epoch: [161][641/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 98.4
Epoch: [161][651/704]	Time 0.121	Data 0.001	Loss 3.53	Acc@1 84.4	Acc@5 95.3
Epoch: [161][661/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [161][671/704]	Time 0.121	Data 0.001	Loss 3.34	Acc@1 85.9	Acc@5 98.4
Epoch: [161][681/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 85.9	Acc@5 100.0
Epoch: [161][691/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 85.9	Acc@5 96.9
Epoch: [161][701/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 90.6	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.5347	Acc@1 70.3125	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.0615	Acc@1 70.3125	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.9074	Acc@1 67.1875	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.2187	Acc@1 64.0625	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.9899	Acc@1 68.7500	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.8735	Acc@1 75.0000	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.2602	Acc@1 75.0000	Acc@5 96.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.0404	Acc@1 71.8750	Acc@5 89.0625
 * prec@1 58.140 prec@5 85.880
 * prec@1 62.020 prec@5 88.300
 * prec@1 67.220 prec@5 91.320
 * prec@1 68.480 prec@5 91.640
Current best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_161.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_161.pth.tar'
Epoch: [162][1/704]	Time 0.334	Data 0.167	Loss 2.97	Acc@1 82.8	Acc@5 100.0
Epoch: [162][11/704]	Time 0.140	Data 0.016	Loss 2.13	Acc@1 89.1	Acc@5 100.0
Epoch: [162][21/704]	Time 0.130	Data 0.008	Loss 2.92	Acc@1 90.6	Acc@5 100.0
Epoch: [162][31/704]	Time 0.127	Data 0.006	Loss 2.62	Acc@1 92.2	Acc@5 98.4
Epoch: [162][41/704]	Time 0.125	Data 0.004	Loss 2.26	Acc@1 92.2	Acc@5 100.0
Epoch: [162][51/704]	Time 0.124	Data 0.004	Loss 2.38	Acc@1 85.9	Acc@5 100.0
Epoch: [162][61/704]	Time 0.124	Data 0.003	Loss 3.04	Acc@1 85.9	Acc@5 96.9
Epoch: [162][71/704]	Time 0.123	Data 0.003	Loss 3.03	Acc@1 76.6	Acc@5 100.0
Epoch: [162][81/704]	Time 0.123	Data 0.002	Loss 2.40	Acc@1 85.9	Acc@5 98.4
Epoch: [162][91/704]	Time 0.123	Data 0.002	Loss 2.70	Acc@1 92.2	Acc@5 100.0
Epoch: [162][101/704]	Time 0.122	Data 0.002	Loss 2.68	Acc@1 85.9	Acc@5 100.0
Epoch: [162][111/704]	Time 0.122	Data 0.002	Loss 3.43	Acc@1 79.7	Acc@5 93.8
Epoch: [162][121/704]	Time 0.122	Data 0.002	Loss 2.25	Acc@1 89.1	Acc@5 100.0
Epoch: [162][131/704]	Time 0.122	Data 0.002	Loss 2.63	Acc@1 82.8	Acc@5 98.4
Epoch: [162][141/704]	Time 0.122	Data 0.001	Loss 2.81	Acc@1 87.5	Acc@5 100.0
Epoch: [162][151/704]	Time 0.122	Data 0.001	Loss 2.58	Acc@1 84.4	Acc@5 98.4
Epoch: [162][161/704]	Time 0.122	Data 0.001	Loss 2.78	Acc@1 87.5	Acc@5 98.4
Epoch: [162][171/704]	Time 0.122	Data 0.001	Loss 2.80	Acc@1 90.6	Acc@5 100.0
Epoch: [162][181/704]	Time 0.122	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 96.9
Epoch: [162][191/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 87.5	Acc@5 100.0
Epoch: [162][201/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 89.1	Acc@5 98.4
Epoch: [162][211/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 89.1	Acc@5 100.0
Epoch: [162][221/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 89.1	Acc@5 100.0
Epoch: [162][231/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 84.4	Acc@5 96.9
Epoch: [162][241/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 92.2	Acc@5 100.0
Epoch: [162][251/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 89.1	Acc@5 98.4
Epoch: [162][261/704]	Time 0.121	Data 0.001	Loss 3.63	Acc@1 81.2	Acc@5 95.3
Epoch: [162][271/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 96.9
Epoch: [162][281/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 84.4	Acc@5 100.0
Epoch: [162][291/704]	Time 0.121	Data 0.001	Loss 3.53	Acc@1 78.1	Acc@5 96.9
Epoch: [162][301/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 87.5	Acc@5 96.9
Epoch: [162][311/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 84.4	Acc@5 100.0
Epoch: [162][321/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 87.5	Acc@5 100.0
Epoch: [162][331/704]	Time 0.121	Data 0.001	Loss 3.68	Acc@1 84.4	Acc@5 98.4
Epoch: [162][341/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 85.9	Acc@5 100.0
Epoch: [162][351/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 87.5	Acc@5 100.0
Epoch: [162][361/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 84.4	Acc@5 98.4
Epoch: [162][371/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 82.8	Acc@5 100.0
Epoch: [162][381/704]	Time 0.121	Data 0.001	Loss 3.00	Acc@1 85.9	Acc@5 100.0
Epoch: [162][391/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 85.9	Acc@5 98.4
Epoch: [162][401/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 78.1	Acc@5 100.0
Epoch: [162][411/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 85.9	Acc@5 98.4
Epoch: [162][421/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [162][431/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 85.9	Acc@5 96.9
Epoch: [162][441/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 82.8	Acc@5 100.0
Epoch: [162][451/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 89.1	Acc@5 100.0
Epoch: [162][461/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 82.8	Acc@5 98.4
Epoch: [162][471/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 89.1	Acc@5 100.0
Epoch: [162][481/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 89.1	Acc@5 100.0
Epoch: [162][491/704]	Time 0.121	Data 0.001	Loss 2.97	Acc@1 85.9	Acc@5 100.0
Epoch: [162][501/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 89.1	Acc@5 98.4
Epoch: [162][511/704]	Time 0.121	Data 0.001	Loss 3.73	Acc@1 85.9	Acc@5 95.3
Epoch: [162][521/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 82.8	Acc@5 100.0
Epoch: [162][531/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 90.6	Acc@5 98.4
Epoch: [162][541/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 87.5	Acc@5 98.4
Epoch: [162][551/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 87.5	Acc@5 96.9
Epoch: [162][561/704]	Time 0.121	Data 0.001	Loss 3.23	Acc@1 82.8	Acc@5 96.9
Epoch: [162][571/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 87.5	Acc@5 100.0
Epoch: [162][581/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 82.8	Acc@5 100.0
Epoch: [162][591/704]	Time 0.121	Data 0.001	Loss 3.61	Acc@1 78.1	Acc@5 100.0
Epoch: [162][601/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 85.9	Acc@5 98.4
Epoch: [162][611/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 84.4	Acc@5 100.0
Epoch: [162][621/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 98.4
Epoch: [162][631/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 87.5	Acc@5 100.0
Epoch: [162][641/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 82.8	Acc@5 100.0
Epoch: [162][651/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 82.8	Acc@5 98.4
Epoch: [162][661/704]	Time 0.121	Data 0.001	Loss 3.57	Acc@1 84.4	Acc@5 98.4
Epoch: [162][671/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 84.4	Acc@5 96.9
Epoch: [162][681/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 87.5	Acc@5 96.9
Epoch: [162][691/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 93.8	Acc@5 98.4
Epoch: [162][701/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.6376	Acc@1 75.0000	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.1065	Acc@1 67.1875	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.3684	Acc@1 68.7500	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.7857	Acc@1 68.7500	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 3.5901	Acc@1 79.6875	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.3913	Acc@1 75.0000	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.9293	Acc@1 65.6250	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3418	Acc@1 68.7500	Acc@5 85.9375
 * prec@1 57.260 prec@5 85.740
 * prec@1 62.680 prec@5 88.540
 * prec@1 67.460 prec@5 90.900
 * prec@1 68.360 prec@5 91.400
Current best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_162.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_162.pth.tar'
Epoch: [163][1/704]	Time 0.299	Data 0.132	Loss 3.00	Acc@1 89.1	Acc@5 98.4
Epoch: [163][11/704]	Time 0.137	Data 0.012	Loss 2.98	Acc@1 87.5	Acc@5 98.4
Epoch: [163][21/704]	Time 0.129	Data 0.007	Loss 3.47	Acc@1 82.8	Acc@5 96.9
Epoch: [163][31/704]	Time 0.126	Data 0.005	Loss 2.31	Acc@1 93.8	Acc@5 100.0
Epoch: [163][41/704]	Time 0.125	Data 0.004	Loss 2.27	Acc@1 93.8	Acc@5 98.4
Epoch: [163][51/704]	Time 0.124	Data 0.003	Loss 1.94	Acc@1 92.2	Acc@5 100.0
Epoch: [163][61/704]	Time 0.123	Data 0.003	Loss 3.19	Acc@1 81.2	Acc@5 98.4
Epoch: [163][71/704]	Time 0.123	Data 0.002	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [163][81/704]	Time 0.123	Data 0.002	Loss 3.37	Acc@1 79.7	Acc@5 96.9
Epoch: [163][91/704]	Time 0.123	Data 0.002	Loss 2.78	Acc@1 84.4	Acc@5 100.0
Epoch: [163][101/704]	Time 0.123	Data 0.002	Loss 3.64	Acc@1 81.2	Acc@5 95.3
Epoch: [163][111/704]	Time 0.122	Data 0.002	Loss 2.69	Acc@1 93.8	Acc@5 100.0
Epoch: [163][121/704]	Time 0.122	Data 0.001	Loss 3.71	Acc@1 82.8	Acc@5 96.9
Epoch: [163][131/704]	Time 0.122	Data 0.001	Loss 2.56	Acc@1 87.5	Acc@5 98.4
Epoch: [163][141/704]	Time 0.122	Data 0.001	Loss 2.94	Acc@1 87.5	Acc@5 98.4
Epoch: [163][151/704]	Time 0.122	Data 0.001	Loss 2.98	Acc@1 81.2	Acc@5 96.9
Epoch: [163][161/704]	Time 0.122	Data 0.001	Loss 3.33	Acc@1 84.4	Acc@5 98.4
Epoch: [163][171/704]	Time 0.122	Data 0.001	Loss 3.24	Acc@1 90.6	Acc@5 100.0
Epoch: [163][181/704]	Time 0.122	Data 0.001	Loss 3.35	Acc@1 87.5	Acc@5 98.4
Epoch: [163][191/704]	Time 0.122	Data 0.001	Loss 3.40	Acc@1 84.4	Acc@5 98.4
Epoch: [163][201/704]	Time 0.122	Data 0.001	Loss 2.37	Acc@1 90.6	Acc@5 98.4
Epoch: [163][211/704]	Time 0.122	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [163][221/704]	Time 0.121	Data 0.001	Loss 2.97	Acc@1 85.9	Acc@5 100.0
Epoch: [163][231/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 81.2	Acc@5 96.9
Epoch: [163][241/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 90.6	Acc@5 96.9
Epoch: [163][251/704]	Time 0.121	Data 0.001	Loss 3.05	Acc@1 85.9	Acc@5 96.9
Epoch: [163][261/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 82.8	Acc@5 100.0
Epoch: [163][271/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 82.8	Acc@5 96.9
Epoch: [163][281/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 82.8	Acc@5 98.4
Epoch: [163][291/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [163][301/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 89.1	Acc@5 96.9
Epoch: [163][311/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 87.5	Acc@5 98.4
Epoch: [163][321/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 89.1	Acc@5 98.4
Epoch: [163][331/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 81.2	Acc@5 98.4
Epoch: [163][341/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 85.9	Acc@5 100.0
Epoch: [163][351/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 79.7	Acc@5 100.0
Epoch: [163][361/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 92.2	Acc@5 96.9
Epoch: [163][371/704]	Time 0.121	Data 0.001	Loss 3.46	Acc@1 84.4	Acc@5 96.9
Epoch: [163][381/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 89.1	Acc@5 100.0
Epoch: [163][391/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 85.9	Acc@5 98.4
Epoch: [163][401/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 87.5	Acc@5 100.0
Epoch: [163][411/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [163][421/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 98.4
Epoch: [163][431/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [163][441/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 85.9	Acc@5 100.0
Epoch: [163][451/704]	Time 0.121	Data 0.001	Loss 3.54	Acc@1 81.2	Acc@5 95.3
Epoch: [163][461/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 89.1	Acc@5 100.0
Epoch: [163][471/704]	Time 0.121	Data 0.001	Loss 3.44	Acc@1 87.5	Acc@5 98.4
Epoch: [163][481/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 84.4	Acc@5 98.4
Epoch: [163][491/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 82.8	Acc@5 100.0
Epoch: [163][501/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 90.6	Acc@5 100.0
Epoch: [163][511/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 84.4	Acc@5 98.4
Epoch: [163][521/704]	Time 0.121	Data 0.001	Loss 3.51	Acc@1 76.6	Acc@5 98.4
Epoch: [163][531/704]	Time 0.121	Data 0.001	Loss 3.39	Acc@1 82.8	Acc@5 96.9
Epoch: [163][541/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 87.5	Acc@5 98.4
Epoch: [163][551/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 81.2	Acc@5 100.0
Epoch: [163][561/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 93.8	Acc@5 98.4
Epoch: [163][571/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 89.1	Acc@5 100.0
Epoch: [163][581/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 84.4	Acc@5 98.4
Epoch: [163][591/704]	Time 0.121	Data 0.001	Loss 3.43	Acc@1 85.9	Acc@5 96.9
Epoch: [163][601/704]	Time 0.121	Data 0.001	Loss 3.18	Acc@1 85.9	Acc@5 96.9
Epoch: [163][611/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 82.8	Acc@5 98.4
Epoch: [163][621/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 89.1	Acc@5 100.0
Epoch: [163][631/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 90.6	Acc@5 98.4
Epoch: [163][641/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 87.5	Acc@5 98.4
Epoch: [163][651/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 92.2	Acc@5 98.4
Epoch: [163][661/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 82.8	Acc@5 98.4
Epoch: [163][671/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 89.1	Acc@5 98.4
Epoch: [163][681/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 89.1	Acc@5 100.0
Epoch: [163][691/704]	Time 0.121	Data 0.001	Loss 3.23	Acc@1 87.5	Acc@5 100.0
Epoch: [163][701/704]	Time 0.121	Data 0.001	Loss 3.68	Acc@1 87.5	Acc@5 96.9
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.1643	Acc@1 70.3125	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.0435	Acc@1 75.0000	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2832	Acc@1 60.9375	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.6758	Acc@1 75.0000	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.6512	Acc@1 73.4375	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.1716	Acc@1 79.6875	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.1262	Acc@1 68.7500	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1249	Acc@1 59.3750	Acc@5 89.0625
 * prec@1 58.140 prec@5 85.560
 * prec@1 62.760 prec@5 88.480
 * prec@1 66.380 prec@5 91.180
 * prec@1 69.420 prec@5 91.680
Current best validation last_bloc_accuracy 69.42
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_163.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_163.pth.tar'
Epoch: [164][1/704]	Time 0.300	Data 0.131	Loss 2.54	Acc@1 87.5	Acc@5 100.0
Epoch: [164][11/704]	Time 0.140	Data 0.012	Loss 3.07	Acc@1 84.4	Acc@5 96.9
Epoch: [164][21/704]	Time 0.131	Data 0.007	Loss 3.36	Acc@1 79.7	Acc@5 96.9
Epoch: [164][31/704]	Time 0.127	Data 0.005	Loss 3.26	Acc@1 87.5	Acc@5 96.9
Epoch: [164][41/704]	Time 0.126	Data 0.004	Loss 2.09	Acc@1 84.4	Acc@5 98.4
Epoch: [164][51/704]	Time 0.125	Data 0.003	Loss 2.53	Acc@1 90.6	Acc@5 95.3
Epoch: [164][61/704]	Time 0.124	Data 0.003	Loss 2.60	Acc@1 85.9	Acc@5 98.4
Epoch: [164][71/704]	Time 0.123	Data 0.002	Loss 2.82	Acc@1 79.7	Acc@5 100.0
Epoch: [164][81/704]	Time 0.123	Data 0.002	Loss 2.93	Acc@1 81.2	Acc@5 98.4
Epoch: [164][91/704]	Time 0.123	Data 0.002	Loss 3.38	Acc@1 87.5	Acc@5 96.9
Epoch: [164][101/704]	Time 0.122	Data 0.002	Loss 2.38	Acc@1 92.2	Acc@5 98.4
Epoch: [164][111/704]	Time 0.122	Data 0.002	Loss 2.88	Acc@1 87.5	Acc@5 98.4
Epoch: [164][121/704]	Time 0.122	Data 0.002	Loss 3.08	Acc@1 90.6	Acc@5 98.4
Epoch: [164][131/704]	Time 0.122	Data 0.001	Loss 3.46	Acc@1 87.5	Acc@5 98.4
Epoch: [164][141/704]	Time 0.122	Data 0.001	Loss 2.98	Acc@1 84.4	Acc@5 96.9
Epoch: [164][151/704]	Time 0.122	Data 0.001	Loss 2.60	Acc@1 87.5	Acc@5 100.0
Epoch: [164][161/704]	Time 0.122	Data 0.001	Loss 2.77	Acc@1 87.5	Acc@5 98.4
Epoch: [164][171/704]	Time 0.122	Data 0.001	Loss 3.39	Acc@1 76.6	Acc@5 98.4
Epoch: [164][181/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 81.2	Acc@5 95.3
Epoch: [164][191/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 82.8	Acc@5 98.4
Epoch: [164][201/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 96.9
Epoch: [164][211/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [164][221/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 90.6	Acc@5 100.0
Epoch: [164][231/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [164][241/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 85.9	Acc@5 100.0
Epoch: [164][251/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 90.6	Acc@5 98.4
Epoch: [164][261/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 92.2	Acc@5 100.0
Epoch: [164][271/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 92.2	Acc@5 100.0
Epoch: [164][281/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 85.9	Acc@5 100.0
Epoch: [164][291/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 84.4	Acc@5 98.4
Epoch: [164][301/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 87.5	Acc@5 100.0
Epoch: [164][311/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 82.8	Acc@5 98.4
Epoch: [164][321/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 85.9	Acc@5 100.0
Epoch: [164][331/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 90.6	Acc@5 98.4
Epoch: [164][341/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 84.4	Acc@5 100.0
Epoch: [164][351/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 85.9	Acc@5 98.4
Epoch: [164][361/704]	Time 0.121	Data 0.001	Loss 4.26	Acc@1 78.1	Acc@5 95.3
Epoch: [164][371/704]	Time 0.121	Data 0.001	Loss 3.46	Acc@1 85.9	Acc@5 98.4
Epoch: [164][381/704]	Time 0.121	Data 0.001	Loss 3.65	Acc@1 76.6	Acc@5 98.4
Epoch: [164][391/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 90.6	Acc@5 98.4
Epoch: [164][401/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 84.4	Acc@5 100.0
Epoch: [164][411/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [164][421/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 85.9	Acc@5 98.4
Epoch: [164][431/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 85.9	Acc@5 96.9
Epoch: [164][441/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 92.2	Acc@5 100.0
Epoch: [164][451/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 100.0
Epoch: [164][461/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 76.6	Acc@5 100.0
Epoch: [164][471/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 100.0
Epoch: [164][481/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 89.1	Acc@5 100.0
Epoch: [164][491/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 98.4
Epoch: [164][501/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 89.1	Acc@5 100.0
Epoch: [164][511/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 98.4
Epoch: [164][521/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 90.6	Acc@5 100.0
Epoch: [164][531/704]	Time 0.121	Data 0.001	Loss 3.95	Acc@1 75.0	Acc@5 95.3
Epoch: [164][541/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [164][551/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 92.2	Acc@5 100.0
Epoch: [164][561/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 78.1	Acc@5 98.4
Epoch: [164][571/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 87.5	Acc@5 100.0
Epoch: [164][581/704]	Time 0.121	Data 0.001	Loss 3.92	Acc@1 79.7	Acc@5 95.3
Epoch: [164][591/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 87.5	Acc@5 98.4
Epoch: [164][601/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 100.0
Epoch: [164][611/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 90.6	Acc@5 98.4
Epoch: [164][621/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 82.8	Acc@5 98.4
Epoch: [164][631/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 78.1	Acc@5 100.0
Epoch: [164][641/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 87.5	Acc@5 96.9
Epoch: [164][651/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 85.9	Acc@5 98.4
Epoch: [164][661/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 82.8	Acc@5 96.9
Epoch: [164][671/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 98.4
Epoch: [164][681/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 93.8	Acc@5 98.4
Epoch: [164][691/704]	Time 0.121	Data 0.001	Loss 3.43	Acc@1 78.1	Acc@5 98.4
Epoch: [164][701/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 82.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.4484	Acc@1 79.6875	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.4135	Acc@1 73.4375	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8654	Acc@1 64.0625	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.7066	Acc@1 67.1875	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2262	Acc@1 65.6250	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.6008	Acc@1 71.8750	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.4025	Acc@1 70.3125	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1658	Acc@1 70.3125	Acc@5 89.0625
 * prec@1 58.040 prec@5 85.120
 * prec@1 62.560 prec@5 88.440
 * prec@1 67.760 prec@5 91.540
 * prec@1 69.500 prec@5 91.700
New best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_164.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_164.pth.tar'
Epoch: [165][1/704]	Time 0.330	Data 0.163	Loss 2.21	Acc@1 93.8	Acc@5 96.9
Epoch: [165][11/704]	Time 0.140	Data 0.015	Loss 2.14	Acc@1 90.6	Acc@5 100.0
Epoch: [165][21/704]	Time 0.131	Data 0.008	Loss 3.44	Acc@1 84.4	Acc@5 96.9
Epoch: [165][31/704]	Time 0.127	Data 0.006	Loss 2.67	Acc@1 89.1	Acc@5 100.0
Epoch: [165][41/704]	Time 0.126	Data 0.004	Loss 2.61	Acc@1 92.2	Acc@5 100.0
Epoch: [165][51/704]	Time 0.125	Data 0.004	Loss 2.14	Acc@1 81.2	Acc@5 100.0
Epoch: [165][61/704]	Time 0.124	Data 0.003	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [165][71/704]	Time 0.123	Data 0.003	Loss 3.16	Acc@1 87.5	Acc@5 100.0
Epoch: [165][81/704]	Time 0.123	Data 0.002	Loss 2.62	Acc@1 87.5	Acc@5 98.4
Epoch: [165][91/704]	Time 0.123	Data 0.002	Loss 3.01	Acc@1 92.2	Acc@5 98.4
Epoch: [165][101/704]	Time 0.122	Data 0.002	Loss 2.12	Acc@1 93.8	Acc@5 98.4
Epoch: [165][111/704]	Time 0.122	Data 0.002	Loss 3.16	Acc@1 85.9	Acc@5 100.0
Epoch: [165][121/704]	Time 0.122	Data 0.002	Loss 2.97	Acc@1 82.8	Acc@5 100.0
Epoch: [165][131/704]	Time 0.122	Data 0.002	Loss 2.77	Acc@1 90.6	Acc@5 100.0
Epoch: [165][141/704]	Time 0.122	Data 0.001	Loss 3.36	Acc@1 84.4	Acc@5 98.4
Epoch: [165][151/704]	Time 0.122	Data 0.001	Loss 2.33	Acc@1 84.4	Acc@5 98.4
Epoch: [165][161/704]	Time 0.122	Data 0.001	Loss 3.40	Acc@1 89.1	Acc@5 96.9
Epoch: [165][171/704]	Time 0.122	Data 0.001	Loss 3.03	Acc@1 81.2	Acc@5 95.3
Epoch: [165][181/704]	Time 0.122	Data 0.001	Loss 2.18	Acc@1 96.9	Acc@5 100.0
Epoch: [165][191/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 85.9	Acc@5 100.0
Epoch: [165][201/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 87.5	Acc@5 100.0
Epoch: [165][211/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 87.5	Acc@5 100.0
Epoch: [165][221/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 87.5	Acc@5 96.9
Epoch: [165][231/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 89.1	Acc@5 100.0
Epoch: [165][241/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 87.5	Acc@5 96.9
Epoch: [165][251/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [165][261/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 84.4	Acc@5 98.4
Epoch: [165][271/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 81.2	Acc@5 100.0
Epoch: [165][281/704]	Time 0.121	Data 0.001	Loss 3.20	Acc@1 89.1	Acc@5 98.4
Epoch: [165][291/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 87.5	Acc@5 100.0
Epoch: [165][301/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 93.8	Acc@5 96.9
Epoch: [165][311/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [165][321/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 87.5	Acc@5 98.4
Epoch: [165][331/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 92.2	Acc@5 98.4
Epoch: [165][341/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 87.5	Acc@5 98.4
Epoch: [165][351/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 89.1	Acc@5 98.4
Epoch: [165][361/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 89.1	Acc@5 100.0
Epoch: [165][371/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [165][381/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 87.5	Acc@5 98.4
Epoch: [165][391/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 81.2	Acc@5 100.0
Epoch: [165][401/704]	Time 0.121	Data 0.001	Loss 3.00	Acc@1 87.5	Acc@5 100.0
Epoch: [165][411/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 84.4	Acc@5 98.4
Epoch: [165][421/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 96.9
Epoch: [165][431/704]	Time 0.121	Data 0.001	Loss 3.21	Acc@1 84.4	Acc@5 98.4
Epoch: [165][441/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 93.8	Acc@5 98.4
Epoch: [165][451/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 78.1	Acc@5 98.4
Epoch: [165][461/704]	Time 0.121	Data 0.001	Loss 3.29	Acc@1 84.4	Acc@5 96.9
Epoch: [165][471/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 85.9	Acc@5 98.4
Epoch: [165][481/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 82.8	Acc@5 96.9
Epoch: [165][491/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 79.7	Acc@5 98.4
Epoch: [165][501/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 87.5	Acc@5 98.4
Epoch: [165][511/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 87.5	Acc@5 100.0
Epoch: [165][521/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 89.1	Acc@5 100.0
Epoch: [165][531/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 90.6	Acc@5 100.0
Epoch: [165][541/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 92.2	Acc@5 98.4
Epoch: [165][551/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 100.0
Epoch: [165][561/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [165][571/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 84.4	Acc@5 100.0
Epoch: [165][581/704]	Time 0.121	Data 0.001	Loss 3.80	Acc@1 82.8	Acc@5 96.9
Epoch: [165][591/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 85.9	Acc@5 100.0
Epoch: [165][601/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 98.4
Epoch: [165][611/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 85.9	Acc@5 100.0
Epoch: [165][621/704]	Time 0.121	Data 0.001	Loss 3.23	Acc@1 84.4	Acc@5 98.4
Epoch: [165][631/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 81.2	Acc@5 96.9
Epoch: [165][641/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 82.8	Acc@5 98.4
Epoch: [165][651/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 85.9	Acc@5 100.0
Epoch: [165][661/704]	Time 0.121	Data 0.001	Loss 3.34	Acc@1 85.9	Acc@5 98.4
Epoch: [165][671/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [165][681/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 98.4
Epoch: [165][691/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 79.7	Acc@5 98.4
Epoch: [165][701/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 85.9	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.6670	Acc@1 73.4375	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.7958	Acc@1 67.1875	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7948	Acc@1 67.1875	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.8177	Acc@1 70.3125	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6055	Acc@1 62.5000	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8322	Acc@1 73.4375	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 3.9735	Acc@1 70.3125	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 3.8493	Acc@1 76.5625	Acc@5 96.8750
 * prec@1 57.640 prec@5 85.480
 * prec@1 63.060 prec@5 88.960
 * prec@1 67.080 prec@5 91.020
 * prec@1 69.060 prec@5 92.200
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_165.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_165.pth.tar'
Epoch: [166][1/704]	Time 0.300	Data 0.133	Loss 2.80	Acc@1 89.1	Acc@5 98.4
Epoch: [166][11/704]	Time 0.137	Data 0.012	Loss 2.44	Acc@1 90.6	Acc@5 98.4
Epoch: [166][21/704]	Time 0.129	Data 0.007	Loss 2.65	Acc@1 93.8	Acc@5 100.0
Epoch: [166][31/704]	Time 0.126	Data 0.005	Loss 2.90	Acc@1 84.4	Acc@5 100.0
Epoch: [166][41/704]	Time 0.125	Data 0.004	Loss 2.64	Acc@1 85.9	Acc@5 100.0
Epoch: [166][51/704]	Time 0.124	Data 0.003	Loss 2.57	Acc@1 92.2	Acc@5 98.4
Epoch: [166][61/704]	Time 0.123	Data 0.003	Loss 2.92	Acc@1 85.9	Acc@5 98.4
Epoch: [166][71/704]	Time 0.123	Data 0.002	Loss 2.37	Acc@1 85.9	Acc@5 100.0
Epoch: [166][81/704]	Time 0.122	Data 0.002	Loss 2.80	Acc@1 84.4	Acc@5 98.4
Epoch: [166][91/704]	Time 0.122	Data 0.002	Loss 2.81	Acc@1 87.5	Acc@5 100.0
Epoch: [166][101/704]	Time 0.122	Data 0.002	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [166][111/704]	Time 0.122	Data 0.002	Loss 2.68	Acc@1 90.6	Acc@5 100.0
Epoch: [166][121/704]	Time 0.122	Data 0.002	Loss 4.04	Acc@1 75.0	Acc@5 93.8
Epoch: [166][131/704]	Time 0.122	Data 0.002	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [166][141/704]	Time 0.122	Data 0.001	Loss 2.92	Acc@1 81.2	Acc@5 100.0
Epoch: [166][151/704]	Time 0.122	Data 0.001	Loss 2.34	Acc@1 90.6	Acc@5 100.0
Epoch: [166][161/704]	Time 0.122	Data 0.001	Loss 2.31	Acc@1 87.5	Acc@5 100.0
Epoch: [166][171/704]	Time 0.121	Data 0.001	Loss 3.93	Acc@1 78.1	Acc@5 96.9
Epoch: [166][181/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 98.4
Epoch: [166][191/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 89.1	Acc@5 100.0
Epoch: [166][201/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 84.4	Acc@5 98.4
Epoch: [166][211/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 84.4	Acc@5 100.0
Epoch: [166][221/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 84.4	Acc@5 100.0
Epoch: [166][231/704]	Time 0.121	Data 0.001	Loss 3.34	Acc@1 84.4	Acc@5 98.4
Epoch: [166][241/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 92.2	Acc@5 98.4
Epoch: [166][251/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 82.8	Acc@5 100.0
Epoch: [166][261/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 92.2	Acc@5 98.4
Epoch: [166][271/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 89.1	Acc@5 100.0
Epoch: [166][281/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 92.2	Acc@5 100.0
Epoch: [166][291/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 89.1	Acc@5 98.4
Epoch: [166][301/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [166][311/704]	Time 0.121	Data 0.001	Loss 3.08	Acc@1 85.9	Acc@5 96.9
Epoch: [166][321/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 98.4
Epoch: [166][331/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 93.8	Acc@5 100.0
Epoch: [166][341/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 82.8	Acc@5 100.0
Epoch: [166][351/704]	Time 0.121	Data 0.001	Loss 3.21	Acc@1 84.4	Acc@5 98.4
Epoch: [166][361/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 85.9	Acc@5 100.0
Epoch: [166][371/704]	Time 0.121	Data 0.001	Loss 3.62	Acc@1 79.7	Acc@5 95.3
Epoch: [166][381/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 100.0
Epoch: [166][391/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 93.8	Acc@5 100.0
Epoch: [166][401/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 85.9	Acc@5 100.0
Epoch: [166][411/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 85.9	Acc@5 98.4
Epoch: [166][421/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 85.9	Acc@5 98.4
Epoch: [166][431/704]	Time 0.121	Data 0.001	Loss 3.05	Acc@1 87.5	Acc@5 96.9
Epoch: [166][441/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 100.0
Epoch: [166][451/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 81.2	Acc@5 98.4
Epoch: [166][461/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 82.8	Acc@5 100.0
Epoch: [166][471/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 100.0
Epoch: [166][481/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 98.4
Epoch: [166][491/704]	Time 0.121	Data 0.001	Loss 4.76	Acc@1 67.2	Acc@5 95.3
Epoch: [166][501/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 87.5	Acc@5 98.4
Epoch: [166][511/704]	Time 0.121	Data 0.001	Loss 3.31	Acc@1 82.8	Acc@5 98.4
Epoch: [166][521/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 81.2	Acc@5 96.9
Epoch: [166][531/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 82.8	Acc@5 100.0
Epoch: [166][541/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 87.5	Acc@5 95.3
Epoch: [166][551/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 89.1	Acc@5 98.4
Epoch: [166][561/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 87.5	Acc@5 98.4
Epoch: [166][571/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 98.4
Epoch: [166][581/704]	Time 0.120	Data 0.001	Loss 3.02	Acc@1 87.5	Acc@5 98.4
Epoch: [166][591/704]	Time 0.120	Data 0.001	Loss 2.89	Acc@1 85.9	Acc@5 98.4
Epoch: [166][601/704]	Time 0.120	Data 0.001	Loss 3.18	Acc@1 90.6	Acc@5 96.9
Epoch: [166][611/704]	Time 0.120	Data 0.001	Loss 3.06	Acc@1 87.5	Acc@5 96.9
Epoch: [166][621/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 89.1	Acc@5 100.0
Epoch: [166][631/704]	Time 0.120	Data 0.001	Loss 3.03	Acc@1 85.9	Acc@5 100.0
Epoch: [166][641/704]	Time 0.120	Data 0.001	Loss 2.63	Acc@1 81.2	Acc@5 96.9
Epoch: [166][651/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [166][661/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 100.0
Epoch: [166][671/704]	Time 0.120	Data 0.001	Loss 2.49	Acc@1 92.2	Acc@5 100.0
Epoch: [166][681/704]	Time 0.120	Data 0.001	Loss 3.41	Acc@1 85.9	Acc@5 93.8
Epoch: [166][691/704]	Time 0.120	Data 0.001	Loss 4.22	Acc@1 82.8	Acc@5 93.8
Epoch: [166][701/704]	Time 0.120	Data 0.001	Loss 3.36	Acc@1 81.2	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.0060	Acc@1 56.2500	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.1160	Acc@1 78.1250	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7512	Acc@1 71.8750	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.9663	Acc@1 62.5000	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.9915	Acc@1 71.8750	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1035	Acc@1 65.6250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.8762	Acc@1 68.7500	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.5503	Acc@1 73.4375	Acc@5 89.0625
 * prec@1 57.620 prec@5 85.160
 * prec@1 62.320 prec@5 88.500
 * prec@1 66.340 prec@5 91.020
 * prec@1 67.920 prec@5 91.440
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_166.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_166.pth.tar'
Epoch: [167][1/704]	Time 0.299	Data 0.131	Loss 2.68	Acc@1 84.4	Acc@5 98.4
Epoch: [167][11/704]	Time 0.137	Data 0.012	Loss 2.50	Acc@1 87.5	Acc@5 100.0
Epoch: [167][21/704]	Time 0.129	Data 0.007	Loss 3.19	Acc@1 87.5	Acc@5 98.4
Epoch: [167][31/704]	Time 0.126	Data 0.005	Loss 2.22	Acc@1 92.2	Acc@5 98.4
Epoch: [167][41/704]	Time 0.125	Data 0.004	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [167][51/704]	Time 0.124	Data 0.003	Loss 2.30	Acc@1 87.5	Acc@5 100.0
Epoch: [167][61/704]	Time 0.124	Data 0.003	Loss 2.45	Acc@1 87.5	Acc@5 100.0
Epoch: [167][71/704]	Time 0.123	Data 0.002	Loss 2.31	Acc@1 84.4	Acc@5 98.4
Epoch: [167][81/704]	Time 0.123	Data 0.002	Loss 2.88	Acc@1 92.2	Acc@5 100.0
Epoch: [167][91/704]	Time 0.123	Data 0.002	Loss 3.38	Acc@1 84.4	Acc@5 100.0
Epoch: [167][101/704]	Time 0.122	Data 0.002	Loss 2.69	Acc@1 89.1	Acc@5 98.4
Epoch: [167][111/704]	Time 0.122	Data 0.002	Loss 2.29	Acc@1 89.1	Acc@5 100.0
Epoch: [167][121/704]	Time 0.122	Data 0.001	Loss 3.99	Acc@1 76.6	Acc@5 96.9
Epoch: [167][131/704]	Time 0.122	Data 0.001	Loss 2.64	Acc@1 89.1	Acc@5 98.4
Epoch: [167][141/704]	Time 0.122	Data 0.001	Loss 3.16	Acc@1 87.5	Acc@5 98.4
Epoch: [167][151/704]	Time 0.122	Data 0.001	Loss 3.29	Acc@1 84.4	Acc@5 96.9
Epoch: [167][161/704]	Time 0.122	Data 0.001	Loss 2.54	Acc@1 81.2	Acc@5 100.0
Epoch: [167][171/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [167][181/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [167][191/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 84.4	Acc@5 100.0
Epoch: [167][201/704]	Time 0.121	Data 0.001	Loss 3.31	Acc@1 85.9	Acc@5 98.4
Epoch: [167][211/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 90.6	Acc@5 100.0
Epoch: [167][221/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 84.4	Acc@5 100.0
Epoch: [167][231/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 98.4
Epoch: [167][241/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 85.9	Acc@5 100.0
Epoch: [167][251/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [167][261/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 100.0
Epoch: [167][271/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 82.8	Acc@5 95.3
Epoch: [167][281/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 84.4	Acc@5 100.0
Epoch: [167][291/704]	Time 0.121	Data 0.001	Loss 4.02	Acc@1 78.1	Acc@5 95.3
Epoch: [167][301/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 81.2	Acc@5 100.0
Epoch: [167][311/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 87.5	Acc@5 100.0
Epoch: [167][321/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [167][331/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 90.6	Acc@5 100.0
Epoch: [167][341/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 85.9	Acc@5 98.4
Epoch: [167][351/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 89.1	Acc@5 98.4
Epoch: [167][361/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 100.0
Epoch: [167][371/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 87.5	Acc@5 100.0
Epoch: [167][381/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 87.5	Acc@5 98.4
Epoch: [167][391/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 81.2	Acc@5 96.9
Epoch: [167][401/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 85.9	Acc@5 100.0
Epoch: [167][411/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 89.1	Acc@5 98.4
Epoch: [167][421/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [167][431/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 90.6	Acc@5 98.4
Epoch: [167][441/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 98.4
Epoch: [167][451/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 85.9	Acc@5 96.9
Epoch: [167][461/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 89.1	Acc@5 98.4
Epoch: [167][471/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 85.9	Acc@5 98.4
Epoch: [167][481/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 85.9	Acc@5 100.0
Epoch: [167][491/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 100.0
Epoch: [167][501/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 82.8	Acc@5 95.3
Epoch: [167][511/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 87.5	Acc@5 98.4
Epoch: [167][521/704]	Time 0.121	Data 0.001	Loss 3.13	Acc@1 84.4	Acc@5 100.0
Epoch: [167][531/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [167][541/704]	Time 0.121	Data 0.001	Loss 3.52	Acc@1 87.5	Acc@5 100.0
Epoch: [167][551/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 87.5	Acc@5 98.4
Epoch: [167][561/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 84.4	Acc@5 96.9
Epoch: [167][571/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 82.8	Acc@5 98.4
Epoch: [167][581/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 90.6	Acc@5 100.0
Epoch: [167][591/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 85.9	Acc@5 100.0
Epoch: [167][601/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 82.8	Acc@5 98.4
Epoch: [167][611/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 89.1	Acc@5 96.9
Epoch: [167][621/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 82.8	Acc@5 98.4
Epoch: [167][631/704]	Time 0.121	Data 0.001	Loss 3.33	Acc@1 81.2	Acc@5 96.9
Epoch: [167][641/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 84.4	Acc@5 96.9
Epoch: [167][651/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 89.1	Acc@5 98.4
Epoch: [167][661/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 85.9	Acc@5 100.0
Epoch: [167][671/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 90.6	Acc@5 100.0
Epoch: [167][681/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 87.5	Acc@5 98.4
Epoch: [167][691/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 93.8	Acc@5 98.4
Epoch: [167][701/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 85.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.1430	Acc@1 76.5625	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4133	Acc@1 62.5000	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.1637	Acc@1 75.0000	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.1274	Acc@1 54.6875	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.8631	Acc@1 70.3125	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.3209	Acc@1 67.1875	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.0592	Acc@1 67.1875	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.1271	Acc@1 71.8750	Acc@5 96.8750
 * prec@1 57.720 prec@5 85.740
 * prec@1 63.400 prec@5 88.980
 * prec@1 66.580 prec@5 91.120
 * prec@1 69.100 prec@5 91.840
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_167.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_167.pth.tar'
Epoch: [168][1/704]	Time 0.330	Data 0.164	Loss 2.63	Acc@1 92.2	Acc@5 96.9
Epoch: [168][11/704]	Time 0.139	Data 0.015	Loss 2.25	Acc@1 90.6	Acc@5 98.4
Epoch: [168][21/704]	Time 0.130	Data 0.008	Loss 2.37	Acc@1 84.4	Acc@5 100.0
Epoch: [168][31/704]	Time 0.127	Data 0.006	Loss 2.83	Acc@1 82.8	Acc@5 100.0
Epoch: [168][41/704]	Time 0.125	Data 0.004	Loss 3.08	Acc@1 85.9	Acc@5 96.9
Epoch: [168][51/704]	Time 0.124	Data 0.004	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [168][61/704]	Time 0.123	Data 0.003	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [168][71/704]	Time 0.123	Data 0.003	Loss 1.87	Acc@1 89.1	Acc@5 100.0
Epoch: [168][81/704]	Time 0.123	Data 0.002	Loss 2.91	Acc@1 81.2	Acc@5 96.9
Epoch: [168][91/704]	Time 0.122	Data 0.002	Loss 2.69	Acc@1 89.1	Acc@5 96.9
Epoch: [168][101/704]	Time 0.122	Data 0.002	Loss 2.56	Acc@1 89.1	Acc@5 98.4
Epoch: [168][111/704]	Time 0.122	Data 0.002	Loss 2.45	Acc@1 87.5	Acc@5 100.0
Epoch: [168][121/704]	Time 0.122	Data 0.002	Loss 1.88	Acc@1 89.1	Acc@5 100.0
Epoch: [168][131/704]	Time 0.122	Data 0.002	Loss 3.28	Acc@1 85.9	Acc@5 98.4
Epoch: [168][141/704]	Time 0.121	Data 0.002	Loss 2.02	Acc@1 90.6	Acc@5 100.0
Epoch: [168][151/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 85.9	Acc@5 98.4
Epoch: [168][161/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 85.9	Acc@5 98.4
Epoch: [168][171/704]	Time 0.121	Data 0.001	Loss 3.19	Acc@1 82.8	Acc@5 96.9
Epoch: [168][181/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 85.9	Acc@5 100.0
Epoch: [168][191/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [168][201/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [168][211/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 87.5	Acc@5 100.0
Epoch: [168][221/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 84.4	Acc@5 98.4
Epoch: [168][231/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 89.1	Acc@5 100.0
Epoch: [168][241/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 89.1	Acc@5 98.4
Epoch: [168][251/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 95.3	Acc@5 98.4
Epoch: [168][261/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 85.9	Acc@5 100.0
Epoch: [168][271/704]	Time 0.121	Data 0.001	Loss 3.49	Acc@1 81.2	Acc@5 96.9
Epoch: [168][281/704]	Time 0.121	Data 0.001	Loss 3.10	Acc@1 90.6	Acc@5 98.4
Epoch: [168][291/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 84.4	Acc@5 98.4
Epoch: [168][301/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 82.8	Acc@5 100.0
Epoch: [168][311/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [168][321/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 87.5	Acc@5 100.0
Epoch: [168][331/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 87.5	Acc@5 98.4
Epoch: [168][341/704]	Time 0.120	Data 0.001	Loss 2.75	Acc@1 92.2	Acc@5 98.4
Epoch: [168][351/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 82.8	Acc@5 98.4
Epoch: [168][361/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 85.9	Acc@5 98.4
Epoch: [168][371/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 90.6	Acc@5 100.0
Epoch: [168][381/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 100.0
Epoch: [168][391/704]	Time 0.121	Data 0.001	Loss 3.35	Acc@1 82.8	Acc@5 98.4
Epoch: [168][401/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 85.9	Acc@5 98.4
Epoch: [168][411/704]	Time 0.120	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 98.4
Epoch: [168][421/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 82.8	Acc@5 100.0
Epoch: [168][431/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [168][441/704]	Time 0.120	Data 0.001	Loss 2.59	Acc@1 90.6	Acc@5 98.4
Epoch: [168][451/704]	Time 0.120	Data 0.001	Loss 2.91	Acc@1 89.1	Acc@5 98.4
Epoch: [168][461/704]	Time 0.120	Data 0.001	Loss 2.98	Acc@1 81.2	Acc@5 98.4
Epoch: [168][471/704]	Time 0.120	Data 0.001	Loss 3.79	Acc@1 79.7	Acc@5 98.4
Epoch: [168][481/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [168][491/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 100.0
Epoch: [168][501/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 98.4
Epoch: [168][511/704]	Time 0.120	Data 0.001	Loss 2.95	Acc@1 89.1	Acc@5 100.0
Epoch: [168][521/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 92.2	Acc@5 100.0
Epoch: [168][531/704]	Time 0.120	Data 0.001	Loss 2.33	Acc@1 89.1	Acc@5 100.0
Epoch: [168][541/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 90.6	Acc@5 98.4
Epoch: [168][551/704]	Time 0.120	Data 0.001	Loss 3.61	Acc@1 85.9	Acc@5 96.9
Epoch: [168][561/704]	Time 0.120	Data 0.001	Loss 2.83	Acc@1 84.4	Acc@5 98.4
Epoch: [168][571/704]	Time 0.120	Data 0.001	Loss 3.54	Acc@1 79.7	Acc@5 98.4
Epoch: [168][581/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 98.4
Epoch: [168][591/704]	Time 0.120	Data 0.001	Loss 2.85	Acc@1 85.9	Acc@5 98.4
Epoch: [168][601/704]	Time 0.120	Data 0.001	Loss 2.93	Acc@1 89.1	Acc@5 98.4
Epoch: [168][611/704]	Time 0.120	Data 0.001	Loss 3.05	Acc@1 84.4	Acc@5 98.4
Epoch: [168][621/704]	Time 0.120	Data 0.001	Loss 2.71	Acc@1 85.9	Acc@5 100.0
Epoch: [168][631/704]	Time 0.120	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [168][641/704]	Time 0.120	Data 0.001	Loss 2.64	Acc@1 90.6	Acc@5 100.0
Epoch: [168][651/704]	Time 0.120	Data 0.001	Loss 2.65	Acc@1 90.6	Acc@5 98.4
Epoch: [168][661/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 92.2	Acc@5 96.9
Epoch: [168][671/704]	Time 0.120	Data 0.001	Loss 2.97	Acc@1 85.9	Acc@5 98.4
Epoch: [168][681/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 90.6	Acc@5 98.4
Epoch: [168][691/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 100.0
Epoch: [168][701/704]	Time 0.120	Data 0.001	Loss 2.82	Acc@1 87.5	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.2787	Acc@1 67.1875	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1861	Acc@1 64.0625	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8315	Acc@1 71.8750	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.2748	Acc@1 73.4375	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.5167	Acc@1 54.6875	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6885	Acc@1 68.7500	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4013	Acc@1 70.3125	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.7402	Acc@1 68.7500	Acc@5 93.7500
 * prec@1 56.820 prec@5 85.300
 * prec@1 62.460 prec@5 88.400
 * prec@1 67.240 prec@5 91.280
 * prec@1 68.620 prec@5 91.420
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_168.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_168.pth.tar'
Epoch: [169][1/704]	Time 0.334	Data 0.168	Loss 2.44	Acc@1 87.5	Acc@5 100.0
Epoch: [169][11/704]	Time 0.140	Data 0.016	Loss 3.73	Acc@1 84.4	Acc@5 95.3
Epoch: [169][21/704]	Time 0.130	Data 0.008	Loss 2.58	Acc@1 87.5	Acc@5 100.0
Epoch: [169][31/704]	Time 0.127	Data 0.006	Loss 2.79	Acc@1 85.9	Acc@5 96.9
Epoch: [169][41/704]	Time 0.125	Data 0.004	Loss 2.85	Acc@1 87.5	Acc@5 100.0
Epoch: [169][51/704]	Time 0.124	Data 0.004	Loss 2.61	Acc@1 84.4	Acc@5 96.9
Epoch: [169][61/704]	Time 0.124	Data 0.003	Loss 2.09	Acc@1 87.5	Acc@5 100.0
Epoch: [169][71/704]	Time 0.123	Data 0.003	Loss 2.40	Acc@1 89.1	Acc@5 100.0
Epoch: [169][81/704]	Time 0.123	Data 0.002	Loss 2.88	Acc@1 90.6	Acc@5 100.0
Epoch: [169][91/704]	Time 0.122	Data 0.002	Loss 1.81	Acc@1 90.6	Acc@5 98.4
Epoch: [169][101/704]	Time 0.122	Data 0.002	Loss 2.79	Acc@1 90.6	Acc@5 98.4
Epoch: [169][111/704]	Time 0.122	Data 0.002	Loss 2.53	Acc@1 84.4	Acc@5 98.4
Epoch: [169][121/704]	Time 0.122	Data 0.002	Loss 2.12	Acc@1 90.6	Acc@5 100.0
Epoch: [169][131/704]	Time 0.122	Data 0.002	Loss 3.00	Acc@1 84.4	Acc@5 96.9
Epoch: [169][141/704]	Time 0.122	Data 0.001	Loss 2.07	Acc@1 92.2	Acc@5 100.0
Epoch: [169][151/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 92.2	Acc@5 100.0
Epoch: [169][161/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 84.4	Acc@5 100.0
Epoch: [169][171/704]	Time 0.121	Data 0.001	Loss 3.13	Acc@1 85.9	Acc@5 98.4
Epoch: [169][181/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [169][191/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 93.8	Acc@5 100.0
Epoch: [169][201/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 93.8	Acc@5 98.4
Epoch: [169][211/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 81.2	Acc@5 100.0
Epoch: [169][221/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 82.8	Acc@5 98.4
Epoch: [169][231/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 85.9	Acc@5 100.0
Epoch: [169][241/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 89.1	Acc@5 98.4
Epoch: [169][251/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 82.8	Acc@5 100.0
Epoch: [169][261/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 90.6	Acc@5 98.4
Epoch: [169][271/704]	Time 0.121	Data 0.001	Loss 3.35	Acc@1 89.1	Acc@5 93.8
Epoch: [169][281/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 82.8	Acc@5 100.0
Epoch: [169][291/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [169][301/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 81.2	Acc@5 100.0
Epoch: [169][311/704]	Time 0.121	Data 0.001	Loss 3.31	Acc@1 81.2	Acc@5 100.0
Epoch: [169][321/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 85.9	Acc@5 100.0
Epoch: [169][331/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 85.9	Acc@5 98.4
Epoch: [169][341/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 85.9	Acc@5 96.9
Epoch: [169][351/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 89.1	Acc@5 98.4
Epoch: [169][361/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 87.5	Acc@5 96.9
Epoch: [169][371/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 84.4	Acc@5 98.4
Epoch: [169][381/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 92.2	Acc@5 100.0
Epoch: [169][391/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 85.9	Acc@5 95.3
Epoch: [169][401/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 89.1	Acc@5 100.0
Epoch: [169][411/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 82.8	Acc@5 100.0
Epoch: [169][421/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 87.5	Acc@5 98.4
Epoch: [169][431/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 100.0
Epoch: [169][441/704]	Time 0.121	Data 0.001	Loss 3.66	Acc@1 85.9	Acc@5 95.3
Epoch: [169][451/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 84.4	Acc@5 100.0
Epoch: [169][461/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 93.8	Acc@5 98.4
Epoch: [169][471/704]	Time 0.120	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 98.4
Epoch: [169][481/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 89.1	Acc@5 100.0
Epoch: [169][491/704]	Time 0.120	Data 0.001	Loss 2.94	Acc@1 84.4	Acc@5 98.4
Epoch: [169][501/704]	Time 0.120	Data 0.001	Loss 2.37	Acc@1 89.1	Acc@5 100.0
Epoch: [169][511/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 93.8	Acc@5 100.0
Epoch: [169][521/704]	Time 0.120	Data 0.001	Loss 3.28	Acc@1 85.9	Acc@5 93.8
Epoch: [169][531/704]	Time 0.120	Data 0.001	Loss 3.26	Acc@1 85.9	Acc@5 98.4
Epoch: [169][541/704]	Time 0.120	Data 0.001	Loss 3.25	Acc@1 82.8	Acc@5 96.9
Epoch: [169][551/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 89.1	Acc@5 96.9
Epoch: [169][561/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 87.5	Acc@5 100.0
Epoch: [169][571/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 96.9	Acc@5 100.0
Epoch: [169][581/704]	Time 0.120	Data 0.001	Loss 2.56	Acc@1 81.2	Acc@5 100.0
Epoch: [169][591/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 87.5	Acc@5 98.4
Epoch: [169][601/704]	Time 0.120	Data 0.001	Loss 2.65	Acc@1 90.6	Acc@5 98.4
Epoch: [169][611/704]	Time 0.120	Data 0.001	Loss 2.93	Acc@1 89.1	Acc@5 98.4
Epoch: [169][621/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 96.9
Epoch: [169][631/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [169][641/704]	Time 0.120	Data 0.001	Loss 2.86	Acc@1 90.6	Acc@5 100.0
Epoch: [169][651/704]	Time 0.120	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 98.4
Epoch: [169][661/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 87.5	Acc@5 100.0
Epoch: [169][671/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 89.1	Acc@5 100.0
Epoch: [169][681/704]	Time 0.120	Data 0.001	Loss 3.06	Acc@1 87.5	Acc@5 96.9
Epoch: [169][691/704]	Time 0.120	Data 0.001	Loss 2.92	Acc@1 84.4	Acc@5 100.0
Epoch: [169][701/704]	Time 0.120	Data 0.001	Loss 2.25	Acc@1 89.1	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.6962	Acc@1 71.8750	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.7221	Acc@1 71.8750	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.6840	Acc@1 62.5000	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.8355	Acc@1 78.1250	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2966	Acc@1 68.7500	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2396	Acc@1 64.0625	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.5977	Acc@1 73.4375	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.1037	Acc@1 73.4375	Acc@5 90.6250
 * prec@1 57.900 prec@5 85.780
 * prec@1 62.460 prec@5 88.780
 * prec@1 66.580 prec@5 90.940
 * prec@1 69.080 prec@5 91.760
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_169.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_169.pth.tar'
Epoch: [170][1/704]	Time 0.300	Data 0.132	Loss 2.04	Acc@1 92.2	Acc@5 100.0
Epoch: [170][11/704]	Time 0.137	Data 0.013	Loss 2.05	Acc@1 90.6	Acc@5 100.0
Epoch: [170][21/704]	Time 0.129	Data 0.007	Loss 3.11	Acc@1 81.2	Acc@5 98.4
Epoch: [170][31/704]	Time 0.126	Data 0.005	Loss 2.88	Acc@1 84.4	Acc@5 98.4
Epoch: [170][41/704]	Time 0.125	Data 0.004	Loss 2.27	Acc@1 85.9	Acc@5 100.0
Epoch: [170][51/704]	Time 0.124	Data 0.003	Loss 3.43	Acc@1 79.7	Acc@5 95.3
Epoch: [170][61/704]	Time 0.123	Data 0.002	Loss 2.51	Acc@1 84.4	Acc@5 98.4
Epoch: [170][71/704]	Time 0.123	Data 0.002	Loss 2.77	Acc@1 89.1	Acc@5 100.0
Epoch: [170][81/704]	Time 0.123	Data 0.002	Loss 2.04	Acc@1 89.1	Acc@5 98.4
Epoch: [170][91/704]	Time 0.123	Data 0.002	Loss 3.14	Acc@1 84.4	Acc@5 98.4
Epoch: [170][101/704]	Time 0.123	Data 0.002	Loss 2.42	Acc@1 89.1	Acc@5 98.4
Epoch: [170][111/704]	Time 0.122	Data 0.002	Loss 3.21	Acc@1 79.7	Acc@5 96.9
Epoch: [170][121/704]	Time 0.122	Data 0.001	Loss 3.32	Acc@1 81.2	Acc@5 98.4
Epoch: [170][131/704]	Time 0.122	Data 0.001	Loss 2.89	Acc@1 82.8	Acc@5 95.3
Epoch: [170][141/704]	Time 0.122	Data 0.001	Loss 3.10	Acc@1 89.1	Acc@5 98.4
Epoch: [170][151/704]	Time 0.122	Data 0.001	Loss 2.55	Acc@1 84.4	Acc@5 100.0
Epoch: [170][161/704]	Time 0.122	Data 0.001	Loss 3.52	Acc@1 85.9	Acc@5 96.9
Epoch: [170][171/704]	Time 0.122	Data 0.001	Loss 3.37	Acc@1 81.2	Acc@5 100.0
Epoch: [170][181/704]	Time 0.122	Data 0.001	Loss 2.75	Acc@1 78.1	Acc@5 100.0
Epoch: [170][191/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 98.4
Epoch: [170][201/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 98.4	Acc@5 100.0
Epoch: [170][211/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 85.9	Acc@5 100.0
Epoch: [170][221/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 87.5	Acc@5 100.0
Epoch: [170][231/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [170][241/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 87.5	Acc@5 100.0
Epoch: [170][251/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 85.9	Acc@5 98.4
Epoch: [170][261/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 87.5	Acc@5 100.0
Epoch: [170][271/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 84.4	Acc@5 96.9
Epoch: [170][281/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 89.1	Acc@5 98.4
Epoch: [170][291/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 89.1	Acc@5 98.4
Epoch: [170][301/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 87.5	Acc@5 96.9
Epoch: [170][311/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 82.8	Acc@5 98.4
Epoch: [170][321/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 90.6	Acc@5 98.4
Epoch: [170][331/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 89.1	Acc@5 98.4
Epoch: [170][341/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [170][351/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 89.1	Acc@5 100.0
Epoch: [170][361/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 85.9	Acc@5 100.0
Epoch: [170][371/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 90.6	Acc@5 100.0
Epoch: [170][381/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 90.6	Acc@5 98.4
Epoch: [170][391/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 84.4	Acc@5 96.9
Epoch: [170][401/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 90.6	Acc@5 100.0
Epoch: [170][411/704]	Time 0.121	Data 0.001	Loss 3.18	Acc@1 85.9	Acc@5 98.4
Epoch: [170][421/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 92.2	Acc@5 96.9
Epoch: [170][431/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 85.9	Acc@5 100.0
Epoch: [170][441/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [170][451/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 92.2	Acc@5 100.0
Epoch: [170][461/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 85.9	Acc@5 98.4
Epoch: [170][471/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 90.6	Acc@5 98.4
Epoch: [170][481/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 79.7	Acc@5 98.4
Epoch: [170][491/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 82.8	Acc@5 95.3
Epoch: [170][501/704]	Time 0.121	Data 0.001	Loss 3.10	Acc@1 81.2	Acc@5 100.0
Epoch: [170][511/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 85.9	Acc@5 100.0
Epoch: [170][521/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 82.8	Acc@5 98.4
Epoch: [170][531/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 87.5	Acc@5 98.4
Epoch: [170][541/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 81.2	Acc@5 98.4
Epoch: [170][551/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 84.4	Acc@5 98.4
Epoch: [170][561/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 81.2	Acc@5 100.0
Epoch: [170][571/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 90.6	Acc@5 98.4
Epoch: [170][581/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 92.2	Acc@5 96.9
Epoch: [170][591/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 89.1	Acc@5 98.4
Epoch: [170][601/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 82.8	Acc@5 98.4
Epoch: [170][611/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 87.5	Acc@5 98.4
Epoch: [170][621/704]	Time 0.121	Data 0.001	Loss 3.33	Acc@1 78.1	Acc@5 98.4
Epoch: [170][631/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 93.8	Acc@5 100.0
Epoch: [170][641/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [170][651/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 89.1	Acc@5 98.4
Epoch: [170][661/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 82.8	Acc@5 96.9
Epoch: [170][671/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 90.6	Acc@5 98.4
Epoch: [170][681/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 92.2	Acc@5 100.0
Epoch: [170][691/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 89.1	Acc@5 96.9
Epoch: [170][701/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 4.8310	Acc@1 75.0000	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.2432	Acc@1 75.0000	Acc@5 96.8750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.1340	Acc@1 68.7500	Acc@5 84.3750
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 4.6238	Acc@1 73.4375	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.8535	Acc@1 68.7500	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.0056	Acc@1 78.1250	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.3234	Acc@1 67.1875	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.4297	Acc@1 67.1875	Acc@5 92.1875
 * prec@1 57.860 prec@5 85.400
 * prec@1 62.480 prec@5 88.060
 * prec@1 66.660 prec@5 91.000
 * prec@1 67.700 prec@5 91.240
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_170.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_170.pth.tar'
Epoch: [171][1/704]	Time 0.300	Data 0.132	Loss 2.02	Acc@1 87.5	Acc@5 100.0
Epoch: [171][11/704]	Time 0.141	Data 0.012	Loss 3.42	Acc@1 81.2	Acc@5 100.0
Epoch: [171][21/704]	Time 0.131	Data 0.007	Loss 2.77	Acc@1 87.5	Acc@5 96.9
Epoch: [171][31/704]	Time 0.128	Data 0.005	Loss 3.03	Acc@1 82.8	Acc@5 100.0
Epoch: [171][41/704]	Time 0.126	Data 0.004	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [171][51/704]	Time 0.125	Data 0.003	Loss 2.88	Acc@1 87.5	Acc@5 100.0
Epoch: [171][61/704]	Time 0.124	Data 0.003	Loss 2.73	Acc@1 93.8	Acc@5 98.4
Epoch: [171][71/704]	Time 0.124	Data 0.002	Loss 2.48	Acc@1 82.8	Acc@5 100.0
Epoch: [171][81/704]	Time 0.123	Data 0.002	Loss 2.98	Acc@1 89.1	Acc@5 96.9
Epoch: [171][91/704]	Time 0.123	Data 0.002	Loss 1.82	Acc@1 93.8	Acc@5 98.4
Epoch: [171][101/704]	Time 0.123	Data 0.002	Loss 2.28	Acc@1 85.9	Acc@5 100.0
Epoch: [171][111/704]	Time 0.122	Data 0.002	Loss 2.79	Acc@1 84.4	Acc@5 100.0
Epoch: [171][121/704]	Time 0.122	Data 0.002	Loss 2.25	Acc@1 92.2	Acc@5 100.0
Epoch: [171][131/704]	Time 0.122	Data 0.001	Loss 3.11	Acc@1 90.6	Acc@5 98.4
Epoch: [171][141/704]	Time 0.122	Data 0.001	Loss 2.76	Acc@1 89.1	Acc@5 96.9
Epoch: [171][151/704]	Time 0.122	Data 0.001	Loss 2.54	Acc@1 96.9	Acc@5 100.0
Epoch: [171][161/704]	Time 0.122	Data 0.001	Loss 2.91	Acc@1 92.2	Acc@5 100.0
Epoch: [171][171/704]	Time 0.122	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [171][181/704]	Time 0.122	Data 0.001	Loss 2.48	Acc@1 92.2	Acc@5 100.0
Epoch: [171][191/704]	Time 0.122	Data 0.001	Loss 2.64	Acc@1 89.1	Acc@5 100.0
Epoch: [171][201/704]	Time 0.122	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 98.4
Epoch: [171][211/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 82.8	Acc@5 98.4
Epoch: [171][221/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 87.5	Acc@5 100.0
Epoch: [171][231/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 85.9	Acc@5 100.0
Epoch: [171][241/704]	Time 0.121	Data 0.001	Loss 3.35	Acc@1 84.4	Acc@5 100.0
Epoch: [171][251/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [171][261/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 81.2	Acc@5 100.0
Epoch: [171][271/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 100.0
Epoch: [171][281/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [171][291/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 87.5	Acc@5 100.0
Epoch: [171][301/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 85.9	Acc@5 98.4
Epoch: [171][311/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 84.4	Acc@5 100.0
Epoch: [171][321/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 90.6	Acc@5 100.0
Epoch: [171][331/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 89.1	Acc@5 100.0
Epoch: [171][341/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 100.0
Epoch: [171][351/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 89.1	Acc@5 100.0
Epoch: [171][361/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 82.8	Acc@5 98.4
Epoch: [171][371/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 84.4	Acc@5 96.9
Epoch: [171][381/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 84.4	Acc@5 100.0
Epoch: [171][391/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 87.5	Acc@5 98.4
Epoch: [171][401/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 85.9	Acc@5 100.0
Epoch: [171][411/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 84.4	Acc@5 96.9
Epoch: [171][421/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 84.4	Acc@5 98.4
Epoch: [171][431/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 89.1	Acc@5 100.0
Epoch: [171][441/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 84.4	Acc@5 100.0
Epoch: [171][451/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 100.0
Epoch: [171][461/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 95.3	Acc@5 98.4
Epoch: [171][471/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 82.8	Acc@5 100.0
Epoch: [171][481/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 100.0
Epoch: [171][491/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 87.5	Acc@5 100.0
Epoch: [171][501/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 79.7	Acc@5 100.0
Epoch: [171][511/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 85.9	Acc@5 100.0
Epoch: [171][521/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 98.4
Epoch: [171][531/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 90.6	Acc@5 98.4
Epoch: [171][541/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 89.1	Acc@5 98.4
Epoch: [171][551/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 89.1	Acc@5 98.4
Epoch: [171][561/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 89.1	Acc@5 100.0
Epoch: [171][571/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [171][581/704]	Time 0.121	Data 0.001	Loss 3.21	Acc@1 85.9	Acc@5 98.4
Epoch: [171][591/704]	Time 0.121	Data 0.001	Loss 3.40	Acc@1 82.8	Acc@5 98.4
Epoch: [171][601/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 82.8	Acc@5 100.0
Epoch: [171][611/704]	Time 0.121	Data 0.001	Loss 3.08	Acc@1 85.9	Acc@5 98.4
Epoch: [171][621/704]	Time 0.121	Data 0.001	Loss 2.97	Acc@1 81.2	Acc@5 98.4
Epoch: [171][631/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 98.4
Epoch: [171][641/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 89.1	Acc@5 100.0
Epoch: [171][651/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 87.5	Acc@5 100.0
Epoch: [171][661/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 92.2	Acc@5 100.0
Epoch: [171][671/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [171][681/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 100.0
Epoch: [171][691/704]	Time 0.121	Data 0.001	Loss 3.37	Acc@1 79.7	Acc@5 100.0
Epoch: [171][701/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 90.6	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.8617	Acc@1 70.3125	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.4815	Acc@1 67.1875	Acc@5 96.8750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6624	Acc@1 60.9375	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.4247	Acc@1 65.6250	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.6049	Acc@1 73.4375	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8386	Acc@1 70.3125	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.6444	Acc@1 73.4375	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.8912	Acc@1 53.1250	Acc@5 85.9375
 * prec@1 57.840 prec@5 85.240
 * prec@1 63.040 prec@5 88.480
 * prec@1 66.560 prec@5 91.040
 * prec@1 68.320 prec@5 91.620
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_171.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_171.pth.tar'
Epoch: [172][1/704]	Time 0.329	Data 0.163	Loss 3.31	Acc@1 87.5	Acc@5 98.4
Epoch: [172][11/704]	Time 0.139	Data 0.015	Loss 2.95	Acc@1 87.5	Acc@5 100.0
Epoch: [172][21/704]	Time 0.130	Data 0.008	Loss 3.02	Acc@1 92.2	Acc@5 98.4
Epoch: [172][31/704]	Time 0.127	Data 0.006	Loss 2.84	Acc@1 85.9	Acc@5 100.0
Epoch: [172][41/704]	Time 0.125	Data 0.004	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [172][51/704]	Time 0.124	Data 0.004	Loss 2.88	Acc@1 84.4	Acc@5 98.4
Epoch: [172][61/704]	Time 0.124	Data 0.003	Loss 2.92	Acc@1 87.5	Acc@5 98.4
Epoch: [172][71/704]	Time 0.123	Data 0.003	Loss 2.30	Acc@1 87.5	Acc@5 100.0
Epoch: [172][81/704]	Time 0.123	Data 0.002	Loss 2.61	Acc@1 87.5	Acc@5 100.0
Epoch: [172][91/704]	Time 0.122	Data 0.002	Loss 2.32	Acc@1 93.8	Acc@5 98.4
Epoch: [172][101/704]	Time 0.122	Data 0.002	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [172][111/704]	Time 0.122	Data 0.002	Loss 2.06	Acc@1 87.5	Acc@5 100.0
Epoch: [172][121/704]	Time 0.122	Data 0.002	Loss 2.37	Acc@1 87.5	Acc@5 98.4
Epoch: [172][131/704]	Time 0.122	Data 0.002	Loss 1.94	Acc@1 92.2	Acc@5 98.4
Epoch: [172][141/704]	Time 0.122	Data 0.002	Loss 2.30	Acc@1 85.9	Acc@5 100.0
Epoch: [172][151/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 85.9	Acc@5 96.9
Epoch: [172][161/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 84.4	Acc@5 98.4
Epoch: [172][171/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 85.9	Acc@5 98.4
Epoch: [172][181/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 87.5	Acc@5 98.4
Epoch: [172][191/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 78.1	Acc@5 98.4
Epoch: [172][201/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 82.8	Acc@5 96.9
Epoch: [172][211/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 87.5	Acc@5 100.0
Epoch: [172][221/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 89.1	Acc@5 100.0
Epoch: [172][231/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 89.1	Acc@5 98.4
Epoch: [172][241/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 96.9
Epoch: [172][251/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 82.8	Acc@5 98.4
Epoch: [172][261/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 90.6	Acc@5 98.4
Epoch: [172][271/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 78.1	Acc@5 100.0
Epoch: [172][281/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 98.4
Epoch: [172][291/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 85.9	Acc@5 98.4
Epoch: [172][301/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 87.5	Acc@5 95.3
Epoch: [172][311/704]	Time 0.121	Data 0.001	Loss 3.79	Acc@1 82.8	Acc@5 95.3
Epoch: [172][321/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [172][331/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 85.9	Acc@5 100.0
Epoch: [172][341/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 87.5	Acc@5 98.4
Epoch: [172][351/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 85.9	Acc@5 100.0
Epoch: [172][361/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 81.2	Acc@5 96.9
Epoch: [172][371/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 84.4	Acc@5 100.0
Epoch: [172][381/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [172][391/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 93.8	Acc@5 100.0
Epoch: [172][401/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 96.9	Acc@5 100.0
Epoch: [172][411/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 79.7	Acc@5 96.9
Epoch: [172][421/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 81.2	Acc@5 98.4
Epoch: [172][431/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 90.6	Acc@5 100.0
Epoch: [172][441/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 100.0
Epoch: [172][451/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 90.6	Acc@5 98.4
Epoch: [172][461/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 84.4	Acc@5 96.9
Epoch: [172][471/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 93.8	Acc@5 98.4
Epoch: [172][481/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 84.4	Acc@5 100.0
Epoch: [172][491/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 92.2	Acc@5 100.0
Epoch: [172][501/704]	Time 0.121	Data 0.001	Loss 3.38	Acc@1 87.5	Acc@5 100.0
Epoch: [172][511/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 100.0
Epoch: [172][521/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 95.3	Acc@5 98.4
Epoch: [172][531/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 98.4
Epoch: [172][541/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 84.4	Acc@5 100.0
Epoch: [172][551/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [172][561/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 92.2	Acc@5 100.0
Epoch: [172][571/704]	Time 0.120	Data 0.001	Loss 3.11	Acc@1 84.4	Acc@5 100.0
Epoch: [172][581/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 92.2	Acc@5 100.0
Epoch: [172][591/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 90.6	Acc@5 100.0
Epoch: [172][601/704]	Time 0.120	Data 0.001	Loss 2.64	Acc@1 82.8	Acc@5 98.4
Epoch: [172][611/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [172][621/704]	Time 0.120	Data 0.001	Loss 2.96	Acc@1 85.9	Acc@5 98.4
Epoch: [172][631/704]	Time 0.120	Data 0.001	Loss 2.72	Acc@1 92.2	Acc@5 100.0
Epoch: [172][641/704]	Time 0.120	Data 0.001	Loss 3.02	Acc@1 84.4	Acc@5 100.0
Epoch: [172][651/704]	Time 0.120	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [172][661/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 84.4	Acc@5 98.4
Epoch: [172][671/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 98.4
Epoch: [172][681/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [172][691/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [172][701/704]	Time 0.120	Data 0.001	Loss 2.75	Acc@1 84.4	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.1992	Acc@1 78.1250	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.2591	Acc@1 62.5000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.1316	Acc@1 62.5000	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.6112	Acc@1 70.3125	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.5857	Acc@1 75.0000	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.7187	Acc@1 70.3125	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5045	Acc@1 70.3125	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.4222	Acc@1 71.8750	Acc@5 93.7500
 * prec@1 57.620 prec@5 85.280
 * prec@1 62.040 prec@5 88.240
 * prec@1 66.380 prec@5 91.000
 * prec@1 68.800 prec@5 91.620
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_172.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_172.pth.tar'
Epoch: [173][1/704]	Time 0.300	Data 0.133	Loss 1.99	Acc@1 87.5	Acc@5 100.0
Epoch: [173][11/704]	Time 0.136	Data 0.012	Loss 2.58	Acc@1 87.5	Acc@5 98.4
Epoch: [173][21/704]	Time 0.129	Data 0.007	Loss 2.99	Acc@1 81.2	Acc@5 98.4
Epoch: [173][31/704]	Time 0.126	Data 0.005	Loss 3.26	Acc@1 81.2	Acc@5 95.3
Epoch: [173][41/704]	Time 0.124	Data 0.004	Loss 2.46	Acc@1 93.8	Acc@5 100.0
Epoch: [173][51/704]	Time 0.124	Data 0.003	Loss 2.27	Acc@1 95.3	Acc@5 100.0
Epoch: [173][61/704]	Time 0.123	Data 0.003	Loss 2.10	Acc@1 89.1	Acc@5 96.9
Epoch: [173][71/704]	Time 0.123	Data 0.002	Loss 2.44	Acc@1 89.1	Acc@5 100.0
Epoch: [173][81/704]	Time 0.122	Data 0.002	Loss 3.12	Acc@1 92.2	Acc@5 98.4
Epoch: [173][91/704]	Time 0.122	Data 0.002	Loss 3.29	Acc@1 84.4	Acc@5 96.9
Epoch: [173][101/704]	Time 0.122	Data 0.002	Loss 2.72	Acc@1 85.9	Acc@5 98.4
Epoch: [173][111/704]	Time 0.122	Data 0.002	Loss 1.99	Acc@1 90.6	Acc@5 100.0
Epoch: [173][121/704]	Time 0.122	Data 0.001	Loss 2.61	Acc@1 89.1	Acc@5 100.0
Epoch: [173][131/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 100.0
Epoch: [173][141/704]	Time 0.122	Data 0.001	Loss 2.80	Acc@1 92.2	Acc@5 98.4
Epoch: [173][151/704]	Time 0.122	Data 0.001	Loss 3.26	Acc@1 82.8	Acc@5 100.0
Epoch: [173][161/704]	Time 0.122	Data 0.001	Loss 3.77	Acc@1 76.6	Acc@5 95.3
Epoch: [173][171/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 89.1	Acc@5 100.0
Epoch: [173][181/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 92.2	Acc@5 100.0
Epoch: [173][191/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 98.4
Epoch: [173][201/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 85.9	Acc@5 100.0
Epoch: [173][211/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 87.5	Acc@5 96.9
Epoch: [173][221/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 92.2	Acc@5 100.0
Epoch: [173][231/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 87.5	Acc@5 100.0
Epoch: [173][241/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 87.5	Acc@5 96.9
Epoch: [173][251/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [173][261/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 92.2	Acc@5 100.0
Epoch: [173][271/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [173][281/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [173][291/704]	Time 0.121	Data 0.001	Loss 3.05	Acc@1 87.5	Acc@5 96.9
Epoch: [173][301/704]	Time 0.121	Data 0.001	Loss 3.43	Acc@1 85.9	Acc@5 96.9
Epoch: [173][311/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 89.1	Acc@5 98.4
Epoch: [173][321/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 87.5	Acc@5 98.4
Epoch: [173][331/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [173][341/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 85.9	Acc@5 100.0
Epoch: [173][351/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 85.9	Acc@5 100.0
Epoch: [173][361/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 93.8	Acc@5 100.0
Epoch: [173][371/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 87.5	Acc@5 98.4
Epoch: [173][381/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [173][391/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 89.1	Acc@5 98.4
Epoch: [173][401/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 85.9	Acc@5 100.0
Epoch: [173][411/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [173][421/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 85.9	Acc@5 98.4
Epoch: [173][431/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 89.1	Acc@5 98.4
Epoch: [173][441/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 95.3	Acc@5 100.0
Epoch: [173][451/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [173][461/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 85.9	Acc@5 98.4
Epoch: [173][471/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 85.9	Acc@5 100.0
Epoch: [173][481/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 98.4
Epoch: [173][491/704]	Time 0.121	Data 0.001	Loss 3.87	Acc@1 84.4	Acc@5 96.9
Epoch: [173][501/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 85.9	Acc@5 98.4
Epoch: [173][511/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 89.1	Acc@5 98.4
Epoch: [173][521/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 100.0
Epoch: [173][531/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 87.5	Acc@5 98.4
Epoch: [173][541/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 89.1	Acc@5 98.4
Epoch: [173][551/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 93.8	Acc@5 98.4
Epoch: [173][561/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [173][571/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 85.9	Acc@5 96.9
Epoch: [173][581/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [173][591/704]	Time 0.121	Data 0.001	Loss 3.18	Acc@1 87.5	Acc@5 98.4
Epoch: [173][601/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 98.4
Epoch: [173][611/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 82.8	Acc@5 96.9
Epoch: [173][621/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 100.0
Epoch: [173][631/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 85.9	Acc@5 98.4
Epoch: [173][641/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 84.4	Acc@5 100.0
Epoch: [173][651/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [173][661/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [173][671/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 89.1	Acc@5 100.0
Epoch: [173][681/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 78.1	Acc@5 96.9
Epoch: [173][691/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 87.5	Acc@5 100.0
Epoch: [173][701/704]	Time 0.121	Data 0.001	Loss 3.08	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.9894	Acc@1 67.1875	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4105	Acc@1 70.3125	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.0515	Acc@1 64.0625	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.1438	Acc@1 71.8750	Acc@5 82.8125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.9715	Acc@1 65.6250	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0272	Acc@1 71.8750	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 3.7325	Acc@1 68.7500	Acc@5 96.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.2958	Acc@1 70.3125	Acc@5 90.6250
 * prec@1 58.100 prec@5 85.720
 * prec@1 62.620 prec@5 88.500
 * prec@1 66.680 prec@5 90.680
 * prec@1 68.580 prec@5 91.460
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_173.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_173.pth.tar'
Epoch: [174][1/704]	Time 0.299	Data 0.132	Loss 2.17	Acc@1 89.1	Acc@5 98.4
Epoch: [174][11/704]	Time 0.137	Data 0.012	Loss 2.94	Acc@1 85.9	Acc@5 98.4
Epoch: [174][21/704]	Time 0.129	Data 0.007	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [174][31/704]	Time 0.126	Data 0.005	Loss 1.93	Acc@1 93.8	Acc@5 98.4
Epoch: [174][41/704]	Time 0.125	Data 0.004	Loss 3.10	Acc@1 85.9	Acc@5 98.4
Epoch: [174][51/704]	Time 0.124	Data 0.003	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [174][61/704]	Time 0.124	Data 0.003	Loss 2.76	Acc@1 90.6	Acc@5 96.9
Epoch: [174][71/704]	Time 0.123	Data 0.002	Loss 2.64	Acc@1 85.9	Acc@5 96.9
Epoch: [174][81/704]	Time 0.123	Data 0.002	Loss 2.90	Acc@1 89.1	Acc@5 100.0
Epoch: [174][91/704]	Time 0.123	Data 0.002	Loss 3.38	Acc@1 79.7	Acc@5 98.4
Epoch: [174][101/704]	Time 0.122	Data 0.002	Loss 2.34	Acc@1 84.4	Acc@5 98.4
Epoch: [174][111/704]	Time 0.122	Data 0.002	Loss 2.89	Acc@1 84.4	Acc@5 96.9
Epoch: [174][121/704]	Time 0.122	Data 0.001	Loss 2.49	Acc@1 93.8	Acc@5 100.0
Epoch: [174][131/704]	Time 0.122	Data 0.001	Loss 3.38	Acc@1 89.1	Acc@5 96.9
Epoch: [174][141/704]	Time 0.122	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 98.4
Epoch: [174][151/704]	Time 0.122	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 100.0
Epoch: [174][161/704]	Time 0.122	Data 0.001	Loss 2.10	Acc@1 87.5	Acc@5 96.9
Epoch: [174][171/704]	Time 0.122	Data 0.001	Loss 3.18	Acc@1 87.5	Acc@5 98.4
Epoch: [174][181/704]	Time 0.122	Data 0.001	Loss 2.18	Acc@1 87.5	Acc@5 100.0
Epoch: [174][191/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [174][201/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 81.2	Acc@5 95.3
Epoch: [174][211/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 90.6	Acc@5 98.4
Epoch: [174][221/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 84.4	Acc@5 100.0
Epoch: [174][231/704]	Time 0.121	Data 0.001	Loss 3.66	Acc@1 81.2	Acc@5 96.9
Epoch: [174][241/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 84.4	Acc@5 100.0
Epoch: [174][251/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 85.9	Acc@5 98.4
Epoch: [174][261/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [174][271/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 90.6	Acc@5 100.0
Epoch: [174][281/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 89.1	Acc@5 95.3
Epoch: [174][291/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 82.8	Acc@5 98.4
Epoch: [174][301/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [174][311/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 95.3	Acc@5 100.0
Epoch: [174][321/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 84.4	Acc@5 98.4
Epoch: [174][331/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 85.9	Acc@5 100.0
Epoch: [174][341/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 87.5	Acc@5 100.0
Epoch: [174][351/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 84.4	Acc@5 100.0
Epoch: [174][361/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 93.8	Acc@5 100.0
Epoch: [174][371/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 85.9	Acc@5 98.4
Epoch: [174][381/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 87.5	Acc@5 100.0
Epoch: [174][391/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 90.6	Acc@5 100.0
Epoch: [174][401/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 87.5	Acc@5 98.4
Epoch: [174][411/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [174][421/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 84.4	Acc@5 98.4
Epoch: [174][431/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 90.6	Acc@5 98.4
Epoch: [174][441/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 87.5	Acc@5 100.0
Epoch: [174][451/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 85.9	Acc@5 100.0
Epoch: [174][461/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 89.1	Acc@5 100.0
Epoch: [174][471/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 90.6	Acc@5 100.0
Epoch: [174][481/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 87.5	Acc@5 100.0
Epoch: [174][491/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 89.1	Acc@5 96.9
Epoch: [174][501/704]	Time 0.121	Data 0.001	Loss 3.62	Acc@1 85.9	Acc@5 95.3
Epoch: [174][511/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 87.5	Acc@5 100.0
Epoch: [174][521/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 90.6	Acc@5 98.4
Epoch: [174][531/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [174][541/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 87.5	Acc@5 100.0
Epoch: [174][551/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 82.8	Acc@5 96.9
Epoch: [174][561/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 87.5	Acc@5 98.4
Epoch: [174][571/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 92.2	Acc@5 100.0
Epoch: [174][581/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 93.8	Acc@5 100.0
Epoch: [174][591/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 85.9	Acc@5 98.4
Epoch: [174][601/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 76.6	Acc@5 95.3
Epoch: [174][611/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 81.2	Acc@5 98.4
Epoch: [174][621/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 92.2	Acc@5 100.0
Epoch: [174][631/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 87.5	Acc@5 96.9
Epoch: [174][641/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 89.1	Acc@5 96.9
Epoch: [174][651/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 89.1	Acc@5 100.0
Epoch: [174][661/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 85.9	Acc@5 96.9
Epoch: [174][671/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 92.2	Acc@5 100.0
Epoch: [174][681/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 84.4	Acc@5 100.0
Epoch: [174][691/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 85.9	Acc@5 100.0
Epoch: [174][701/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 3.9811	Acc@1 73.4375	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.4857	Acc@1 79.6875	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.0206	Acc@1 68.7500	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.0801	Acc@1 64.0625	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.2533	Acc@1 68.7500	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8976	Acc@1 64.0625	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.4975	Acc@1 71.8750	Acc@5 96.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.8070	Acc@1 73.4375	Acc@5 87.5000
 * prec@1 57.420 prec@5 85.360
 * prec@1 63.020 prec@5 88.280
 * prec@1 66.240 prec@5 91.340
 * prec@1 68.320 prec@5 91.300
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_174.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_174.pth.tar'
Epoch: [175][1/704]	Time 0.332	Data 0.165	Loss 1.98	Acc@1 92.2	Acc@5 98.4
Epoch: [175][11/704]	Time 0.140	Data 0.015	Loss 3.19	Acc@1 84.4	Acc@5 100.0
Epoch: [175][21/704]	Time 0.130	Data 0.008	Loss 2.31	Acc@1 93.8	Acc@5 100.0
Epoch: [175][31/704]	Time 0.127	Data 0.006	Loss 2.38	Acc@1 90.6	Acc@5 100.0
Epoch: [175][41/704]	Time 0.125	Data 0.004	Loss 2.82	Acc@1 87.5	Acc@5 98.4
Epoch: [175][51/704]	Time 0.124	Data 0.004	Loss 2.06	Acc@1 92.2	Acc@5 100.0
Epoch: [175][61/704]	Time 0.124	Data 0.003	Loss 2.31	Acc@1 90.6	Acc@5 100.0
Epoch: [175][71/704]	Time 0.123	Data 0.003	Loss 2.86	Acc@1 93.8	Acc@5 98.4
Epoch: [175][81/704]	Time 0.123	Data 0.002	Loss 2.60	Acc@1 90.6	Acc@5 100.0
Epoch: [175][91/704]	Time 0.123	Data 0.002	Loss 1.96	Acc@1 90.6	Acc@5 100.0
Epoch: [175][101/704]	Time 0.122	Data 0.002	Loss 2.27	Acc@1 92.2	Acc@5 98.4
Epoch: [175][111/704]	Time 0.122	Data 0.002	Loss 2.80	Acc@1 89.1	Acc@5 98.4
Epoch: [175][121/704]	Time 0.122	Data 0.002	Loss 1.50	Acc@1 92.2	Acc@5 98.4
Epoch: [175][131/704]	Time 0.122	Data 0.002	Loss 2.31	Acc@1 89.1	Acc@5 96.9
Epoch: [175][141/704]	Time 0.122	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [175][151/704]	Time 0.122	Data 0.001	Loss 3.02	Acc@1 82.8	Acc@5 98.4
Epoch: [175][161/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [175][171/704]	Time 0.122	Data 0.001	Loss 2.28	Acc@1 92.2	Acc@5 100.0
Epoch: [175][181/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 87.5	Acc@5 100.0
Epoch: [175][191/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 90.6	Acc@5 100.0
Epoch: [175][201/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [175][211/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [175][221/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 100.0
Epoch: [175][231/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 84.4	Acc@5 95.3
Epoch: [175][241/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 92.2	Acc@5 98.4
Epoch: [175][251/704]	Time 0.121	Data 0.001	Loss 3.47	Acc@1 84.4	Acc@5 95.3
Epoch: [175][261/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 90.6	Acc@5 100.0
Epoch: [175][271/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [175][281/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 100.0
Epoch: [175][291/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 87.5	Acc@5 100.0
Epoch: [175][301/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 90.6	Acc@5 98.4
Epoch: [175][311/704]	Time 0.121	Data 0.001	Loss 3.40	Acc@1 82.8	Acc@5 96.9
Epoch: [175][321/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 90.6	Acc@5 100.0
Epoch: [175][331/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 81.2	Acc@5 98.4
Epoch: [175][341/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [175][351/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [175][361/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 87.5	Acc@5 96.9
Epoch: [175][371/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 82.8	Acc@5 98.4
Epoch: [175][381/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 92.2	Acc@5 98.4
Epoch: [175][391/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 87.5	Acc@5 100.0
Epoch: [175][401/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 89.1	Acc@5 100.0
Epoch: [175][411/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 89.1	Acc@5 98.4
Epoch: [175][421/704]	Time 0.121	Data 0.001	Loss 3.47	Acc@1 87.5	Acc@5 98.4
Epoch: [175][431/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 92.2	Acc@5 100.0
Epoch: [175][441/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 84.4	Acc@5 100.0
Epoch: [175][451/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 93.8	Acc@5 96.9
Epoch: [175][461/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 96.9	Acc@5 100.0
Epoch: [175][471/704]	Time 0.121	Data 0.001	Loss 3.19	Acc@1 81.2	Acc@5 100.0
Epoch: [175][481/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 87.5	Acc@5 100.0
Epoch: [175][491/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 90.6	Acc@5 100.0
Epoch: [175][501/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 100.0
Epoch: [175][511/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 89.1	Acc@5 98.4
Epoch: [175][521/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 89.1	Acc@5 98.4
Epoch: [175][531/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 95.3	Acc@5 100.0
Epoch: [175][541/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 87.5	Acc@5 96.9
Epoch: [175][551/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 98.4
Epoch: [175][561/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 89.1	Acc@5 100.0
Epoch: [175][571/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 87.5	Acc@5 98.4
Epoch: [175][581/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 84.4	Acc@5 100.0
Epoch: [175][591/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 87.5	Acc@5 98.4
Epoch: [175][601/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 84.4	Acc@5 100.0
Epoch: [175][611/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 96.9
Epoch: [175][621/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 84.4	Acc@5 98.4
Epoch: [175][631/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 90.6	Acc@5 98.4
Epoch: [175][641/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 89.1	Acc@5 100.0
Epoch: [175][651/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 92.2	Acc@5 98.4
Epoch: [175][661/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 98.4
Epoch: [175][671/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 85.9	Acc@5 98.4
Epoch: [175][681/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 87.5	Acc@5 98.4
Epoch: [175][691/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 85.9	Acc@5 100.0
Epoch: [175][701/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.8917	Acc@1 71.8750	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.8270	Acc@1 75.0000	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2944	Acc@1 73.4375	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.2667	Acc@1 65.6250	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6370	Acc@1 57.8125	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.2094	Acc@1 73.4375	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.5286	Acc@1 68.7500	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.1562	Acc@1 70.3125	Acc@5 92.1875
 * prec@1 57.380 prec@5 85.640
 * prec@1 63.060 prec@5 88.560
 * prec@1 66.840 prec@5 90.980
 * prec@1 68.840 prec@5 91.340
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_175.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_175.pth.tar'
Epoch: [176][1/704]	Time 0.335	Data 0.168	Loss 2.45	Acc@1 89.1	Acc@5 100.0
Epoch: [176][11/704]	Time 0.140	Data 0.015	Loss 2.63	Acc@1 89.1	Acc@5 100.0
Epoch: [176][21/704]	Time 0.131	Data 0.008	Loss 3.82	Acc@1 78.1	Acc@5 98.4
Epoch: [176][31/704]	Time 0.127	Data 0.006	Loss 1.90	Acc@1 89.1	Acc@5 100.0
Epoch: [176][41/704]	Time 0.126	Data 0.004	Loss 2.15	Acc@1 93.8	Acc@5 98.4
Epoch: [176][51/704]	Time 0.125	Data 0.004	Loss 2.50	Acc@1 82.8	Acc@5 100.0
Epoch: [176][61/704]	Time 0.124	Data 0.003	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [176][71/704]	Time 0.123	Data 0.003	Loss 2.54	Acc@1 89.1	Acc@5 98.4
Epoch: [176][81/704]	Time 0.123	Data 0.002	Loss 2.13	Acc@1 90.6	Acc@5 100.0
Epoch: [176][91/704]	Time 0.123	Data 0.002	Loss 2.65	Acc@1 89.1	Acc@5 100.0
Epoch: [176][101/704]	Time 0.123	Data 0.002	Loss 2.56	Acc@1 85.9	Acc@5 100.0
Epoch: [176][111/704]	Time 0.122	Data 0.002	Loss 2.38	Acc@1 90.6	Acc@5 100.0
Epoch: [176][121/704]	Time 0.122	Data 0.002	Loss 3.23	Acc@1 81.2	Acc@5 96.9
Epoch: [176][131/704]	Time 0.122	Data 0.002	Loss 2.84	Acc@1 90.6	Acc@5 100.0
Epoch: [176][141/704]	Time 0.122	Data 0.001	Loss 2.61	Acc@1 92.2	Acc@5 100.0
Epoch: [176][151/704]	Time 0.122	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [176][161/704]	Time 0.122	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 98.4
Epoch: [176][171/704]	Time 0.122	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [176][181/704]	Time 0.122	Data 0.001	Loss 2.62	Acc@1 85.9	Acc@5 98.4
Epoch: [176][191/704]	Time 0.122	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 98.4
Epoch: [176][201/704]	Time 0.122	Data 0.001	Loss 2.73	Acc@1 89.1	Acc@5 98.4
Epoch: [176][211/704]	Time 0.122	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [176][221/704]	Time 0.122	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [176][231/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 85.9	Acc@5 98.4
Epoch: [176][241/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 92.2	Acc@5 98.4
Epoch: [176][251/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 95.3	Acc@5 100.0
Epoch: [176][261/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [176][271/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 84.4	Acc@5 96.9
Epoch: [176][281/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 100.0
Epoch: [176][291/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 100.0
Epoch: [176][301/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 92.2	Acc@5 96.9
Epoch: [176][311/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [176][321/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 92.2	Acc@5 98.4
Epoch: [176][331/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 87.5	Acc@5 100.0
Epoch: [176][341/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 89.1	Acc@5 100.0
Epoch: [176][351/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 81.2	Acc@5 100.0
Epoch: [176][361/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 90.6	Acc@5 100.0
Epoch: [176][371/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 87.5	Acc@5 96.9
Epoch: [176][381/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 85.9	Acc@5 100.0
Epoch: [176][391/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 85.9	Acc@5 100.0
Epoch: [176][401/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 84.4	Acc@5 98.4
Epoch: [176][411/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 87.5	Acc@5 96.9
Epoch: [176][421/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 90.6	Acc@5 98.4
Epoch: [176][431/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 89.1	Acc@5 100.0
Epoch: [176][441/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 90.6	Acc@5 98.4
Epoch: [176][451/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 95.3	Acc@5 96.9
Epoch: [176][461/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 93.8	Acc@5 100.0
Epoch: [176][471/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 100.0
Epoch: [176][481/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 89.1	Acc@5 100.0
Epoch: [176][491/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 84.4	Acc@5 96.9
Epoch: [176][501/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 84.4	Acc@5 98.4
Epoch: [176][511/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 100.0
Epoch: [176][521/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [176][531/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 87.5	Acc@5 98.4
Epoch: [176][541/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 87.5	Acc@5 98.4
Epoch: [176][551/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [176][561/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 90.6	Acc@5 98.4
Epoch: [176][571/704]	Time 0.121	Data 0.001	Loss 3.58	Acc@1 84.4	Acc@5 96.9
Epoch: [176][581/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 84.4	Acc@5 100.0
Epoch: [176][591/704]	Time 0.121	Data 0.001	Loss 3.94	Acc@1 76.6	Acc@5 98.4
Epoch: [176][601/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 89.1	Acc@5 98.4
Epoch: [176][611/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [176][621/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 89.1	Acc@5 98.4
Epoch: [176][631/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 79.7	Acc@5 98.4
Epoch: [176][641/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 87.5	Acc@5 100.0
Epoch: [176][651/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 90.6	Acc@5 100.0
Epoch: [176][661/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 85.9	Acc@5 100.0
Epoch: [176][671/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 90.6	Acc@5 98.4
Epoch: [176][681/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 89.1	Acc@5 98.4
Epoch: [176][691/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 98.4
Epoch: [176][701/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.8044	Acc@1 67.1875	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.7537	Acc@1 64.0625	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7869	Acc@1 64.0625	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.6789	Acc@1 64.0625	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.5691	Acc@1 73.4375	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0190	Acc@1 70.3125	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.2834	Acc@1 71.8750	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.5934	Acc@1 78.1250	Acc@5 95.3125
 * prec@1 58.400 prec@5 85.500
 * prec@1 62.760 prec@5 88.380
 * prec@1 67.140 prec@5 91.020
 * prec@1 68.820 prec@5 91.420
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_176.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_176.pth.tar'
Epoch: [177][1/704]	Time 0.298	Data 0.131	Loss 2.26	Acc@1 92.2	Acc@5 100.0
Epoch: [177][11/704]	Time 0.137	Data 0.012	Loss 2.58	Acc@1 90.6	Acc@5 100.0
Epoch: [177][21/704]	Time 0.129	Data 0.007	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [177][31/704]	Time 0.126	Data 0.005	Loss 2.52	Acc@1 90.6	Acc@5 98.4
Epoch: [177][41/704]	Time 0.124	Data 0.004	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [177][51/704]	Time 0.124	Data 0.003	Loss 1.83	Acc@1 89.1	Acc@5 100.0
Epoch: [177][61/704]	Time 0.123	Data 0.002	Loss 2.93	Acc@1 85.9	Acc@5 98.4
Epoch: [177][71/704]	Time 0.123	Data 0.002	Loss 2.89	Acc@1 85.9	Acc@5 100.0
Epoch: [177][81/704]	Time 0.122	Data 0.002	Loss 2.59	Acc@1 84.4	Acc@5 98.4
Epoch: [177][91/704]	Time 0.122	Data 0.002	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [177][101/704]	Time 0.122	Data 0.002	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [177][111/704]	Time 0.122	Data 0.002	Loss 2.47	Acc@1 93.8	Acc@5 98.4
Epoch: [177][121/704]	Time 0.122	Data 0.001	Loss 1.79	Acc@1 90.6	Acc@5 100.0
Epoch: [177][131/704]	Time 0.122	Data 0.001	Loss 3.20	Acc@1 81.2	Acc@5 96.9
Epoch: [177][141/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [177][151/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 96.9	Acc@5 100.0
Epoch: [177][161/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [177][171/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 89.1	Acc@5 100.0
Epoch: [177][181/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 96.9	Acc@5 100.0
Epoch: [177][191/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 96.9
Epoch: [177][201/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [177][211/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [177][221/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [177][231/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [177][241/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 85.9	Acc@5 98.4
Epoch: [177][251/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 96.9
Epoch: [177][261/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 89.1	Acc@5 98.4
Epoch: [177][271/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 82.8	Acc@5 100.0
Epoch: [177][281/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 87.5	Acc@5 100.0
Epoch: [177][291/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 90.6	Acc@5 100.0
Epoch: [177][301/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 85.9	Acc@5 98.4
Epoch: [177][311/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 89.1	Acc@5 96.9
Epoch: [177][321/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 90.6	Acc@5 98.4
Epoch: [177][331/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 89.1	Acc@5 98.4
Epoch: [177][341/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 90.6	Acc@5 96.9
Epoch: [177][351/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [177][361/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 85.9	Acc@5 100.0
Epoch: [177][371/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 87.5	Acc@5 100.0
Epoch: [177][381/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 85.9	Acc@5 98.4
Epoch: [177][391/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 79.7	Acc@5 98.4
Epoch: [177][401/704]	Time 0.120	Data 0.001	Loss 3.62	Acc@1 87.5	Acc@5 96.9
Epoch: [177][411/704]	Time 0.120	Data 0.001	Loss 3.50	Acc@1 85.9	Acc@5 98.4
Epoch: [177][421/704]	Time 0.120	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 98.4
Epoch: [177][431/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 90.6	Acc@5 100.0
Epoch: [177][441/704]	Time 0.120	Data 0.001	Loss 3.20	Acc@1 82.8	Acc@5 98.4
Epoch: [177][451/704]	Time 0.120	Data 0.001	Loss 2.50	Acc@1 90.6	Acc@5 100.0
Epoch: [177][461/704]	Time 0.120	Data 0.001	Loss 2.64	Acc@1 92.2	Acc@5 100.0
Epoch: [177][471/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 98.4
Epoch: [177][481/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 90.6	Acc@5 98.4
Epoch: [177][491/704]	Time 0.120	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [177][501/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [177][511/704]	Time 0.120	Data 0.001	Loss 2.64	Acc@1 87.5	Acc@5 100.0
Epoch: [177][521/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 89.1	Acc@5 96.9
Epoch: [177][531/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 92.2	Acc@5 98.4
Epoch: [177][541/704]	Time 0.120	Data 0.001	Loss 2.73	Acc@1 81.2	Acc@5 100.0
Epoch: [177][551/704]	Time 0.120	Data 0.001	Loss 2.37	Acc@1 90.6	Acc@5 100.0
Epoch: [177][561/704]	Time 0.120	Data 0.001	Loss 2.80	Acc@1 85.9	Acc@5 100.0
Epoch: [177][571/704]	Time 0.120	Data 0.001	Loss 2.86	Acc@1 82.8	Acc@5 100.0
Epoch: [177][581/704]	Time 0.120	Data 0.001	Loss 1.99	Acc@1 87.5	Acc@5 100.0
Epoch: [177][591/704]	Time 0.120	Data 0.001	Loss 3.35	Acc@1 81.2	Acc@5 98.4
Epoch: [177][601/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 87.5	Acc@5 100.0
Epoch: [177][611/704]	Time 0.120	Data 0.001	Loss 2.92	Acc@1 84.4	Acc@5 100.0
Epoch: [177][621/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 98.4
Epoch: [177][631/704]	Time 0.120	Data 0.001	Loss 2.94	Acc@1 85.9	Acc@5 100.0
Epoch: [177][641/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 96.9
Epoch: [177][651/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 90.6	Acc@5 100.0
Epoch: [177][661/704]	Time 0.120	Data 0.001	Loss 2.33	Acc@1 90.6	Acc@5 96.9
Epoch: [177][671/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 98.4
Epoch: [177][681/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 84.4	Acc@5 98.4
Epoch: [177][691/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 100.0
Epoch: [177][701/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.4754	Acc@1 68.7500	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.0741	Acc@1 71.8750	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2632	Acc@1 65.6250	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.1876	Acc@1 68.7500	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.0088	Acc@1 68.7500	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.3797	Acc@1 73.4375	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.8512	Acc@1 62.5000	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.8498	Acc@1 73.4375	Acc@5 93.7500
 * prec@1 57.380 prec@5 85.400
 * prec@1 62.500 prec@5 88.500
 * prec@1 67.760 prec@5 91.140
 * prec@1 68.320 prec@5 91.720
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_177.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_177.pth.tar'
Epoch: [178][1/704]	Time 0.300	Data 0.132	Loss 2.27	Acc@1 93.8	Acc@5 100.0
Epoch: [178][11/704]	Time 0.141	Data 0.012	Loss 2.84	Acc@1 89.1	Acc@5 100.0
Epoch: [178][21/704]	Time 0.131	Data 0.007	Loss 2.69	Acc@1 82.8	Acc@5 100.0
Epoch: [178][31/704]	Time 0.128	Data 0.005	Loss 2.35	Acc@1 84.4	Acc@5 100.0
Epoch: [178][41/704]	Time 0.126	Data 0.004	Loss 2.37	Acc@1 93.8	Acc@5 98.4
Epoch: [178][51/704]	Time 0.125	Data 0.003	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [178][61/704]	Time 0.124	Data 0.002	Loss 2.33	Acc@1 89.1	Acc@5 98.4
Epoch: [178][71/704]	Time 0.124	Data 0.002	Loss 2.82	Acc@1 87.5	Acc@5 96.9
Epoch: [178][81/704]	Time 0.123	Data 0.002	Loss 2.45	Acc@1 87.5	Acc@5 100.0
Epoch: [178][91/704]	Time 0.123	Data 0.002	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [178][101/704]	Time 0.123	Data 0.002	Loss 3.15	Acc@1 82.8	Acc@5 96.9
Epoch: [178][111/704]	Time 0.123	Data 0.002	Loss 2.84	Acc@1 82.8	Acc@5 98.4
Epoch: [178][121/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [178][131/704]	Time 0.122	Data 0.001	Loss 2.60	Acc@1 84.4	Acc@5 98.4
Epoch: [178][141/704]	Time 0.122	Data 0.001	Loss 3.12	Acc@1 84.4	Acc@5 98.4
Epoch: [178][151/704]	Time 0.122	Data 0.001	Loss 2.07	Acc@1 87.5	Acc@5 100.0
Epoch: [178][161/704]	Time 0.122	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 100.0
Epoch: [178][171/704]	Time 0.122	Data 0.001	Loss 2.51	Acc@1 93.8	Acc@5 100.0
Epoch: [178][181/704]	Time 0.122	Data 0.001	Loss 2.42	Acc@1 89.1	Acc@5 98.4
Epoch: [178][191/704]	Time 0.122	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 96.9
Epoch: [178][201/704]	Time 0.122	Data 0.001	Loss 2.54	Acc@1 93.8	Acc@5 98.4
Epoch: [178][211/704]	Time 0.122	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 98.4
Epoch: [178][221/704]	Time 0.122	Data 0.001	Loss 2.38	Acc@1 90.6	Acc@5 98.4
Epoch: [178][231/704]	Time 0.122	Data 0.001	Loss 2.80	Acc@1 85.9	Acc@5 100.0
Epoch: [178][241/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 87.5	Acc@5 96.9
Epoch: [178][251/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 79.7	Acc@5 100.0
Epoch: [178][261/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 85.9	Acc@5 100.0
Epoch: [178][271/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 87.5	Acc@5 98.4
Epoch: [178][281/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [178][291/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [178][301/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 98.4
Epoch: [178][311/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 96.9
Epoch: [178][321/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 81.2	Acc@5 98.4
Epoch: [178][331/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 93.8	Acc@5 98.4
Epoch: [178][341/704]	Time 0.121	Data 0.001	Loss 3.40	Acc@1 82.8	Acc@5 100.0
Epoch: [178][351/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 93.8	Acc@5 100.0
Epoch: [178][361/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 87.5	Acc@5 100.0
Epoch: [178][371/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 87.5	Acc@5 100.0
Epoch: [178][381/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 90.6	Acc@5 100.0
Epoch: [178][391/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 89.1	Acc@5 100.0
Epoch: [178][401/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 92.2	Acc@5 100.0
Epoch: [178][411/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 98.4
Epoch: [178][421/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 85.9	Acc@5 98.4
Epoch: [178][431/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 89.1	Acc@5 100.0
Epoch: [178][441/704]	Time 0.121	Data 0.001	Loss 3.28	Acc@1 87.5	Acc@5 98.4
Epoch: [178][451/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 100.0
Epoch: [178][461/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 92.2	Acc@5 98.4
Epoch: [178][471/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 92.2	Acc@5 100.0
Epoch: [178][481/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 89.1	Acc@5 100.0
Epoch: [178][491/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [178][501/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 89.1	Acc@5 96.9
Epoch: [178][511/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 95.3	Acc@5 98.4
Epoch: [178][521/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 87.5	Acc@5 96.9
Epoch: [178][531/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 89.1	Acc@5 100.0
Epoch: [178][541/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 93.8	Acc@5 100.0
Epoch: [178][551/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 87.5	Acc@5 100.0
Epoch: [178][561/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 100.0
Epoch: [178][571/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 87.5	Acc@5 98.4
Epoch: [178][581/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 85.9	Acc@5 100.0
Epoch: [178][591/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 90.6	Acc@5 100.0
Epoch: [178][601/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 89.1	Acc@5 98.4
Epoch: [178][611/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 92.2	Acc@5 98.4
Epoch: [178][621/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 85.9	Acc@5 100.0
Epoch: [178][631/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [178][641/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [178][651/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 87.5	Acc@5 98.4
Epoch: [178][661/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 96.9
Epoch: [178][671/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 87.5	Acc@5 100.0
Epoch: [178][681/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [178][691/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [178][701/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 87.5	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.3927	Acc@1 71.8750	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.3462	Acc@1 70.3125	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.9431	Acc@1 67.1875	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5681	Acc@1 65.6250	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9721	Acc@1 67.1875	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.7025	Acc@1 70.3125	Acc@5 98.4375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.4157	Acc@1 76.5625	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.8855	Acc@1 70.3125	Acc@5 92.1875
 * prec@1 57.760 prec@5 84.940
 * prec@1 63.620 prec@5 87.780
 * prec@1 66.740 prec@5 90.920
 * prec@1 67.960 prec@5 91.380
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_178.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_178.pth.tar'
Epoch: [179][1/704]	Time 0.330	Data 0.163	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [179][11/704]	Time 0.140	Data 0.015	Loss 2.01	Acc@1 87.5	Acc@5 98.4
Epoch: [179][21/704]	Time 0.130	Data 0.008	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [179][31/704]	Time 0.127	Data 0.006	Loss 2.56	Acc@1 85.9	Acc@5 98.4
Epoch: [179][41/704]	Time 0.126	Data 0.004	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [179][51/704]	Time 0.124	Data 0.004	Loss 1.92	Acc@1 92.2	Acc@5 100.0
Epoch: [179][61/704]	Time 0.124	Data 0.003	Loss 2.86	Acc@1 85.9	Acc@5 100.0
Epoch: [179][71/704]	Time 0.123	Data 0.003	Loss 2.64	Acc@1 87.5	Acc@5 100.0
Epoch: [179][81/704]	Time 0.123	Data 0.002	Loss 2.38	Acc@1 85.9	Acc@5 100.0
Epoch: [179][91/704]	Time 0.123	Data 0.002	Loss 2.78	Acc@1 87.5	Acc@5 100.0
Epoch: [179][101/704]	Time 0.122	Data 0.002	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [179][111/704]	Time 0.122	Data 0.002	Loss 2.37	Acc@1 90.6	Acc@5 98.4
Epoch: [179][121/704]	Time 0.122	Data 0.002	Loss 2.53	Acc@1 90.6	Acc@5 100.0
Epoch: [179][131/704]	Time 0.122	Data 0.002	Loss 2.39	Acc@1 90.6	Acc@5 98.4
Epoch: [179][141/704]	Time 0.122	Data 0.002	Loss 1.92	Acc@1 87.5	Acc@5 100.0
Epoch: [179][151/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [179][161/704]	Time 0.122	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 98.4
Epoch: [179][171/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 92.2	Acc@5 100.0
Epoch: [179][181/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 89.1	Acc@5 100.0
Epoch: [179][191/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 90.6	Acc@5 100.0
Epoch: [179][201/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 85.9	Acc@5 98.4
Epoch: [179][211/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 85.9	Acc@5 100.0
Epoch: [179][221/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 92.2	Acc@5 96.9
Epoch: [179][231/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 93.8	Acc@5 100.0
Epoch: [179][241/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 85.9	Acc@5 98.4
Epoch: [179][251/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [179][261/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [179][271/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 89.1	Acc@5 100.0
Epoch: [179][281/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 85.9	Acc@5 100.0
Epoch: [179][291/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 84.4	Acc@5 98.4
Epoch: [179][301/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 89.1	Acc@5 98.4
Epoch: [179][311/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 93.8	Acc@5 98.4
Epoch: [179][321/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 90.6	Acc@5 100.0
Epoch: [179][331/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 89.1	Acc@5 100.0
Epoch: [179][341/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [179][351/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 85.9	Acc@5 98.4
Epoch: [179][361/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 92.2	Acc@5 96.9
Epoch: [179][371/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [179][381/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 87.5	Acc@5 98.4
Epoch: [179][391/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [179][401/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 90.6	Acc@5 98.4
Epoch: [179][411/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 89.1	Acc@5 100.0
Epoch: [179][421/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 92.2	Acc@5 98.4
Epoch: [179][431/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 90.6	Acc@5 100.0
Epoch: [179][441/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 84.4	Acc@5 96.9
Epoch: [179][451/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 100.0
Epoch: [179][461/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 89.1	Acc@5 98.4
Epoch: [179][471/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 87.5	Acc@5 100.0
Epoch: [179][481/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 90.6	Acc@5 98.4
Epoch: [179][491/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [179][501/704]	Time 0.121	Data 0.001	Loss 3.20	Acc@1 87.5	Acc@5 96.9
Epoch: [179][511/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 89.1	Acc@5 100.0
Epoch: [179][521/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 96.9	Acc@5 100.0
Epoch: [179][531/704]	Time 0.120	Data 0.001	Loss 2.93	Acc@1 82.8	Acc@5 100.0
Epoch: [179][541/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [179][551/704]	Time 0.120	Data 0.001	Loss 2.74	Acc@1 90.6	Acc@5 98.4
Epoch: [179][561/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 96.9
Epoch: [179][571/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 89.1	Acc@5 98.4
Epoch: [179][581/704]	Time 0.120	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 100.0
Epoch: [179][591/704]	Time 0.120	Data 0.001	Loss 2.89	Acc@1 85.9	Acc@5 100.0
Epoch: [179][601/704]	Time 0.120	Data 0.001	Loss 3.44	Acc@1 84.4	Acc@5 100.0
Epoch: [179][611/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [179][621/704]	Time 0.120	Data 0.001	Loss 2.76	Acc@1 90.6	Acc@5 100.0
Epoch: [179][631/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 92.2	Acc@5 100.0
Epoch: [179][641/704]	Time 0.120	Data 0.001	Loss 2.56	Acc@1 90.6	Acc@5 100.0
Epoch: [179][651/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 90.6	Acc@5 100.0
Epoch: [179][661/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 81.2	Acc@5 100.0
Epoch: [179][671/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [179][681/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 87.5	Acc@5 100.0
Epoch: [179][691/704]	Time 0.120	Data 0.001	Loss 3.04	Acc@1 85.9	Acc@5 100.0
Epoch: [179][701/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 92.2	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.9036	Acc@1 68.7500	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.5064	Acc@1 65.6250	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.1687	Acc@1 64.0625	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.0744	Acc@1 67.1875	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2750	Acc@1 65.6250	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.0005	Acc@1 68.7500	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.2243	Acc@1 64.0625	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.4898	Acc@1 78.1250	Acc@5 92.1875
 * prec@1 57.760 prec@5 85.400
 * prec@1 62.180 prec@5 88.740
 * prec@1 66.340 prec@5 90.820
 * prec@1 68.480 prec@5 91.220
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_179.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_179.pth.tar'
Epoch: [180][1/704]	Time 0.301	Data 0.132	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [180][11/704]	Time 0.137	Data 0.012	Loss 2.44	Acc@1 92.2	Acc@5 100.0
Epoch: [180][21/704]	Time 0.129	Data 0.007	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [180][31/704]	Time 0.126	Data 0.005	Loss 2.29	Acc@1 87.5	Acc@5 100.0
Epoch: [180][41/704]	Time 0.125	Data 0.004	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [180][51/704]	Time 0.124	Data 0.003	Loss 2.59	Acc@1 81.2	Acc@5 100.0
Epoch: [180][61/704]	Time 0.123	Data 0.003	Loss 2.48	Acc@1 92.2	Acc@5 100.0
Epoch: [180][71/704]	Time 0.123	Data 0.002	Loss 2.64	Acc@1 92.2	Acc@5 100.0
Epoch: [180][81/704]	Time 0.123	Data 0.002	Loss 2.38	Acc@1 92.2	Acc@5 100.0
Epoch: [180][91/704]	Time 0.122	Data 0.002	Loss 2.80	Acc@1 87.5	Acc@5 100.0
Epoch: [180][101/704]	Time 0.122	Data 0.002	Loss 2.21	Acc@1 87.5	Acc@5 98.4
Epoch: [180][111/704]	Time 0.122	Data 0.002	Loss 2.66	Acc@1 85.9	Acc@5 96.9
Epoch: [180][121/704]	Time 0.122	Data 0.001	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [180][131/704]	Time 0.122	Data 0.001	Loss 2.57	Acc@1 92.2	Acc@5 100.0
Epoch: [180][141/704]	Time 0.122	Data 0.001	Loss 2.47	Acc@1 96.9	Acc@5 98.4
Epoch: [180][151/704]	Time 0.122	Data 0.001	Loss 2.74	Acc@1 89.1	Acc@5 98.4
Epoch: [180][161/704]	Time 0.122	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [180][171/704]	Time 0.122	Data 0.001	Loss 2.42	Acc@1 81.2	Acc@5 100.0
Epoch: [180][181/704]	Time 0.122	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [180][191/704]	Time 0.122	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 98.4
Epoch: [180][201/704]	Time 0.122	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [180][211/704]	Time 0.122	Data 0.001	Loss 2.97	Acc@1 82.8	Acc@5 100.0
Epoch: [180][221/704]	Time 0.122	Data 0.001	Loss 2.01	Acc@1 89.1	Acc@5 100.0
Epoch: [180][231/704]	Time 0.122	Data 0.001	Loss 2.32	Acc@1 87.5	Acc@5 100.0
Epoch: [180][241/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [180][251/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 87.5	Acc@5 100.0
Epoch: [180][261/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 84.4	Acc@5 98.4
Epoch: [180][271/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 89.1	Acc@5 100.0
Epoch: [180][281/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 89.1	Acc@5 98.4
Epoch: [180][291/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 87.5	Acc@5 100.0
Epoch: [180][301/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 90.6	Acc@5 98.4
Epoch: [180][311/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 92.2	Acc@5 100.0
Epoch: [180][321/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 95.3	Acc@5 100.0
Epoch: [180][331/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 87.5	Acc@5 98.4
Epoch: [180][341/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 92.2	Acc@5 100.0
Epoch: [180][351/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 98.4
Epoch: [180][361/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 98.4	Acc@5 100.0
Epoch: [180][371/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 96.9
Epoch: [180][381/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [180][391/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 98.4
Epoch: [180][401/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 92.2	Acc@5 100.0
Epoch: [180][411/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 98.4
Epoch: [180][421/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 87.5	Acc@5 100.0
Epoch: [180][431/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 85.9	Acc@5 100.0
Epoch: [180][441/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 96.9	Acc@5 100.0
Epoch: [180][451/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 92.2	Acc@5 100.0
Epoch: [180][461/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 79.7	Acc@5 98.4
Epoch: [180][471/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 90.6	Acc@5 100.0
Epoch: [180][481/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 90.6	Acc@5 100.0
Epoch: [180][491/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 87.5	Acc@5 100.0
Epoch: [180][501/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 95.3	Acc@5 100.0
Epoch: [180][511/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [180][521/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 90.6	Acc@5 98.4
Epoch: [180][531/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 87.5	Acc@5 96.9
Epoch: [180][541/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 82.8	Acc@5 100.0
Epoch: [180][551/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [180][561/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [180][571/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 92.2	Acc@5 98.4
Epoch: [180][581/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 100.0
Epoch: [180][591/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 92.2	Acc@5 98.4
Epoch: [180][601/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 90.6	Acc@5 100.0
Epoch: [180][611/704]	Time 0.121	Data 0.001	Loss 3.78	Acc@1 81.2	Acc@5 98.4
Epoch: [180][621/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 87.5	Acc@5 100.0
Epoch: [180][631/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 90.6	Acc@5 100.0
Epoch: [180][641/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 90.6	Acc@5 98.4
Epoch: [180][651/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 92.2	Acc@5 100.0
Epoch: [180][661/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [180][671/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 87.5	Acc@5 100.0
Epoch: [180][681/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 82.8	Acc@5 100.0
Epoch: [180][691/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 90.6	Acc@5 100.0
Epoch: [180][701/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 87.5	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 4.0983	Acc@1 71.8750	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 4.5965	Acc@1 67.1875	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.1919	Acc@1 60.9375	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3416	Acc@1 59.3750	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9186	Acc@1 54.6875	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.2474	Acc@1 68.7500	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.3119	Acc@1 78.1250	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.5846	Acc@1 67.1875	Acc@5 96.8750
 * prec@1 58.660 prec@5 85.300
 * prec@1 62.760 prec@5 88.320
 * prec@1 66.580 prec@5 91.160
 * prec@1 68.160 prec@5 91.880
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_180.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_180.pth.tar'
Epoch: [181][1/704]	Time 0.298	Data 0.131	Loss 2.25	Acc@1 95.3	Acc@5 100.0
Epoch: [181][11/704]	Time 0.136	Data 0.012	Loss 2.54	Acc@1 90.6	Acc@5 100.0
Epoch: [181][21/704]	Time 0.129	Data 0.007	Loss 2.73	Acc@1 87.5	Acc@5 100.0
Epoch: [181][31/704]	Time 0.126	Data 0.005	Loss 1.99	Acc@1 90.6	Acc@5 100.0
Epoch: [181][41/704]	Time 0.124	Data 0.004	Loss 2.36	Acc@1 95.3	Acc@5 100.0
Epoch: [181][51/704]	Time 0.123	Data 0.003	Loss 2.75	Acc@1 82.8	Acc@5 100.0
Epoch: [181][61/704]	Time 0.123	Data 0.002	Loss 2.14	Acc@1 93.8	Acc@5 100.0
Epoch: [181][71/704]	Time 0.123	Data 0.002	Loss 2.25	Acc@1 93.8	Acc@5 100.0
Epoch: [181][81/704]	Time 0.123	Data 0.002	Loss 2.10	Acc@1 87.5	Acc@5 100.0
Epoch: [181][91/704]	Time 0.122	Data 0.002	Loss 2.72	Acc@1 85.9	Acc@5 96.9
Epoch: [181][101/704]	Time 0.122	Data 0.002	Loss 2.19	Acc@1 87.5	Acc@5 98.4
Epoch: [181][111/704]	Time 0.122	Data 0.002	Loss 1.68	Acc@1 92.2	Acc@5 100.0
Epoch: [181][121/704]	Time 0.122	Data 0.001	Loss 3.12	Acc@1 93.8	Acc@5 100.0
Epoch: [181][131/704]	Time 0.122	Data 0.001	Loss 2.73	Acc@1 90.6	Acc@5 100.0
Epoch: [181][141/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [181][151/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 87.5	Acc@5 100.0
Epoch: [181][161/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 100.0
Epoch: [181][171/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 92.2	Acc@5 100.0
Epoch: [181][181/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 92.2	Acc@5 98.4
Epoch: [181][191/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [181][201/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 84.4	Acc@5 98.4
Epoch: [181][211/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 98.4
Epoch: [181][221/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 98.4
Epoch: [181][231/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 87.5	Acc@5 98.4
Epoch: [181][241/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 87.5	Acc@5 100.0
Epoch: [181][251/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [181][261/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 100.0
Epoch: [181][271/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 93.8	Acc@5 100.0
Epoch: [181][281/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 79.7	Acc@5 100.0
Epoch: [181][291/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 85.9	Acc@5 100.0
Epoch: [181][301/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 89.1	Acc@5 98.4
Epoch: [181][311/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 87.5	Acc@5 100.0
Epoch: [181][321/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 98.4
Epoch: [181][331/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 87.5	Acc@5 98.4
Epoch: [181][341/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 100.0
Epoch: [181][351/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 87.5	Acc@5 100.0
Epoch: [181][361/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 87.5	Acc@5 100.0
Epoch: [181][371/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 89.1	Acc@5 100.0
Epoch: [181][381/704]	Time 0.120	Data 0.001	Loss 3.17	Acc@1 85.9	Acc@5 98.4
Epoch: [181][391/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 89.1	Acc@5 98.4
Epoch: [181][401/704]	Time 0.120	Data 0.001	Loss 2.73	Acc@1 87.5	Acc@5 95.3
Epoch: [181][411/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [181][421/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 85.9	Acc@5 98.4
Epoch: [181][431/704]	Time 0.120	Data 0.001	Loss 2.76	Acc@1 87.5	Acc@5 100.0
Epoch: [181][441/704]	Time 0.120	Data 0.001	Loss 2.78	Acc@1 87.5	Acc@5 100.0
Epoch: [181][451/704]	Time 0.120	Data 0.001	Loss 3.11	Acc@1 89.1	Acc@5 98.4
Epoch: [181][461/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [181][471/704]	Time 0.120	Data 0.001	Loss 2.14	Acc@1 93.8	Acc@5 100.0
Epoch: [181][481/704]	Time 0.120	Data 0.001	Loss 2.25	Acc@1 89.1	Acc@5 100.0
Epoch: [181][491/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 93.8	Acc@5 96.9
Epoch: [181][501/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 87.5	Acc@5 98.4
Epoch: [181][511/704]	Time 0.120	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [181][521/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 89.1	Acc@5 100.0
Epoch: [181][531/704]	Time 0.120	Data 0.001	Loss 3.06	Acc@1 85.9	Acc@5 100.0
Epoch: [181][541/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 98.4
Epoch: [181][551/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 100.0
Epoch: [181][561/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 90.6	Acc@5 96.9
Epoch: [181][571/704]	Time 0.120	Data 0.001	Loss 2.28	Acc@1 89.1	Acc@5 100.0
Epoch: [181][581/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 90.6	Acc@5 100.0
Epoch: [181][591/704]	Time 0.120	Data 0.001	Loss 2.61	Acc@1 87.5	Acc@5 100.0
Epoch: [181][601/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 84.4	Acc@5 100.0
Epoch: [181][611/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [181][621/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 89.1	Acc@5 100.0
Epoch: [181][631/704]	Time 0.120	Data 0.001	Loss 3.25	Acc@1 92.2	Acc@5 98.4
Epoch: [181][641/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 89.1	Acc@5 98.4
Epoch: [181][651/704]	Time 0.120	Data 0.001	Loss 2.89	Acc@1 90.6	Acc@5 100.0
Epoch: [181][661/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 90.6	Acc@5 98.4
Epoch: [181][671/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 93.8	Acc@5 100.0
Epoch: [181][681/704]	Time 0.120	Data 0.001	Loss 2.88	Acc@1 84.4	Acc@5 98.4
Epoch: [181][691/704]	Time 0.120	Data 0.001	Loss 2.77	Acc@1 85.9	Acc@5 100.0
Epoch: [181][701/704]	Time 0.120	Data 0.001	Loss 2.96	Acc@1 85.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.6557	Acc@1 59.3750	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 4.8902	Acc@1 68.7500	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.7281	Acc@1 73.4375	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 3.8730	Acc@1 81.2500	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.5065	Acc@1 70.3125	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.0449	Acc@1 64.0625	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.8350	Acc@1 65.6250	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.9707	Acc@1 75.0000	Acc@5 92.1875
 * prec@1 57.940 prec@5 85.240
 * prec@1 62.380 prec@5 88.680
 * prec@1 66.840 prec@5 90.880
 * prec@1 68.600 prec@5 91.520
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_181.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_181.pth.tar'
Epoch: [182][1/704]	Time 0.334	Data 0.166	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [182][11/704]	Time 0.141	Data 0.016	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [182][21/704]	Time 0.131	Data 0.008	Loss 2.92	Acc@1 90.6	Acc@5 98.4
Epoch: [182][31/704]	Time 0.128	Data 0.006	Loss 2.39	Acc@1 89.1	Acc@5 96.9
Epoch: [182][41/704]	Time 0.126	Data 0.004	Loss 2.60	Acc@1 87.5	Acc@5 100.0
Epoch: [182][51/704]	Time 0.125	Data 0.004	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [182][61/704]	Time 0.125	Data 0.003	Loss 2.56	Acc@1 84.4	Acc@5 100.0
Epoch: [182][71/704]	Time 0.124	Data 0.003	Loss 1.96	Acc@1 87.5	Acc@5 98.4
Epoch: [182][81/704]	Time 0.124	Data 0.002	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [182][91/704]	Time 0.123	Data 0.002	Loss 2.62	Acc@1 87.5	Acc@5 98.4
Epoch: [182][101/704]	Time 0.123	Data 0.002	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [182][111/704]	Time 0.123	Data 0.002	Loss 1.46	Acc@1 93.8	Acc@5 100.0
Epoch: [182][121/704]	Time 0.123	Data 0.002	Loss 2.61	Acc@1 90.6	Acc@5 100.0
Epoch: [182][131/704]	Time 0.123	Data 0.002	Loss 2.54	Acc@1 89.1	Acc@5 98.4
Epoch: [182][141/704]	Time 0.122	Data 0.002	Loss 2.44	Acc@1 89.1	Acc@5 100.0
Epoch: [182][151/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 92.2	Acc@5 100.0
Epoch: [182][161/704]	Time 0.122	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [182][171/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 85.9	Acc@5 100.0
Epoch: [182][181/704]	Time 0.122	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [182][191/704]	Time 0.122	Data 0.001	Loss 2.75	Acc@1 82.8	Acc@5 96.9
Epoch: [182][201/704]	Time 0.122	Data 0.001	Loss 2.03	Acc@1 96.9	Acc@5 100.0
Epoch: [182][211/704]	Time 0.122	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [182][221/704]	Time 0.122	Data 0.001	Loss 3.39	Acc@1 89.1	Acc@5 96.9
Epoch: [182][231/704]	Time 0.122	Data 0.001	Loss 2.15	Acc@1 89.1	Acc@5 98.4
Epoch: [182][241/704]	Time 0.122	Data 0.001	Loss 2.77	Acc@1 85.9	Acc@5 100.0
Epoch: [182][251/704]	Time 0.122	Data 0.001	Loss 2.40	Acc@1 90.6	Acc@5 100.0
Epoch: [182][261/704]	Time 0.122	Data 0.001	Loss 2.08	Acc@1 87.5	Acc@5 98.4
Epoch: [182][271/704]	Time 0.122	Data 0.001	Loss 3.67	Acc@1 84.4	Acc@5 100.0
Epoch: [182][281/704]	Time 0.122	Data 0.001	Loss 2.34	Acc@1 90.6	Acc@5 100.0
Epoch: [182][291/704]	Time 0.122	Data 0.001	Loss 2.17	Acc@1 85.9	Acc@5 100.0
Epoch: [182][301/704]	Time 0.122	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 100.0
Epoch: [182][311/704]	Time 0.122	Data 0.001	Loss 2.97	Acc@1 84.4	Acc@5 95.3
Epoch: [182][321/704]	Time 0.122	Data 0.001	Loss 2.86	Acc@1 93.8	Acc@5 100.0
Epoch: [182][331/704]	Time 0.122	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 98.4
Epoch: [182][341/704]	Time 0.122	Data 0.001	Loss 2.08	Acc@1 89.1	Acc@5 98.4
Epoch: [182][351/704]	Time 0.122	Data 0.001	Loss 2.40	Acc@1 85.9	Acc@5 100.0
Epoch: [182][361/704]	Time 0.122	Data 0.001	Loss 2.65	Acc@1 92.2	Acc@5 98.4
Epoch: [182][371/704]	Time 0.122	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 98.4
Epoch: [182][381/704]	Time 0.122	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [182][391/704]	Time 0.122	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 100.0
Epoch: [182][401/704]	Time 0.122	Data 0.001	Loss 2.12	Acc@1 87.5	Acc@5 100.0
Epoch: [182][411/704]	Time 0.122	Data 0.001	Loss 2.74	Acc@1 85.9	Acc@5 100.0
Epoch: [182][421/704]	Time 0.122	Data 0.001	Loss 1.94	Acc@1 87.5	Acc@5 100.0
Epoch: [182][431/704]	Time 0.122	Data 0.001	Loss 2.67	Acc@1 82.8	Acc@5 98.4
Epoch: [182][441/704]	Time 0.122	Data 0.001	Loss 2.82	Acc@1 92.2	Acc@5 100.0
Epoch: [182][451/704]	Time 0.122	Data 0.001	Loss 3.04	Acc@1 84.4	Acc@5 98.4
Epoch: [182][461/704]	Time 0.122	Data 0.001	Loss 2.37	Acc@1 90.6	Acc@5 100.0
Epoch: [182][471/704]	Time 0.122	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 100.0
Epoch: [182][481/704]	Time 0.122	Data 0.001	Loss 2.93	Acc@1 89.1	Acc@5 96.9
Epoch: [182][491/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [182][501/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 82.8	Acc@5 96.9
Epoch: [182][511/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 90.6	Acc@5 100.0
Epoch: [182][521/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [182][531/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 92.2	Acc@5 100.0
Epoch: [182][541/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 84.4	Acc@5 100.0
Epoch: [182][551/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 89.1	Acc@5 100.0
Epoch: [182][561/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 89.1	Acc@5 100.0
Epoch: [182][571/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 90.6	Acc@5 100.0
Epoch: [182][581/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 95.3	Acc@5 100.0
Epoch: [182][591/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 98.4
Epoch: [182][601/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 82.8	Acc@5 100.0
Epoch: [182][611/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [182][621/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 89.1	Acc@5 100.0
Epoch: [182][631/704]	Time 0.121	Data 0.001	Loss 3.35	Acc@1 81.2	Acc@5 96.9
Epoch: [182][641/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 89.1	Acc@5 100.0
Epoch: [182][651/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 93.8	Acc@5 100.0
Epoch: [182][661/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 100.0
Epoch: [182][671/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 81.2	Acc@5 98.4
Epoch: [182][681/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 89.1	Acc@5 100.0
Epoch: [182][691/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 87.5	Acc@5 100.0
Epoch: [182][701/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 87.5	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.0125	Acc@1 78.1250	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.4437	Acc@1 76.5625	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5506	Acc@1 68.7500	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.0725	Acc@1 67.1875	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4580	Acc@1 60.9375	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.9603	Acc@1 73.4375	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5075	Acc@1 67.1875	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.6011	Acc@1 76.5625	Acc@5 96.8750
 * prec@1 57.940 prec@5 84.840
 * prec@1 62.060 prec@5 88.720
 * prec@1 67.340 prec@5 91.060
 * prec@1 69.480 prec@5 91.320
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_182.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_182.pth.tar'
Epoch: [183][1/704]	Time 0.333	Data 0.167	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [183][11/704]	Time 0.140	Data 0.016	Loss 2.00	Acc@1 95.3	Acc@5 100.0
Epoch: [183][21/704]	Time 0.131	Data 0.008	Loss 2.65	Acc@1 90.6	Acc@5 100.0
Epoch: [183][31/704]	Time 0.127	Data 0.006	Loss 2.23	Acc@1 92.2	Acc@5 100.0
Epoch: [183][41/704]	Time 0.126	Data 0.004	Loss 2.41	Acc@1 85.9	Acc@5 100.0
Epoch: [183][51/704]	Time 0.125	Data 0.004	Loss 2.68	Acc@1 89.1	Acc@5 98.4
Epoch: [183][61/704]	Time 0.124	Data 0.003	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [183][71/704]	Time 0.123	Data 0.003	Loss 2.37	Acc@1 89.1	Acc@5 100.0
Epoch: [183][81/704]	Time 0.123	Data 0.002	Loss 2.36	Acc@1 89.1	Acc@5 100.0
Epoch: [183][91/704]	Time 0.123	Data 0.002	Loss 2.52	Acc@1 90.6	Acc@5 98.4
Epoch: [183][101/704]	Time 0.122	Data 0.002	Loss 1.62	Acc@1 93.8	Acc@5 100.0
Epoch: [183][111/704]	Time 0.122	Data 0.002	Loss 2.39	Acc@1 93.8	Acc@5 100.0
Epoch: [183][121/704]	Time 0.122	Data 0.002	Loss 2.71	Acc@1 84.4	Acc@5 98.4
Epoch: [183][131/704]	Time 0.122	Data 0.002	Loss 1.77	Acc@1 90.6	Acc@5 96.9
Epoch: [183][141/704]	Time 0.122	Data 0.002	Loss 2.38	Acc@1 90.6	Acc@5 98.4
Epoch: [183][151/704]	Time 0.122	Data 0.001	Loss 2.05	Acc@1 87.5	Acc@5 100.0
Epoch: [183][161/704]	Time 0.122	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [183][171/704]	Time 0.122	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [183][181/704]	Time 0.122	Data 0.001	Loss 1.77	Acc@1 90.6	Acc@5 100.0
Epoch: [183][191/704]	Time 0.122	Data 0.001	Loss 2.35	Acc@1 85.9	Acc@5 100.0
Epoch: [183][201/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 90.6	Acc@5 100.0
Epoch: [183][211/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 90.6	Acc@5 100.0
Epoch: [183][221/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 98.4
Epoch: [183][231/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 92.2	Acc@5 100.0
Epoch: [183][241/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 84.4	Acc@5 100.0
Epoch: [183][251/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [183][261/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [183][271/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 85.9	Acc@5 100.0
Epoch: [183][281/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 89.1	Acc@5 98.4
Epoch: [183][291/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 92.2	Acc@5 100.0
Epoch: [183][301/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 95.3
Epoch: [183][311/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 90.6	Acc@5 100.0
Epoch: [183][321/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 100.0
Epoch: [183][331/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 98.4
Epoch: [183][341/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 84.4	Acc@5 100.0
Epoch: [183][351/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 85.9	Acc@5 100.0
Epoch: [183][361/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 92.2	Acc@5 100.0
Epoch: [183][371/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 100.0
Epoch: [183][381/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 79.7	Acc@5 100.0
Epoch: [183][391/704]	Time 0.121	Data 0.001	Loss 3.55	Acc@1 76.6	Acc@5 98.4
Epoch: [183][401/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 87.5	Acc@5 96.9
Epoch: [183][411/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 92.2	Acc@5 98.4
Epoch: [183][421/704]	Time 0.121	Data 0.001	Loss 3.72	Acc@1 79.7	Acc@5 96.9
Epoch: [183][431/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 85.9	Acc@5 100.0
Epoch: [183][441/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 84.4	Acc@5 100.0
Epoch: [183][451/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 92.2	Acc@5 98.4
Epoch: [183][461/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 84.4	Acc@5 98.4
Epoch: [183][471/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [183][481/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 100.0
Epoch: [183][491/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 89.1	Acc@5 100.0
Epoch: [183][501/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 87.5	Acc@5 96.9
Epoch: [183][511/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 89.1	Acc@5 100.0
Epoch: [183][521/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [183][531/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 87.5	Acc@5 100.0
Epoch: [183][541/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 90.6	Acc@5 100.0
Epoch: [183][551/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 89.1	Acc@5 98.4
Epoch: [183][561/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [183][571/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 95.3	Acc@5 100.0
Epoch: [183][581/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 85.9	Acc@5 100.0
Epoch: [183][591/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 84.4	Acc@5 100.0
Epoch: [183][601/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 87.5	Acc@5 98.4
Epoch: [183][611/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 82.8	Acc@5 98.4
Epoch: [183][621/704]	Time 0.121	Data 0.001	Loss 3.17	Acc@1 95.3	Acc@5 100.0
Epoch: [183][631/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 98.4
Epoch: [183][641/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [183][651/704]	Time 0.121	Data 0.001	Loss 3.00	Acc@1 89.1	Acc@5 100.0
Epoch: [183][661/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 89.1	Acc@5 100.0
Epoch: [183][671/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [183][681/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 87.5	Acc@5 98.4
Epoch: [183][691/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 89.1	Acc@5 100.0
Epoch: [183][701/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 92.2	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 3.3161	Acc@1 75.0000	Acc@5 96.8750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.6614	Acc@1 62.5000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0995	Acc@1 59.3750	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3304	Acc@1 65.6250	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 3.9714	Acc@1 71.8750	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.1444	Acc@1 71.8750	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.1874	Acc@1 71.8750	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.0646	Acc@1 62.5000	Acc@5 87.5000
 * prec@1 58.620 prec@5 84.920
 * prec@1 62.720 prec@5 87.660
 * prec@1 66.720 prec@5 90.840
 * prec@1 67.720 prec@5 91.000
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_183.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_183.pth.tar'
Epoch: [184][1/704]	Time 0.299	Data 0.132	Loss 2.13	Acc@1 95.3	Acc@5 100.0
Epoch: [184][11/704]	Time 0.137	Data 0.012	Loss 2.96	Acc@1 79.7	Acc@5 98.4
Epoch: [184][21/704]	Time 0.129	Data 0.007	Loss 1.96	Acc@1 95.3	Acc@5 98.4
Epoch: [184][31/704]	Time 0.126	Data 0.005	Loss 3.23	Acc@1 85.9	Acc@5 98.4
Epoch: [184][41/704]	Time 0.125	Data 0.004	Loss 2.12	Acc@1 89.1	Acc@5 100.0
Epoch: [184][51/704]	Time 0.124	Data 0.003	Loss 2.72	Acc@1 89.1	Acc@5 98.4
Epoch: [184][61/704]	Time 0.123	Data 0.003	Loss 2.04	Acc@1 93.8	Acc@5 96.9
Epoch: [184][71/704]	Time 0.123	Data 0.002	Loss 2.83	Acc@1 85.9	Acc@5 98.4
Epoch: [184][81/704]	Time 0.123	Data 0.002	Loss 2.08	Acc@1 90.6	Acc@5 100.0
Epoch: [184][91/704]	Time 0.123	Data 0.002	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [184][101/704]	Time 0.123	Data 0.002	Loss 1.95	Acc@1 89.1	Acc@5 100.0
Epoch: [184][111/704]	Time 0.122	Data 0.002	Loss 2.03	Acc@1 89.1	Acc@5 100.0
Epoch: [184][121/704]	Time 0.122	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [184][131/704]	Time 0.122	Data 0.001	Loss 2.09	Acc@1 85.9	Acc@5 98.4
Epoch: [184][141/704]	Time 0.122	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 98.4
Epoch: [184][151/704]	Time 0.122	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [184][161/704]	Time 0.122	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [184][171/704]	Time 0.122	Data 0.001	Loss 2.49	Acc@1 87.5	Acc@5 98.4
Epoch: [184][181/704]	Time 0.122	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [184][191/704]	Time 0.122	Data 0.001	Loss 2.43	Acc@1 89.1	Acc@5 98.4
Epoch: [184][201/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 82.8	Acc@5 100.0
Epoch: [184][211/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [184][221/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 89.1	Acc@5 98.4
Epoch: [184][231/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 90.6	Acc@5 100.0
Epoch: [184][241/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 89.1	Acc@5 100.0
Epoch: [184][251/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 89.1	Acc@5 100.0
Epoch: [184][261/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 100.0
Epoch: [184][271/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 93.8	Acc@5 100.0
Epoch: [184][281/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 93.8	Acc@5 100.0
Epoch: [184][291/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 89.1	Acc@5 96.9
Epoch: [184][301/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 85.9	Acc@5 100.0
Epoch: [184][311/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [184][321/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 90.6	Acc@5 100.0
Epoch: [184][331/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 89.1	Acc@5 100.0
Epoch: [184][341/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 87.5	Acc@5 100.0
Epoch: [184][351/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 98.4
Epoch: [184][361/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 87.5	Acc@5 100.0
Epoch: [184][371/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 82.8	Acc@5 96.9
Epoch: [184][381/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 87.5	Acc@5 98.4
Epoch: [184][391/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 89.1	Acc@5 100.0
Epoch: [184][401/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [184][411/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [184][421/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 93.8	Acc@5 98.4
Epoch: [184][431/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 87.5	Acc@5 100.0
Epoch: [184][441/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [184][451/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 90.6	Acc@5 96.9
Epoch: [184][461/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 98.4
Epoch: [184][471/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [184][481/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 90.6	Acc@5 100.0
Epoch: [184][491/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 92.2	Acc@5 98.4
Epoch: [184][501/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 85.9	Acc@5 98.4
Epoch: [184][511/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 98.4
Epoch: [184][521/704]	Time 0.121	Data 0.001	Loss 2.99	Acc@1 87.5	Acc@5 98.4
Epoch: [184][531/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 100.0
Epoch: [184][541/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 85.9	Acc@5 100.0
Epoch: [184][551/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 87.5	Acc@5 100.0
Epoch: [184][561/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 76.6	Acc@5 98.4
Epoch: [184][571/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 89.1	Acc@5 98.4
Epoch: [184][581/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [184][591/704]	Time 0.121	Data 0.001	Loss 3.19	Acc@1 87.5	Acc@5 100.0
Epoch: [184][601/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 95.3	Acc@5 100.0
Epoch: [184][611/704]	Time 0.121	Data 0.001	Loss 3.37	Acc@1 85.9	Acc@5 95.3
Epoch: [184][621/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 98.4
Epoch: [184][631/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 90.6	Acc@5 98.4
Epoch: [184][641/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 89.1	Acc@5 100.0
Epoch: [184][651/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 89.1	Acc@5 98.4
Epoch: [184][661/704]	Time 0.121	Data 0.001	Loss 3.54	Acc@1 81.2	Acc@5 96.9
Epoch: [184][671/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 98.4
Epoch: [184][681/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 96.9
Epoch: [184][691/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 84.4	Acc@5 98.4
Epoch: [184][701/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.105	Data 0.089	Loss 5.5406	Acc@1 75.0000	Acc@5 92.1875
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 5.4526	Acc@1 68.7500	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.5523	Acc@1 75.0000	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.0520	Acc@1 64.0625	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.1840	Acc@1 60.9375	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0353	Acc@1 67.1875	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 3.1998	Acc@1 85.9375	Acc@5 96.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.2295	Acc@1 56.2500	Acc@5 87.5000
 * prec@1 57.940 prec@5 85.180
 * prec@1 62.600 prec@5 88.200
 * prec@1 66.740 prec@5 90.920
 * prec@1 68.000 prec@5 90.880
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_184.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_184.pth.tar'
Epoch: [185][1/704]	Time 0.306	Data 0.136	Loss 2.15	Acc@1 84.4	Acc@5 100.0
Epoch: [185][11/704]	Time 0.142	Data 0.013	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [185][21/704]	Time 0.132	Data 0.007	Loss 2.76	Acc@1 87.5	Acc@5 100.0
Epoch: [185][31/704]	Time 0.128	Data 0.005	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [185][41/704]	Time 0.126	Data 0.004	Loss 2.06	Acc@1 92.2	Acc@5 100.0
Epoch: [185][51/704]	Time 0.125	Data 0.003	Loss 2.72	Acc@1 89.1	Acc@5 100.0
Epoch: [185][61/704]	Time 0.125	Data 0.003	Loss 2.73	Acc@1 90.6	Acc@5 98.4
Epoch: [185][71/704]	Time 0.124	Data 0.002	Loss 2.00	Acc@1 89.1	Acc@5 100.0
Epoch: [185][81/704]	Time 0.124	Data 0.002	Loss 2.08	Acc@1 89.1	Acc@5 100.0
Epoch: [185][91/704]	Time 0.123	Data 0.002	Loss 2.10	Acc@1 85.9	Acc@5 98.4
Epoch: [185][101/704]	Time 0.123	Data 0.002	Loss 2.73	Acc@1 85.9	Acc@5 98.4
Epoch: [185][111/704]	Time 0.123	Data 0.002	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [185][121/704]	Time 0.122	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 98.4
Epoch: [185][131/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 85.9	Acc@5 100.0
Epoch: [185][141/704]	Time 0.122	Data 0.001	Loss 2.81	Acc@1 82.8	Acc@5 100.0
Epoch: [185][151/704]	Time 0.122	Data 0.001	Loss 2.81	Acc@1 84.4	Acc@5 98.4
Epoch: [185][161/704]	Time 0.122	Data 0.001	Loss 3.20	Acc@1 81.2	Acc@5 98.4
Epoch: [185][171/704]	Time 0.122	Data 0.001	Loss 2.60	Acc@1 85.9	Acc@5 100.0
Epoch: [185][181/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [185][191/704]	Time 0.122	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [185][201/704]	Time 0.122	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 98.4
Epoch: [185][211/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [185][221/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 87.5	Acc@5 100.0
Epoch: [185][231/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [185][241/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 90.6	Acc@5 100.0
Epoch: [185][251/704]	Time 0.121	Data 0.001	Loss 3.76	Acc@1 79.7	Acc@5 100.0
Epoch: [185][261/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 90.6	Acc@5 98.4
Epoch: [185][271/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 100.0
Epoch: [185][281/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 90.6	Acc@5 98.4
Epoch: [185][291/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 82.8	Acc@5 100.0
Epoch: [185][301/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 85.9	Acc@5 100.0
Epoch: [185][311/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 98.4
Epoch: [185][321/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 89.1	Acc@5 100.0
Epoch: [185][331/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [185][341/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 93.8	Acc@5 100.0
Epoch: [185][351/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 89.1	Acc@5 100.0
Epoch: [185][361/704]	Time 0.121	Data 0.001	Loss 3.84	Acc@1 85.9	Acc@5 100.0
Epoch: [185][371/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 84.4	Acc@5 100.0
Epoch: [185][381/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [185][391/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 85.9	Acc@5 96.9
Epoch: [185][401/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 95.3	Acc@5 100.0
Epoch: [185][411/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [185][421/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 87.5	Acc@5 100.0
Epoch: [185][431/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 87.5	Acc@5 100.0
Epoch: [185][441/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 90.6	Acc@5 100.0
Epoch: [185][451/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 92.2	Acc@5 100.0
Epoch: [185][461/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 87.5	Acc@5 98.4
Epoch: [185][471/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 96.9	Acc@5 98.4
Epoch: [185][481/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 90.6	Acc@5 98.4
Epoch: [185][491/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 89.1	Acc@5 100.0
Epoch: [185][501/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 90.6	Acc@5 100.0
Epoch: [185][511/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 89.1	Acc@5 96.9
Epoch: [185][521/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [185][531/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 82.8	Acc@5 100.0
Epoch: [185][541/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 98.4
Epoch: [185][551/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 82.8	Acc@5 100.0
Epoch: [185][561/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 87.5	Acc@5 100.0
Epoch: [185][571/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 100.0
Epoch: [185][581/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [185][591/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 89.1	Acc@5 96.9
Epoch: [185][601/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 85.9	Acc@5 100.0
Epoch: [185][611/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 85.9	Acc@5 98.4
Epoch: [185][621/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 90.6	Acc@5 100.0
Epoch: [185][631/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 85.9	Acc@5 100.0
Epoch: [185][641/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 85.9	Acc@5 98.4
Epoch: [185][651/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 87.5	Acc@5 100.0
Epoch: [185][661/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 89.1	Acc@5 98.4
Epoch: [185][671/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 87.5	Acc@5 96.9
Epoch: [185][681/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [185][691/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 89.1	Acc@5 100.0
Epoch: [185][701/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 92.2	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.8190	Acc@1 67.1875	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.5921	Acc@1 65.6250	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2595	Acc@1 68.7500	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.9431	Acc@1 70.3125	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.3766	Acc@1 75.0000	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.5188	Acc@1 65.6250	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5285	Acc@1 70.3125	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.8407	Acc@1 67.1875	Acc@5 90.6250
 * prec@1 56.540 prec@5 84.960
 * prec@1 62.580 prec@5 88.940
 * prec@1 67.480 prec@5 90.760
 * prec@1 67.800 prec@5 91.400
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_185.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_185.pth.tar'
Epoch: [186][1/704]	Time 0.329	Data 0.162	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [186][11/704]	Time 0.140	Data 0.015	Loss 2.57	Acc@1 90.6	Acc@5 98.4
Epoch: [186][21/704]	Time 0.130	Data 0.008	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [186][31/704]	Time 0.127	Data 0.006	Loss 1.93	Acc@1 92.2	Acc@5 98.4
Epoch: [186][41/704]	Time 0.125	Data 0.004	Loss 2.28	Acc@1 89.1	Acc@5 98.4
Epoch: [186][51/704]	Time 0.124	Data 0.004	Loss 3.14	Acc@1 89.1	Acc@5 96.9
Epoch: [186][61/704]	Time 0.124	Data 0.003	Loss 2.85	Acc@1 87.5	Acc@5 98.4
Epoch: [186][71/704]	Time 0.123	Data 0.003	Loss 2.76	Acc@1 89.1	Acc@5 100.0
Epoch: [186][81/704]	Time 0.123	Data 0.002	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [186][91/704]	Time 0.122	Data 0.002	Loss 1.93	Acc@1 89.1	Acc@5 100.0
Epoch: [186][101/704]	Time 0.122	Data 0.002	Loss 3.34	Acc@1 85.9	Acc@5 98.4
Epoch: [186][111/704]	Time 0.122	Data 0.002	Loss 2.42	Acc@1 90.6	Acc@5 98.4
Epoch: [186][121/704]	Time 0.122	Data 0.002	Loss 2.93	Acc@1 87.5	Acc@5 98.4
Epoch: [186][131/704]	Time 0.122	Data 0.002	Loss 2.64	Acc@1 89.1	Acc@5 100.0
Epoch: [186][141/704]	Time 0.122	Data 0.002	Loss 2.09	Acc@1 84.4	Acc@5 98.4
Epoch: [186][151/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 90.6	Acc@5 100.0
Epoch: [186][161/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [186][171/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [186][181/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 89.1	Acc@5 100.0
Epoch: [186][191/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 98.4
Epoch: [186][201/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 84.4	Acc@5 100.0
Epoch: [186][211/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 90.6	Acc@5 98.4
Epoch: [186][221/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 87.5	Acc@5 100.0
Epoch: [186][231/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 95.3	Acc@5 96.9
Epoch: [186][241/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 84.4	Acc@5 96.9
Epoch: [186][251/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 92.2	Acc@5 100.0
Epoch: [186][261/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 87.5	Acc@5 98.4
Epoch: [186][271/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 90.6	Acc@5 98.4
Epoch: [186][281/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 89.1	Acc@5 100.0
Epoch: [186][291/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 90.6	Acc@5 98.4
Epoch: [186][301/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 92.2	Acc@5 100.0
Epoch: [186][311/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 89.1	Acc@5 95.3
Epoch: [186][321/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 87.5	Acc@5 100.0
Epoch: [186][331/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 98.4
Epoch: [186][341/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 90.6	Acc@5 100.0
Epoch: [186][351/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 85.9	Acc@5 100.0
Epoch: [186][361/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 100.0
Epoch: [186][371/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 93.8	Acc@5 98.4
Epoch: [186][381/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 89.1	Acc@5 100.0
Epoch: [186][391/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 90.6	Acc@5 100.0
Epoch: [186][401/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 85.9	Acc@5 98.4
Epoch: [186][411/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 92.2	Acc@5 98.4
Epoch: [186][421/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [186][431/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [186][441/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 89.1	Acc@5 98.4
Epoch: [186][451/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 87.5	Acc@5 100.0
Epoch: [186][461/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 85.9	Acc@5 98.4
Epoch: [186][471/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 92.2	Acc@5 98.4
Epoch: [186][481/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 81.2	Acc@5 96.9
Epoch: [186][491/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 85.9	Acc@5 100.0
Epoch: [186][501/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 90.6	Acc@5 100.0
Epoch: [186][511/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 84.4	Acc@5 100.0
Epoch: [186][521/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 89.1	Acc@5 100.0
Epoch: [186][531/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 87.5	Acc@5 100.0
Epoch: [186][541/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 87.5	Acc@5 98.4
Epoch: [186][551/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [186][561/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 92.2	Acc@5 96.9
Epoch: [186][571/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 85.9	Acc@5 98.4
Epoch: [186][581/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 87.5	Acc@5 100.0
Epoch: [186][591/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 89.1	Acc@5 100.0
Epoch: [186][601/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 82.8	Acc@5 98.4
Epoch: [186][611/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 87.5	Acc@5 98.4
Epoch: [186][621/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 95.3	Acc@5 98.4
Epoch: [186][631/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 89.1	Acc@5 96.9
Epoch: [186][641/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 93.8	Acc@5 100.0
Epoch: [186][651/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 84.4	Acc@5 100.0
Epoch: [186][661/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [186][671/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 96.9
Epoch: [186][681/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [186][691/704]	Time 0.120	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 100.0
Epoch: [186][701/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 90.6	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.0798	Acc@1 71.8750	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.4006	Acc@1 75.0000	Acc@5 98.4375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.0722	Acc@1 62.5000	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7977	Acc@1 57.8125	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.8927	Acc@1 59.3750	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.8069	Acc@1 70.3125	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.8894	Acc@1 75.0000	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1364	Acc@1 67.1875	Acc@5 87.5000
 * prec@1 56.960 prec@5 85.320
 * prec@1 62.520 prec@5 88.120
 * prec@1 66.780 prec@5 90.520
 * prec@1 68.260 prec@5 91.480
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_186.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_186.pth.tar'
Epoch: [187][1/704]	Time 0.298	Data 0.130	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [187][11/704]	Time 0.137	Data 0.012	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [187][21/704]	Time 0.129	Data 0.006	Loss 2.85	Acc@1 93.8	Acc@5 98.4
Epoch: [187][31/704]	Time 0.126	Data 0.004	Loss 2.12	Acc@1 90.6	Acc@5 100.0
Epoch: [187][41/704]	Time 0.125	Data 0.003	Loss 2.09	Acc@1 89.1	Acc@5 100.0
Epoch: [187][51/704]	Time 0.124	Data 0.003	Loss 2.13	Acc@1 96.9	Acc@5 100.0
Epoch: [187][61/704]	Time 0.123	Data 0.002	Loss 2.11	Acc@1 92.2	Acc@5 98.4
Epoch: [187][71/704]	Time 0.123	Data 0.002	Loss 2.37	Acc@1 92.2	Acc@5 98.4
Epoch: [187][81/704]	Time 0.122	Data 0.002	Loss 2.95	Acc@1 84.4	Acc@5 100.0
Epoch: [187][91/704]	Time 0.122	Data 0.002	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [187][101/704]	Time 0.122	Data 0.002	Loss 2.64	Acc@1 92.2	Acc@5 100.0
Epoch: [187][111/704]	Time 0.122	Data 0.001	Loss 2.64	Acc@1 95.3	Acc@5 100.0
Epoch: [187][121/704]	Time 0.122	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [187][131/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [187][141/704]	Time 0.122	Data 0.001	Loss 2.48	Acc@1 89.1	Acc@5 100.0
Epoch: [187][151/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 93.8	Acc@5 98.4
Epoch: [187][161/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 98.4
Epoch: [187][171/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [187][181/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [187][191/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 89.1	Acc@5 98.4
Epoch: [187][201/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 93.8	Acc@5 100.0
Epoch: [187][211/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 85.9	Acc@5 98.4
Epoch: [187][221/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 85.9	Acc@5 100.0
Epoch: [187][231/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 85.9	Acc@5 100.0
Epoch: [187][241/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 93.8	Acc@5 100.0
Epoch: [187][251/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 84.4	Acc@5 100.0
Epoch: [187][261/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [187][271/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 82.8	Acc@5 100.0
Epoch: [187][281/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 92.2	Acc@5 98.4
Epoch: [187][291/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 89.1	Acc@5 100.0
Epoch: [187][301/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 89.1	Acc@5 98.4
Epoch: [187][311/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [187][321/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [187][331/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 87.5	Acc@5 100.0
Epoch: [187][341/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [187][351/704]	Time 0.120	Data 0.001	Loss 2.43	Acc@1 93.8	Acc@5 100.0
Epoch: [187][361/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 90.6	Acc@5 100.0
Epoch: [187][371/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 96.9	Acc@5 100.0
Epoch: [187][381/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [187][391/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 87.5	Acc@5 100.0
Epoch: [187][401/704]	Time 0.120	Data 0.001	Loss 1.90	Acc@1 87.5	Acc@5 98.4
Epoch: [187][411/704]	Time 0.120	Data 0.001	Loss 3.47	Acc@1 85.9	Acc@5 98.4
Epoch: [187][421/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 98.4
Epoch: [187][431/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [187][441/704]	Time 0.120	Data 0.001	Loss 2.73	Acc@1 89.1	Acc@5 96.9
Epoch: [187][451/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 100.0
Epoch: [187][461/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 96.9	Acc@5 100.0
Epoch: [187][471/704]	Time 0.120	Data 0.001	Loss 2.80	Acc@1 89.1	Acc@5 96.9
Epoch: [187][481/704]	Time 0.120	Data 0.001	Loss 3.63	Acc@1 84.4	Acc@5 100.0
Epoch: [187][491/704]	Time 0.120	Data 0.001	Loss 2.69	Acc@1 82.8	Acc@5 100.0
Epoch: [187][501/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 90.6	Acc@5 100.0
Epoch: [187][511/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [187][521/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [187][531/704]	Time 0.120	Data 0.001	Loss 2.97	Acc@1 82.8	Acc@5 100.0
Epoch: [187][541/704]	Time 0.120	Data 0.001	Loss 3.56	Acc@1 82.8	Acc@5 96.9
Epoch: [187][551/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 93.8	Acc@5 100.0
Epoch: [187][561/704]	Time 0.120	Data 0.001	Loss 2.49	Acc@1 85.9	Acc@5 98.4
Epoch: [187][571/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 90.6	Acc@5 100.0
Epoch: [187][581/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 89.1	Acc@5 100.0
Epoch: [187][591/704]	Time 0.120	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 98.4
Epoch: [187][601/704]	Time 0.120	Data 0.001	Loss 2.90	Acc@1 90.6	Acc@5 100.0
Epoch: [187][611/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 96.9	Acc@5 100.0
Epoch: [187][621/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 89.1	Acc@5 100.0
Epoch: [187][631/704]	Time 0.120	Data 0.001	Loss 3.23	Acc@1 85.9	Acc@5 98.4
Epoch: [187][641/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 87.5	Acc@5 96.9
Epoch: [187][651/704]	Time 0.120	Data 0.001	Loss 2.66	Acc@1 90.6	Acc@5 96.9
Epoch: [187][661/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 90.6	Acc@5 100.0
Epoch: [187][671/704]	Time 0.120	Data 0.001	Loss 3.19	Acc@1 87.5	Acc@5 98.4
Epoch: [187][681/704]	Time 0.120	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [187][691/704]	Time 0.120	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 96.9
Epoch: [187][701/704]	Time 0.120	Data 0.001	Loss 2.43	Acc@1 89.1	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.1830	Acc@1 60.9375	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.4699	Acc@1 71.8750	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.4274	Acc@1 75.0000	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.5075	Acc@1 75.0000	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3057	Acc@1 78.1250	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.9423	Acc@1 71.8750	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.8121	Acc@1 70.3125	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.8549	Acc@1 65.6250	Acc@5 95.3125
 * prec@1 57.740 prec@5 85.200
 * prec@1 62.620 prec@5 87.960
 * prec@1 66.320 prec@5 90.520
 * prec@1 67.840 prec@5 91.140
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_187.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_187.pth.tar'
Epoch: [188][1/704]	Time 0.296	Data 0.128	Loss 1.80	Acc@1 95.3	Acc@5 98.4
Epoch: [188][11/704]	Time 0.136	Data 0.012	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [188][21/704]	Time 0.128	Data 0.006	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [188][31/704]	Time 0.126	Data 0.005	Loss 2.14	Acc@1 95.3	Acc@5 98.4
Epoch: [188][41/704]	Time 0.124	Data 0.003	Loss 1.95	Acc@1 87.5	Acc@5 98.4
Epoch: [188][51/704]	Time 0.123	Data 0.003	Loss 1.59	Acc@1 92.2	Acc@5 100.0
Epoch: [188][61/704]	Time 0.123	Data 0.002	Loss 1.66	Acc@1 92.2	Acc@5 100.0
Epoch: [188][71/704]	Time 0.123	Data 0.002	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [188][81/704]	Time 0.123	Data 0.002	Loss 2.51	Acc@1 93.8	Acc@5 100.0
Epoch: [188][91/704]	Time 0.122	Data 0.002	Loss 1.81	Acc@1 92.2	Acc@5 98.4
Epoch: [188][101/704]	Time 0.122	Data 0.002	Loss 1.89	Acc@1 89.1	Acc@5 98.4
Epoch: [188][111/704]	Time 0.122	Data 0.002	Loss 2.43	Acc@1 89.1	Acc@5 98.4
Epoch: [188][121/704]	Time 0.122	Data 0.001	Loss 2.97	Acc@1 85.9	Acc@5 98.4
Epoch: [188][131/704]	Time 0.122	Data 0.001	Loss 2.18	Acc@1 87.5	Acc@5 100.0
Epoch: [188][141/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 87.5	Acc@5 100.0
Epoch: [188][151/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 92.2	Acc@5 100.0
Epoch: [188][161/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 85.9	Acc@5 98.4
Epoch: [188][171/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 85.9	Acc@5 100.0
Epoch: [188][181/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 98.4
Epoch: [188][191/704]	Time 0.121	Data 0.001	Loss 3.08	Acc@1 89.1	Acc@5 98.4
Epoch: [188][201/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 98.4
Epoch: [188][211/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 87.5	Acc@5 96.9
Epoch: [188][221/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 87.5	Acc@5 100.0
Epoch: [188][231/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 93.8	Acc@5 100.0
Epoch: [188][241/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [188][251/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 89.1	Acc@5 100.0
Epoch: [188][261/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 85.9	Acc@5 100.0
Epoch: [188][271/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 98.4
Epoch: [188][281/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [188][291/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 85.9	Acc@5 98.4
Epoch: [188][301/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [188][311/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [188][321/704]	Time 0.120	Data 0.001	Loss 2.25	Acc@1 82.8	Acc@5 98.4
Epoch: [188][331/704]	Time 0.120	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [188][341/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 98.4
Epoch: [188][351/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 87.5	Acc@5 100.0
Epoch: [188][361/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 96.9	Acc@5 100.0
Epoch: [188][371/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 85.9	Acc@5 96.9
Epoch: [188][381/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 92.2	Acc@5 100.0
Epoch: [188][391/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 85.9	Acc@5 100.0
Epoch: [188][401/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [188][411/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [188][421/704]	Time 0.120	Data 0.001	Loss 3.23	Acc@1 76.6	Acc@5 98.4
Epoch: [188][431/704]	Time 0.120	Data 0.001	Loss 2.76	Acc@1 85.9	Acc@5 100.0
Epoch: [188][441/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 82.8	Acc@5 100.0
Epoch: [188][451/704]	Time 0.120	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 95.3
Epoch: [188][461/704]	Time 0.120	Data 0.001	Loss 3.03	Acc@1 92.2	Acc@5 100.0
Epoch: [188][471/704]	Time 0.120	Data 0.001	Loss 2.98	Acc@1 84.4	Acc@5 98.4
Epoch: [188][481/704]	Time 0.120	Data 0.001	Loss 2.61	Acc@1 89.1	Acc@5 96.9
Epoch: [188][491/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 84.4	Acc@5 98.4
Epoch: [188][501/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 90.6	Acc@5 100.0
Epoch: [188][511/704]	Time 0.120	Data 0.001	Loss 2.85	Acc@1 90.6	Acc@5 98.4
Epoch: [188][521/704]	Time 0.120	Data 0.001	Loss 3.01	Acc@1 84.4	Acc@5 98.4
Epoch: [188][531/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 92.2	Acc@5 100.0
Epoch: [188][541/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 85.9	Acc@5 98.4
Epoch: [188][551/704]	Time 0.120	Data 0.001	Loss 2.33	Acc@1 92.2	Acc@5 100.0
Epoch: [188][561/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 89.1	Acc@5 100.0
Epoch: [188][571/704]	Time 0.120	Data 0.001	Loss 2.33	Acc@1 90.6	Acc@5 98.4
Epoch: [188][581/704]	Time 0.120	Data 0.001	Loss 2.44	Acc@1 87.5	Acc@5 98.4
Epoch: [188][591/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 89.1	Acc@5 98.4
Epoch: [188][601/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 89.1	Acc@5 100.0
Epoch: [188][611/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 98.4
Epoch: [188][621/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [188][631/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 85.9	Acc@5 100.0
Epoch: [188][641/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [188][651/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 89.1	Acc@5 98.4
Epoch: [188][661/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 85.9	Acc@5 100.0
Epoch: [188][671/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 84.4	Acc@5 100.0
Epoch: [188][681/704]	Time 0.120	Data 0.001	Loss 2.99	Acc@1 87.5	Acc@5 96.9
Epoch: [188][691/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 90.6	Acc@5 98.4
Epoch: [188][701/704]	Time 0.120	Data 0.001	Loss 3.23	Acc@1 87.5	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.3661	Acc@1 67.1875	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.3568	Acc@1 62.5000	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.1192	Acc@1 62.5000	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.4869	Acc@1 71.8750	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.6292	Acc@1 78.1250	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.5910	Acc@1 59.3750	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5734	Acc@1 70.3125	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.9827	Acc@1 76.5625	Acc@5 93.7500
 * prec@1 58.180 prec@5 84.780
 * prec@1 61.960 prec@5 87.920
 * prec@1 66.560 prec@5 91.260
 * prec@1 68.160 prec@5 91.460
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_188.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_188.pth.tar'
Epoch: [189][1/704]	Time 0.331	Data 0.165	Loss 2.64	Acc@1 87.5	Acc@5 100.0
Epoch: [189][11/704]	Time 0.139	Data 0.015	Loss 2.80	Acc@1 85.9	Acc@5 100.0
Epoch: [189][21/704]	Time 0.130	Data 0.008	Loss 1.53	Acc@1 90.6	Acc@5 100.0
Epoch: [189][31/704]	Time 0.127	Data 0.006	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [189][41/704]	Time 0.125	Data 0.004	Loss 1.69	Acc@1 92.2	Acc@5 98.4
Epoch: [189][51/704]	Time 0.124	Data 0.004	Loss 3.28	Acc@1 89.1	Acc@5 96.9
Epoch: [189][61/704]	Time 0.124	Data 0.003	Loss 2.69	Acc@1 85.9	Acc@5 98.4
Epoch: [189][71/704]	Time 0.123	Data 0.003	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [189][81/704]	Time 0.123	Data 0.002	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [189][91/704]	Time 0.122	Data 0.002	Loss 2.31	Acc@1 90.6	Acc@5 98.4
Epoch: [189][101/704]	Time 0.122	Data 0.002	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [189][111/704]	Time 0.122	Data 0.002	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [189][121/704]	Time 0.122	Data 0.002	Loss 3.37	Acc@1 89.1	Acc@5 100.0
Epoch: [189][131/704]	Time 0.122	Data 0.002	Loss 2.24	Acc@1 87.5	Acc@5 100.0
Epoch: [189][141/704]	Time 0.122	Data 0.001	Loss 2.30	Acc@1 82.8	Acc@5 100.0
Epoch: [189][151/704]	Time 0.122	Data 0.001	Loss 2.69	Acc@1 89.1	Acc@5 98.4
Epoch: [189][161/704]	Time 0.122	Data 0.001	Loss 2.43	Acc@1 93.8	Acc@5 98.4
Epoch: [189][171/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 84.4	Acc@5 100.0
Epoch: [189][181/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 90.6	Acc@5 98.4
Epoch: [189][191/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 90.6	Acc@5 100.0
Epoch: [189][201/704]	Time 0.121	Data 0.001	Loss 3.56	Acc@1 82.8	Acc@5 98.4
Epoch: [189][211/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [189][221/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 98.4
Epoch: [189][231/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [189][241/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 92.2	Acc@5 98.4
Epoch: [189][251/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 100.0
Epoch: [189][261/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 96.9	Acc@5 100.0
Epoch: [189][271/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 90.6	Acc@5 100.0
Epoch: [189][281/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 85.9	Acc@5 95.3
Epoch: [189][291/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 90.6	Acc@5 100.0
Epoch: [189][301/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 87.5	Acc@5 98.4
Epoch: [189][311/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 85.9	Acc@5 98.4
Epoch: [189][321/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 85.9	Acc@5 100.0
Epoch: [189][331/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 84.4	Acc@5 100.0
Epoch: [189][341/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 89.1	Acc@5 100.0
Epoch: [189][351/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [189][361/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 89.1	Acc@5 100.0
Epoch: [189][371/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 82.8	Acc@5 98.4
Epoch: [189][381/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 87.5	Acc@5 100.0
Epoch: [189][391/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 92.2	Acc@5 100.0
Epoch: [189][401/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 89.1	Acc@5 98.4
Epoch: [189][411/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 92.2	Acc@5 100.0
Epoch: [189][421/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 89.1	Acc@5 100.0
Epoch: [189][431/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 89.1	Acc@5 100.0
Epoch: [189][441/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [189][451/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 89.1	Acc@5 100.0
Epoch: [189][461/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 89.1	Acc@5 100.0
Epoch: [189][471/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [189][481/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 85.9	Acc@5 98.4
Epoch: [189][491/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 84.4	Acc@5 100.0
Epoch: [189][501/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 84.4	Acc@5 100.0
Epoch: [189][511/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 90.6	Acc@5 98.4
Epoch: [189][521/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [189][531/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 92.2	Acc@5 98.4
Epoch: [189][541/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 82.8	Acc@5 100.0
Epoch: [189][551/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [189][561/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [189][571/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [189][581/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 95.3	Acc@5 100.0
Epoch: [189][591/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 92.2	Acc@5 100.0
Epoch: [189][601/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 90.6	Acc@5 98.4
Epoch: [189][611/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 85.9	Acc@5 100.0
Epoch: [189][621/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [189][631/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 89.1	Acc@5 100.0
Epoch: [189][641/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [189][651/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 90.6	Acc@5 100.0
Epoch: [189][661/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 100.0
Epoch: [189][671/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 84.4	Acc@5 98.4
Epoch: [189][681/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [189][691/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 87.5	Acc@5 100.0
Epoch: [189][701/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.7416	Acc@1 64.0625	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.2332	Acc@1 76.5625	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2859	Acc@1 71.8750	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5298	Acc@1 60.9375	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2567	Acc@1 67.1875	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.0202	Acc@1 62.5000	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.0747	Acc@1 73.4375	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.8620	Acc@1 68.7500	Acc@5 90.6250
 * prec@1 56.680 prec@5 84.800
 * prec@1 62.500 prec@5 88.300
 * prec@1 66.160 prec@5 90.360
 * prec@1 67.780 prec@5 91.060
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_189.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_189.pth.tar'
Epoch: [190][1/704]	Time 0.334	Data 0.167	Loss 3.14	Acc@1 92.2	Acc@5 100.0
Epoch: [190][11/704]	Time 0.140	Data 0.016	Loss 2.29	Acc@1 90.6	Acc@5 98.4
Epoch: [190][21/704]	Time 0.131	Data 0.008	Loss 2.46	Acc@1 90.6	Acc@5 100.0
Epoch: [190][31/704]	Time 0.127	Data 0.006	Loss 1.51	Acc@1 92.2	Acc@5 100.0
Epoch: [190][41/704]	Time 0.126	Data 0.004	Loss 2.65	Acc@1 85.9	Acc@5 100.0
Epoch: [190][51/704]	Time 0.125	Data 0.004	Loss 1.87	Acc@1 89.1	Acc@5 98.4
Epoch: [190][61/704]	Time 0.124	Data 0.003	Loss 2.16	Acc@1 89.1	Acc@5 100.0
Epoch: [190][71/704]	Time 0.123	Data 0.003	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [190][81/704]	Time 0.123	Data 0.002	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [190][91/704]	Time 0.123	Data 0.002	Loss 3.06	Acc@1 87.5	Acc@5 100.0
Epoch: [190][101/704]	Time 0.123	Data 0.002	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [190][111/704]	Time 0.122	Data 0.002	Loss 1.98	Acc@1 96.9	Acc@5 100.0
Epoch: [190][121/704]	Time 0.122	Data 0.002	Loss 2.19	Acc@1 87.5	Acc@5 100.0
Epoch: [190][131/704]	Time 0.122	Data 0.002	Loss 2.62	Acc@1 90.6	Acc@5 100.0
Epoch: [190][141/704]	Time 0.122	Data 0.002	Loss 2.07	Acc@1 93.8	Acc@5 98.4
Epoch: [190][151/704]	Time 0.122	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 98.4
Epoch: [190][161/704]	Time 0.122	Data 0.001	Loss 2.49	Acc@1 84.4	Acc@5 96.9
Epoch: [190][171/704]	Time 0.122	Data 0.001	Loss 2.99	Acc@1 85.9	Acc@5 100.0
Epoch: [190][181/704]	Time 0.122	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [190][191/704]	Time 0.122	Data 0.001	Loss 2.83	Acc@1 84.4	Acc@5 98.4
Epoch: [190][201/704]	Time 0.122	Data 0.001	Loss 2.14	Acc@1 96.9	Acc@5 100.0
Epoch: [190][211/704]	Time 0.122	Data 0.001	Loss 2.60	Acc@1 84.4	Acc@5 98.4
Epoch: [190][221/704]	Time 0.122	Data 0.001	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [190][231/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 89.1	Acc@5 100.0
Epoch: [190][241/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 96.9
Epoch: [190][251/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 95.3	Acc@5 98.4
Epoch: [190][261/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 93.8	Acc@5 100.0
Epoch: [190][271/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 89.1	Acc@5 98.4
Epoch: [190][281/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 100.0
Epoch: [190][291/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 92.2	Acc@5 100.0
Epoch: [190][301/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 89.1	Acc@5 100.0
Epoch: [190][311/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 90.6	Acc@5 100.0
Epoch: [190][321/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 93.8	Acc@5 100.0
Epoch: [190][331/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 93.8	Acc@5 100.0
Epoch: [190][341/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [190][351/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 92.2	Acc@5 98.4
Epoch: [190][361/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [190][371/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 98.4
Epoch: [190][381/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [190][391/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [190][401/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 89.1	Acc@5 98.4
Epoch: [190][411/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 85.9	Acc@5 96.9
Epoch: [190][421/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 90.6	Acc@5 100.0
Epoch: [190][431/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [190][441/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 93.8	Acc@5 100.0
Epoch: [190][451/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 87.5	Acc@5 98.4
Epoch: [190][461/704]	Time 0.121	Data 0.001	Loss 3.80	Acc@1 79.7	Acc@5 100.0
Epoch: [190][471/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [190][481/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 84.4	Acc@5 98.4
Epoch: [190][491/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 89.1	Acc@5 100.0
Epoch: [190][501/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 89.1	Acc@5 100.0
Epoch: [190][511/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 90.6	Acc@5 98.4
Epoch: [190][521/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 92.2	Acc@5 100.0
Epoch: [190][531/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [190][541/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 93.8	Acc@5 100.0
Epoch: [190][551/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 90.6	Acc@5 98.4
Epoch: [190][561/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 87.5	Acc@5 100.0
Epoch: [190][571/704]	Time 0.121	Data 0.001	Loss 3.59	Acc@1 79.7	Acc@5 98.4
Epoch: [190][581/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 82.8	Acc@5 100.0
Epoch: [190][591/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 89.1	Acc@5 100.0
Epoch: [190][601/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [190][611/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 87.5	Acc@5 98.4
Epoch: [190][621/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 92.2	Acc@5 98.4
Epoch: [190][631/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 89.1	Acc@5 100.0
Epoch: [190][641/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 89.1	Acc@5 100.0
Epoch: [190][651/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [190][661/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 87.5	Acc@5 100.0
Epoch: [190][671/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 100.0
Epoch: [190][681/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 89.1	Acc@5 96.9
Epoch: [190][691/704]	Time 0.121	Data 0.001	Loss 2.97	Acc@1 90.6	Acc@5 95.3
Epoch: [190][701/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 79.7	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.3775	Acc@1 67.1875	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.3986	Acc@1 60.9375	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.4695	Acc@1 75.0000	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.3531	Acc@1 73.4375	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6603	Acc@1 67.1875	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.1138	Acc@1 68.7500	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.7100	Acc@1 76.5625	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2467	Acc@1 60.9375	Acc@5 84.3750
 * prec@1 57.240 prec@5 85.000
 * prec@1 61.820 prec@5 89.020
 * prec@1 66.360 prec@5 90.500
 * prec@1 68.460 prec@5 91.220
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_190.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_190.pth.tar'
Epoch: [191][1/704]	Time 0.301	Data 0.132	Loss 2.06	Acc@1 89.1	Acc@5 100.0
Epoch: [191][11/704]	Time 0.137	Data 0.012	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [191][21/704]	Time 0.129	Data 0.007	Loss 3.18	Acc@1 79.7	Acc@5 96.9
Epoch: [191][31/704]	Time 0.126	Data 0.005	Loss 2.94	Acc@1 84.4	Acc@5 98.4
Epoch: [191][41/704]	Time 0.125	Data 0.004	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [191][51/704]	Time 0.124	Data 0.003	Loss 2.41	Acc@1 85.9	Acc@5 98.4
Epoch: [191][61/704]	Time 0.123	Data 0.003	Loss 2.53	Acc@1 87.5	Acc@5 100.0
Epoch: [191][71/704]	Time 0.123	Data 0.002	Loss 3.30	Acc@1 82.8	Acc@5 100.0
Epoch: [191][81/704]	Time 0.123	Data 0.002	Loss 2.27	Acc@1 95.3	Acc@5 100.0
Epoch: [191][91/704]	Time 0.123	Data 0.002	Loss 1.98	Acc@1 96.9	Acc@5 98.4
Epoch: [191][101/704]	Time 0.123	Data 0.002	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [191][111/704]	Time 0.122	Data 0.002	Loss 2.52	Acc@1 84.4	Acc@5 98.4
Epoch: [191][121/704]	Time 0.122	Data 0.001	Loss 2.51	Acc@1 89.1	Acc@5 100.0
Epoch: [191][131/704]	Time 0.122	Data 0.001	Loss 2.58	Acc@1 87.5	Acc@5 100.0
Epoch: [191][141/704]	Time 0.122	Data 0.001	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [191][151/704]	Time 0.122	Data 0.001	Loss 2.59	Acc@1 89.1	Acc@5 96.9
Epoch: [191][161/704]	Time 0.122	Data 0.001	Loss 2.55	Acc@1 89.1	Acc@5 100.0
Epoch: [191][171/704]	Time 0.122	Data 0.001	Loss 2.20	Acc@1 95.3	Acc@5 100.0
Epoch: [191][181/704]	Time 0.122	Data 0.001	Loss 2.54	Acc@1 87.5	Acc@5 98.4
Epoch: [191][191/704]	Time 0.122	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 98.4
Epoch: [191][201/704]	Time 0.122	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 98.4
Epoch: [191][211/704]	Time 0.122	Data 0.001	Loss 2.58	Acc@1 87.5	Acc@5 100.0
Epoch: [191][221/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [191][231/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 98.4
Epoch: [191][241/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 98.4
Epoch: [191][251/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 85.9	Acc@5 100.0
Epoch: [191][261/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [191][271/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 98.4
Epoch: [191][281/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 84.4	Acc@5 100.0
Epoch: [191][291/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [191][301/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 82.8	Acc@5 100.0
Epoch: [191][311/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 87.5	Acc@5 96.9
Epoch: [191][321/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 89.1	Acc@5 100.0
Epoch: [191][331/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 92.2	Acc@5 100.0
Epoch: [191][341/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 90.6	Acc@5 98.4
Epoch: [191][351/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 85.9	Acc@5 98.4
Epoch: [191][361/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 100.0
Epoch: [191][371/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [191][381/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [191][391/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 85.9	Acc@5 100.0
Epoch: [191][401/704]	Time 0.121	Data 0.001	Loss 2.97	Acc@1 87.5	Acc@5 98.4
Epoch: [191][411/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 89.1	Acc@5 100.0
Epoch: [191][421/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 87.5	Acc@5 100.0
Epoch: [191][431/704]	Time 0.121	Data 0.001	Loss 3.43	Acc@1 84.4	Acc@5 100.0
Epoch: [191][441/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 87.5	Acc@5 100.0
Epoch: [191][451/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 90.6	Acc@5 100.0
Epoch: [191][461/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 93.8	Acc@5 96.9
Epoch: [191][471/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [191][481/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 90.6	Acc@5 98.4
Epoch: [191][491/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [191][501/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 90.6	Acc@5 98.4
Epoch: [191][511/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 85.9	Acc@5 100.0
Epoch: [191][521/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 92.2	Acc@5 100.0
Epoch: [191][531/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 100.0
Epoch: [191][541/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 82.8	Acc@5 100.0
Epoch: [191][551/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 84.4	Acc@5 100.0
Epoch: [191][561/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [191][571/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 85.9	Acc@5 98.4
Epoch: [191][581/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 100.0
Epoch: [191][591/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 85.9	Acc@5 96.9
Epoch: [191][601/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 89.1	Acc@5 100.0
Epoch: [191][611/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 87.5	Acc@5 100.0
Epoch: [191][621/704]	Time 0.121	Data 0.001	Loss 3.56	Acc@1 76.6	Acc@5 98.4
Epoch: [191][631/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 87.5	Acc@5 100.0
Epoch: [191][641/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 85.9	Acc@5 98.4
Epoch: [191][651/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 85.9	Acc@5 100.0
Epoch: [191][661/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [191][671/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 98.4
Epoch: [191][681/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 87.5	Acc@5 100.0
Epoch: [191][691/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 89.1	Acc@5 100.0
Epoch: [191][701/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 85.9	Acc@5 95.3
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.7560	Acc@1 71.8750	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.9779	Acc@1 68.7500	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.3611	Acc@1 68.7500	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.8322	Acc@1 59.3750	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9108	Acc@1 73.4375	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.0888	Acc@1 78.1250	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.4259	Acc@1 68.7500	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1686	Acc@1 65.6250	Acc@5 90.6250
 * prec@1 57.780 prec@5 85.000
 * prec@1 62.660 prec@5 88.200
 * prec@1 66.620 prec@5 90.700
 * prec@1 68.400 prec@5 91.380
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_191.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_191.pth.tar'
Epoch: [192][1/704]	Time 0.302	Data 0.133	Loss 3.22	Acc@1 81.2	Acc@5 96.9
Epoch: [192][11/704]	Time 0.141	Data 0.013	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [192][21/704]	Time 0.131	Data 0.007	Loss 2.33	Acc@1 85.9	Acc@5 100.0
Epoch: [192][31/704]	Time 0.128	Data 0.005	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [192][41/704]	Time 0.126	Data 0.004	Loss 2.59	Acc@1 90.6	Acc@5 98.4
Epoch: [192][51/704]	Time 0.125	Data 0.003	Loss 2.83	Acc@1 85.9	Acc@5 96.9
Epoch: [192][61/704]	Time 0.124	Data 0.003	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [192][71/704]	Time 0.123	Data 0.002	Loss 2.69	Acc@1 84.4	Acc@5 98.4
Epoch: [192][81/704]	Time 0.123	Data 0.002	Loss 2.29	Acc@1 84.4	Acc@5 100.0
Epoch: [192][91/704]	Time 0.123	Data 0.002	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [192][101/704]	Time 0.123	Data 0.002	Loss 3.02	Acc@1 87.5	Acc@5 100.0
Epoch: [192][111/704]	Time 0.122	Data 0.002	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [192][121/704]	Time 0.122	Data 0.001	Loss 2.61	Acc@1 90.6	Acc@5 100.0
Epoch: [192][131/704]	Time 0.122	Data 0.001	Loss 2.83	Acc@1 78.1	Acc@5 98.4
Epoch: [192][141/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 90.6	Acc@5 100.0
Epoch: [192][151/704]	Time 0.122	Data 0.001	Loss 2.40	Acc@1 87.5	Acc@5 100.0
Epoch: [192][161/704]	Time 0.122	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [192][171/704]	Time 0.122	Data 0.001	Loss 2.03	Acc@1 90.6	Acc@5 100.0
Epoch: [192][181/704]	Time 0.122	Data 0.001	Loss 3.02	Acc@1 90.6	Acc@5 98.4
Epoch: [192][191/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 89.1	Acc@5 100.0
Epoch: [192][201/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 82.8	Acc@5 100.0
Epoch: [192][211/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 100.0
Epoch: [192][221/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 87.5	Acc@5 98.4
Epoch: [192][231/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [192][241/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 85.9	Acc@5 96.9
Epoch: [192][251/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 93.8	Acc@5 100.0
Epoch: [192][261/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 81.2	Acc@5 100.0
Epoch: [192][271/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 92.2	Acc@5 100.0
Epoch: [192][281/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 93.8	Acc@5 98.4
Epoch: [192][291/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 81.2	Acc@5 100.0
Epoch: [192][301/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 90.6	Acc@5 98.4
Epoch: [192][311/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 89.1	Acc@5 96.9
Epoch: [192][321/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 85.9	Acc@5 100.0
Epoch: [192][331/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 90.6	Acc@5 100.0
Epoch: [192][341/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 92.2	Acc@5 100.0
Epoch: [192][351/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 81.2	Acc@5 98.4
Epoch: [192][361/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 82.8	Acc@5 100.0
Epoch: [192][371/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 100.0
Epoch: [192][381/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 87.5	Acc@5 98.4
Epoch: [192][391/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [192][401/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 84.4	Acc@5 98.4
Epoch: [192][411/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 89.1	Acc@5 100.0
Epoch: [192][421/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [192][431/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 90.6	Acc@5 100.0
Epoch: [192][441/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 98.4
Epoch: [192][451/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 85.9	Acc@5 98.4
Epoch: [192][461/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 90.6	Acc@5 100.0
Epoch: [192][471/704]	Time 0.121	Data 0.001	Loss 3.36	Acc@1 85.9	Acc@5 98.4
Epoch: [192][481/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 93.8	Acc@5 100.0
Epoch: [192][491/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 87.5	Acc@5 100.0
Epoch: [192][501/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 96.9
Epoch: [192][511/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 92.2	Acc@5 100.0
Epoch: [192][521/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 89.1	Acc@5 100.0
Epoch: [192][531/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 85.9	Acc@5 100.0
Epoch: [192][541/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 90.6	Acc@5 100.0
Epoch: [192][551/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 87.5	Acc@5 98.4
Epoch: [192][561/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [192][571/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 89.1	Acc@5 100.0
Epoch: [192][581/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 92.2	Acc@5 100.0
Epoch: [192][591/704]	Time 0.121	Data 0.001	Loss 3.18	Acc@1 81.2	Acc@5 98.4
Epoch: [192][601/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 90.6	Acc@5 98.4
Epoch: [192][611/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 93.8	Acc@5 100.0
Epoch: [192][621/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 98.4
Epoch: [192][631/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 100.0
Epoch: [192][641/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 89.1	Acc@5 100.0
Epoch: [192][651/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [192][661/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 98.4
Epoch: [192][671/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 87.5	Acc@5 100.0
Epoch: [192][681/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 87.5	Acc@5 98.4
Epoch: [192][691/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 90.6	Acc@5 100.0
Epoch: [192][701/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.9343	Acc@1 71.8750	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 7.0071	Acc@1 60.9375	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8642	Acc@1 68.7500	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9248	Acc@1 64.0625	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.9363	Acc@1 64.0625	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.9138	Acc@1 70.3125	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.3259	Acc@1 62.5000	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.2759	Acc@1 68.7500	Acc@5 92.1875
 * prec@1 57.260 prec@5 85.320
 * prec@1 62.480 prec@5 88.340
 * prec@1 66.120 prec@5 90.500
 * prec@1 67.800 prec@5 91.320
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_192.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_192.pth.tar'
Epoch: [193][1/704]	Time 0.331	Data 0.165	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [193][11/704]	Time 0.140	Data 0.015	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [193][21/704]	Time 0.130	Data 0.008	Loss 1.78	Acc@1 84.4	Acc@5 100.0
Epoch: [193][31/704]	Time 0.127	Data 0.006	Loss 3.38	Acc@1 89.1	Acc@5 98.4
Epoch: [193][41/704]	Time 0.125	Data 0.004	Loss 2.11	Acc@1 84.4	Acc@5 98.4
Epoch: [193][51/704]	Time 0.124	Data 0.004	Loss 2.27	Acc@1 90.6	Acc@5 100.0
Epoch: [193][61/704]	Time 0.124	Data 0.003	Loss 3.19	Acc@1 89.1	Acc@5 100.0
Epoch: [193][71/704]	Time 0.123	Data 0.003	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [193][81/704]	Time 0.123	Data 0.002	Loss 2.74	Acc@1 90.6	Acc@5 100.0
Epoch: [193][91/704]	Time 0.123	Data 0.002	Loss 2.01	Acc@1 92.2	Acc@5 100.0
Epoch: [193][101/704]	Time 0.122	Data 0.002	Loss 2.57	Acc@1 90.6	Acc@5 100.0
Epoch: [193][111/704]	Time 0.122	Data 0.002	Loss 1.93	Acc@1 90.6	Acc@5 100.0
Epoch: [193][121/704]	Time 0.122	Data 0.002	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [193][131/704]	Time 0.122	Data 0.002	Loss 2.20	Acc@1 92.2	Acc@5 96.9
Epoch: [193][141/704]	Time 0.122	Data 0.001	Loss 2.80	Acc@1 85.9	Acc@5 100.0
Epoch: [193][151/704]	Time 0.122	Data 0.001	Loss 2.33	Acc@1 92.2	Acc@5 98.4
Epoch: [193][161/704]	Time 0.122	Data 0.001	Loss 2.73	Acc@1 92.2	Acc@5 98.4
Epoch: [193][171/704]	Time 0.122	Data 0.001	Loss 2.55	Acc@1 85.9	Acc@5 100.0
Epoch: [193][181/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 95.3	Acc@5 98.4
Epoch: [193][191/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 98.4
Epoch: [193][201/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 90.6	Acc@5 100.0
Epoch: [193][211/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [193][221/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 84.4	Acc@5 96.9
Epoch: [193][231/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [193][241/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 98.4
Epoch: [193][251/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 87.5	Acc@5 98.4
Epoch: [193][261/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 100.0	Acc@5 100.0
Epoch: [193][271/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 100.0
Epoch: [193][281/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 84.4	Acc@5 98.4
Epoch: [193][291/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 98.4
Epoch: [193][301/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 98.4
Epoch: [193][311/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 100.0
Epoch: [193][321/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 90.6	Acc@5 100.0
Epoch: [193][331/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 85.9	Acc@5 100.0
Epoch: [193][341/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [193][351/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 89.1	Acc@5 100.0
Epoch: [193][361/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 92.2	Acc@5 100.0
Epoch: [193][371/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 98.4
Epoch: [193][381/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 85.9	Acc@5 100.0
Epoch: [193][391/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 87.5	Acc@5 100.0
Epoch: [193][401/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [193][411/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 89.1	Acc@5 100.0
Epoch: [193][421/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 90.6	Acc@5 100.0
Epoch: [193][431/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 84.4	Acc@5 100.0
Epoch: [193][441/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 90.6	Acc@5 98.4
Epoch: [193][451/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 89.1	Acc@5 100.0
Epoch: [193][461/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 87.5	Acc@5 100.0
Epoch: [193][471/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 98.4
Epoch: [193][481/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 90.6	Acc@5 100.0
Epoch: [193][491/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 85.9	Acc@5 100.0
Epoch: [193][501/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [193][511/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 87.5	Acc@5 98.4
Epoch: [193][521/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 98.4
Epoch: [193][531/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [193][541/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 87.5	Acc@5 96.9
Epoch: [193][551/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 89.1	Acc@5 100.0
Epoch: [193][561/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 90.6	Acc@5 100.0
Epoch: [193][571/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 85.9	Acc@5 100.0
Epoch: [193][581/704]	Time 0.121	Data 0.001	Loss 3.20	Acc@1 79.7	Acc@5 96.9
Epoch: [193][591/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 89.1	Acc@5 100.0
Epoch: [193][601/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 93.8	Acc@5 98.4
Epoch: [193][611/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [193][621/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [193][631/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [193][641/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 90.6	Acc@5 100.0
Epoch: [193][651/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [193][661/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 95.3	Acc@5 100.0
Epoch: [193][671/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 89.1	Acc@5 96.9
Epoch: [193][681/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 87.5	Acc@5 96.9
Epoch: [193][691/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 98.4
Epoch: [193][701/704]	Time 0.121	Data 0.001	Loss 3.30	Acc@1 90.6	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5461	Acc@1 65.6250	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.8886	Acc@1 67.1875	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.4072	Acc@1 65.6250	Acc@5 98.4375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.4712	Acc@1 67.1875	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.5457	Acc@1 71.8750	Acc@5 89.0625
Epoch: [51/79]	Time 0.019	Data 0.006	Loss 6.0903	Acc@1 65.6250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.9651	Acc@1 70.3125	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.3000	Acc@1 67.1875	Acc@5 92.1875
 * prec@1 57.340 prec@5 85.380
 * prec@1 62.600 prec@5 88.500
 * prec@1 65.940 prec@5 90.340
 * prec@1 67.960 prec@5 90.920
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_193.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_193.pth.tar'
Epoch: [194][1/704]	Time 0.299	Data 0.132	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [194][11/704]	Time 0.137	Data 0.012	Loss 1.98	Acc@1 92.2	Acc@5 98.4
Epoch: [194][21/704]	Time 0.129	Data 0.007	Loss 2.42	Acc@1 85.9	Acc@5 100.0
Epoch: [194][31/704]	Time 0.126	Data 0.005	Loss 2.20	Acc@1 93.8	Acc@5 100.0
Epoch: [194][41/704]	Time 0.125	Data 0.004	Loss 2.41	Acc@1 90.6	Acc@5 98.4
Epoch: [194][51/704]	Time 0.124	Data 0.003	Loss 1.12	Acc@1 96.9	Acc@5 100.0
Epoch: [194][61/704]	Time 0.123	Data 0.003	Loss 2.70	Acc@1 89.1	Acc@5 100.0
Epoch: [194][71/704]	Time 0.123	Data 0.002	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [194][81/704]	Time 0.122	Data 0.002	Loss 2.03	Acc@1 85.9	Acc@5 98.4
Epoch: [194][91/704]	Time 0.122	Data 0.002	Loss 1.87	Acc@1 90.6	Acc@5 100.0
Epoch: [194][101/704]	Time 0.122	Data 0.002	Loss 1.91	Acc@1 92.2	Acc@5 100.0
Epoch: [194][111/704]	Time 0.122	Data 0.002	Loss 2.79	Acc@1 89.1	Acc@5 98.4
Epoch: [194][121/704]	Time 0.122	Data 0.001	Loss 2.83	Acc@1 81.2	Acc@5 100.0
Epoch: [194][131/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 90.6	Acc@5 100.0
Epoch: [194][141/704]	Time 0.122	Data 0.001	Loss 2.17	Acc@1 89.1	Acc@5 100.0
Epoch: [194][151/704]	Time 0.122	Data 0.001	Loss 2.54	Acc@1 87.5	Acc@5 96.9
Epoch: [194][161/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 84.4	Acc@5 98.4
Epoch: [194][171/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 90.6	Acc@5 100.0
Epoch: [194][181/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [194][191/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 87.5	Acc@5 98.4
Epoch: [194][201/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 89.1	Acc@5 100.0
Epoch: [194][211/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 89.1	Acc@5 100.0
Epoch: [194][221/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 98.4
Epoch: [194][231/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 96.9	Acc@5 100.0
Epoch: [194][241/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [194][251/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 89.1	Acc@5 98.4
Epoch: [194][261/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 90.6	Acc@5 100.0
Epoch: [194][271/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 85.9	Acc@5 100.0
Epoch: [194][281/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 98.4
Epoch: [194][291/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 92.2	Acc@5 98.4
Epoch: [194][301/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 92.2	Acc@5 100.0
Epoch: [194][311/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [194][321/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 85.9	Acc@5 98.4
Epoch: [194][331/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 93.8	Acc@5 100.0
Epoch: [194][341/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [194][351/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 87.5	Acc@5 100.0
Epoch: [194][361/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 87.5	Acc@5 100.0
Epoch: [194][371/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 87.5	Acc@5 96.9
Epoch: [194][381/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 85.9	Acc@5 98.4
Epoch: [194][391/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [194][401/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 84.4	Acc@5 98.4
Epoch: [194][411/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 79.7	Acc@5 100.0
Epoch: [194][421/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 95.3	Acc@5 100.0
Epoch: [194][431/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 93.8	Acc@5 100.0
Epoch: [194][441/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 95.3	Acc@5 100.0
Epoch: [194][451/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 87.5	Acc@5 100.0
Epoch: [194][461/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 82.8	Acc@5 98.4
Epoch: [194][471/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 92.2	Acc@5 100.0
Epoch: [194][481/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 75.0	Acc@5 98.4
Epoch: [194][491/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 89.1	Acc@5 100.0
Epoch: [194][501/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 90.6	Acc@5 96.9
Epoch: [194][511/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 89.1	Acc@5 100.0
Epoch: [194][521/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 89.1	Acc@5 100.0
Epoch: [194][531/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [194][541/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [194][551/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 89.1	Acc@5 100.0
Epoch: [194][561/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 100.0
Epoch: [194][571/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 89.1	Acc@5 98.4
Epoch: [194][581/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 90.6	Acc@5 100.0
Epoch: [194][591/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 100.0
Epoch: [194][601/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 89.1	Acc@5 100.0
Epoch: [194][611/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 98.4
Epoch: [194][621/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [194][631/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 98.4
Epoch: [194][641/704]	Time 0.121	Data 0.001	Loss 3.51	Acc@1 79.7	Acc@5 96.9
Epoch: [194][651/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 98.4
Epoch: [194][661/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [194][671/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 90.6	Acc@5 98.4
Epoch: [194][681/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [194][691/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 84.4	Acc@5 100.0
Epoch: [194][701/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 93.8	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.0985	Acc@1 57.8125	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.0356	Acc@1 70.3125	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.9125	Acc@1 64.0625	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.8575	Acc@1 57.8125	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2212	Acc@1 65.6250	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.1006	Acc@1 82.8125	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6122	Acc@1 65.6250	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.7773	Acc@1 64.0625	Acc@5 92.1875
 * prec@1 57.380 prec@5 85.340
 * prec@1 62.400 prec@5 88.340
 * prec@1 65.920 prec@5 90.840
 * prec@1 67.300 prec@5 91.380
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_194.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_194.pth.tar'
Epoch: [195][1/704]	Time 0.299	Data 0.132	Loss 2.45	Acc@1 82.8	Acc@5 98.4
Epoch: [195][11/704]	Time 0.137	Data 0.012	Loss 2.28	Acc@1 85.9	Acc@5 100.0
Epoch: [195][21/704]	Time 0.129	Data 0.007	Loss 1.90	Acc@1 92.2	Acc@5 98.4
Epoch: [195][31/704]	Time 0.126	Data 0.005	Loss 1.94	Acc@1 87.5	Acc@5 100.0
Epoch: [195][41/704]	Time 0.125	Data 0.004	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [195][51/704]	Time 0.124	Data 0.003	Loss 2.62	Acc@1 92.2	Acc@5 100.0
Epoch: [195][61/704]	Time 0.124	Data 0.002	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [195][71/704]	Time 0.123	Data 0.002	Loss 2.09	Acc@1 89.1	Acc@5 100.0
Epoch: [195][81/704]	Time 0.123	Data 0.002	Loss 2.76	Acc@1 84.4	Acc@5 100.0
Epoch: [195][91/704]	Time 0.123	Data 0.002	Loss 2.48	Acc@1 87.5	Acc@5 100.0
Epoch: [195][101/704]	Time 0.123	Data 0.002	Loss 2.21	Acc@1 90.6	Acc@5 96.9
Epoch: [195][111/704]	Time 0.122	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 98.4
Epoch: [195][121/704]	Time 0.122	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [195][131/704]	Time 0.122	Data 0.001	Loss 1.93	Acc@1 82.8	Acc@5 100.0
Epoch: [195][141/704]	Time 0.122	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 100.0
Epoch: [195][151/704]	Time 0.122	Data 0.001	Loss 2.61	Acc@1 82.8	Acc@5 100.0
Epoch: [195][161/704]	Time 0.122	Data 0.001	Loss 2.29	Acc@1 85.9	Acc@5 98.4
Epoch: [195][171/704]	Time 0.122	Data 0.001	Loss 2.88	Acc@1 90.6	Acc@5 98.4
Epoch: [195][181/704]	Time 0.122	Data 0.001	Loss 2.94	Acc@1 87.5	Acc@5 100.0
Epoch: [195][191/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 98.4
Epoch: [195][201/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 87.5	Acc@5 100.0
Epoch: [195][211/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [195][221/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 92.2	Acc@5 100.0
Epoch: [195][231/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 92.2	Acc@5 100.0
Epoch: [195][241/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 85.9	Acc@5 100.0
Epoch: [195][251/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 85.9	Acc@5 100.0
Epoch: [195][261/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [195][271/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 98.4
Epoch: [195][281/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 92.2	Acc@5 100.0
Epoch: [195][291/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 100.0	Acc@5 100.0
Epoch: [195][301/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 90.6	Acc@5 100.0
Epoch: [195][311/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 85.9	Acc@5 100.0
Epoch: [195][321/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [195][331/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 85.9	Acc@5 100.0
Epoch: [195][341/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 87.5	Acc@5 100.0
Epoch: [195][351/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [195][361/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [195][371/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [195][381/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 90.6	Acc@5 100.0
Epoch: [195][391/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 89.1	Acc@5 98.4
Epoch: [195][401/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [195][411/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 98.4
Epoch: [195][421/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [195][431/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 100.0
Epoch: [195][441/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 90.6	Acc@5 98.4
Epoch: [195][451/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 90.6	Acc@5 100.0
Epoch: [195][461/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 87.5	Acc@5 100.0
Epoch: [195][471/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 90.6	Acc@5 100.0
Epoch: [195][481/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 100.0
Epoch: [195][491/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 87.5	Acc@5 100.0
Epoch: [195][501/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 93.8	Acc@5 98.4
Epoch: [195][511/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 89.1	Acc@5 100.0
Epoch: [195][521/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [195][531/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 90.6	Acc@5 100.0
Epoch: [195][541/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [195][551/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [195][561/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [195][571/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [195][581/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 85.9	Acc@5 100.0
Epoch: [195][591/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [195][601/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 90.6	Acc@5 100.0
Epoch: [195][611/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 100.0
Epoch: [195][621/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 85.9	Acc@5 100.0
Epoch: [195][631/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 100.0
Epoch: [195][641/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [195][651/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 87.5	Acc@5 100.0
Epoch: [195][661/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 98.4
Epoch: [195][671/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 89.1	Acc@5 100.0
Epoch: [195][681/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 87.5	Acc@5 100.0
Epoch: [195][691/704]	Time 0.121	Data 0.001	Loss 3.13	Acc@1 79.7	Acc@5 98.4
Epoch: [195][701/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.3682	Acc@1 76.5625	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.6750	Acc@1 68.7500	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2322	Acc@1 62.5000	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.9995	Acc@1 73.4375	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6138	Acc@1 70.3125	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.4690	Acc@1 67.1875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.5498	Acc@1 62.5000	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.5790	Acc@1 68.7500	Acc@5 90.6250
 * prec@1 57.500 prec@5 85.120
 * prec@1 62.760 prec@5 88.000
 * prec@1 67.040 prec@5 90.960
 * prec@1 68.460 prec@5 91.440
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_195.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_195.pth.tar'
Epoch: [196][1/704]	Time 0.332	Data 0.166	Loss 2.43	Acc@1 95.3	Acc@5 100.0
Epoch: [196][11/704]	Time 0.140	Data 0.015	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [196][21/704]	Time 0.131	Data 0.008	Loss 2.43	Acc@1 93.8	Acc@5 100.0
Epoch: [196][31/704]	Time 0.128	Data 0.006	Loss 2.46	Acc@1 87.5	Acc@5 100.0
Epoch: [196][41/704]	Time 0.126	Data 0.004	Loss 2.28	Acc@1 90.6	Acc@5 100.0
Epoch: [196][51/704]	Time 0.125	Data 0.004	Loss 1.62	Acc@1 90.6	Acc@5 100.0
Epoch: [196][61/704]	Time 0.125	Data 0.003	Loss 2.60	Acc@1 89.1	Acc@5 100.0
Epoch: [196][71/704]	Time 0.124	Data 0.003	Loss 2.72	Acc@1 89.1	Acc@5 96.9
Epoch: [196][81/704]	Time 0.123	Data 0.002	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [196][91/704]	Time 0.123	Data 0.002	Loss 2.20	Acc@1 93.8	Acc@5 100.0
Epoch: [196][101/704]	Time 0.123	Data 0.002	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [196][111/704]	Time 0.122	Data 0.002	Loss 2.29	Acc@1 90.6	Acc@5 100.0
Epoch: [196][121/704]	Time 0.122	Data 0.002	Loss 2.42	Acc@1 92.2	Acc@5 100.0
Epoch: [196][131/704]	Time 0.122	Data 0.002	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [196][141/704]	Time 0.122	Data 0.002	Loss 2.13	Acc@1 85.9	Acc@5 98.4
Epoch: [196][151/704]	Time 0.122	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 100.0
Epoch: [196][161/704]	Time 0.122	Data 0.001	Loss 2.27	Acc@1 85.9	Acc@5 100.0
Epoch: [196][171/704]	Time 0.122	Data 0.001	Loss 3.37	Acc@1 84.4	Acc@5 96.9
Epoch: [196][181/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 87.5	Acc@5 98.4
Epoch: [196][191/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 87.5	Acc@5 100.0
Epoch: [196][201/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 87.5	Acc@5 100.0
Epoch: [196][211/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 89.1	Acc@5 98.4
Epoch: [196][221/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [196][231/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 95.3	Acc@5 100.0
Epoch: [196][241/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 82.8	Acc@5 100.0
Epoch: [196][251/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 87.5	Acc@5 98.4
Epoch: [196][261/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 92.2	Acc@5 98.4
Epoch: [196][271/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [196][281/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 90.6	Acc@5 100.0
Epoch: [196][291/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 87.5	Acc@5 100.0
Epoch: [196][301/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 90.6	Acc@5 98.4
Epoch: [196][311/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 87.5	Acc@5 98.4
Epoch: [196][321/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 90.6	Acc@5 100.0
Epoch: [196][331/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 89.1	Acc@5 98.4
Epoch: [196][341/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 100.0
Epoch: [196][351/704]	Time 0.121	Data 0.001	Loss 3.41	Acc@1 87.5	Acc@5 98.4
Epoch: [196][361/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 89.1	Acc@5 100.0
Epoch: [196][371/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 87.5	Acc@5 98.4
Epoch: [196][381/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 92.2	Acc@5 100.0
Epoch: [196][391/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 85.9	Acc@5 100.0
Epoch: [196][401/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 92.2	Acc@5 98.4
Epoch: [196][411/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 90.6	Acc@5 98.4
Epoch: [196][421/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [196][431/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 93.8	Acc@5 100.0
Epoch: [196][441/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 98.4
Epoch: [196][451/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 90.6	Acc@5 98.4
Epoch: [196][461/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 100.0
Epoch: [196][471/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 89.1	Acc@5 98.4
Epoch: [196][481/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 98.4
Epoch: [196][491/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 84.4	Acc@5 100.0
Epoch: [196][501/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 89.1	Acc@5 100.0
Epoch: [196][511/704]	Time 0.120	Data 0.001	Loss 3.18	Acc@1 84.4	Acc@5 100.0
Epoch: [196][521/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [196][531/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 90.6	Acc@5 98.4
Epoch: [196][541/704]	Time 0.120	Data 0.001	Loss 3.40	Acc@1 87.5	Acc@5 100.0
Epoch: [196][551/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [196][561/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 98.4
Epoch: [196][571/704]	Time 0.120	Data 0.001	Loss 3.13	Acc@1 82.8	Acc@5 100.0
Epoch: [196][581/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [196][591/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [196][601/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 98.4
Epoch: [196][611/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [196][621/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 90.6	Acc@5 100.0
Epoch: [196][631/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [196][641/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [196][651/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 92.2	Acc@5 100.0
Epoch: [196][661/704]	Time 0.120	Data 0.001	Loss 2.93	Acc@1 90.6	Acc@5 98.4
Epoch: [196][671/704]	Time 0.120	Data 0.001	Loss 2.25	Acc@1 90.6	Acc@5 100.0
Epoch: [196][681/704]	Time 0.120	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 98.4
Epoch: [196][691/704]	Time 0.120	Data 0.001	Loss 3.33	Acc@1 90.6	Acc@5 100.0
Epoch: [196][701/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.6560	Acc@1 71.8750	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4599	Acc@1 68.7500	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.9674	Acc@1 64.0625	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.2228	Acc@1 65.6250	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3814	Acc@1 75.0000	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9354	Acc@1 64.0625	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.2172	Acc@1 76.5625	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.4083	Acc@1 70.3125	Acc@5 90.6250
 * prec@1 57.640 prec@5 85.180
 * prec@1 62.060 prec@5 88.620
 * prec@1 66.820 prec@5 90.760
 * prec@1 68.200 prec@5 91.420
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_196.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_196.pth.tar'
Epoch: [197][1/704]	Time 0.326	Data 0.161	Loss 2.38	Acc@1 89.1	Acc@5 100.0
Epoch: [197][11/704]	Time 0.138	Data 0.015	Loss 2.59	Acc@1 87.5	Acc@5 98.4
Epoch: [197][21/704]	Time 0.129	Data 0.008	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [197][31/704]	Time 0.126	Data 0.006	Loss 2.16	Acc@1 90.6	Acc@5 98.4
Epoch: [197][41/704]	Time 0.125	Data 0.004	Loss 2.87	Acc@1 90.6	Acc@5 98.4
Epoch: [197][51/704]	Time 0.124	Data 0.004	Loss 2.61	Acc@1 90.6	Acc@5 100.0
Epoch: [197][61/704]	Time 0.123	Data 0.003	Loss 2.60	Acc@1 81.2	Acc@5 98.4
Epoch: [197][71/704]	Time 0.122	Data 0.003	Loss 2.57	Acc@1 89.1	Acc@5 100.0
Epoch: [197][81/704]	Time 0.122	Data 0.002	Loss 2.34	Acc@1 90.6	Acc@5 100.0
Epoch: [197][91/704]	Time 0.122	Data 0.002	Loss 1.89	Acc@1 89.1	Acc@5 98.4
Epoch: [197][101/704]	Time 0.121	Data 0.002	Loss 3.17	Acc@1 81.2	Acc@5 96.9
Epoch: [197][111/704]	Time 0.121	Data 0.002	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [197][121/704]	Time 0.121	Data 0.002	Loss 1.76	Acc@1 92.2	Acc@5 100.0
Epoch: [197][131/704]	Time 0.121	Data 0.002	Loss 2.03	Acc@1 90.6	Acc@5 100.0
Epoch: [197][141/704]	Time 0.121	Data 0.002	Loss 1.89	Acc@1 92.2	Acc@5 98.4
Epoch: [197][151/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 90.6	Acc@5 98.4
Epoch: [197][161/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 96.9	Acc@5 100.0
Epoch: [197][171/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 92.2	Acc@5 98.4
Epoch: [197][181/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 90.6	Acc@5 100.0
Epoch: [197][191/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 87.5	Acc@5 100.0
Epoch: [197][201/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 85.9	Acc@5 100.0
Epoch: [197][211/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 96.9	Acc@5 100.0
Epoch: [197][221/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 98.4
Epoch: [197][231/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 100.0
Epoch: [197][241/704]	Time 0.120	Data 0.001	Loss 2.73	Acc@1 93.8	Acc@5 100.0
Epoch: [197][251/704]	Time 0.120	Data 0.001	Loss 2.65	Acc@1 92.2	Acc@5 98.4
Epoch: [197][261/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 93.8	Acc@5 100.0
Epoch: [197][271/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 98.4
Epoch: [197][281/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 85.9	Acc@5 100.0
Epoch: [197][291/704]	Time 0.120	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [197][301/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [197][311/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 89.1	Acc@5 100.0
Epoch: [197][321/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 98.4
Epoch: [197][331/704]	Time 0.120	Data 0.001	Loss 2.89	Acc@1 85.9	Acc@5 100.0
Epoch: [197][341/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 90.6	Acc@5 100.0
Epoch: [197][351/704]	Time 0.120	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 98.4
Epoch: [197][361/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 90.6	Acc@5 100.0
Epoch: [197][371/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 100.0
Epoch: [197][381/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [197][391/704]	Time 0.120	Data 0.001	Loss 2.50	Acc@1 92.2	Acc@5 98.4
Epoch: [197][401/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 87.5	Acc@5 98.4
Epoch: [197][411/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [197][421/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 98.4
Epoch: [197][431/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 96.9
Epoch: [197][441/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 98.4
Epoch: [197][451/704]	Time 0.120	Data 0.001	Loss 2.43	Acc@1 92.2	Acc@5 100.0
Epoch: [197][461/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 87.5	Acc@5 100.0
Epoch: [197][471/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [197][481/704]	Time 0.120	Data 0.001	Loss 2.72	Acc@1 87.5	Acc@5 98.4
Epoch: [197][491/704]	Time 0.120	Data 0.001	Loss 2.60	Acc@1 87.5	Acc@5 100.0
Epoch: [197][501/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 92.2	Acc@5 100.0
Epoch: [197][511/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 87.5	Acc@5 100.0
Epoch: [197][521/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 90.6	Acc@5 100.0
Epoch: [197][531/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 90.6	Acc@5 100.0
Epoch: [197][541/704]	Time 0.120	Data 0.001	Loss 2.37	Acc@1 89.1	Acc@5 96.9
Epoch: [197][551/704]	Time 0.120	Data 0.001	Loss 2.37	Acc@1 95.3	Acc@5 100.0
Epoch: [197][561/704]	Time 0.120	Data 0.001	Loss 2.59	Acc@1 90.6	Acc@5 100.0
Epoch: [197][571/704]	Time 0.120	Data 0.001	Loss 2.70	Acc@1 98.4	Acc@5 100.0
Epoch: [197][581/704]	Time 0.120	Data 0.001	Loss 3.30	Acc@1 82.8	Acc@5 95.3
Epoch: [197][591/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 87.5	Acc@5 98.4
Epoch: [197][601/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 98.4
Epoch: [197][611/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 92.2	Acc@5 100.0
Epoch: [197][621/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 84.4	Acc@5 100.0
Epoch: [197][631/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [197][641/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [197][651/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 89.1	Acc@5 98.4
Epoch: [197][661/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [197][671/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [197][681/704]	Time 0.120	Data 0.001	Loss 2.66	Acc@1 85.9	Acc@5 98.4
Epoch: [197][691/704]	Time 0.120	Data 0.001	Loss 2.63	Acc@1 92.2	Acc@5 98.4
Epoch: [197][701/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.9599	Acc@1 59.3750	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.0030	Acc@1 67.1875	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.6106	Acc@1 68.7500	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.4419	Acc@1 81.2500	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.7483	Acc@1 76.5625	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0458	Acc@1 75.0000	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.4509	Acc@1 71.8750	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 4.8693	Acc@1 70.3125	Acc@5 93.7500
 * prec@1 56.480 prec@5 84.580
 * prec@1 61.580 prec@5 87.660
 * prec@1 66.400 prec@5 90.340
 * prec@1 67.140 prec@5 90.820
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_197.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_197.pth.tar'
Epoch: [198][1/704]	Time 0.294	Data 0.126	Loss 2.40	Acc@1 92.2	Acc@5 98.4
Epoch: [198][11/704]	Time 0.136	Data 0.012	Loss 2.12	Acc@1 90.6	Acc@5 100.0
Epoch: [198][21/704]	Time 0.129	Data 0.006	Loss 2.58	Acc@1 87.5	Acc@5 100.0
Epoch: [198][31/704]	Time 0.126	Data 0.005	Loss 3.09	Acc@1 87.5	Acc@5 96.9
Epoch: [198][41/704]	Time 0.125	Data 0.004	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [198][51/704]	Time 0.124	Data 0.003	Loss 2.89	Acc@1 84.4	Acc@5 98.4
Epoch: [198][61/704]	Time 0.123	Data 0.003	Loss 1.88	Acc@1 92.2	Acc@5 98.4
Epoch: [198][71/704]	Time 0.123	Data 0.002	Loss 2.13	Acc@1 84.4	Acc@5 100.0
Epoch: [198][81/704]	Time 0.122	Data 0.002	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [198][91/704]	Time 0.123	Data 0.002	Loss 2.83	Acc@1 87.5	Acc@5 100.0
Epoch: [198][101/704]	Time 0.122	Data 0.002	Loss 2.57	Acc@1 85.9	Acc@5 100.0
Epoch: [198][111/704]	Time 0.122	Data 0.002	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [198][121/704]	Time 0.122	Data 0.002	Loss 3.02	Acc@1 89.1	Acc@5 98.4
Epoch: [198][131/704]	Time 0.122	Data 0.001	Loss 2.54	Acc@1 89.1	Acc@5 98.4
Epoch: [198][141/704]	Time 0.122	Data 0.001	Loss 2.66	Acc@1 90.6	Acc@5 100.0
Epoch: [198][151/704]	Time 0.122	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [198][161/704]	Time 0.122	Data 0.001	Loss 2.96	Acc@1 89.1	Acc@5 100.0
Epoch: [198][171/704]	Time 0.122	Data 0.001	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [198][181/704]	Time 0.122	Data 0.001	Loss 2.07	Acc@1 89.1	Acc@5 98.4
Epoch: [198][191/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [198][201/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 84.4	Acc@5 96.9
Epoch: [198][211/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 90.6	Acc@5 100.0
Epoch: [198][221/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [198][231/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 85.9	Acc@5 100.0
Epoch: [198][241/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 100.0
Epoch: [198][251/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 87.5	Acc@5 100.0
Epoch: [198][261/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 98.4
Epoch: [198][271/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 92.2	Acc@5 98.4
Epoch: [198][281/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 90.6	Acc@5 100.0
Epoch: [198][291/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [198][301/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [198][311/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 92.2	Acc@5 98.4
Epoch: [198][321/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [198][331/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 100.0
Epoch: [198][341/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 90.6	Acc@5 96.9
Epoch: [198][351/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 95.3	Acc@5 100.0
Epoch: [198][361/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 85.9	Acc@5 100.0
Epoch: [198][371/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [198][381/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 89.1	Acc@5 98.4
Epoch: [198][391/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 84.4	Acc@5 100.0
Epoch: [198][401/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 85.9	Acc@5 98.4
Epoch: [198][411/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 85.9	Acc@5 100.0
Epoch: [198][421/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 92.2	Acc@5 98.4
Epoch: [198][431/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 90.6	Acc@5 100.0
Epoch: [198][441/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 85.9	Acc@5 100.0
Epoch: [198][451/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 92.2	Acc@5 98.4
Epoch: [198][461/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 89.1	Acc@5 100.0
Epoch: [198][471/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 87.5	Acc@5 98.4
Epoch: [198][481/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [198][491/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 93.8	Acc@5 100.0
Epoch: [198][501/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 96.9
Epoch: [198][511/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [198][521/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 84.4	Acc@5 98.4
Epoch: [198][531/704]	Time 0.121	Data 0.001	Loss 3.29	Acc@1 89.1	Acc@5 98.4
Epoch: [198][541/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [198][551/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 89.1	Acc@5 98.4
Epoch: [198][561/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 89.1	Acc@5 100.0
Epoch: [198][571/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 92.2	Acc@5 98.4
Epoch: [198][581/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [198][591/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 89.1	Acc@5 98.4
Epoch: [198][601/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 98.4
Epoch: [198][611/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 89.1	Acc@5 98.4
Epoch: [198][621/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 92.2	Acc@5 100.0
Epoch: [198][631/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 90.6	Acc@5 98.4
Epoch: [198][641/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 85.9	Acc@5 100.0
Epoch: [198][651/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 85.9	Acc@5 100.0
Epoch: [198][661/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 85.9	Acc@5 100.0
Epoch: [198][671/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [198][681/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [198][691/704]	Time 0.121	Data 0.001	Loss 3.33	Acc@1 87.5	Acc@5 98.4
Epoch: [198][701/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 85.9	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.8808	Acc@1 65.6250	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4732	Acc@1 70.3125	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.6900	Acc@1 70.3125	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.9302	Acc@1 68.7500	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6410	Acc@1 62.5000	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7688	Acc@1 67.1875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5262	Acc@1 60.9375	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.1153	Acc@1 62.5000	Acc@5 90.6250
 * prec@1 57.040 prec@5 85.300
 * prec@1 61.980 prec@5 88.140
 * prec@1 65.500 prec@5 90.560
 * prec@1 67.420 prec@5 91.060
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_198.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_198.pth.tar'
Epoch: [199][1/704]	Time 0.295	Data 0.126	Loss 2.93	Acc@1 87.5	Acc@5 96.9
Epoch: [199][11/704]	Time 0.140	Data 0.012	Loss 2.50	Acc@1 84.4	Acc@5 100.0
Epoch: [199][21/704]	Time 0.131	Data 0.006	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [199][31/704]	Time 0.127	Data 0.004	Loss 2.12	Acc@1 85.9	Acc@5 100.0
Epoch: [199][41/704]	Time 0.126	Data 0.003	Loss 1.94	Acc@1 90.6	Acc@5 100.0
Epoch: [199][51/704]	Time 0.125	Data 0.003	Loss 2.32	Acc@1 95.3	Acc@5 98.4
Epoch: [199][61/704]	Time 0.124	Data 0.002	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [199][71/704]	Time 0.123	Data 0.002	Loss 2.67	Acc@1 85.9	Acc@5 100.0
Epoch: [199][81/704]	Time 0.123	Data 0.002	Loss 2.73	Acc@1 93.8	Acc@5 96.9
Epoch: [199][91/704]	Time 0.123	Data 0.002	Loss 2.52	Acc@1 84.4	Acc@5 100.0
Epoch: [199][101/704]	Time 0.122	Data 0.001	Loss 2.73	Acc@1 78.1	Acc@5 98.4
Epoch: [199][111/704]	Time 0.122	Data 0.001	Loss 2.48	Acc@1 92.2	Acc@5 100.0
Epoch: [199][121/704]	Time 0.122	Data 0.001	Loss 2.27	Acc@1 95.3	Acc@5 100.0
Epoch: [199][131/704]	Time 0.122	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [199][141/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [199][151/704]	Time 0.122	Data 0.001	Loss 2.60	Acc@1 90.6	Acc@5 100.0
Epoch: [199][161/704]	Time 0.122	Data 0.001	Loss 3.00	Acc@1 84.4	Acc@5 98.4
Epoch: [199][171/704]	Time 0.122	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [199][181/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 95.3	Acc@5 100.0
Epoch: [199][191/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 95.3	Acc@5 100.0
Epoch: [199][201/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 82.8	Acc@5 98.4
Epoch: [199][211/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [199][221/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 87.5	Acc@5 98.4
Epoch: [199][231/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 96.9	Acc@5 100.0
Epoch: [199][241/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 84.4	Acc@5 100.0
Epoch: [199][251/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 93.8	Acc@5 100.0
Epoch: [199][261/704]	Time 0.121	Data 0.001	Loss 3.22	Acc@1 89.1	Acc@5 98.4
Epoch: [199][271/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 95.3	Acc@5 100.0
Epoch: [199][281/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [199][291/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 89.1	Acc@5 100.0
Epoch: [199][301/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 90.6	Acc@5 98.4
Epoch: [199][311/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [199][321/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 82.8	Acc@5 100.0
Epoch: [199][331/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 87.5	Acc@5 96.9
Epoch: [199][341/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 89.1	Acc@5 100.0
Epoch: [199][351/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 92.2	Acc@5 100.0
Epoch: [199][361/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [199][371/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 89.1	Acc@5 100.0
Epoch: [199][381/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [199][391/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 84.4	Acc@5 98.4
Epoch: [199][401/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 98.4
Epoch: [199][411/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 98.4
Epoch: [199][421/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 89.1	Acc@5 100.0
Epoch: [199][431/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 90.6	Acc@5 100.0
Epoch: [199][441/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [199][451/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 98.4
Epoch: [199][461/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 87.5	Acc@5 100.0
Epoch: [199][471/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 95.3	Acc@5 100.0
Epoch: [199][481/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [199][491/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 87.5	Acc@5 100.0
Epoch: [199][501/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 82.8	Acc@5 96.9
Epoch: [199][511/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 87.5	Acc@5 98.4
Epoch: [199][521/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 92.2	Acc@5 100.0
Epoch: [199][531/704]	Time 0.121	Data 0.001	Loss 3.10	Acc@1 78.1	Acc@5 100.0
Epoch: [199][541/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 93.8	Acc@5 100.0
Epoch: [199][551/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 92.2	Acc@5 100.0
Epoch: [199][561/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 85.9	Acc@5 100.0
Epoch: [199][571/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [199][581/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 84.4	Acc@5 95.3
Epoch: [199][591/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 87.5	Acc@5 100.0
Epoch: [199][601/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 100.0
Epoch: [199][611/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 90.6	Acc@5 100.0
Epoch: [199][621/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 92.2	Acc@5 100.0
Epoch: [199][631/704]	Time 0.121	Data 0.000	Loss 3.02	Acc@1 89.1	Acc@5 98.4
Epoch: [199][641/704]	Time 0.121	Data 0.000	Loss 3.07	Acc@1 90.6	Acc@5 98.4
Epoch: [199][651/704]	Time 0.121	Data 0.000	Loss 2.25	Acc@1 95.3	Acc@5 100.0
Epoch: [199][661/704]	Time 0.121	Data 0.000	Loss 2.75	Acc@1 89.1	Acc@5 98.4
Epoch: [199][671/704]	Time 0.121	Data 0.000	Loss 2.17	Acc@1 85.9	Acc@5 100.0
Epoch: [199][681/704]	Time 0.121	Data 0.000	Loss 2.92	Acc@1 84.4	Acc@5 100.0
Epoch: [199][691/704]	Time 0.121	Data 0.000	Loss 2.54	Acc@1 90.6	Acc@5 100.0
Epoch: [199][701/704]	Time 0.121	Data 0.000	Loss 2.89	Acc@1 85.9	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 5.1398	Acc@1 76.5625	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.2418	Acc@1 64.0625	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.1495	Acc@1 70.3125	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9967	Acc@1 56.2500	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.7326	Acc@1 71.8750	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.3131	Acc@1 79.6875	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.1004	Acc@1 71.8750	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.1140	Acc@1 76.5625	Acc@5 93.7500
 * prec@1 56.940 prec@5 85.000
 * prec@1 62.700 prec@5 87.900
 * prec@1 65.920 prec@5 90.460
 * prec@1 67.220 prec@5 90.880
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_199.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_199.pth.tar'
Epoch: [200][1/704]	Time 0.330	Data 0.163	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [200][11/704]	Time 0.139	Data 0.015	Loss 2.36	Acc@1 92.2	Acc@5 98.4
Epoch: [200][21/704]	Time 0.130	Data 0.008	Loss 2.11	Acc@1 90.6	Acc@5 98.4
Epoch: [200][31/704]	Time 0.127	Data 0.006	Loss 2.21	Acc@1 95.3	Acc@5 100.0
Epoch: [200][41/704]	Time 0.125	Data 0.004	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [200][51/704]	Time 0.124	Data 0.003	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [200][61/704]	Time 0.124	Data 0.003	Loss 2.62	Acc@1 81.2	Acc@5 100.0
Epoch: [200][71/704]	Time 0.123	Data 0.003	Loss 3.05	Acc@1 92.2	Acc@5 100.0
Epoch: [200][81/704]	Time 0.123	Data 0.002	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [200][91/704]	Time 0.122	Data 0.002	Loss 2.20	Acc@1 84.4	Acc@5 96.9
Epoch: [200][101/704]	Time 0.122	Data 0.002	Loss 3.05	Acc@1 89.1	Acc@5 98.4
Epoch: [200][111/704]	Time 0.122	Data 0.002	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [200][121/704]	Time 0.122	Data 0.002	Loss 2.06	Acc@1 89.1	Acc@5 100.0
Epoch: [200][131/704]	Time 0.122	Data 0.002	Loss 2.57	Acc@1 87.5	Acc@5 98.4
Epoch: [200][141/704]	Time 0.122	Data 0.001	Loss 2.68	Acc@1 84.4	Acc@5 96.9
Epoch: [200][151/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 87.5	Acc@5 100.0
Epoch: [200][161/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 84.4	Acc@5 98.4
Epoch: [200][171/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [200][181/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 92.2	Acc@5 100.0
Epoch: [200][191/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 85.9	Acc@5 100.0
Epoch: [200][201/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 87.5	Acc@5 100.0
Epoch: [200][211/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 98.4
Epoch: [200][221/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 81.2	Acc@5 100.0
Epoch: [200][231/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [200][241/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 89.1	Acc@5 100.0
Epoch: [200][251/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [200][261/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 81.2	Acc@5 98.4
Epoch: [200][271/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 98.4
Epoch: [200][281/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 98.4
Epoch: [200][291/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 87.5	Acc@5 100.0
Epoch: [200][301/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 93.8	Acc@5 100.0
Epoch: [200][311/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 87.5	Acc@5 98.4
Epoch: [200][321/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 93.8	Acc@5 100.0
Epoch: [200][331/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 95.3	Acc@5 100.0
Epoch: [200][341/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 90.6	Acc@5 100.0
Epoch: [200][351/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [200][361/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [200][371/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 89.1	Acc@5 98.4
Epoch: [200][381/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 92.2	Acc@5 100.0
Epoch: [200][391/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 92.2	Acc@5 100.0
Epoch: [200][401/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 84.4	Acc@5 100.0
Epoch: [200][411/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 87.5	Acc@5 98.4
Epoch: [200][421/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [200][431/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [200][441/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 87.5	Acc@5 100.0
Epoch: [200][451/704]	Time 0.121	Data 0.001	Loss 3.14	Acc@1 90.6	Acc@5 96.9
Epoch: [200][461/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 96.9
Epoch: [200][471/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 92.2	Acc@5 100.0
Epoch: [200][481/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 87.5	Acc@5 100.0
Epoch: [200][491/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 89.1	Acc@5 100.0
Epoch: [200][501/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 87.5	Acc@5 98.4
Epoch: [200][511/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [200][521/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [200][531/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 87.5	Acc@5 100.0
Epoch: [200][541/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [200][551/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 100.0
Epoch: [200][561/704]	Time 0.120	Data 0.001	Loss 2.97	Acc@1 81.2	Acc@5 98.4
Epoch: [200][571/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [200][581/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 82.8	Acc@5 98.4
Epoch: [200][591/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 89.1	Acc@5 100.0
Epoch: [200][601/704]	Time 0.120	Data 0.001	Loss 2.62	Acc@1 92.2	Acc@5 98.4
Epoch: [200][611/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [200][621/704]	Time 0.120	Data 0.001	Loss 3.17	Acc@1 89.1	Acc@5 100.0
Epoch: [200][631/704]	Time 0.120	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [200][641/704]	Time 0.120	Data 0.001	Loss 2.61	Acc@1 90.6	Acc@5 100.0
Epoch: [200][651/704]	Time 0.120	Data 0.001	Loss 2.75	Acc@1 87.5	Acc@5 98.4
Epoch: [200][661/704]	Time 0.120	Data 0.001	Loss 2.76	Acc@1 90.6	Acc@5 98.4
Epoch: [200][671/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 89.1	Acc@5 98.4
Epoch: [200][681/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 93.8	Acc@5 98.4
Epoch: [200][691/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 93.8	Acc@5 100.0
Epoch: [200][701/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.7634	Acc@1 73.4375	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.8526	Acc@1 70.3125	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.4583	Acc@1 64.0625	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4551	Acc@1 68.7500	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6961	Acc@1 65.6250	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6749	Acc@1 73.4375	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4966	Acc@1 64.0625	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.0089	Acc@1 57.8125	Acc@5 92.1875
 * prec@1 57.040 prec@5 84.760
 * prec@1 61.080 prec@5 87.500
 * prec@1 65.540 prec@5 90.040
 * prec@1 66.380 prec@5 91.100
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_200.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_200.pth.tar'
Epoch: [201][1/704]	Time 0.300	Data 0.132	Loss 2.38	Acc@1 87.5	Acc@5 100.0
Epoch: [201][11/704]	Time 0.136	Data 0.012	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [201][21/704]	Time 0.129	Data 0.007	Loss 2.20	Acc@1 93.8	Acc@5 100.0
Epoch: [201][31/704]	Time 0.126	Data 0.005	Loss 2.24	Acc@1 92.2	Acc@5 98.4
Epoch: [201][41/704]	Time 0.124	Data 0.004	Loss 2.96	Acc@1 92.2	Acc@5 100.0
Epoch: [201][51/704]	Time 0.124	Data 0.003	Loss 2.33	Acc@1 90.6	Acc@5 98.4
Epoch: [201][61/704]	Time 0.123	Data 0.002	Loss 2.80	Acc@1 90.6	Acc@5 100.0
Epoch: [201][71/704]	Time 0.123	Data 0.002	Loss 1.77	Acc@1 90.6	Acc@5 100.0
Epoch: [201][81/704]	Time 0.122	Data 0.002	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [201][91/704]	Time 0.122	Data 0.002	Loss 2.27	Acc@1 93.8	Acc@5 100.0
Epoch: [201][101/704]	Time 0.122	Data 0.002	Loss 2.84	Acc@1 85.9	Acc@5 96.9
Epoch: [201][111/704]	Time 0.122	Data 0.001	Loss 2.09	Acc@1 85.9	Acc@5 98.4
Epoch: [201][121/704]	Time 0.122	Data 0.001	Loss 2.37	Acc@1 92.2	Acc@5 98.4
Epoch: [201][131/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 93.8	Acc@5 100.0
Epoch: [201][141/704]	Time 0.122	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [201][151/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 87.5	Acc@5 100.0
Epoch: [201][161/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [201][171/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 87.5	Acc@5 100.0
Epoch: [201][181/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [201][191/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 87.5	Acc@5 98.4
Epoch: [201][201/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 90.6	Acc@5 98.4
Epoch: [201][211/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 89.1	Acc@5 98.4
Epoch: [201][221/704]	Time 0.121	Data 0.001	Loss 3.48	Acc@1 81.2	Acc@5 93.8
Epoch: [201][231/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 85.9	Acc@5 98.4
Epoch: [201][241/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 98.4
Epoch: [201][251/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 84.4	Acc@5 100.0
Epoch: [201][261/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 100.0
Epoch: [201][271/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 98.4
Epoch: [201][281/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [201][291/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 90.6	Acc@5 100.0
Epoch: [201][301/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 87.5	Acc@5 100.0
Epoch: [201][311/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 92.2	Acc@5 100.0
Epoch: [201][321/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 90.6	Acc@5 100.0
Epoch: [201][331/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [201][341/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [201][351/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 85.9	Acc@5 98.4
Epoch: [201][361/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 87.5	Acc@5 98.4
Epoch: [201][371/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [201][381/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [201][391/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [201][401/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 95.3	Acc@5 96.9
Epoch: [201][411/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [201][421/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 93.8	Acc@5 100.0
Epoch: [201][431/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 95.3	Acc@5 100.0
Epoch: [201][441/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 84.4	Acc@5 100.0
Epoch: [201][451/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 89.1	Acc@5 100.0
Epoch: [201][461/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 87.5	Acc@5 100.0
Epoch: [201][471/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [201][481/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [201][491/704]	Time 0.121	Data 0.001	Loss 3.12	Acc@1 81.2	Acc@5 95.3
Epoch: [201][501/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 90.6	Acc@5 100.0
Epoch: [201][511/704]	Time 0.121	Data 0.001	Loss 3.26	Acc@1 85.9	Acc@5 98.4
Epoch: [201][521/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 84.4	Acc@5 98.4
Epoch: [201][531/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 89.1	Acc@5 100.0
Epoch: [201][541/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 90.6	Acc@5 98.4
Epoch: [201][551/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 84.4	Acc@5 96.9
Epoch: [201][561/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 93.8	Acc@5 100.0
Epoch: [201][571/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 87.5	Acc@5 100.0
Epoch: [201][581/704]	Time 0.120	Data 0.001	Loss 2.48	Acc@1 85.9	Acc@5 100.0
Epoch: [201][591/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 85.9	Acc@5 100.0
Epoch: [201][601/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 85.9	Acc@5 98.4
Epoch: [201][611/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [201][621/704]	Time 0.120	Data 0.001	Loss 2.83	Acc@1 89.1	Acc@5 100.0
Epoch: [201][631/704]	Time 0.120	Data 0.000	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [201][641/704]	Time 0.120	Data 0.000	Loss 2.27	Acc@1 87.5	Acc@5 100.0
Epoch: [201][651/704]	Time 0.121	Data 0.000	Loss 2.36	Acc@1 89.1	Acc@5 100.0
Epoch: [201][661/704]	Time 0.121	Data 0.000	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [201][671/704]	Time 0.120	Data 0.000	Loss 2.28	Acc@1 89.1	Acc@5 100.0
Epoch: [201][681/704]	Time 0.120	Data 0.000	Loss 2.35	Acc@1 89.1	Acc@5 100.0
Epoch: [201][691/704]	Time 0.120	Data 0.000	Loss 2.71	Acc@1 89.1	Acc@5 100.0
Epoch: [201][701/704]	Time 0.120	Data 0.000	Loss 2.14	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.085	Loss 5.5227	Acc@1 64.0625	Acc@5 96.8750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 8.6485	Acc@1 62.5000	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.6716	Acc@1 70.3125	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.0287	Acc@1 70.3125	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.5101	Acc@1 64.0625	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.2789	Acc@1 70.3125	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7795	Acc@1 70.3125	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1425	Acc@1 59.3750	Acc@5 89.0625
 * prec@1 57.120 prec@5 85.040
 * prec@1 61.940 prec@5 88.280
 * prec@1 65.700 prec@5 90.180
 * prec@1 67.180 prec@5 91.220
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_201.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_201.pth.tar'
Epoch: [202][1/704]	Time 0.298	Data 0.131	Loss 2.16	Acc@1 92.2	Acc@5 98.4
Epoch: [202][11/704]	Time 0.137	Data 0.012	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [202][21/704]	Time 0.129	Data 0.007	Loss 1.82	Acc@1 92.2	Acc@5 100.0
Epoch: [202][31/704]	Time 0.126	Data 0.005	Loss 1.96	Acc@1 93.8	Acc@5 98.4
Epoch: [202][41/704]	Time 0.125	Data 0.003	Loss 2.24	Acc@1 90.6	Acc@5 100.0
Epoch: [202][51/704]	Time 0.124	Data 0.003	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [202][61/704]	Time 0.124	Data 0.002	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [202][71/704]	Time 0.123	Data 0.002	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [202][81/704]	Time 0.123	Data 0.002	Loss 1.86	Acc@1 89.1	Acc@5 100.0
Epoch: [202][91/704]	Time 0.123	Data 0.002	Loss 2.57	Acc@1 93.8	Acc@5 100.0
Epoch: [202][101/704]	Time 0.122	Data 0.002	Loss 2.25	Acc@1 89.1	Acc@5 100.0
Epoch: [202][111/704]	Time 0.122	Data 0.001	Loss 1.69	Acc@1 90.6	Acc@5 100.0
Epoch: [202][121/704]	Time 0.122	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [202][131/704]	Time 0.122	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 100.0
Epoch: [202][141/704]	Time 0.122	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [202][151/704]	Time 0.122	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 98.4
Epoch: [202][161/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 100.0
Epoch: [202][171/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 90.6	Acc@5 100.0
Epoch: [202][181/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 90.6	Acc@5 100.0
Epoch: [202][191/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 85.9	Acc@5 100.0
Epoch: [202][201/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 93.8	Acc@5 100.0
Epoch: [202][211/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 87.5	Acc@5 98.4
Epoch: [202][221/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 95.3	Acc@5 100.0
Epoch: [202][231/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 87.5	Acc@5 100.0
Epoch: [202][241/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 87.5	Acc@5 100.0
Epoch: [202][251/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [202][261/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 96.9	Acc@5 98.4
Epoch: [202][271/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [202][281/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 85.9	Acc@5 98.4
Epoch: [202][291/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 84.4	Acc@5 98.4
Epoch: [202][301/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 93.8	Acc@5 96.9
Epoch: [202][311/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 92.2	Acc@5 100.0
Epoch: [202][321/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 92.2	Acc@5 96.9
Epoch: [202][331/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [202][341/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 87.5	Acc@5 100.0
Epoch: [202][351/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 92.2	Acc@5 98.4
Epoch: [202][361/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 98.4
Epoch: [202][371/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 92.2	Acc@5 98.4
Epoch: [202][381/704]	Time 0.121	Data 0.001	Loss 3.01	Acc@1 84.4	Acc@5 100.0
Epoch: [202][391/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 87.5	Acc@5 100.0
Epoch: [202][401/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 89.1	Acc@5 100.0
Epoch: [202][411/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [202][421/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 85.9	Acc@5 100.0
Epoch: [202][431/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 87.5	Acc@5 98.4
Epoch: [202][441/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 100.0
Epoch: [202][451/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 89.1	Acc@5 98.4
Epoch: [202][461/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [202][471/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 95.3	Acc@5 100.0
Epoch: [202][481/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 89.1	Acc@5 100.0
Epoch: [202][491/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 92.2	Acc@5 100.0
Epoch: [202][501/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 85.9	Acc@5 100.0
Epoch: [202][511/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 92.2	Acc@5 98.4
Epoch: [202][521/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 90.6	Acc@5 98.4
Epoch: [202][531/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [202][541/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 82.8	Acc@5 98.4
Epoch: [202][551/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 92.2	Acc@5 98.4
Epoch: [202][561/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 81.2	Acc@5 98.4
Epoch: [202][571/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 98.4
Epoch: [202][581/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 89.1	Acc@5 98.4
Epoch: [202][591/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 85.9	Acc@5 98.4
Epoch: [202][601/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 100.0
Epoch: [202][611/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 87.5	Acc@5 100.0
Epoch: [202][621/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 96.9	Acc@5 100.0
Epoch: [202][631/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 92.2	Acc@5 100.0
Epoch: [202][641/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 95.3	Acc@5 100.0
Epoch: [202][651/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 89.1	Acc@5 100.0
Epoch: [202][661/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 98.4
Epoch: [202][671/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 92.2	Acc@5 100.0
Epoch: [202][681/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [202][691/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 81.2	Acc@5 98.4
Epoch: [202][701/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 92.2	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.3980	Acc@1 62.5000	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.4762	Acc@1 62.5000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.8818	Acc@1 59.3750	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.7674	Acc@1 67.1875	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.2943	Acc@1 64.0625	Acc@5 98.4375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8002	Acc@1 70.3125	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.1161	Acc@1 75.0000	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.1859	Acc@1 67.1875	Acc@5 89.0625
 * prec@1 58.460 prec@5 84.500
 * prec@1 62.100 prec@5 88.460
 * prec@1 66.500 prec@5 90.300
 * prec@1 68.100 prec@5 90.640
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_202.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_202.pth.tar'
Epoch: [203][1/704]	Time 0.331	Data 0.165	Loss 1.81	Acc@1 98.4	Acc@5 100.0
Epoch: [203][11/704]	Time 0.140	Data 0.015	Loss 2.27	Acc@1 90.6	Acc@5 100.0
Epoch: [203][21/704]	Time 0.131	Data 0.008	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [203][31/704]	Time 0.127	Data 0.006	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [203][41/704]	Time 0.125	Data 0.004	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [203][51/704]	Time 0.124	Data 0.004	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [203][61/704]	Time 0.124	Data 0.003	Loss 2.47	Acc@1 84.4	Acc@5 100.0
Epoch: [203][71/704]	Time 0.123	Data 0.003	Loss 2.23	Acc@1 85.9	Acc@5 96.9
Epoch: [203][81/704]	Time 0.123	Data 0.002	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [203][91/704]	Time 0.122	Data 0.002	Loss 2.56	Acc@1 93.8	Acc@5 98.4
Epoch: [203][101/704]	Time 0.122	Data 0.002	Loss 2.06	Acc@1 87.5	Acc@5 100.0
Epoch: [203][111/704]	Time 0.122	Data 0.002	Loss 2.46	Acc@1 85.9	Acc@5 100.0
Epoch: [203][121/704]	Time 0.122	Data 0.002	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [203][131/704]	Time 0.122	Data 0.002	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [203][141/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [203][151/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [203][161/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 92.2	Acc@5 98.4
Epoch: [203][171/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 84.4	Acc@5 100.0
Epoch: [203][181/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 82.8	Acc@5 98.4
Epoch: [203][191/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [203][201/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 98.4
Epoch: [203][211/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 100.0
Epoch: [203][221/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 89.1	Acc@5 98.4
Epoch: [203][231/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 92.2	Acc@5 100.0
Epoch: [203][241/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [203][251/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 85.9	Acc@5 100.0
Epoch: [203][261/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 93.8	Acc@5 100.0
Epoch: [203][271/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [203][281/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 93.8	Acc@5 98.4
Epoch: [203][291/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 90.6	Acc@5 100.0
Epoch: [203][301/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 81.2	Acc@5 100.0
Epoch: [203][311/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 93.8	Acc@5 98.4
Epoch: [203][321/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 89.1	Acc@5 96.9
Epoch: [203][331/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 98.4
Epoch: [203][341/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [203][351/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 89.1	Acc@5 100.0
Epoch: [203][361/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 90.6	Acc@5 100.0
Epoch: [203][371/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 87.5	Acc@5 98.4
Epoch: [203][381/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 89.1	Acc@5 98.4
Epoch: [203][391/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 89.1	Acc@5 98.4
Epoch: [203][401/704]	Time 0.121	Data 0.001	Loss 2.97	Acc@1 87.5	Acc@5 100.0
Epoch: [203][411/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [203][421/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [203][431/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 100.0
Epoch: [203][441/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [203][451/704]	Time 0.120	Data 0.001	Loss 2.23	Acc@1 93.8	Acc@5 100.0
Epoch: [203][461/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 85.9	Acc@5 98.4
Epoch: [203][471/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [203][481/704]	Time 0.120	Data 0.001	Loss 2.44	Acc@1 93.8	Acc@5 98.4
Epoch: [203][491/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [203][501/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 98.4
Epoch: [203][511/704]	Time 0.120	Data 0.001	Loss 3.41	Acc@1 79.7	Acc@5 95.3
Epoch: [203][521/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [203][531/704]	Time 0.120	Data 0.001	Loss 2.34	Acc@1 92.2	Acc@5 100.0
Epoch: [203][541/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 89.1	Acc@5 100.0
Epoch: [203][551/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 92.2	Acc@5 100.0
Epoch: [203][561/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [203][571/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 84.4	Acc@5 98.4
Epoch: [203][581/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 98.4
Epoch: [203][591/704]	Time 0.120	Data 0.001	Loss 2.64	Acc@1 90.6	Acc@5 100.0
Epoch: [203][601/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 89.1	Acc@5 100.0
Epoch: [203][611/704]	Time 0.120	Data 0.001	Loss 2.60	Acc@1 89.1	Acc@5 98.4
Epoch: [203][621/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 92.2	Acc@5 96.9
Epoch: [203][631/704]	Time 0.120	Data 0.001	Loss 2.07	Acc@1 89.1	Acc@5 98.4
Epoch: [203][641/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 87.5	Acc@5 100.0
Epoch: [203][651/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 93.8	Acc@5 98.4
Epoch: [203][661/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [203][671/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 92.2	Acc@5 100.0
Epoch: [203][681/704]	Time 0.120	Data 0.001	Loss 2.97	Acc@1 84.4	Acc@5 98.4
Epoch: [203][691/704]	Time 0.120	Data 0.001	Loss 2.78	Acc@1 92.2	Acc@5 98.4
Epoch: [203][701/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.6984	Acc@1 65.6250	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 4.9200	Acc@1 65.6250	Acc@5 96.8750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.7793	Acc@1 62.5000	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4588	Acc@1 62.5000	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6919	Acc@1 68.7500	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1752	Acc@1 73.4375	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.6167	Acc@1 70.3125	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.4829	Acc@1 67.1875	Acc@5 89.0625
 * prec@1 56.560 prec@5 85.160
 * prec@1 61.660 prec@5 88.020
 * prec@1 65.880 prec@5 90.460
 * prec@1 67.460 prec@5 91.140
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_203.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_203.pth.tar'
Epoch: [204][1/704]	Time 0.334	Data 0.167	Loss 2.61	Acc@1 92.2	Acc@5 98.4
Epoch: [204][11/704]	Time 0.140	Data 0.016	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [204][21/704]	Time 0.130	Data 0.009	Loss 2.56	Acc@1 87.5	Acc@5 100.0
Epoch: [204][31/704]	Time 0.127	Data 0.006	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [204][41/704]	Time 0.125	Data 0.005	Loss 2.25	Acc@1 89.1	Acc@5 98.4
Epoch: [204][51/704]	Time 0.124	Data 0.004	Loss 2.39	Acc@1 92.2	Acc@5 100.0
Epoch: [204][61/704]	Time 0.124	Data 0.003	Loss 2.29	Acc@1 84.4	Acc@5 100.0
Epoch: [204][71/704]	Time 0.123	Data 0.003	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [204][81/704]	Time 0.123	Data 0.002	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [204][91/704]	Time 0.122	Data 0.002	Loss 2.65	Acc@1 90.6	Acc@5 98.4
Epoch: [204][101/704]	Time 0.122	Data 0.002	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [204][111/704]	Time 0.122	Data 0.002	Loss 2.68	Acc@1 87.5	Acc@5 98.4
Epoch: [204][121/704]	Time 0.122	Data 0.002	Loss 3.70	Acc@1 90.6	Acc@5 100.0
Epoch: [204][131/704]	Time 0.122	Data 0.002	Loss 1.83	Acc@1 90.6	Acc@5 100.0
Epoch: [204][141/704]	Time 0.122	Data 0.002	Loss 2.94	Acc@1 85.9	Acc@5 100.0
Epoch: [204][151/704]	Time 0.121	Data 0.002	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [204][161/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 85.9	Acc@5 100.0
Epoch: [204][171/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [204][181/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [204][191/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 98.4
Epoch: [204][201/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 92.2	Acc@5 100.0
Epoch: [204][211/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 89.1	Acc@5 96.9
Epoch: [204][221/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 93.8	Acc@5 98.4
Epoch: [204][231/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 89.1	Acc@5 100.0
Epoch: [204][241/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [204][251/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 100.0
Epoch: [204][261/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [204][271/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 85.9	Acc@5 98.4
Epoch: [204][281/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 89.1	Acc@5 100.0
Epoch: [204][291/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 100.0
Epoch: [204][301/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [204][311/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 96.9	Acc@5 100.0
Epoch: [204][321/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 92.2	Acc@5 100.0
Epoch: [204][331/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [204][341/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 89.1	Acc@5 100.0
Epoch: [204][351/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 90.6	Acc@5 100.0
Epoch: [204][361/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 90.6	Acc@5 100.0
Epoch: [204][371/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 84.4	Acc@5 100.0
Epoch: [204][381/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 98.4
Epoch: [204][391/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 89.1	Acc@5 98.4
Epoch: [204][401/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 92.2	Acc@5 98.4
Epoch: [204][411/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [204][421/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 100.0
Epoch: [204][431/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 90.6	Acc@5 98.4
Epoch: [204][441/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 95.3	Acc@5 100.0
Epoch: [204][451/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 90.6	Acc@5 100.0
Epoch: [204][461/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 92.2	Acc@5 100.0
Epoch: [204][471/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [204][481/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 89.1	Acc@5 98.4
Epoch: [204][491/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 100.0
Epoch: [204][501/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 84.4	Acc@5 96.9
Epoch: [204][511/704]	Time 0.121	Data 0.001	Loss 3.41	Acc@1 90.6	Acc@5 98.4
Epoch: [204][521/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 89.1	Acc@5 100.0
Epoch: [204][531/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 81.2	Acc@5 98.4
Epoch: [204][541/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 89.1	Acc@5 98.4
Epoch: [204][551/704]	Time 0.120	Data 0.001	Loss 2.63	Acc@1 85.9	Acc@5 96.9
Epoch: [204][561/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 100.0
Epoch: [204][571/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 84.4	Acc@5 98.4
Epoch: [204][581/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [204][591/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 100.0
Epoch: [204][601/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [204][611/704]	Time 0.120	Data 0.001	Loss 2.61	Acc@1 89.1	Acc@5 100.0
Epoch: [204][621/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [204][631/704]	Time 0.120	Data 0.001	Loss 3.72	Acc@1 82.8	Acc@5 100.0
Epoch: [204][641/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 98.4
Epoch: [204][651/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [204][661/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 98.4
Epoch: [204][671/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 90.6	Acc@5 100.0
Epoch: [204][681/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 98.4
Epoch: [204][691/704]	Time 0.120	Data 0.001	Loss 2.25	Acc@1 89.1	Acc@5 100.0
Epoch: [204][701/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 85.9	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5867	Acc@1 62.5000	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.0612	Acc@1 64.0625	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.4082	Acc@1 65.6250	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.6750	Acc@1 81.2500	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.1356	Acc@1 76.5625	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.3346	Acc@1 59.3750	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.5812	Acc@1 68.7500	Acc@5 98.4375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.9665	Acc@1 73.4375	Acc@5 93.7500
 * prec@1 58.540 prec@5 85.400
 * prec@1 61.580 prec@5 88.100
 * prec@1 65.580 prec@5 90.680
 * prec@1 67.360 prec@5 91.100
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_204.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_204.pth.tar'
Epoch: [205][1/704]	Time 0.298	Data 0.131	Loss 2.29	Acc@1 93.8	Acc@5 98.4
Epoch: [205][11/704]	Time 0.136	Data 0.012	Loss 1.75	Acc@1 90.6	Acc@5 100.0
Epoch: [205][21/704]	Time 0.128	Data 0.007	Loss 2.71	Acc@1 87.5	Acc@5 100.0
Epoch: [205][31/704]	Time 0.126	Data 0.005	Loss 1.68	Acc@1 89.1	Acc@5 100.0
Epoch: [205][41/704]	Time 0.124	Data 0.004	Loss 2.07	Acc@1 92.2	Acc@5 98.4
Epoch: [205][51/704]	Time 0.124	Data 0.003	Loss 1.88	Acc@1 92.2	Acc@5 98.4
Epoch: [205][61/704]	Time 0.123	Data 0.003	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [205][71/704]	Time 0.122	Data 0.002	Loss 2.51	Acc@1 93.8	Acc@5 100.0
Epoch: [205][81/704]	Time 0.122	Data 0.002	Loss 2.06	Acc@1 87.5	Acc@5 100.0
Epoch: [205][91/704]	Time 0.122	Data 0.002	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [205][101/704]	Time 0.122	Data 0.002	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [205][111/704]	Time 0.122	Data 0.002	Loss 3.42	Acc@1 87.5	Acc@5 98.4
Epoch: [205][121/704]	Time 0.122	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [205][131/704]	Time 0.122	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 98.4
Epoch: [205][141/704]	Time 0.122	Data 0.001	Loss 2.90	Acc@1 89.1	Acc@5 100.0
Epoch: [205][151/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 96.9	Acc@5 98.4
Epoch: [205][161/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 87.5	Acc@5 98.4
Epoch: [205][171/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 90.6	Acc@5 100.0
Epoch: [205][181/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [205][191/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 98.4	Acc@5 100.0
Epoch: [205][201/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 92.2	Acc@5 98.4
Epoch: [205][211/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 87.5	Acc@5 98.4
Epoch: [205][221/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [205][231/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 85.9	Acc@5 100.0
Epoch: [205][241/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [205][251/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 95.3	Acc@5 100.0
Epoch: [205][261/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [205][271/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 100.0
Epoch: [205][281/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 87.5	Acc@5 100.0
Epoch: [205][291/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [205][301/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 85.9	Acc@5 98.4
Epoch: [205][311/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [205][321/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 84.4	Acc@5 98.4
Epoch: [205][331/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 92.2	Acc@5 100.0
Epoch: [205][341/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 98.4
Epoch: [205][351/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [205][361/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [205][371/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 89.1	Acc@5 100.0
Epoch: [205][381/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 89.1	Acc@5 100.0
Epoch: [205][391/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 92.2	Acc@5 100.0
Epoch: [205][401/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 89.1	Acc@5 96.9
Epoch: [205][411/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 90.6	Acc@5 100.0
Epoch: [205][421/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [205][431/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 90.6	Acc@5 98.4
Epoch: [205][441/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 100.0
Epoch: [205][451/704]	Time 0.120	Data 0.001	Loss 3.11	Acc@1 84.4	Acc@5 100.0
Epoch: [205][461/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 93.8	Acc@5 98.4
Epoch: [205][471/704]	Time 0.120	Data 0.001	Loss 2.71	Acc@1 90.6	Acc@5 98.4
Epoch: [205][481/704]	Time 0.120	Data 0.001	Loss 2.86	Acc@1 87.5	Acc@5 100.0
Epoch: [205][491/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [205][501/704]	Time 0.120	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 100.0
Epoch: [205][511/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 92.2	Acc@5 96.9
Epoch: [205][521/704]	Time 0.120	Data 0.001	Loss 2.81	Acc@1 85.9	Acc@5 98.4
Epoch: [205][531/704]	Time 0.120	Data 0.001	Loss 2.62	Acc@1 92.2	Acc@5 98.4
Epoch: [205][541/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 95.3	Acc@5 98.4
Epoch: [205][551/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 92.2	Acc@5 100.0
Epoch: [205][561/704]	Time 0.120	Data 0.001	Loss 2.86	Acc@1 85.9	Acc@5 98.4
Epoch: [205][571/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [205][581/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 92.2	Acc@5 100.0
Epoch: [205][591/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 87.5	Acc@5 100.0
Epoch: [205][601/704]	Time 0.120	Data 0.001	Loss 2.60	Acc@1 90.6	Acc@5 100.0
Epoch: [205][611/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 100.0
Epoch: [205][621/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [205][631/704]	Time 0.120	Data 0.001	Loss 3.21	Acc@1 84.4	Acc@5 98.4
Epoch: [205][641/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 85.9	Acc@5 100.0
Epoch: [205][651/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [205][661/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 85.9	Acc@5 100.0
Epoch: [205][671/704]	Time 0.120	Data 0.001	Loss 2.92	Acc@1 87.5	Acc@5 98.4
Epoch: [205][681/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [205][691/704]	Time 0.120	Data 0.001	Loss 2.50	Acc@1 90.6	Acc@5 98.4
Epoch: [205][701/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.3888	Acc@1 65.6250	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8893	Acc@1 64.0625	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2248	Acc@1 70.3125	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.2193	Acc@1 71.8750	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.3104	Acc@1 70.3125	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.7406	Acc@1 73.4375	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.1830	Acc@1 70.3125	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 4.5033	Acc@1 73.4375	Acc@5 96.8750
 * prec@1 57.300 prec@5 84.940
 * prec@1 61.720 prec@5 88.200
 * prec@1 66.400 prec@5 90.820
 * prec@1 67.540 prec@5 91.140
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_205.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_205.pth.tar'
Epoch: [206][1/704]	Time 0.299	Data 0.131	Loss 1.76	Acc@1 89.1	Acc@5 100.0
Epoch: [206][11/704]	Time 0.141	Data 0.012	Loss 1.64	Acc@1 93.8	Acc@5 100.0
Epoch: [206][21/704]	Time 0.131	Data 0.007	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [206][31/704]	Time 0.127	Data 0.005	Loss 2.62	Acc@1 90.6	Acc@5 98.4
Epoch: [206][41/704]	Time 0.126	Data 0.004	Loss 2.35	Acc@1 90.6	Acc@5 100.0
Epoch: [206][51/704]	Time 0.124	Data 0.003	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [206][61/704]	Time 0.124	Data 0.003	Loss 2.24	Acc@1 89.1	Acc@5 100.0
Epoch: [206][71/704]	Time 0.123	Data 0.002	Loss 2.18	Acc@1 87.5	Acc@5 98.4
Epoch: [206][81/704]	Time 0.123	Data 0.002	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [206][91/704]	Time 0.123	Data 0.002	Loss 1.93	Acc@1 92.2	Acc@5 100.0
Epoch: [206][101/704]	Time 0.122	Data 0.002	Loss 2.03	Acc@1 92.2	Acc@5 98.4
Epoch: [206][111/704]	Time 0.122	Data 0.002	Loss 2.15	Acc@1 90.6	Acc@5 100.0
Epoch: [206][121/704]	Time 0.122	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 98.4
Epoch: [206][131/704]	Time 0.122	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [206][141/704]	Time 0.122	Data 0.001	Loss 2.47	Acc@1 90.6	Acc@5 100.0
Epoch: [206][151/704]	Time 0.122	Data 0.001	Loss 2.38	Acc@1 93.8	Acc@5 100.0
Epoch: [206][161/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 95.3	Acc@5 100.0
Epoch: [206][171/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [206][181/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [206][191/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 89.1	Acc@5 100.0
Epoch: [206][201/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 89.1	Acc@5 96.9
Epoch: [206][211/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 93.8	Acc@5 98.4
Epoch: [206][221/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 92.2	Acc@5 100.0
Epoch: [206][231/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 93.8	Acc@5 100.0
Epoch: [206][241/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 98.4
Epoch: [206][251/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [206][261/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 93.8	Acc@5 98.4
Epoch: [206][271/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [206][281/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 92.2	Acc@5 100.0
Epoch: [206][291/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 92.2	Acc@5 100.0
Epoch: [206][301/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [206][311/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 93.8	Acc@5 98.4
Epoch: [206][321/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [206][331/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 92.2	Acc@5 98.4
Epoch: [206][341/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [206][351/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 89.1	Acc@5 100.0
Epoch: [206][361/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 93.8	Acc@5 98.4
Epoch: [206][371/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 100.0
Epoch: [206][381/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 89.1	Acc@5 98.4
Epoch: [206][391/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 92.2	Acc@5 100.0
Epoch: [206][401/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 89.1	Acc@5 100.0
Epoch: [206][411/704]	Time 0.121	Data 0.001	Loss 3.25	Acc@1 82.8	Acc@5 100.0
Epoch: [206][421/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 82.8	Acc@5 98.4
Epoch: [206][431/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [206][441/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 100.0
Epoch: [206][451/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 84.4	Acc@5 100.0
Epoch: [206][461/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 98.4
Epoch: [206][471/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 85.9	Acc@5 100.0
Epoch: [206][481/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 89.1	Acc@5 100.0
Epoch: [206][491/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 98.4
Epoch: [206][501/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 89.1	Acc@5 96.9
Epoch: [206][511/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 98.4
Epoch: [206][521/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 89.1	Acc@5 98.4
Epoch: [206][531/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 89.1	Acc@5 100.0
Epoch: [206][541/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 89.1	Acc@5 98.4
Epoch: [206][551/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 95.3	Acc@5 100.0
Epoch: [206][561/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 98.4
Epoch: [206][571/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 90.6	Acc@5 98.4
Epoch: [206][581/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 92.2	Acc@5 98.4
Epoch: [206][591/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 85.9	Acc@5 95.3
Epoch: [206][601/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 85.9	Acc@5 100.0
Epoch: [206][611/704]	Time 0.121	Data 0.001	Loss 3.32	Acc@1 78.1	Acc@5 96.9
Epoch: [206][621/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 89.1	Acc@5 100.0
Epoch: [206][631/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 84.4	Acc@5 100.0
Epoch: [206][641/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 82.8	Acc@5 100.0
Epoch: [206][651/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 92.2	Acc@5 100.0
Epoch: [206][661/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 92.2	Acc@5 98.4
Epoch: [206][671/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 87.5	Acc@5 98.4
Epoch: [206][681/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 100.0
Epoch: [206][691/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 87.5	Acc@5 100.0
Epoch: [206][701/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 90.6	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.6745	Acc@1 54.6875	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.3319	Acc@1 57.8125	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5867	Acc@1 70.3125	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.0792	Acc@1 65.6250	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.8036	Acc@1 71.8750	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.1261	Acc@1 71.8750	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.0571	Acc@1 73.4375	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.8285	Acc@1 70.3125	Acc@5 85.9375
 * prec@1 56.580 prec@5 84.940
 * prec@1 61.740 prec@5 88.080
 * prec@1 66.320 prec@5 90.800
 * prec@1 67.620 prec@5 90.400
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_206.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_206.pth.tar'
Epoch: [207][1/704]	Time 0.330	Data 0.164	Loss 2.26	Acc@1 92.2	Acc@5 100.0
Epoch: [207][11/704]	Time 0.139	Data 0.015	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [207][21/704]	Time 0.130	Data 0.008	Loss 1.86	Acc@1 89.1	Acc@5 98.4
Epoch: [207][31/704]	Time 0.127	Data 0.006	Loss 2.62	Acc@1 90.6	Acc@5 98.4
Epoch: [207][41/704]	Time 0.125	Data 0.004	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [207][51/704]	Time 0.124	Data 0.003	Loss 2.17	Acc@1 85.9	Acc@5 100.0
Epoch: [207][61/704]	Time 0.123	Data 0.003	Loss 2.08	Acc@1 93.8	Acc@5 98.4
Epoch: [207][71/704]	Time 0.123	Data 0.003	Loss 2.24	Acc@1 92.2	Acc@5 100.0
Epoch: [207][81/704]	Time 0.123	Data 0.002	Loss 2.18	Acc@1 85.9	Acc@5 98.4
Epoch: [207][91/704]	Time 0.122	Data 0.002	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [207][101/704]	Time 0.122	Data 0.002	Loss 2.51	Acc@1 87.5	Acc@5 100.0
Epoch: [207][111/704]	Time 0.122	Data 0.002	Loss 2.24	Acc@1 92.2	Acc@5 98.4
Epoch: [207][121/704]	Time 0.122	Data 0.002	Loss 3.33	Acc@1 87.5	Acc@5 96.9
Epoch: [207][131/704]	Time 0.122	Data 0.002	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [207][141/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 84.4	Acc@5 100.0
Epoch: [207][151/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 89.1	Acc@5 98.4
Epoch: [207][161/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [207][171/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 98.4
Epoch: [207][181/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 96.9
Epoch: [207][191/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 90.6	Acc@5 100.0
Epoch: [207][201/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 87.5	Acc@5 100.0
Epoch: [207][211/704]	Time 0.121	Data 0.001	Loss 2.80	Acc@1 90.6	Acc@5 98.4
Epoch: [207][221/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 90.6	Acc@5 100.0
Epoch: [207][231/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 95.3	Acc@5 100.0
Epoch: [207][241/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 89.1	Acc@5 100.0
Epoch: [207][251/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [207][261/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 98.4
Epoch: [207][271/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 90.6	Acc@5 100.0
Epoch: [207][281/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [207][291/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 100.0
Epoch: [207][301/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 89.1	Acc@5 100.0
Epoch: [207][311/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 85.9	Acc@5 100.0
Epoch: [207][321/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [207][331/704]	Time 0.121	Data 0.001	Loss 3.19	Acc@1 85.9	Acc@5 100.0
Epoch: [207][341/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [207][351/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 90.6	Acc@5 100.0
Epoch: [207][361/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 90.6	Acc@5 100.0
Epoch: [207][371/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 87.5	Acc@5 98.4
Epoch: [207][381/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 89.1	Acc@5 98.4
Epoch: [207][391/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 92.2	Acc@5 100.0
Epoch: [207][401/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 89.1	Acc@5 98.4
Epoch: [207][411/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 87.5	Acc@5 100.0
Epoch: [207][421/704]	Time 0.121	Data 0.001	Loss 3.29	Acc@1 81.2	Acc@5 98.4
Epoch: [207][431/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 89.1	Acc@5 100.0
Epoch: [207][441/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 85.9	Acc@5 100.0
Epoch: [207][451/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 79.7	Acc@5 100.0
Epoch: [207][461/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [207][471/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 90.6	Acc@5 98.4
Epoch: [207][481/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 100.0
Epoch: [207][491/704]	Time 0.120	Data 0.001	Loss 2.77	Acc@1 89.1	Acc@5 100.0
Epoch: [207][501/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [207][511/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 89.1	Acc@5 100.0
Epoch: [207][521/704]	Time 0.120	Data 0.001	Loss 2.34	Acc@1 85.9	Acc@5 98.4
Epoch: [207][531/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 100.0
Epoch: [207][541/704]	Time 0.120	Data 0.001	Loss 2.90	Acc@1 87.5	Acc@5 98.4
Epoch: [207][551/704]	Time 0.120	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [207][561/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 93.8	Acc@5 100.0
Epoch: [207][571/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [207][581/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [207][591/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 100.0
Epoch: [207][601/704]	Time 0.120	Data 0.001	Loss 2.99	Acc@1 90.6	Acc@5 98.4
Epoch: [207][611/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 96.9	Acc@5 96.9
Epoch: [207][621/704]	Time 0.120	Data 0.001	Loss 2.97	Acc@1 89.1	Acc@5 98.4
Epoch: [207][631/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 93.8	Acc@5 98.4
Epoch: [207][641/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 90.6	Acc@5 98.4
Epoch: [207][651/704]	Time 0.120	Data 0.001	Loss 1.42	Acc@1 93.8	Acc@5 100.0
Epoch: [207][661/704]	Time 0.120	Data 0.001	Loss 2.73	Acc@1 90.6	Acc@5 100.0
Epoch: [207][671/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 82.8	Acc@5 100.0
Epoch: [207][681/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 100.0
Epoch: [207][691/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [207][701/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.8665	Acc@1 71.8750	Acc@5 96.8750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7625	Acc@1 59.3750	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2542	Acc@1 67.1875	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.8358	Acc@1 68.7500	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 8.4968	Acc@1 60.9375	Acc@5 82.8125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.0091	Acc@1 78.1250	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.2511	Acc@1 59.3750	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.6086	Acc@1 65.6250	Acc@5 85.9375
 * prec@1 57.080 prec@5 83.760
 * prec@1 61.480 prec@5 87.480
 * prec@1 65.400 prec@5 90.120
 * prec@1 67.460 prec@5 90.720
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_207.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_207.pth.tar'
Epoch: [208][1/704]	Time 0.299	Data 0.132	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [208][11/704]	Time 0.136	Data 0.012	Loss 2.34	Acc@1 92.2	Acc@5 100.0
Epoch: [208][21/704]	Time 0.128	Data 0.007	Loss 2.00	Acc@1 95.3	Acc@5 100.0
Epoch: [208][31/704]	Time 0.126	Data 0.005	Loss 2.64	Acc@1 87.5	Acc@5 100.0
Epoch: [208][41/704]	Time 0.124	Data 0.004	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [208][51/704]	Time 0.123	Data 0.003	Loss 1.92	Acc@1 89.1	Acc@5 100.0
Epoch: [208][61/704]	Time 0.123	Data 0.002	Loss 2.63	Acc@1 87.5	Acc@5 100.0
Epoch: [208][71/704]	Time 0.122	Data 0.002	Loss 2.14	Acc@1 85.9	Acc@5 100.0
Epoch: [208][81/704]	Time 0.122	Data 0.002	Loss 2.01	Acc@1 90.6	Acc@5 100.0
Epoch: [208][91/704]	Time 0.122	Data 0.002	Loss 1.90	Acc@1 90.6	Acc@5 100.0
Epoch: [208][101/704]	Time 0.122	Data 0.002	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [208][111/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [208][121/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 98.4
Epoch: [208][131/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 87.5	Acc@5 100.0
Epoch: [208][141/704]	Time 0.121	Data 0.001	Loss 2.93	Acc@1 84.4	Acc@5 100.0
Epoch: [208][151/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 87.5	Acc@5 100.0
Epoch: [208][161/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 87.5	Acc@5 100.0
Epoch: [208][171/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 93.8	Acc@5 100.0
Epoch: [208][181/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 90.6	Acc@5 100.0
Epoch: [208][191/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 85.9	Acc@5 100.0
Epoch: [208][201/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 92.2	Acc@5 98.4
Epoch: [208][211/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [208][221/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 93.8	Acc@5 100.0
Epoch: [208][231/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [208][241/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [208][251/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 92.2	Acc@5 100.0
Epoch: [208][261/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 84.4	Acc@5 100.0
Epoch: [208][271/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 87.5	Acc@5 100.0
Epoch: [208][281/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 89.1	Acc@5 96.9
Epoch: [208][291/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [208][301/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 100.0
Epoch: [208][311/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 98.4
Epoch: [208][321/704]	Time 0.120	Data 0.001	Loss 2.56	Acc@1 92.2	Acc@5 100.0
Epoch: [208][331/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 90.6	Acc@5 100.0
Epoch: [208][341/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [208][351/704]	Time 0.120	Data 0.001	Loss 2.85	Acc@1 85.9	Acc@5 98.4
Epoch: [208][361/704]	Time 0.120	Data 0.001	Loss 2.92	Acc@1 82.8	Acc@5 100.0
Epoch: [208][371/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 98.4
Epoch: [208][381/704]	Time 0.120	Data 0.001	Loss 2.67	Acc@1 89.1	Acc@5 98.4
Epoch: [208][391/704]	Time 0.120	Data 0.001	Loss 2.98	Acc@1 87.5	Acc@5 100.0
Epoch: [208][401/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [208][411/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 100.0
Epoch: [208][421/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [208][431/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 93.8	Acc@5 100.0
Epoch: [208][441/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 95.3	Acc@5 100.0
Epoch: [208][451/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 85.9	Acc@5 98.4
Epoch: [208][461/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 93.8	Acc@5 100.0
Epoch: [208][471/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [208][481/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [208][491/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [208][501/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 84.4	Acc@5 96.9
Epoch: [208][511/704]	Time 0.120	Data 0.001	Loss 3.21	Acc@1 84.4	Acc@5 96.9
Epoch: [208][521/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 87.5	Acc@5 100.0
Epoch: [208][531/704]	Time 0.120	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [208][541/704]	Time 0.120	Data 0.001	Loss 2.90	Acc@1 90.6	Acc@5 100.0
Epoch: [208][551/704]	Time 0.120	Data 0.001	Loss 2.69	Acc@1 84.4	Acc@5 96.9
Epoch: [208][561/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 96.9	Acc@5 100.0
Epoch: [208][571/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [208][581/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 85.9	Acc@5 100.0
Epoch: [208][591/704]	Time 0.120	Data 0.001	Loss 2.49	Acc@1 89.1	Acc@5 100.0
Epoch: [208][601/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [208][611/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 87.5	Acc@5 100.0
Epoch: [208][621/704]	Time 0.120	Data 0.001	Loss 3.21	Acc@1 87.5	Acc@5 100.0
Epoch: [208][631/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 96.9	Acc@5 100.0
Epoch: [208][641/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 95.3	Acc@5 98.4
Epoch: [208][651/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 96.9	Acc@5 100.0
Epoch: [208][661/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [208][671/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 92.2	Acc@5 98.4
Epoch: [208][681/704]	Time 0.120	Data 0.001	Loss 2.23	Acc@1 87.5	Acc@5 100.0
Epoch: [208][691/704]	Time 0.120	Data 0.001	Loss 2.80	Acc@1 89.1	Acc@5 100.0
Epoch: [208][701/704]	Time 0.120	Data 0.001	Loss 3.06	Acc@1 92.2	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.1396	Acc@1 64.0625	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.4670	Acc@1 70.3125	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.3274	Acc@1 59.3750	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.1061	Acc@1 64.0625	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.1048	Acc@1 81.2500	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.4180	Acc@1 71.8750	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.7527	Acc@1 70.3125	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.5900	Acc@1 71.8750	Acc@5 95.3125
 * prec@1 57.140 prec@5 84.480
 * prec@1 60.980 prec@5 88.360
 * prec@1 65.820 prec@5 90.400
 * prec@1 67.020 prec@5 91.180
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_208.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_208.pth.tar'
Epoch: [209][1/704]	Time 0.295	Data 0.127	Loss 2.53	Acc@1 90.6	Acc@5 98.4
Epoch: [209][11/704]	Time 0.136	Data 0.012	Loss 3.11	Acc@1 89.1	Acc@5 98.4
Epoch: [209][21/704]	Time 0.128	Data 0.006	Loss 2.38	Acc@1 82.8	Acc@5 98.4
Epoch: [209][31/704]	Time 0.126	Data 0.004	Loss 2.25	Acc@1 90.6	Acc@5 100.0
Epoch: [209][41/704]	Time 0.124	Data 0.003	Loss 2.16	Acc@1 92.2	Acc@5 98.4
Epoch: [209][51/704]	Time 0.123	Data 0.003	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [209][61/704]	Time 0.124	Data 0.002	Loss 1.88	Acc@1 89.1	Acc@5 100.0
Epoch: [209][71/704]	Time 0.123	Data 0.002	Loss 2.48	Acc@1 93.8	Acc@5 100.0
Epoch: [209][81/704]	Time 0.123	Data 0.002	Loss 3.03	Acc@1 85.9	Acc@5 98.4
Epoch: [209][91/704]	Time 0.122	Data 0.002	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [209][101/704]	Time 0.122	Data 0.002	Loss 2.29	Acc@1 90.6	Acc@5 100.0
Epoch: [209][111/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [209][121/704]	Time 0.122	Data 0.001	Loss 2.37	Acc@1 93.8	Acc@5 100.0
Epoch: [209][131/704]	Time 0.122	Data 0.001	Loss 2.10	Acc@1 92.2	Acc@5 98.4
Epoch: [209][141/704]	Time 0.122	Data 0.001	Loss 2.04	Acc@1 90.6	Acc@5 100.0
Epoch: [209][151/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 90.6	Acc@5 100.0
Epoch: [209][161/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 87.5	Acc@5 100.0
Epoch: [209][171/704]	Time 0.121	Data 0.001	Loss 3.04	Acc@1 82.8	Acc@5 100.0
Epoch: [209][181/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 90.6	Acc@5 98.4
Epoch: [209][191/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [209][201/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 89.1	Acc@5 98.4
Epoch: [209][211/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [209][221/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [209][231/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [209][241/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 89.1	Acc@5 100.0
Epoch: [209][251/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 85.9	Acc@5 100.0
Epoch: [209][261/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [209][271/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [209][281/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 93.8	Acc@5 100.0
Epoch: [209][291/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 100.0	Acc@5 100.0
Epoch: [209][301/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 98.4
Epoch: [209][311/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 92.2	Acc@5 100.0
Epoch: [209][321/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 92.2	Acc@5 100.0
Epoch: [209][331/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 81.2	Acc@5 100.0
Epoch: [209][341/704]	Time 0.121	Data 0.001	Loss 3.06	Acc@1 89.1	Acc@5 96.9
Epoch: [209][351/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [209][361/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 90.6	Acc@5 100.0
Epoch: [209][371/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 98.4
Epoch: [209][381/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [209][391/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [209][401/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 89.1	Acc@5 98.4
Epoch: [209][411/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 89.1	Acc@5 98.4
Epoch: [209][421/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 93.8	Acc@5 96.9
Epoch: [209][431/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 81.2	Acc@5 100.0
Epoch: [209][441/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [209][451/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 89.1	Acc@5 100.0
Epoch: [209][461/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 89.1	Acc@5 98.4
Epoch: [209][471/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 89.1	Acc@5 100.0
Epoch: [209][481/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 89.1	Acc@5 98.4
Epoch: [209][491/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 84.4	Acc@5 100.0
Epoch: [209][501/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 92.2	Acc@5 100.0
Epoch: [209][511/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 90.6	Acc@5 100.0
Epoch: [209][521/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 98.4
Epoch: [209][531/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 85.9	Acc@5 100.0
Epoch: [209][541/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 96.9	Acc@5 100.0
Epoch: [209][551/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [209][561/704]	Time 0.120	Data 0.001	Loss 2.59	Acc@1 89.1	Acc@5 100.0
Epoch: [209][571/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 90.6	Acc@5 100.0
Epoch: [209][581/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 92.2	Acc@5 100.0
Epoch: [209][591/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 84.4	Acc@5 100.0
Epoch: [209][601/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [209][611/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [209][621/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 87.5	Acc@5 98.4
Epoch: [209][631/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 90.6	Acc@5 100.0
Epoch: [209][641/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 89.1	Acc@5 100.0
Epoch: [209][651/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 89.1	Acc@5 98.4
Epoch: [209][661/704]	Time 0.120	Data 0.001	Loss 2.94	Acc@1 89.1	Acc@5 100.0
Epoch: [209][671/704]	Time 0.120	Data 0.001	Loss 2.89	Acc@1 90.6	Acc@5 100.0
Epoch: [209][681/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 87.5	Acc@5 100.0
Epoch: [209][691/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 81.2	Acc@5 100.0
Epoch: [209][701/704]	Time 0.120	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.7979	Acc@1 64.0625	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.0371	Acc@1 70.3125	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.9501	Acc@1 59.3750	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5648	Acc@1 56.2500	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.4506	Acc@1 70.3125	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8467	Acc@1 60.9375	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.9980	Acc@1 62.5000	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.6217	Acc@1 70.3125	Acc@5 93.7500
 * prec@1 56.400 prec@5 84.460
 * prec@1 60.720 prec@5 87.840
 * prec@1 65.380 prec@5 89.780
 * prec@1 67.400 prec@5 91.120
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_209.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_209.pth.tar'
Epoch: [210][1/704]	Time 0.329	Data 0.163	Loss 2.27	Acc@1 93.8	Acc@5 100.0
Epoch: [210][11/704]	Time 0.139	Data 0.015	Loss 2.72	Acc@1 82.8	Acc@5 100.0
Epoch: [210][21/704]	Time 0.130	Data 0.008	Loss 2.45	Acc@1 95.3	Acc@5 100.0
Epoch: [210][31/704]	Time 0.127	Data 0.006	Loss 2.25	Acc@1 87.5	Acc@5 100.0
Epoch: [210][41/704]	Time 0.125	Data 0.004	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [210][51/704]	Time 0.124	Data 0.004	Loss 2.36	Acc@1 89.1	Acc@5 98.4
Epoch: [210][61/704]	Time 0.123	Data 0.003	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [210][71/704]	Time 0.123	Data 0.003	Loss 2.41	Acc@1 95.3	Acc@5 100.0
Epoch: [210][81/704]	Time 0.123	Data 0.002	Loss 2.58	Acc@1 90.6	Acc@5 100.0
Epoch: [210][91/704]	Time 0.122	Data 0.002	Loss 2.78	Acc@1 89.1	Acc@5 98.4
Epoch: [210][101/704]	Time 0.122	Data 0.002	Loss 2.65	Acc@1 90.6	Acc@5 100.0
Epoch: [210][111/704]	Time 0.122	Data 0.002	Loss 2.41	Acc@1 90.6	Acc@5 98.4
Epoch: [210][121/704]	Time 0.122	Data 0.002	Loss 2.04	Acc@1 90.6	Acc@5 98.4
Epoch: [210][131/704]	Time 0.122	Data 0.002	Loss 1.95	Acc@1 98.4	Acc@5 100.0
Epoch: [210][141/704]	Time 0.122	Data 0.002	Loss 2.07	Acc@1 96.9	Acc@5 100.0
Epoch: [210][151/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [210][161/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 90.6	Acc@5 100.0
Epoch: [210][171/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 90.6	Acc@5 100.0
Epoch: [210][181/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [210][191/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 98.4
Epoch: [210][201/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [210][211/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [210][221/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [210][231/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 96.9	Acc@5 100.0
Epoch: [210][241/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 100.0
Epoch: [210][251/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [210][261/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 87.5	Acc@5 98.4
Epoch: [210][271/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [210][281/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 89.1	Acc@5 100.0
Epoch: [210][291/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [210][301/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [210][311/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 92.2	Acc@5 100.0
Epoch: [210][321/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 90.6	Acc@5 100.0
Epoch: [210][331/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [210][341/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 92.2	Acc@5 100.0
Epoch: [210][351/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 92.2	Acc@5 98.4
Epoch: [210][361/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [210][371/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 98.4
Epoch: [210][381/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 100.0
Epoch: [210][391/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 90.6	Acc@5 98.4
Epoch: [210][401/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 98.4
Epoch: [210][411/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [210][421/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 93.8	Acc@5 100.0
Epoch: [210][431/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [210][441/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 90.6	Acc@5 100.0
Epoch: [210][451/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 85.9	Acc@5 100.0
Epoch: [210][461/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [210][471/704]	Time 0.120	Data 0.001	Loss 3.00	Acc@1 87.5	Acc@5 98.4
Epoch: [210][481/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 98.4
Epoch: [210][491/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 90.6	Acc@5 98.4
Epoch: [210][501/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 96.9
Epoch: [210][511/704]	Time 0.120	Data 0.001	Loss 2.78	Acc@1 84.4	Acc@5 98.4
Epoch: [210][521/704]	Time 0.120	Data 0.001	Loss 2.71	Acc@1 87.5	Acc@5 98.4
Epoch: [210][531/704]	Time 0.120	Data 0.001	Loss 2.72	Acc@1 85.9	Acc@5 100.0
Epoch: [210][541/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [210][551/704]	Time 0.120	Data 0.001	Loss 3.02	Acc@1 82.8	Acc@5 98.4
Epoch: [210][561/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [210][571/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 93.8	Acc@5 100.0
Epoch: [210][581/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 90.6	Acc@5 100.0
Epoch: [210][591/704]	Time 0.120	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 98.4
Epoch: [210][601/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 98.4
Epoch: [210][611/704]	Time 0.120	Data 0.001	Loss 2.07	Acc@1 89.1	Acc@5 100.0
Epoch: [210][621/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 90.6	Acc@5 100.0
Epoch: [210][631/704]	Time 0.120	Data 0.001	Loss 2.33	Acc@1 85.9	Acc@5 100.0
Epoch: [210][641/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [210][651/704]	Time 0.120	Data 0.001	Loss 2.95	Acc@1 82.8	Acc@5 100.0
Epoch: [210][661/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 87.5	Acc@5 96.9
Epoch: [210][671/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 100.0
Epoch: [210][681/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 93.8	Acc@5 100.0
Epoch: [210][691/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 90.6	Acc@5 98.4
Epoch: [210][701/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.8487	Acc@1 73.4375	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.6935	Acc@1 64.0625	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2953	Acc@1 75.0000	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4226	Acc@1 68.7500	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.0780	Acc@1 76.5625	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.4277	Acc@1 51.5625	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4764	Acc@1 62.5000	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.3961	Acc@1 75.0000	Acc@5 95.3125
 * prec@1 56.840 prec@5 84.780
 * prec@1 61.460 prec@5 87.860
 * prec@1 65.500 prec@5 90.640
 * prec@1 67.480 prec@5 91.160
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_210.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_210.pth.tar'
Epoch: [211][1/704]	Time 0.331	Data 0.165	Loss 1.94	Acc@1 89.1	Acc@5 100.0
Epoch: [211][11/704]	Time 0.139	Data 0.015	Loss 2.73	Acc@1 89.1	Acc@5 100.0
Epoch: [211][21/704]	Time 0.130	Data 0.008	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [211][31/704]	Time 0.127	Data 0.006	Loss 2.35	Acc@1 82.8	Acc@5 100.0
Epoch: [211][41/704]	Time 0.125	Data 0.004	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [211][51/704]	Time 0.124	Data 0.004	Loss 2.07	Acc@1 90.6	Acc@5 98.4
Epoch: [211][61/704]	Time 0.123	Data 0.003	Loss 2.22	Acc@1 95.3	Acc@5 98.4
Epoch: [211][71/704]	Time 0.123	Data 0.003	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [211][81/704]	Time 0.122	Data 0.002	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [211][91/704]	Time 0.122	Data 0.002	Loss 3.00	Acc@1 85.9	Acc@5 93.8
Epoch: [211][101/704]	Time 0.122	Data 0.002	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [211][111/704]	Time 0.122	Data 0.002	Loss 2.11	Acc@1 92.2	Acc@5 96.9
Epoch: [211][121/704]	Time 0.122	Data 0.002	Loss 1.96	Acc@1 87.5	Acc@5 98.4
Epoch: [211][131/704]	Time 0.122	Data 0.002	Loss 2.25	Acc@1 92.2	Acc@5 100.0
Epoch: [211][141/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 98.4
Epoch: [211][151/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 92.2	Acc@5 100.0
Epoch: [211][161/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 92.2	Acc@5 100.0
Epoch: [211][171/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 98.4
Epoch: [211][181/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [211][191/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 98.4
Epoch: [211][201/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [211][211/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 90.6	Acc@5 98.4
Epoch: [211][221/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [211][231/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 98.4
Epoch: [211][241/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 89.1	Acc@5 100.0
Epoch: [211][251/704]	Time 0.121	Data 0.001	Loss 3.00	Acc@1 87.5	Acc@5 96.9
Epoch: [211][261/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 85.9	Acc@5 100.0
Epoch: [211][271/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [211][281/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 85.9	Acc@5 98.4
Epoch: [211][291/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [211][301/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 90.6	Acc@5 100.0
Epoch: [211][311/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 85.9	Acc@5 96.9
Epoch: [211][321/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [211][331/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 93.8	Acc@5 100.0
Epoch: [211][341/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 85.9	Acc@5 100.0
Epoch: [211][351/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 98.4
Epoch: [211][361/704]	Time 0.121	Data 0.001	Loss 2.79	Acc@1 90.6	Acc@5 96.9
Epoch: [211][371/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 87.5	Acc@5 100.0
Epoch: [211][381/704]	Time 0.120	Data 0.001	Loss 2.25	Acc@1 90.6	Acc@5 100.0
Epoch: [211][391/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 90.6	Acc@5 100.0
Epoch: [211][401/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [211][411/704]	Time 0.120	Data 0.001	Loss 2.34	Acc@1 93.8	Acc@5 100.0
Epoch: [211][421/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 98.4
Epoch: [211][431/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 100.0
Epoch: [211][441/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 100.0
Epoch: [211][451/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 96.9
Epoch: [211][461/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 96.9	Acc@5 100.0
Epoch: [211][471/704]	Time 0.120	Data 0.001	Loss 2.88	Acc@1 84.4	Acc@5 100.0
Epoch: [211][481/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [211][491/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 87.5	Acc@5 96.9
Epoch: [211][501/704]	Time 0.120	Data 0.001	Loss 3.21	Acc@1 79.7	Acc@5 98.4
Epoch: [211][511/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 98.4
Epoch: [211][521/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [211][531/704]	Time 0.120	Data 0.001	Loss 2.36	Acc@1 84.4	Acc@5 100.0
Epoch: [211][541/704]	Time 0.120	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 96.9
Epoch: [211][551/704]	Time 0.120	Data 0.001	Loss 2.49	Acc@1 90.6	Acc@5 98.4
Epoch: [211][561/704]	Time 0.120	Data 0.001	Loss 2.96	Acc@1 85.9	Acc@5 98.4
Epoch: [211][571/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 87.5	Acc@5 100.0
Epoch: [211][581/704]	Time 0.120	Data 0.001	Loss 2.48	Acc@1 84.4	Acc@5 100.0
Epoch: [211][591/704]	Time 0.120	Data 0.001	Loss 2.66	Acc@1 89.1	Acc@5 100.0
Epoch: [211][601/704]	Time 0.120	Data 0.001	Loss 3.77	Acc@1 82.8	Acc@5 100.0
Epoch: [211][611/704]	Time 0.120	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [211][621/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 93.8	Acc@5 100.0
Epoch: [211][631/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 92.2	Acc@5 100.0
Epoch: [211][641/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [211][651/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [211][661/704]	Time 0.120	Data 0.001	Loss 2.36	Acc@1 89.1	Acc@5 98.4
Epoch: [211][671/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 84.4	Acc@5 100.0
Epoch: [211][681/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [211][691/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 89.1	Acc@5 100.0
Epoch: [211][701/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.2041	Acc@1 68.7500	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.8651	Acc@1 64.0625	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2705	Acc@1 62.5000	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4039	Acc@1 59.3750	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.1350	Acc@1 70.3125	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9741	Acc@1 60.9375	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.0465	Acc@1 64.0625	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.4758	Acc@1 62.5000	Acc@5 95.3125
 * prec@1 57.400 prec@5 84.460
 * prec@1 61.200 prec@5 88.200
 * prec@1 65.900 prec@5 89.760
 * prec@1 67.300 prec@5 90.720
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_211.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_211.pth.tar'
Epoch: [212][1/704]	Time 0.298	Data 0.131	Loss 2.31	Acc@1 87.5	Acc@5 96.9
Epoch: [212][11/704]	Time 0.136	Data 0.012	Loss 3.42	Acc@1 85.9	Acc@5 100.0
Epoch: [212][21/704]	Time 0.128	Data 0.007	Loss 2.02	Acc@1 95.3	Acc@5 98.4
Epoch: [212][31/704]	Time 0.126	Data 0.005	Loss 2.41	Acc@1 90.6	Acc@5 100.0
Epoch: [212][41/704]	Time 0.124	Data 0.004	Loss 2.55	Acc@1 87.5	Acc@5 100.0
Epoch: [212][51/704]	Time 0.123	Data 0.003	Loss 1.76	Acc@1 98.4	Acc@5 100.0
Epoch: [212][61/704]	Time 0.123	Data 0.002	Loss 2.11	Acc@1 87.5	Acc@5 98.4
Epoch: [212][71/704]	Time 0.122	Data 0.002	Loss 2.03	Acc@1 92.2	Acc@5 98.4
Epoch: [212][81/704]	Time 0.122	Data 0.002	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [212][91/704]	Time 0.122	Data 0.002	Loss 2.44	Acc@1 87.5	Acc@5 100.0
Epoch: [212][101/704]	Time 0.122	Data 0.002	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [212][111/704]	Time 0.122	Data 0.001	Loss 2.31	Acc@1 89.1	Acc@5 96.9
Epoch: [212][121/704]	Time 0.122	Data 0.001	Loss 1.82	Acc@1 89.1	Acc@5 100.0
Epoch: [212][131/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [212][141/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 87.5	Acc@5 100.0
Epoch: [212][151/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 90.6	Acc@5 100.0
Epoch: [212][161/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 89.1	Acc@5 100.0
Epoch: [212][171/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [212][181/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [212][191/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 89.1	Acc@5 100.0
Epoch: [212][201/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [212][211/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 100.0
Epoch: [212][221/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 95.3	Acc@5 98.4
Epoch: [212][231/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 98.4
Epoch: [212][241/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 92.2	Acc@5 100.0
Epoch: [212][251/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 90.6	Acc@5 100.0
Epoch: [212][261/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 100.0
Epoch: [212][271/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 90.6	Acc@5 100.0
Epoch: [212][281/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [212][291/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 81.2	Acc@5 98.4
Epoch: [212][301/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 98.4
Epoch: [212][311/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 98.4
Epoch: [212][321/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 93.8	Acc@5 98.4
Epoch: [212][331/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [212][341/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 90.6	Acc@5 100.0
Epoch: [212][351/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 96.9	Acc@5 98.4
Epoch: [212][361/704]	Time 0.120	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [212][371/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 98.4
Epoch: [212][381/704]	Time 0.120	Data 0.001	Loss 2.82	Acc@1 85.9	Acc@5 98.4
Epoch: [212][391/704]	Time 0.120	Data 0.001	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [212][401/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 87.5	Acc@5 98.4
Epoch: [212][411/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [212][421/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [212][431/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 98.4
Epoch: [212][441/704]	Time 0.120	Data 0.001	Loss 2.75	Acc@1 85.9	Acc@5 100.0
Epoch: [212][451/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 90.6	Acc@5 96.9
Epoch: [212][461/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [212][471/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 87.5	Acc@5 100.0
Epoch: [212][481/704]	Time 0.120	Data 0.001	Loss 2.60	Acc@1 93.8	Acc@5 98.4
Epoch: [212][491/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [212][501/704]	Time 0.120	Data 0.001	Loss 2.86	Acc@1 90.6	Acc@5 98.4
Epoch: [212][511/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 92.2	Acc@5 98.4
Epoch: [212][521/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 93.8	Acc@5 100.0
Epoch: [212][531/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 90.6	Acc@5 100.0
Epoch: [212][541/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 89.1	Acc@5 100.0
Epoch: [212][551/704]	Time 0.120	Data 0.001	Loss 2.62	Acc@1 93.8	Acc@5 96.9
Epoch: [212][561/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 98.4
Epoch: [212][571/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 87.5	Acc@5 100.0
Epoch: [212][581/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 98.4
Epoch: [212][591/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [212][601/704]	Time 0.120	Data 0.001	Loss 2.94	Acc@1 82.8	Acc@5 100.0
Epoch: [212][611/704]	Time 0.120	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 100.0
Epoch: [212][621/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [212][631/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [212][641/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [212][651/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 95.3	Acc@5 100.0
Epoch: [212][661/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 85.9	Acc@5 98.4
Epoch: [212][671/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 85.9	Acc@5 100.0
Epoch: [212][681/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 92.2	Acc@5 98.4
Epoch: [212][691/704]	Time 0.120	Data 0.001	Loss 2.87	Acc@1 85.9	Acc@5 98.4
Epoch: [212][701/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.7677	Acc@1 59.3750	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 4.7654	Acc@1 76.5625	Acc@5 96.8750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8043	Acc@1 60.9375	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.6662	Acc@1 70.3125	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.1889	Acc@1 65.6250	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.7337	Acc@1 64.0625	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.2273	Acc@1 60.9375	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7768	Acc@1 64.0625	Acc@5 90.6250
 * prec@1 56.800 prec@5 84.720
 * prec@1 61.260 prec@5 87.560
 * prec@1 65.300 prec@5 90.100
 * prec@1 67.080 prec@5 90.500
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_212.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_212.pth.tar'
Epoch: [213][1/704]	Time 0.299	Data 0.131	Loss 2.09	Acc@1 96.9	Acc@5 100.0
Epoch: [213][11/704]	Time 0.140	Data 0.012	Loss 2.84	Acc@1 87.5	Acc@5 98.4
Epoch: [213][21/704]	Time 0.131	Data 0.007	Loss 1.84	Acc@1 89.1	Acc@5 98.4
Epoch: [213][31/704]	Time 0.127	Data 0.005	Loss 2.22	Acc@1 90.6	Acc@5 100.0
Epoch: [213][41/704]	Time 0.126	Data 0.004	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [213][51/704]	Time 0.124	Data 0.003	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [213][61/704]	Time 0.124	Data 0.002	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [213][71/704]	Time 0.123	Data 0.002	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [213][81/704]	Time 0.123	Data 0.002	Loss 1.64	Acc@1 93.8	Acc@5 98.4
Epoch: [213][91/704]	Time 0.123	Data 0.002	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [213][101/704]	Time 0.122	Data 0.002	Loss 1.45	Acc@1 93.8	Acc@5 100.0
Epoch: [213][111/704]	Time 0.122	Data 0.002	Loss 1.71	Acc@1 98.4	Acc@5 100.0
Epoch: [213][121/704]	Time 0.122	Data 0.001	Loss 2.11	Acc@1 92.2	Acc@5 100.0
Epoch: [213][131/704]	Time 0.122	Data 0.001	Loss 2.24	Acc@1 89.1	Acc@5 100.0
Epoch: [213][141/704]	Time 0.122	Data 0.001	Loss 2.07	Acc@1 87.5	Acc@5 100.0
Epoch: [213][151/704]	Time 0.122	Data 0.001	Loss 2.51	Acc@1 84.4	Acc@5 98.4
Epoch: [213][161/704]	Time 0.122	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 96.9
Epoch: [213][171/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 92.2	Acc@5 100.0
Epoch: [213][181/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 89.1	Acc@5 100.0
Epoch: [213][191/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [213][201/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [213][211/704]	Time 0.121	Data 0.001	Loss 3.19	Acc@1 93.8	Acc@5 100.0
Epoch: [213][221/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 90.6	Acc@5 100.0
Epoch: [213][231/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [213][241/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [213][251/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 85.9	Acc@5 98.4
Epoch: [213][261/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 87.5	Acc@5 100.0
Epoch: [213][271/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [213][281/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [213][291/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 100.0	Acc@5 100.0
Epoch: [213][301/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 85.9	Acc@5 100.0
Epoch: [213][311/704]	Time 0.121	Data 0.001	Loss 2.75	Acc@1 87.5	Acc@5 98.4
Epoch: [213][321/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 100.0	Acc@5 100.0
Epoch: [213][331/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [213][341/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 87.5	Acc@5 100.0
Epoch: [213][351/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [213][361/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [213][371/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 85.9	Acc@5 96.9
Epoch: [213][381/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 92.2	Acc@5 100.0
Epoch: [213][391/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 85.9	Acc@5 98.4
Epoch: [213][401/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 92.2	Acc@5 100.0
Epoch: [213][411/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 78.1	Acc@5 98.4
Epoch: [213][421/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [213][431/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 89.1	Acc@5 96.9
Epoch: [213][441/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 92.2	Acc@5 100.0
Epoch: [213][451/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [213][461/704]	Time 0.121	Data 0.001	Loss 3.05	Acc@1 90.6	Acc@5 100.0
Epoch: [213][471/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 100.0
Epoch: [213][481/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 84.4	Acc@5 100.0
Epoch: [213][491/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 89.1	Acc@5 100.0
Epoch: [213][501/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 100.0
Epoch: [213][511/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 89.1	Acc@5 100.0
Epoch: [213][521/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 100.0
Epoch: [213][531/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 87.5	Acc@5 100.0
Epoch: [213][541/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 96.9	Acc@5 100.0
Epoch: [213][551/704]	Time 0.121	Data 0.001	Loss 3.49	Acc@1 78.1	Acc@5 98.4
Epoch: [213][561/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 87.5	Acc@5 96.9
Epoch: [213][571/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 90.6	Acc@5 98.4
Epoch: [213][581/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 89.1	Acc@5 98.4
Epoch: [213][591/704]	Time 0.121	Data 0.001	Loss 3.09	Acc@1 92.2	Acc@5 100.0
Epoch: [213][601/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 100.0
Epoch: [213][611/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [213][621/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 85.9	Acc@5 98.4
Epoch: [213][631/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [213][641/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 87.5	Acc@5 100.0
Epoch: [213][651/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 89.1	Acc@5 100.0
Epoch: [213][661/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 96.9	Acc@5 98.4
Epoch: [213][671/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 84.4	Acc@5 100.0
Epoch: [213][681/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 98.4
Epoch: [213][691/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 92.2	Acc@5 100.0
Epoch: [213][701/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 89.1	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.8784	Acc@1 60.9375	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.1870	Acc@1 57.8125	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.4763	Acc@1 64.0625	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7985	Acc@1 65.6250	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.1807	Acc@1 65.6250	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.5525	Acc@1 75.0000	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.3583	Acc@1 62.5000	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.0001	Acc@1 56.2500	Acc@5 89.0625
 * prec@1 57.500 prec@5 84.400
 * prec@1 61.400 prec@5 87.480
 * prec@1 65.720 prec@5 90.020
 * prec@1 66.580 prec@5 90.580
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_213.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_213.pth.tar'
Epoch: [214][1/704]	Time 0.328	Data 0.162	Loss 2.28	Acc@1 87.5	Acc@5 100.0
Epoch: [214][11/704]	Time 0.139	Data 0.015	Loss 2.24	Acc@1 96.9	Acc@5 100.0
Epoch: [214][21/704]	Time 0.130	Data 0.008	Loss 2.05	Acc@1 93.8	Acc@5 98.4
Epoch: [214][31/704]	Time 0.127	Data 0.006	Loss 2.55	Acc@1 92.2	Acc@5 100.0
Epoch: [214][41/704]	Time 0.125	Data 0.004	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [214][51/704]	Time 0.124	Data 0.004	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [214][61/704]	Time 0.123	Data 0.003	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [214][71/704]	Time 0.123	Data 0.003	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [214][81/704]	Time 0.122	Data 0.002	Loss 1.87	Acc@1 90.6	Acc@5 100.0
Epoch: [214][91/704]	Time 0.122	Data 0.002	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [214][101/704]	Time 0.122	Data 0.002	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [214][111/704]	Time 0.122	Data 0.002	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [214][121/704]	Time 0.121	Data 0.002	Loss 2.97	Acc@1 87.5	Acc@5 95.3
Epoch: [214][131/704]	Time 0.121	Data 0.002	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [214][141/704]	Time 0.121	Data 0.002	Loss 2.38	Acc@1 90.6	Acc@5 100.0
Epoch: [214][151/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 85.9	Acc@5 100.0
Epoch: [214][161/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 96.9	Acc@5 100.0
Epoch: [214][171/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 89.1	Acc@5 98.4
Epoch: [214][181/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [214][191/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 98.4
Epoch: [214][201/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [214][211/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 87.5	Acc@5 100.0
Epoch: [214][221/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 95.3	Acc@5 98.4
Epoch: [214][231/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [214][241/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 98.4
Epoch: [214][251/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 100.0
Epoch: [214][261/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 98.4
Epoch: [214][271/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [214][281/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [214][291/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 89.1	Acc@5 100.0
Epoch: [214][301/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [214][311/704]	Time 0.120	Data 0.001	Loss 2.33	Acc@1 90.6	Acc@5 98.4
Epoch: [214][321/704]	Time 0.120	Data 0.001	Loss 2.07	Acc@1 96.9	Acc@5 100.0
Epoch: [214][331/704]	Time 0.120	Data 0.001	Loss 2.87	Acc@1 82.8	Acc@5 100.0
Epoch: [214][341/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 95.3	Acc@5 100.0
Epoch: [214][351/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [214][361/704]	Time 0.120	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [214][371/704]	Time 0.120	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [214][381/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 100.0
Epoch: [214][391/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [214][401/704]	Time 0.120	Data 0.001	Loss 2.49	Acc@1 92.2	Acc@5 100.0
Epoch: [214][411/704]	Time 0.120	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [214][421/704]	Time 0.120	Data 0.001	Loss 2.52	Acc@1 92.2	Acc@5 100.0
Epoch: [214][431/704]	Time 0.120	Data 0.001	Loss 2.36	Acc@1 96.9	Acc@5 100.0
Epoch: [214][441/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 87.5	Acc@5 100.0
Epoch: [214][451/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 90.6	Acc@5 98.4
Epoch: [214][461/704]	Time 0.120	Data 0.001	Loss 2.23	Acc@1 89.1	Acc@5 98.4
Epoch: [214][471/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [214][481/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 87.5	Acc@5 98.4
Epoch: [214][491/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 87.5	Acc@5 98.4
Epoch: [214][501/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 92.2	Acc@5 100.0
Epoch: [214][511/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [214][521/704]	Time 0.120	Data 0.001	Loss 2.77	Acc@1 90.6	Acc@5 98.4
Epoch: [214][531/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 85.9	Acc@5 98.4
Epoch: [214][541/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 89.1	Acc@5 100.0
Epoch: [214][551/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [214][561/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 84.4	Acc@5 100.0
Epoch: [214][571/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 98.4
Epoch: [214][581/704]	Time 0.120	Data 0.001	Loss 2.75	Acc@1 89.1	Acc@5 100.0
Epoch: [214][591/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 85.9	Acc@5 100.0
Epoch: [214][601/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [214][611/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [214][621/704]	Time 0.120	Data 0.001	Loss 2.64	Acc@1 89.1	Acc@5 98.4
Epoch: [214][631/704]	Time 0.120	Data 0.001	Loss 2.95	Acc@1 84.4	Acc@5 98.4
Epoch: [214][641/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 90.6	Acc@5 100.0
Epoch: [214][651/704]	Time 0.120	Data 0.001	Loss 2.37	Acc@1 87.5	Acc@5 100.0
Epoch: [214][661/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 89.1	Acc@5 98.4
Epoch: [214][671/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 98.4
Epoch: [214][681/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 98.4
Epoch: [214][691/704]	Time 0.120	Data 0.001	Loss 2.52	Acc@1 90.6	Acc@5 100.0
Epoch: [214][701/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 85.9	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.9159	Acc@1 70.3125	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.2773	Acc@1 70.3125	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2642	Acc@1 67.1875	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.1398	Acc@1 71.8750	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.3367	Acc@1 71.8750	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.4624	Acc@1 68.7500	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7476	Acc@1 70.3125	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.1988	Acc@1 71.8750	Acc@5 92.1875
 * prec@1 57.460 prec@5 84.580
 * prec@1 61.560 prec@5 88.140
 * prec@1 65.400 prec@5 90.620
 * prec@1 67.880 prec@5 90.900
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_214.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_214.pth.tar'
Epoch: [215][1/704]	Time 0.299	Data 0.132	Loss 1.88	Acc@1 89.1	Acc@5 100.0
Epoch: [215][11/704]	Time 0.136	Data 0.012	Loss 2.27	Acc@1 93.8	Acc@5 98.4
Epoch: [215][21/704]	Time 0.129	Data 0.007	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [215][31/704]	Time 0.126	Data 0.005	Loss 2.58	Acc@1 87.5	Acc@5 98.4
Epoch: [215][41/704]	Time 0.124	Data 0.004	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [215][51/704]	Time 0.123	Data 0.003	Loss 2.76	Acc@1 90.6	Acc@5 100.0
Epoch: [215][61/704]	Time 0.123	Data 0.003	Loss 2.02	Acc@1 95.3	Acc@5 100.0
Epoch: [215][71/704]	Time 0.122	Data 0.002	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [215][81/704]	Time 0.122	Data 0.002	Loss 2.97	Acc@1 89.1	Acc@5 100.0
Epoch: [215][91/704]	Time 0.122	Data 0.002	Loss 2.16	Acc@1 87.5	Acc@5 100.0
Epoch: [215][101/704]	Time 0.122	Data 0.002	Loss 2.56	Acc@1 90.6	Acc@5 100.0
Epoch: [215][111/704]	Time 0.122	Data 0.002	Loss 2.29	Acc@1 87.5	Acc@5 98.4
Epoch: [215][121/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 93.8	Acc@5 100.0
Epoch: [215][131/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 98.4
Epoch: [215][141/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 89.1	Acc@5 100.0
Epoch: [215][151/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [215][161/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 89.1	Acc@5 100.0
Epoch: [215][171/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 89.1	Acc@5 98.4
Epoch: [215][181/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 96.9	Acc@5 100.0
Epoch: [215][191/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 89.1	Acc@5 100.0
Epoch: [215][201/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 84.4	Acc@5 100.0
Epoch: [215][211/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 84.4	Acc@5 96.9
Epoch: [215][221/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [215][231/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 98.4
Epoch: [215][241/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 89.1	Acc@5 100.0
Epoch: [215][251/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 92.2	Acc@5 100.0
Epoch: [215][261/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 89.1	Acc@5 100.0
Epoch: [215][271/704]	Time 0.121	Data 0.001	Loss 2.85	Acc@1 87.5	Acc@5 100.0
Epoch: [215][281/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 100.0
Epoch: [215][291/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 98.4
Epoch: [215][301/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 84.4	Acc@5 100.0
Epoch: [215][311/704]	Time 0.121	Data 0.001	Loss 2.78	Acc@1 84.4	Acc@5 95.3
Epoch: [215][321/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 87.5	Acc@5 100.0
Epoch: [215][331/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 89.1	Acc@5 100.0
Epoch: [215][341/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 100.0
Epoch: [215][351/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 92.2	Acc@5 100.0
Epoch: [215][361/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 93.8	Acc@5 100.0
Epoch: [215][371/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [215][381/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 98.4
Epoch: [215][391/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 87.5	Acc@5 98.4
Epoch: [215][401/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 90.6	Acc@5 100.0
Epoch: [215][411/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 93.8	Acc@5 100.0
Epoch: [215][421/704]	Time 0.120	Data 0.001	Loss 2.66	Acc@1 85.9	Acc@5 100.0
Epoch: [215][431/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [215][441/704]	Time 0.120	Data 0.001	Loss 3.16	Acc@1 84.4	Acc@5 98.4
Epoch: [215][451/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 98.4	Acc@5 100.0
Epoch: [215][461/704]	Time 0.120	Data 0.001	Loss 3.29	Acc@1 76.6	Acc@5 100.0
Epoch: [215][471/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 100.0
Epoch: [215][481/704]	Time 0.120	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 98.4
Epoch: [215][491/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [215][501/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 87.5	Acc@5 100.0
Epoch: [215][511/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 92.2	Acc@5 100.0
Epoch: [215][521/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 87.5	Acc@5 100.0
Epoch: [215][531/704]	Time 0.120	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [215][541/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [215][551/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 98.4
Epoch: [215][561/704]	Time 0.120	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [215][571/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 100.0
Epoch: [215][581/704]	Time 0.120	Data 0.001	Loss 3.11	Acc@1 85.9	Acc@5 98.4
Epoch: [215][591/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [215][601/704]	Time 0.120	Data 0.001	Loss 2.44	Acc@1 87.5	Acc@5 98.4
Epoch: [215][611/704]	Time 0.120	Data 0.001	Loss 3.60	Acc@1 79.7	Acc@5 96.9
Epoch: [215][621/704]	Time 0.120	Data 0.001	Loss 2.44	Acc@1 93.8	Acc@5 98.4
Epoch: [215][631/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [215][641/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 87.5	Acc@5 98.4
Epoch: [215][651/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 87.5	Acc@5 100.0
Epoch: [215][661/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [215][671/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [215][681/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 85.9	Acc@5 100.0
Epoch: [215][691/704]	Time 0.120	Data 0.001	Loss 3.04	Acc@1 87.5	Acc@5 98.4
Epoch: [215][701/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 84.4	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.7522	Acc@1 64.0625	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.2891	Acc@1 73.4375	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.1798	Acc@1 64.0625	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.7337	Acc@1 81.2500	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.1778	Acc@1 70.3125	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.1122	Acc@1 68.7500	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.5651	Acc@1 64.0625	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.6773	Acc@1 57.8125	Acc@5 79.6875
 * prec@1 56.880 prec@5 84.760
 * prec@1 60.760 prec@5 88.100
 * prec@1 66.060 prec@5 90.080
 * prec@1 68.440 prec@5 90.880
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_215.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_215.pth.tar'
Epoch: [216][1/704]	Time 0.297	Data 0.130	Loss 2.90	Acc@1 90.6	Acc@5 98.4
Epoch: [216][11/704]	Time 0.136	Data 0.012	Loss 2.25	Acc@1 85.9	Acc@5 98.4
Epoch: [216][21/704]	Time 0.128	Data 0.007	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [216][31/704]	Time 0.126	Data 0.005	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [216][41/704]	Time 0.124	Data 0.004	Loss 2.46	Acc@1 85.9	Acc@5 100.0
Epoch: [216][51/704]	Time 0.123	Data 0.003	Loss 1.75	Acc@1 92.2	Acc@5 100.0
Epoch: [216][61/704]	Time 0.124	Data 0.002	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [216][71/704]	Time 0.123	Data 0.002	Loss 2.48	Acc@1 93.8	Acc@5 100.0
Epoch: [216][81/704]	Time 0.123	Data 0.002	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [216][91/704]	Time 0.122	Data 0.002	Loss 2.94	Acc@1 90.6	Acc@5 100.0
Epoch: [216][101/704]	Time 0.122	Data 0.002	Loss 2.41	Acc@1 90.6	Acc@5 98.4
Epoch: [216][111/704]	Time 0.122	Data 0.002	Loss 2.05	Acc@1 89.1	Acc@5 100.0
Epoch: [216][121/704]	Time 0.122	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [216][131/704]	Time 0.122	Data 0.001	Loss 2.63	Acc@1 87.5	Acc@5 98.4
Epoch: [216][141/704]	Time 0.122	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 98.4
Epoch: [216][151/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [216][161/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 89.1	Acc@5 100.0
Epoch: [216][171/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 85.9	Acc@5 100.0
Epoch: [216][181/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 90.6	Acc@5 98.4
Epoch: [216][191/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 84.4	Acc@5 100.0
Epoch: [216][201/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 98.4
Epoch: [216][211/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 85.9	Acc@5 98.4
Epoch: [216][221/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 90.6	Acc@5 100.0
Epoch: [216][231/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 87.5	Acc@5 100.0
Epoch: [216][241/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 81.2	Acc@5 98.4
Epoch: [216][251/704]	Time 0.121	Data 0.001	Loss 3.28	Acc@1 81.2	Acc@5 100.0
Epoch: [216][261/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 89.1	Acc@5 100.0
Epoch: [216][271/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 93.8	Acc@5 100.0
Epoch: [216][281/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 92.2	Acc@5 100.0
Epoch: [216][291/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [216][301/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [216][311/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [216][321/704]	Time 0.121	Data 0.001	Loss 2.68	Acc@1 82.8	Acc@5 96.9
Epoch: [216][331/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 92.2	Acc@5 100.0
Epoch: [216][341/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 92.2	Acc@5 100.0
Epoch: [216][351/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 90.6	Acc@5 100.0
Epoch: [216][361/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [216][371/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 90.6	Acc@5 98.4
Epoch: [216][381/704]	Time 0.121	Data 0.001	Loss 2.88	Acc@1 93.8	Acc@5 100.0
Epoch: [216][391/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [216][401/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 92.2	Acc@5 100.0
Epoch: [216][411/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 87.5	Acc@5 100.0
Epoch: [216][421/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 100.0
Epoch: [216][431/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 87.5	Acc@5 98.4
Epoch: [216][441/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [216][451/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 90.6	Acc@5 100.0
Epoch: [216][461/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 95.3
Epoch: [216][471/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [216][481/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 84.4	Acc@5 96.9
Epoch: [216][491/704]	Time 0.120	Data 0.001	Loss 2.80	Acc@1 89.1	Acc@5 100.0
Epoch: [216][501/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 85.9	Acc@5 96.9
Epoch: [216][511/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 98.4
Epoch: [216][521/704]	Time 0.120	Data 0.001	Loss 2.70	Acc@1 92.2	Acc@5 98.4
Epoch: [216][531/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 84.4	Acc@5 98.4
Epoch: [216][541/704]	Time 0.120	Data 0.001	Loss 2.93	Acc@1 87.5	Acc@5 100.0
Epoch: [216][551/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 92.2	Acc@5 98.4
Epoch: [216][561/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 93.8	Acc@5 98.4
Epoch: [216][571/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 98.4
Epoch: [216][581/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [216][591/704]	Time 0.120	Data 0.001	Loss 2.49	Acc@1 81.2	Acc@5 100.0
Epoch: [216][601/704]	Time 0.120	Data 0.001	Loss 2.72	Acc@1 89.1	Acc@5 98.4
Epoch: [216][611/704]	Time 0.120	Data 0.001	Loss 2.74	Acc@1 85.9	Acc@5 100.0
Epoch: [216][621/704]	Time 0.120	Data 0.001	Loss 2.63	Acc@1 84.4	Acc@5 100.0
Epoch: [216][631/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 89.1	Acc@5 100.0
Epoch: [216][641/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 89.1	Acc@5 100.0
Epoch: [216][651/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 82.8	Acc@5 100.0
Epoch: [216][661/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 89.1	Acc@5 100.0
Epoch: [216][671/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 84.4	Acc@5 100.0
Epoch: [216][681/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [216][691/704]	Time 0.120	Data 0.001	Loss 2.87	Acc@1 89.1	Acc@5 98.4
Epoch: [216][701/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.6116	Acc@1 60.9375	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.9827	Acc@1 64.0625	Acc@5 96.8750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.6602	Acc@1 68.7500	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.6299	Acc@1 71.8750	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7706	Acc@1 62.5000	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.2157	Acc@1 60.9375	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.4572	Acc@1 65.6250	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.0764	Acc@1 75.0000	Acc@5 85.9375
 * prec@1 56.020 prec@5 84.100
 * prec@1 62.100 prec@5 87.320
 * prec@1 65.620 prec@5 89.980
 * prec@1 66.520 prec@5 90.120
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_216.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_216.pth.tar'
Epoch: [217][1/704]	Time 0.330	Data 0.165	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [217][11/704]	Time 0.139	Data 0.015	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [217][21/704]	Time 0.130	Data 0.008	Loss 2.42	Acc@1 87.5	Acc@5 100.0
Epoch: [217][31/704]	Time 0.127	Data 0.006	Loss 2.10	Acc@1 89.1	Acc@5 100.0
Epoch: [217][41/704]	Time 0.125	Data 0.004	Loss 2.36	Acc@1 87.5	Acc@5 100.0
Epoch: [217][51/704]	Time 0.124	Data 0.004	Loss 2.60	Acc@1 89.1	Acc@5 100.0
Epoch: [217][61/704]	Time 0.123	Data 0.003	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [217][71/704]	Time 0.123	Data 0.003	Loss 2.36	Acc@1 87.5	Acc@5 98.4
Epoch: [217][81/704]	Time 0.122	Data 0.002	Loss 2.28	Acc@1 92.2	Acc@5 98.4
Epoch: [217][91/704]	Time 0.122	Data 0.002	Loss 2.36	Acc@1 85.9	Acc@5 98.4
Epoch: [217][101/704]	Time 0.122	Data 0.002	Loss 1.99	Acc@1 90.6	Acc@5 100.0
Epoch: [217][111/704]	Time 0.122	Data 0.002	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [217][121/704]	Time 0.121	Data 0.002	Loss 2.35	Acc@1 96.9	Acc@5 100.0
Epoch: [217][131/704]	Time 0.121	Data 0.002	Loss 2.70	Acc@1 84.4	Acc@5 100.0
Epoch: [217][141/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 93.8	Acc@5 100.0
Epoch: [217][151/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 98.4
Epoch: [217][161/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 93.8	Acc@5 100.0
Epoch: [217][171/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 98.4
Epoch: [217][181/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [217][191/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 92.2	Acc@5 100.0
Epoch: [217][201/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [217][211/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 93.8	Acc@5 98.4
Epoch: [217][221/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 92.2	Acc@5 98.4
Epoch: [217][231/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 84.4	Acc@5 100.0
Epoch: [217][241/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 87.5	Acc@5 100.0
Epoch: [217][251/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 92.2	Acc@5 98.4
Epoch: [217][261/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 89.1	Acc@5 100.0
Epoch: [217][271/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 87.5	Acc@5 100.0
Epoch: [217][281/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 87.5	Acc@5 100.0
Epoch: [217][291/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 98.4	Acc@5 100.0
Epoch: [217][301/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [217][311/704]	Time 0.120	Data 0.001	Loss 1.79	Acc@1 90.6	Acc@5 98.4
Epoch: [217][321/704]	Time 0.120	Data 0.001	Loss 2.28	Acc@1 93.8	Acc@5 98.4
Epoch: [217][331/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 89.1	Acc@5 100.0
Epoch: [217][341/704]	Time 0.120	Data 0.001	Loss 2.61	Acc@1 90.6	Acc@5 98.4
Epoch: [217][351/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [217][361/704]	Time 0.120	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [217][371/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 89.1	Acc@5 98.4
Epoch: [217][381/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 87.5	Acc@5 100.0
Epoch: [217][391/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 100.0
Epoch: [217][401/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 98.4	Acc@5 100.0
Epoch: [217][411/704]	Time 0.120	Data 0.001	Loss 2.82	Acc@1 78.1	Acc@5 100.0
Epoch: [217][421/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 87.5	Acc@5 100.0
Epoch: [217][431/704]	Time 0.120	Data 0.001	Loss 2.44	Acc@1 93.8	Acc@5 100.0
Epoch: [217][441/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 89.1	Acc@5 98.4
Epoch: [217][451/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [217][461/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 87.5	Acc@5 100.0
Epoch: [217][471/704]	Time 0.120	Data 0.001	Loss 2.65	Acc@1 89.1	Acc@5 100.0
Epoch: [217][481/704]	Time 0.120	Data 0.001	Loss 3.17	Acc@1 85.9	Acc@5 100.0
Epoch: [217][491/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [217][501/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 89.1	Acc@5 100.0
Epoch: [217][511/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [217][521/704]	Time 0.120	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [217][531/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 89.1	Acc@5 100.0
Epoch: [217][541/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 87.5	Acc@5 100.0
Epoch: [217][551/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 90.6	Acc@5 100.0
Epoch: [217][561/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 90.6	Acc@5 100.0
Epoch: [217][571/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 98.4
Epoch: [217][581/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 82.8	Acc@5 100.0
Epoch: [217][591/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 85.9	Acc@5 100.0
Epoch: [217][601/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 87.5	Acc@5 100.0
Epoch: [217][611/704]	Time 0.120	Data 0.001	Loss 3.06	Acc@1 89.1	Acc@5 100.0
Epoch: [217][621/704]	Time 0.120	Data 0.001	Loss 2.81	Acc@1 85.9	Acc@5 98.4
Epoch: [217][631/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 98.4
Epoch: [217][641/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 87.5	Acc@5 100.0
Epoch: [217][651/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 87.5	Acc@5 100.0
Epoch: [217][661/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [217][671/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 87.5	Acc@5 98.4
Epoch: [217][681/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [217][691/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 90.6	Acc@5 100.0
Epoch: [217][701/704]	Time 0.120	Data 0.001	Loss 2.52	Acc@1 87.5	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.6734	Acc@1 65.6250	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.8164	Acc@1 75.0000	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.5670	Acc@1 64.0625	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.9374	Acc@1 60.9375	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3539	Acc@1 68.7500	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.8670	Acc@1 78.1250	Acc@5 98.4375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.9615	Acc@1 65.6250	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.8627	Acc@1 60.9375	Acc@5 81.2500
 * prec@1 56.440 prec@5 85.020
 * prec@1 61.940 prec@5 88.340
 * prec@1 66.300 prec@5 90.520
 * prec@1 66.860 prec@5 91.260
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_217.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_217.pth.tar'
Epoch: [218][1/704]	Time 0.329	Data 0.163	Loss 2.18	Acc@1 93.8	Acc@5 96.9
Epoch: [218][11/704]	Time 0.139	Data 0.015	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [218][21/704]	Time 0.130	Data 0.008	Loss 1.98	Acc@1 89.1	Acc@5 100.0
Epoch: [218][31/704]	Time 0.127	Data 0.006	Loss 2.54	Acc@1 85.9	Acc@5 100.0
Epoch: [218][41/704]	Time 0.125	Data 0.004	Loss 2.10	Acc@1 93.8	Acc@5 100.0
Epoch: [218][51/704]	Time 0.124	Data 0.004	Loss 2.61	Acc@1 92.2	Acc@5 100.0
Epoch: [218][61/704]	Time 0.123	Data 0.003	Loss 2.70	Acc@1 92.2	Acc@5 100.0
Epoch: [218][71/704]	Time 0.123	Data 0.003	Loss 2.82	Acc@1 87.5	Acc@5 100.0
Epoch: [218][81/704]	Time 0.122	Data 0.002	Loss 1.99	Acc@1 87.5	Acc@5 100.0
Epoch: [218][91/704]	Time 0.122	Data 0.002	Loss 2.20	Acc@1 87.5	Acc@5 98.4
Epoch: [218][101/704]	Time 0.122	Data 0.002	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [218][111/704]	Time 0.122	Data 0.002	Loss 2.18	Acc@1 92.2	Acc@5 100.0
Epoch: [218][121/704]	Time 0.121	Data 0.002	Loss 2.09	Acc@1 95.3	Acc@5 100.0
Epoch: [218][131/704]	Time 0.121	Data 0.002	Loss 2.20	Acc@1 95.3	Acc@5 100.0
Epoch: [218][141/704]	Time 0.121	Data 0.002	Loss 2.11	Acc@1 95.3	Acc@5 98.4
Epoch: [218][151/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 87.5	Acc@5 96.9
Epoch: [218][161/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [218][171/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 87.5	Acc@5 100.0
Epoch: [218][181/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 87.5	Acc@5 100.0
Epoch: [218][191/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [218][201/704]	Time 0.121	Data 0.001	Loss 3.35	Acc@1 89.1	Acc@5 100.0
Epoch: [218][211/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [218][221/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 89.1	Acc@5 100.0
Epoch: [218][231/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 98.4
Epoch: [218][241/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 95.3	Acc@5 100.0
Epoch: [218][251/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 81.2	Acc@5 98.4
Epoch: [218][261/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 84.4	Acc@5 96.9
Epoch: [218][271/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 85.9	Acc@5 100.0
Epoch: [218][281/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 92.2	Acc@5 100.0
Epoch: [218][291/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [218][301/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [218][311/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [218][321/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 85.9	Acc@5 100.0
Epoch: [218][331/704]	Time 0.120	Data 0.001	Loss 2.09	Acc@1 95.3	Acc@5 100.0
Epoch: [218][341/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [218][351/704]	Time 0.120	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [218][361/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 92.2	Acc@5 100.0
Epoch: [218][371/704]	Time 0.120	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 100.0
Epoch: [218][381/704]	Time 0.120	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [218][391/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 87.5	Acc@5 100.0
Epoch: [218][401/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 90.6	Acc@5 100.0
Epoch: [218][411/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [218][421/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 100.0
Epoch: [218][431/704]	Time 0.120	Data 0.001	Loss 2.53	Acc@1 92.2	Acc@5 98.4
Epoch: [218][441/704]	Time 0.120	Data 0.001	Loss 2.85	Acc@1 78.1	Acc@5 96.9
Epoch: [218][451/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 90.6	Acc@5 100.0
Epoch: [218][461/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 100.0
Epoch: [218][471/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 85.9	Acc@5 100.0
Epoch: [218][481/704]	Time 0.120	Data 0.001	Loss 2.71	Acc@1 84.4	Acc@5 100.0
Epoch: [218][491/704]	Time 0.120	Data 0.001	Loss 2.50	Acc@1 93.8	Acc@5 98.4
Epoch: [218][501/704]	Time 0.120	Data 0.001	Loss 3.02	Acc@1 92.2	Acc@5 100.0
Epoch: [218][511/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 89.1	Acc@5 98.4
Epoch: [218][521/704]	Time 0.120	Data 0.001	Loss 2.63	Acc@1 89.1	Acc@5 100.0
Epoch: [218][531/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 93.8	Acc@5 100.0
Epoch: [218][541/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 87.5	Acc@5 98.4
Epoch: [218][551/704]	Time 0.120	Data 0.001	Loss 2.37	Acc@1 87.5	Acc@5 100.0
Epoch: [218][561/704]	Time 0.120	Data 0.001	Loss 3.04	Acc@1 90.6	Acc@5 100.0
Epoch: [218][571/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 85.9	Acc@5 100.0
Epoch: [218][581/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 90.6	Acc@5 100.0
Epoch: [218][591/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 90.6	Acc@5 100.0
Epoch: [218][601/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [218][611/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [218][621/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 89.1	Acc@5 100.0
Epoch: [218][631/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 98.4
Epoch: [218][641/704]	Time 0.120	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 98.4
Epoch: [218][651/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 84.4	Acc@5 100.0
Epoch: [218][661/704]	Time 0.120	Data 0.001	Loss 2.79	Acc@1 89.1	Acc@5 100.0
Epoch: [218][671/704]	Time 0.120	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 100.0
Epoch: [218][681/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [218][691/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 84.4	Acc@5 100.0
Epoch: [218][701/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 82.8	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5226	Acc@1 62.5000	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.5681	Acc@1 68.7500	Acc@5 96.8750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.9956	Acc@1 59.3750	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.2302	Acc@1 76.5625	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.4952	Acc@1 73.4375	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.8827	Acc@1 62.5000	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.1036	Acc@1 64.0625	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.2523	Acc@1 62.5000	Acc@5 90.6250
 * prec@1 56.860 prec@5 84.860
 * prec@1 61.020 prec@5 87.540
 * prec@1 65.020 prec@5 90.580
 * prec@1 66.680 prec@5 90.820
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_218.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_218.pth.tar'
Epoch: [219][1/704]	Time 0.299	Data 0.131	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [219][11/704]	Time 0.137	Data 0.012	Loss 2.33	Acc@1 87.5	Acc@5 96.9
Epoch: [219][21/704]	Time 0.129	Data 0.007	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [219][31/704]	Time 0.126	Data 0.005	Loss 2.34	Acc@1 87.5	Acc@5 100.0
Epoch: [219][41/704]	Time 0.124	Data 0.004	Loss 2.74	Acc@1 89.1	Acc@5 100.0
Epoch: [219][51/704]	Time 0.123	Data 0.003	Loss 2.13	Acc@1 90.6	Acc@5 100.0
Epoch: [219][61/704]	Time 0.123	Data 0.002	Loss 1.71	Acc@1 89.1	Acc@5 100.0
Epoch: [219][71/704]	Time 0.122	Data 0.002	Loss 2.86	Acc@1 85.9	Acc@5 100.0
Epoch: [219][81/704]	Time 0.122	Data 0.002	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [219][91/704]	Time 0.122	Data 0.002	Loss 2.05	Acc@1 95.3	Acc@5 100.0
Epoch: [219][101/704]	Time 0.122	Data 0.002	Loss 2.20	Acc@1 90.6	Acc@5 98.4
Epoch: [219][111/704]	Time 0.122	Data 0.002	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [219][121/704]	Time 0.122	Data 0.001	Loss 2.35	Acc@1 92.2	Acc@5 100.0
Epoch: [219][131/704]	Time 0.122	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [219][141/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 96.9
Epoch: [219][151/704]	Time 0.121	Data 0.001	Loss 2.91	Acc@1 84.4	Acc@5 98.4
Epoch: [219][161/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [219][171/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 89.1	Acc@5 100.0
Epoch: [219][181/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 90.6	Acc@5 100.0
Epoch: [219][191/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 84.4	Acc@5 98.4
Epoch: [219][201/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 98.4
Epoch: [219][211/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 95.3	Acc@5 100.0
Epoch: [219][221/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 98.4	Acc@5 100.0
Epoch: [219][231/704]	Time 0.121	Data 0.001	Loss 3.11	Acc@1 89.1	Acc@5 98.4
Epoch: [219][241/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 89.1	Acc@5 100.0
Epoch: [219][251/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [219][261/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 90.6	Acc@5 100.0
Epoch: [219][271/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 95.3	Acc@5 100.0
Epoch: [219][281/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 92.2	Acc@5 98.4
Epoch: [219][291/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [219][301/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 93.8	Acc@5 100.0
Epoch: [219][311/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 87.5	Acc@5 98.4
Epoch: [219][321/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 93.8	Acc@5 100.0
Epoch: [219][331/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 90.6	Acc@5 100.0
Epoch: [219][341/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 87.5	Acc@5 100.0
Epoch: [219][351/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 98.4
Epoch: [219][361/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 90.6	Acc@5 98.4
Epoch: [219][371/704]	Time 0.121	Data 0.001	Loss 3.71	Acc@1 82.8	Acc@5 95.3
Epoch: [219][381/704]	Time 0.120	Data 0.001	Loss 2.66	Acc@1 89.1	Acc@5 98.4
Epoch: [219][391/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [219][401/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 98.4
Epoch: [219][411/704]	Time 0.120	Data 0.001	Loss 3.29	Acc@1 85.9	Acc@5 100.0
Epoch: [219][421/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 98.4
Epoch: [219][431/704]	Time 0.120	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 98.4
Epoch: [219][441/704]	Time 0.120	Data 0.001	Loss 2.82	Acc@1 87.5	Acc@5 98.4
Epoch: [219][451/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 85.9	Acc@5 98.4
Epoch: [219][461/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 90.6	Acc@5 100.0
Epoch: [219][471/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [219][481/704]	Time 0.120	Data 0.001	Loss 2.96	Acc@1 85.9	Acc@5 98.4
Epoch: [219][491/704]	Time 0.120	Data 0.001	Loss 2.29	Acc@1 85.9	Acc@5 98.4
Epoch: [219][501/704]	Time 0.120	Data 0.001	Loss 2.60	Acc@1 85.9	Acc@5 96.9
Epoch: [219][511/704]	Time 0.120	Data 0.001	Loss 2.56	Acc@1 87.5	Acc@5 100.0
Epoch: [219][521/704]	Time 0.120	Data 0.001	Loss 2.68	Acc@1 81.2	Acc@5 100.0
Epoch: [219][531/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 90.6	Acc@5 100.0
Epoch: [219][541/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 89.1	Acc@5 96.9
Epoch: [219][551/704]	Time 0.120	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [219][561/704]	Time 0.120	Data 0.001	Loss 2.75	Acc@1 96.9	Acc@5 98.4
Epoch: [219][571/704]	Time 0.120	Data 0.001	Loss 3.15	Acc@1 84.4	Acc@5 100.0
Epoch: [219][581/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 92.2	Acc@5 100.0
Epoch: [219][591/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [219][601/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 89.1	Acc@5 100.0
Epoch: [219][611/704]	Time 0.120	Data 0.001	Loss 2.69	Acc@1 89.1	Acc@5 98.4
Epoch: [219][621/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [219][631/704]	Time 0.120	Data 0.001	Loss 3.63	Acc@1 87.5	Acc@5 98.4
Epoch: [219][641/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [219][651/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 92.2	Acc@5 100.0
Epoch: [219][661/704]	Time 0.120	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [219][671/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 90.6	Acc@5 100.0
Epoch: [219][681/704]	Time 0.120	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 100.0
Epoch: [219][691/704]	Time 0.120	Data 0.001	Loss 2.72	Acc@1 85.9	Acc@5 100.0
Epoch: [219][701/704]	Time 0.120	Data 0.001	Loss 2.37	Acc@1 89.1	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5410	Acc@1 59.3750	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7421	Acc@1 65.6250	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.4633	Acc@1 64.0625	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.7523	Acc@1 68.7500	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.1865	Acc@1 76.5625	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6543	Acc@1 68.7500	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5648	Acc@1 70.3125	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.1180	Acc@1 59.3750	Acc@5 92.1875
 * prec@1 56.700 prec@5 84.400
 * prec@1 61.040 prec@5 87.680
 * prec@1 65.580 prec@5 90.140
 * prec@1 66.940 prec@5 90.460
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_219.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_219.pth.tar'
Epoch: [220][1/704]	Time 0.299	Data 0.131	Loss 2.31	Acc@1 90.6	Acc@5 100.0
Epoch: [220][11/704]	Time 0.140	Data 0.012	Loss 2.02	Acc@1 89.1	Acc@5 100.0
Epoch: [220][21/704]	Time 0.131	Data 0.007	Loss 2.55	Acc@1 89.1	Acc@5 100.0
Epoch: [220][31/704]	Time 0.127	Data 0.005	Loss 2.76	Acc@1 85.9	Acc@5 100.0
Epoch: [220][41/704]	Time 0.126	Data 0.004	Loss 2.88	Acc@1 84.4	Acc@5 100.0
Epoch: [220][51/704]	Time 0.124	Data 0.003	Loss 2.86	Acc@1 87.5	Acc@5 98.4
Epoch: [220][61/704]	Time 0.124	Data 0.002	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [220][71/704]	Time 0.123	Data 0.002	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [220][81/704]	Time 0.123	Data 0.002	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [220][91/704]	Time 0.122	Data 0.002	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [220][101/704]	Time 0.122	Data 0.002	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [220][111/704]	Time 0.122	Data 0.002	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [220][121/704]	Time 0.122	Data 0.001	Loss 2.84	Acc@1 81.2	Acc@5 98.4
Epoch: [220][131/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [220][141/704]	Time 0.122	Data 0.001	Loss 2.36	Acc@1 87.5	Acc@5 100.0
Epoch: [220][151/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 81.2	Acc@5 98.4
Epoch: [220][161/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 92.2	Acc@5 98.4
Epoch: [220][171/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [220][181/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 87.5	Acc@5 100.0
Epoch: [220][191/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 85.9	Acc@5 100.0
Epoch: [220][201/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 84.4	Acc@5 100.0
Epoch: [220][211/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 100.0
Epoch: [220][221/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [220][231/704]	Time 0.121	Data 0.001	Loss 3.03	Acc@1 87.5	Acc@5 98.4
Epoch: [220][241/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 92.2	Acc@5 100.0
Epoch: [220][251/704]	Time 0.121	Data 0.001	Loss 2.92	Acc@1 82.8	Acc@5 100.0
Epoch: [220][261/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 90.6	Acc@5 100.0
Epoch: [220][271/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 93.8	Acc@5 98.4
Epoch: [220][281/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 89.1	Acc@5 98.4
Epoch: [220][291/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 100.0
Epoch: [220][301/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 87.5	Acc@5 100.0
Epoch: [220][311/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 89.1	Acc@5 100.0
Epoch: [220][321/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 90.6	Acc@5 98.4
Epoch: [220][331/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [220][341/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [220][351/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 90.6	Acc@5 98.4
Epoch: [220][361/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 90.6	Acc@5 100.0
Epoch: [220][371/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 92.2	Acc@5 98.4
Epoch: [220][381/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 98.4
Epoch: [220][391/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 92.2	Acc@5 100.0
Epoch: [220][401/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 98.4
Epoch: [220][411/704]	Time 0.121	Data 0.001	Loss 2.59	Acc@1 89.1	Acc@5 100.0
Epoch: [220][421/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [220][431/704]	Time 0.121	Data 0.001	Loss 2.96	Acc@1 89.1	Acc@5 100.0
Epoch: [220][441/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 87.5	Acc@5 100.0
Epoch: [220][451/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 85.9	Acc@5 100.0
Epoch: [220][461/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [220][471/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 89.1	Acc@5 100.0
Epoch: [220][481/704]	Time 0.120	Data 0.001	Loss 2.74	Acc@1 76.6	Acc@5 96.9
Epoch: [220][491/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 98.4
Epoch: [220][501/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 92.2	Acc@5 100.0
Epoch: [220][511/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 87.5	Acc@5 98.4
Epoch: [220][521/704]	Time 0.121	Data 0.001	Loss 3.75	Acc@1 87.5	Acc@5 98.4
Epoch: [220][531/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [220][541/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 87.5	Acc@5 100.0
Epoch: [220][551/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 85.9	Acc@5 100.0
Epoch: [220][561/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 100.0
Epoch: [220][571/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 95.3	Acc@5 100.0
Epoch: [220][581/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [220][591/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 89.1	Acc@5 98.4
Epoch: [220][601/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [220][611/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [220][621/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [220][631/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [220][641/704]	Time 0.120	Data 0.001	Loss 2.44	Acc@1 93.8	Acc@5 100.0
Epoch: [220][651/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 87.5	Acc@5 100.0
Epoch: [220][661/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 93.8	Acc@5 98.4
Epoch: [220][671/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [220][681/704]	Time 0.120	Data 0.001	Loss 2.77	Acc@1 85.9	Acc@5 98.4
Epoch: [220][691/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 90.6	Acc@5 100.0
Epoch: [220][701/704]	Time 0.120	Data 0.001	Loss 2.88	Acc@1 87.5	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.5510	Acc@1 67.1875	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.2696	Acc@1 67.1875	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.4133	Acc@1 65.6250	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3704	Acc@1 67.1875	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9985	Acc@1 60.9375	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.3974	Acc@1 79.6875	Acc@5 100.0000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.6917	Acc@1 56.2500	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.9539	Acc@1 62.5000	Acc@5 87.5000
 * prec@1 56.800 prec@5 84.740
 * prec@1 60.920 prec@5 88.280
 * prec@1 65.460 prec@5 90.440
 * prec@1 67.460 prec@5 90.780
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_220.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_220.pth.tar'
Epoch: [221][1/704]	Time 0.325	Data 0.159	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [221][11/704]	Time 0.139	Data 0.015	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [221][21/704]	Time 0.130	Data 0.008	Loss 3.00	Acc@1 85.9	Acc@5 100.0
Epoch: [221][31/704]	Time 0.127	Data 0.005	Loss 1.75	Acc@1 92.2	Acc@5 100.0
Epoch: [221][41/704]	Time 0.125	Data 0.004	Loss 2.46	Acc@1 89.1	Acc@5 98.4
Epoch: [221][51/704]	Time 0.124	Data 0.003	Loss 1.81	Acc@1 90.6	Acc@5 98.4
Epoch: [221][61/704]	Time 0.123	Data 0.003	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [221][71/704]	Time 0.123	Data 0.002	Loss 2.72	Acc@1 82.8	Acc@5 98.4
Epoch: [221][81/704]	Time 0.123	Data 0.002	Loss 2.76	Acc@1 90.6	Acc@5 98.4
Epoch: [221][91/704]	Time 0.122	Data 0.002	Loss 2.38	Acc@1 92.2	Acc@5 100.0
Epoch: [221][101/704]	Time 0.122	Data 0.002	Loss 1.99	Acc@1 92.2	Acc@5 98.4
Epoch: [221][111/704]	Time 0.122	Data 0.002	Loss 1.65	Acc@1 92.2	Acc@5 100.0
Epoch: [221][121/704]	Time 0.122	Data 0.002	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [221][131/704]	Time 0.122	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [221][141/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [221][151/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 89.1	Acc@5 100.0
Epoch: [221][161/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 85.9	Acc@5 100.0
Epoch: [221][171/704]	Time 0.121	Data 0.001	Loss 2.86	Acc@1 92.2	Acc@5 100.0
Epoch: [221][181/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 89.1	Acc@5 100.0
Epoch: [221][191/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [221][201/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 87.5	Acc@5 100.0
Epoch: [221][211/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 93.8	Acc@5 100.0
Epoch: [221][221/704]	Time 0.121	Data 0.001	Loss 2.95	Acc@1 87.5	Acc@5 100.0
Epoch: [221][231/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [221][241/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 89.1	Acc@5 100.0
Epoch: [221][251/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 92.2	Acc@5 100.0
Epoch: [221][261/704]	Time 0.121	Data 0.001	Loss 3.15	Acc@1 84.4	Acc@5 98.4
Epoch: [221][271/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 89.1	Acc@5 100.0
Epoch: [221][281/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 92.2	Acc@5 100.0
Epoch: [221][291/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 87.5	Acc@5 100.0
Epoch: [221][301/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [221][311/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 84.4	Acc@5 98.4
Epoch: [221][321/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 78.1	Acc@5 96.9
Epoch: [221][331/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 90.6	Acc@5 98.4
Epoch: [221][341/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 90.6	Acc@5 96.9
Epoch: [221][351/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 87.5	Acc@5 100.0
Epoch: [221][361/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [221][371/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 89.1	Acc@5 98.4
Epoch: [221][381/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 82.8	Acc@5 100.0
Epoch: [221][391/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 89.1	Acc@5 100.0
Epoch: [221][401/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 87.5	Acc@5 100.0
Epoch: [221][411/704]	Time 0.120	Data 0.001	Loss 3.04	Acc@1 84.4	Acc@5 100.0
Epoch: [221][421/704]	Time 0.120	Data 0.001	Loss 2.66	Acc@1 89.1	Acc@5 98.4
Epoch: [221][431/704]	Time 0.120	Data 0.001	Loss 2.41	Acc@1 87.5	Acc@5 98.4
Epoch: [221][441/704]	Time 0.120	Data 0.001	Loss 2.56	Acc@1 82.8	Acc@5 100.0
Epoch: [221][451/704]	Time 0.120	Data 0.001	Loss 3.11	Acc@1 84.4	Acc@5 100.0
Epoch: [221][461/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [221][471/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 90.6	Acc@5 100.0
Epoch: [221][481/704]	Time 0.120	Data 0.001	Loss 1.99	Acc@1 90.6	Acc@5 100.0
Epoch: [221][491/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [221][501/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [221][511/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [221][521/704]	Time 0.120	Data 0.001	Loss 2.56	Acc@1 92.2	Acc@5 100.0
Epoch: [221][531/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 95.3	Acc@5 100.0
Epoch: [221][541/704]	Time 0.120	Data 0.001	Loss 2.61	Acc@1 93.8	Acc@5 100.0
Epoch: [221][551/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [221][561/704]	Time 0.120	Data 0.001	Loss 2.37	Acc@1 95.3	Acc@5 100.0
Epoch: [221][571/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [221][581/704]	Time 0.120	Data 0.001	Loss 2.60	Acc@1 89.1	Acc@5 100.0
Epoch: [221][591/704]	Time 0.120	Data 0.001	Loss 2.67	Acc@1 90.6	Acc@5 100.0
Epoch: [221][601/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 89.1	Acc@5 100.0
Epoch: [221][611/704]	Time 0.120	Data 0.001	Loss 2.36	Acc@1 89.1	Acc@5 100.0
Epoch: [221][621/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [221][631/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 89.1	Acc@5 98.4
Epoch: [221][641/704]	Time 0.120	Data 0.001	Loss 2.72	Acc@1 78.1	Acc@5 100.0
Epoch: [221][651/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 89.1	Acc@5 100.0
Epoch: [221][661/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 100.0
Epoch: [221][671/704]	Time 0.120	Data 0.001	Loss 2.50	Acc@1 81.2	Acc@5 100.0
Epoch: [221][681/704]	Time 0.120	Data 0.001	Loss 2.57	Acc@1 84.4	Acc@5 98.4
Epoch: [221][691/704]	Time 0.120	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [221][701/704]	Time 0.120	Data 0.001	Loss 2.53	Acc@1 87.5	Acc@5 96.9
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.3853	Acc@1 59.3750	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.9486	Acc@1 68.7500	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8636	Acc@1 68.7500	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.5819	Acc@1 57.8125	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.8379	Acc@1 68.7500	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.3746	Acc@1 68.7500	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7280	Acc@1 71.8750	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.4639	Acc@1 73.4375	Acc@5 92.1875
 * prec@1 56.400 prec@5 84.660
 * prec@1 61.060 prec@5 87.240
 * prec@1 65.720 prec@5 89.960
 * prec@1 67.020 prec@5 90.740
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_221.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_221.pth.tar'
Epoch: [222][1/704]	Time 0.299	Data 0.132	Loss 2.49	Acc@1 92.2	Acc@5 100.0
Epoch: [222][11/704]	Time 0.136	Data 0.012	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [222][21/704]	Time 0.128	Data 0.007	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [222][31/704]	Time 0.126	Data 0.005	Loss 2.15	Acc@1 96.9	Acc@5 100.0
Epoch: [222][41/704]	Time 0.124	Data 0.004	Loss 2.53	Acc@1 84.4	Acc@5 100.0
Epoch: [222][51/704]	Time 0.123	Data 0.003	Loss 1.52	Acc@1 93.8	Acc@5 100.0
Epoch: [222][61/704]	Time 0.123	Data 0.003	Loss 2.32	Acc@1 93.8	Acc@5 100.0
Epoch: [222][71/704]	Time 0.122	Data 0.002	Loss 2.55	Acc@1 87.5	Acc@5 100.0
Epoch: [222][81/704]	Time 0.122	Data 0.002	Loss 2.94	Acc@1 89.1	Acc@5 98.4
Epoch: [222][91/704]	Time 0.122	Data 0.002	Loss 2.71	Acc@1 92.2	Acc@5 98.4
Epoch: [222][101/704]	Time 0.122	Data 0.002	Loss 2.72	Acc@1 87.5	Acc@5 98.4
Epoch: [222][111/704]	Time 0.121	Data 0.002	Loss 2.86	Acc@1 92.2	Acc@5 100.0
Epoch: [222][121/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [222][131/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 90.6	Acc@5 100.0
Epoch: [222][141/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 89.1	Acc@5 100.0
Epoch: [222][151/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 90.6	Acc@5 100.0
Epoch: [222][161/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 90.6	Acc@5 100.0
Epoch: [222][171/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [222][181/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 90.6	Acc@5 100.0
Epoch: [222][191/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [222][201/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 87.5	Acc@5 98.4
Epoch: [222][211/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 89.1	Acc@5 100.0
Epoch: [222][221/704]	Time 0.121	Data 0.001	Loss 2.98	Acc@1 90.6	Acc@5 100.0
Epoch: [222][231/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 87.5	Acc@5 100.0
Epoch: [222][241/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 92.2	Acc@5 100.0
Epoch: [222][251/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 92.2	Acc@5 100.0
Epoch: [222][261/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 100.0
Epoch: [222][271/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 96.9	Acc@5 100.0
Epoch: [222][281/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 87.5	Acc@5 98.4
Epoch: [222][291/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 100.0	Acc@5 100.0
Epoch: [222][301/704]	Time 0.120	Data 0.001	Loss 2.81	Acc@1 84.4	Acc@5 100.0
Epoch: [222][311/704]	Time 0.120	Data 0.001	Loss 2.64	Acc@1 90.6	Acc@5 100.0
Epoch: [222][321/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [222][331/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 89.1	Acc@5 100.0
Epoch: [222][341/704]	Time 0.120	Data 0.001	Loss 2.42	Acc@1 87.5	Acc@5 100.0
Epoch: [222][351/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [222][361/704]	Time 0.120	Data 0.001	Loss 2.44	Acc@1 93.8	Acc@5 100.0
Epoch: [222][371/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [222][381/704]	Time 0.120	Data 0.001	Loss 2.28	Acc@1 87.5	Acc@5 100.0
Epoch: [222][391/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [222][401/704]	Time 0.120	Data 0.001	Loss 2.61	Acc@1 92.2	Acc@5 100.0
Epoch: [222][411/704]	Time 0.120	Data 0.001	Loss 3.58	Acc@1 89.1	Acc@5 98.4
Epoch: [222][421/704]	Time 0.120	Data 0.001	Loss 2.95	Acc@1 85.9	Acc@5 95.3
Epoch: [222][431/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 92.2	Acc@5 98.4
Epoch: [222][441/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 89.1	Acc@5 100.0
Epoch: [222][451/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 89.1	Acc@5 100.0
Epoch: [222][461/704]	Time 0.120	Data 0.001	Loss 2.86	Acc@1 90.6	Acc@5 96.9
Epoch: [222][471/704]	Time 0.120	Data 0.001	Loss 2.51	Acc@1 87.5	Acc@5 100.0
Epoch: [222][481/704]	Time 0.120	Data 0.001	Loss 2.46	Acc@1 89.1	Acc@5 100.0
Epoch: [222][491/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 95.3	Acc@5 100.0
Epoch: [222][501/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 89.1	Acc@5 100.0
Epoch: [222][511/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 93.8	Acc@5 98.4
Epoch: [222][521/704]	Time 0.120	Data 0.001	Loss 3.09	Acc@1 81.2	Acc@5 98.4
Epoch: [222][531/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [222][541/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [222][551/704]	Time 0.120	Data 0.001	Loss 2.58	Acc@1 85.9	Acc@5 100.0
Epoch: [222][561/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [222][571/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 100.0
Epoch: [222][581/704]	Time 0.120	Data 0.001	Loss 2.80	Acc@1 87.5	Acc@5 100.0
Epoch: [222][591/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 95.3	Acc@5 100.0
Epoch: [222][601/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 100.0
Epoch: [222][611/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 93.8	Acc@5 100.0
Epoch: [222][621/704]	Time 0.120	Data 0.001	Loss 2.50	Acc@1 84.4	Acc@5 100.0
Epoch: [222][631/704]	Time 0.120	Data 0.001	Loss 2.95	Acc@1 84.4	Acc@5 100.0
Epoch: [222][641/704]	Time 0.120	Data 0.001	Loss 3.70	Acc@1 78.1	Acc@5 93.8
Epoch: [222][651/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 98.4
Epoch: [222][661/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 90.6	Acc@5 100.0
Epoch: [222][671/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [222][681/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 90.6	Acc@5 100.0
Epoch: [222][691/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 90.6	Acc@5 100.0
Epoch: [222][701/704]	Time 0.120	Data 0.001	Loss 2.76	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.4997	Acc@1 64.0625	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.4861	Acc@1 67.1875	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5356	Acc@1 62.5000	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.4024	Acc@1 70.3125	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2209	Acc@1 65.6250	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9233	Acc@1 67.1875	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6987	Acc@1 62.5000	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.9487	Acc@1 68.7500	Acc@5 89.0625
 * prec@1 56.840 prec@5 84.060
 * prec@1 61.280 prec@5 87.600
 * prec@1 65.220 prec@5 90.360
 * prec@1 67.200 prec@5 90.720
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_222.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_222.pth.tar'
Epoch: [223][1/704]	Time 0.295	Data 0.127	Loss 2.72	Acc@1 92.2	Acc@5 98.4
Epoch: [223][11/704]	Time 0.137	Data 0.012	Loss 2.26	Acc@1 92.2	Acc@5 100.0
Epoch: [223][21/704]	Time 0.129	Data 0.006	Loss 2.05	Acc@1 90.6	Acc@5 100.0
Epoch: [223][31/704]	Time 0.126	Data 0.004	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [223][41/704]	Time 0.125	Data 0.003	Loss 2.60	Acc@1 92.2	Acc@5 100.0
Epoch: [223][51/704]	Time 0.124	Data 0.003	Loss 1.91	Acc@1 87.5	Acc@5 100.0
Epoch: [223][61/704]	Time 0.124	Data 0.002	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [223][71/704]	Time 0.124	Data 0.002	Loss 1.31	Acc@1 92.2	Acc@5 100.0
Epoch: [223][81/704]	Time 0.123	Data 0.002	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [223][91/704]	Time 0.123	Data 0.002	Loss 1.49	Acc@1 100.0	Acc@5 100.0
Epoch: [223][101/704]	Time 0.123	Data 0.002	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [223][111/704]	Time 0.123	Data 0.001	Loss 2.67	Acc@1 87.5	Acc@5 96.9
Epoch: [223][121/704]	Time 0.123	Data 0.001	Loss 3.52	Acc@1 85.9	Acc@5 98.4
Epoch: [223][131/704]	Time 0.122	Data 0.001	Loss 2.60	Acc@1 85.9	Acc@5 96.9
Epoch: [223][141/704]	Time 0.122	Data 0.001	Loss 2.57	Acc@1 90.6	Acc@5 100.0
Epoch: [223][151/704]	Time 0.122	Data 0.001	Loss 3.28	Acc@1 85.9	Acc@5 96.9
Epoch: [223][161/704]	Time 0.122	Data 0.001	Loss 3.02	Acc@1 84.4	Acc@5 98.4
Epoch: [223][171/704]	Time 0.122	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [223][181/704]	Time 0.122	Data 0.001	Loss 2.12	Acc@1 90.6	Acc@5 100.0
Epoch: [223][191/704]	Time 0.122	Data 0.001	Loss 1.77	Acc@1 90.6	Acc@5 98.4
Epoch: [223][201/704]	Time 0.122	Data 0.001	Loss 2.05	Acc@1 90.6	Acc@5 100.0
Epoch: [223][211/704]	Time 0.122	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 98.4
Epoch: [223][221/704]	Time 0.122	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [223][231/704]	Time 0.122	Data 0.001	Loss 2.56	Acc@1 92.2	Acc@5 100.0
Epoch: [223][241/704]	Time 0.122	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [223][251/704]	Time 0.122	Data 0.001	Loss 2.55	Acc@1 89.1	Acc@5 100.0
Epoch: [223][261/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [223][271/704]	Time 0.121	Data 0.001	Loss 3.07	Acc@1 89.1	Acc@5 100.0
Epoch: [223][281/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 82.8	Acc@5 100.0
Epoch: [223][291/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 89.1	Acc@5 100.0
Epoch: [223][301/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 84.4	Acc@5 100.0
Epoch: [223][311/704]	Time 0.121	Data 0.001	Loss 2.56	Acc@1 96.9	Acc@5 100.0
Epoch: [223][321/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 84.4	Acc@5 100.0
Epoch: [223][331/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 96.9	Acc@5 100.0
Epoch: [223][341/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 95.3	Acc@5 98.4
Epoch: [223][351/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 85.9	Acc@5 100.0
Epoch: [223][361/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 89.1	Acc@5 100.0
Epoch: [223][371/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 82.8	Acc@5 100.0
Epoch: [223][381/704]	Time 0.121	Data 0.001	Loss 3.16	Acc@1 85.9	Acc@5 96.9
Epoch: [223][391/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 90.6	Acc@5 98.4
Epoch: [223][401/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 89.1	Acc@5 98.4
Epoch: [223][411/704]	Time 0.121	Data 0.001	Loss 3.39	Acc@1 84.4	Acc@5 98.4
Epoch: [223][421/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 93.8	Acc@5 100.0
Epoch: [223][431/704]	Time 0.121	Data 0.001	Loss 2.72	Acc@1 90.6	Acc@5 98.4
Epoch: [223][441/704]	Time 0.121	Data 0.001	Loss 2.54	Acc@1 87.5	Acc@5 100.0
Epoch: [223][451/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 85.9	Acc@5 100.0
Epoch: [223][461/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 85.9	Acc@5 100.0
Epoch: [223][471/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 93.8	Acc@5 100.0
Epoch: [223][481/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [223][491/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 87.5	Acc@5 98.4
Epoch: [223][501/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [223][511/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 96.9	Acc@5 100.0
Epoch: [223][521/704]	Time 0.121	Data 0.001	Loss 3.24	Acc@1 79.7	Acc@5 100.0
Epoch: [223][531/704]	Time 0.121	Data 0.001	Loss 2.77	Acc@1 79.7	Acc@5 100.0
Epoch: [223][541/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [223][551/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 98.4
Epoch: [223][561/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 93.8	Acc@5 100.0
Epoch: [223][571/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 90.6	Acc@5 100.0
Epoch: [223][581/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 92.2	Acc@5 100.0
Epoch: [223][591/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 89.1	Acc@5 100.0
Epoch: [223][601/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 84.4	Acc@5 98.4
Epoch: [223][611/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 89.1	Acc@5 100.0
Epoch: [223][621/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 90.6	Acc@5 100.0
Epoch: [223][631/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 90.6	Acc@5 98.4
Epoch: [223][641/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 87.5	Acc@5 100.0
Epoch: [223][651/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 81.2	Acc@5 98.4
Epoch: [223][661/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 98.4
Epoch: [223][671/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 90.6	Acc@5 98.4
Epoch: [223][681/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [223][691/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 85.9	Acc@5 100.0
Epoch: [223][701/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.4155	Acc@1 67.1875	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.1161	Acc@1 71.8750	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.3062	Acc@1 68.7500	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.3473	Acc@1 70.3125	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.8034	Acc@1 65.6250	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.1586	Acc@1 60.9375	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 3.7770	Acc@1 81.2500	Acc@5 98.4375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.2356	Acc@1 62.5000	Acc@5 89.0625
 * prec@1 56.620 prec@5 84.560
 * prec@1 61.100 prec@5 87.620
 * prec@1 65.380 prec@5 90.080
 * prec@1 67.300 prec@5 90.740
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_223.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_223.pth.tar'
Epoch: [224][1/704]	Time 0.333	Data 0.166	Loss 1.71	Acc@1 85.9	Acc@5 100.0
Epoch: [224][11/704]	Time 0.140	Data 0.015	Loss 2.56	Acc@1 92.2	Acc@5 100.0
Epoch: [224][21/704]	Time 0.131	Data 0.008	Loss 1.81	Acc@1 89.1	Acc@5 100.0
Epoch: [224][31/704]	Time 0.127	Data 0.006	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [224][41/704]	Time 0.126	Data 0.004	Loss 2.10	Acc@1 96.9	Acc@5 100.0
Epoch: [224][51/704]	Time 0.125	Data 0.004	Loss 2.70	Acc@1 90.6	Acc@5 100.0
Epoch: [224][61/704]	Time 0.124	Data 0.003	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [224][71/704]	Time 0.124	Data 0.003	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [224][81/704]	Time 0.123	Data 0.002	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [224][91/704]	Time 0.123	Data 0.002	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [224][101/704]	Time 0.123	Data 0.002	Loss 2.20	Acc@1 85.9	Acc@5 100.0
Epoch: [224][111/704]	Time 0.123	Data 0.002	Loss 2.49	Acc@1 92.2	Acc@5 98.4
Epoch: [224][121/704]	Time 0.122	Data 0.002	Loss 1.96	Acc@1 96.9	Acc@5 100.0
Epoch: [224][131/704]	Time 0.122	Data 0.002	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [224][141/704]	Time 0.122	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [224][151/704]	Time 0.122	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 100.0
Epoch: [224][161/704]	Time 0.122	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [224][171/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 92.2	Acc@5 100.0
Epoch: [224][181/704]	Time 0.122	Data 0.001	Loss 2.15	Acc@1 90.6	Acc@5 100.0
Epoch: [224][191/704]	Time 0.122	Data 0.001	Loss 1.95	Acc@1 89.1	Acc@5 100.0
Epoch: [224][201/704]	Time 0.122	Data 0.001	Loss 2.43	Acc@1 90.6	Acc@5 100.0
Epoch: [224][211/704]	Time 0.122	Data 0.001	Loss 1.69	Acc@1 92.2	Acc@5 100.0
Epoch: [224][221/704]	Time 0.122	Data 0.001	Loss 2.36	Acc@1 90.6	Acc@5 98.4
Epoch: [224][231/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 92.2	Acc@5 100.0
Epoch: [224][241/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 98.4
Epoch: [224][251/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 92.2	Acc@5 98.4
Epoch: [224][261/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 92.2	Acc@5 100.0
Epoch: [224][271/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 96.9
Epoch: [224][281/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [224][291/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 90.6	Acc@5 98.4
Epoch: [224][301/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 85.9	Acc@5 100.0
Epoch: [224][311/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 90.6	Acc@5 100.0
Epoch: [224][321/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 100.0
Epoch: [224][331/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 92.2	Acc@5 98.4
Epoch: [224][341/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 90.6	Acc@5 100.0
Epoch: [224][351/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [224][361/704]	Time 0.121	Data 0.001	Loss 2.66	Acc@1 92.2	Acc@5 100.0
Epoch: [224][371/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 93.8	Acc@5 100.0
Epoch: [224][381/704]	Time 0.121	Data 0.001	Loss 2.76	Acc@1 85.9	Acc@5 98.4
Epoch: [224][391/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 93.8	Acc@5 100.0
Epoch: [224][401/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [224][411/704]	Time 0.121	Data 0.001	Loss 2.84	Acc@1 89.1	Acc@5 100.0
Epoch: [224][421/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [224][431/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 89.1	Acc@5 98.4
Epoch: [224][441/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 87.5	Acc@5 98.4
Epoch: [224][451/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 89.1	Acc@5 100.0
Epoch: [224][461/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 93.8	Acc@5 100.0
Epoch: [224][471/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 90.6	Acc@5 100.0
Epoch: [224][481/704]	Time 0.121	Data 0.001	Loss 3.79	Acc@1 87.5	Acc@5 100.0
Epoch: [224][491/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [224][501/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 92.2	Acc@5 100.0
Epoch: [224][511/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 100.0
Epoch: [224][521/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [224][531/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 92.2	Acc@5 100.0
Epoch: [224][541/704]	Time 0.121	Data 0.001	Loss 3.42	Acc@1 90.6	Acc@5 100.0
Epoch: [224][551/704]	Time 0.121	Data 0.001	Loss 2.69	Acc@1 85.9	Acc@5 96.9
Epoch: [224][561/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [224][571/704]	Time 0.121	Data 0.001	Loss 2.71	Acc@1 90.6	Acc@5 100.0
Epoch: [224][581/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 92.2	Acc@5 100.0
Epoch: [224][591/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 85.9	Acc@5 96.9
Epoch: [224][601/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [224][611/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 87.5	Acc@5 100.0
Epoch: [224][621/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 89.1	Acc@5 98.4
Epoch: [224][631/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [224][641/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 90.6	Acc@5 98.4
Epoch: [224][651/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 96.9
Epoch: [224][661/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [224][671/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 89.1	Acc@5 100.0
Epoch: [224][681/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 90.6	Acc@5 96.9
Epoch: [224][691/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 96.9	Acc@5 100.0
Epoch: [224][701/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 90.6	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.1852	Acc@1 70.3125	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.5938	Acc@1 68.7500	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2905	Acc@1 73.4375	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9742	Acc@1 64.0625	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5113	Acc@1 65.6250	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0272	Acc@1 64.0625	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.9471	Acc@1 57.8125	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.5523	Acc@1 71.8750	Acc@5 92.1875
 * prec@1 56.280 prec@5 84.120
 * prec@1 60.460 prec@5 88.060
 * prec@1 65.660 prec@5 89.920
 * prec@1 67.300 prec@5 91.080
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_224.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_224.pth.tar'
Epoch: [225][1/704]	Time 0.336	Data 0.169	Loss 2.71	Acc@1 84.4	Acc@5 98.4
Epoch: [225][11/704]	Time 0.140	Data 0.016	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [225][21/704]	Time 0.131	Data 0.008	Loss 2.14	Acc@1 89.1	Acc@5 100.0
Epoch: [225][31/704]	Time 0.128	Data 0.006	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [225][41/704]	Time 0.126	Data 0.004	Loss 2.36	Acc@1 90.6	Acc@5 100.0
Epoch: [225][51/704]	Time 0.125	Data 0.004	Loss 1.93	Acc@1 90.6	Acc@5 100.0
Epoch: [225][61/704]	Time 0.124	Data 0.003	Loss 2.01	Acc@1 87.5	Acc@5 100.0
Epoch: [225][71/704]	Time 0.123	Data 0.003	Loss 1.91	Acc@1 90.6	Acc@5 100.0
Epoch: [225][81/704]	Time 0.123	Data 0.002	Loss 2.01	Acc@1 90.6	Acc@5 100.0
Epoch: [225][91/704]	Time 0.123	Data 0.002	Loss 2.34	Acc@1 92.2	Acc@5 100.0
Epoch: [225][101/704]	Time 0.123	Data 0.002	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [225][111/704]	Time 0.122	Data 0.002	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [225][121/704]	Time 0.122	Data 0.002	Loss 1.72	Acc@1 90.6	Acc@5 100.0
Epoch: [225][131/704]	Time 0.122	Data 0.002	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [225][141/704]	Time 0.122	Data 0.002	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [225][151/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [225][161/704]	Time 0.122	Data 0.001	Loss 2.40	Acc@1 93.8	Acc@5 100.0
Epoch: [225][171/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 90.6	Acc@5 100.0
Epoch: [225][181/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [225][191/704]	Time 0.122	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [225][201/704]	Time 0.122	Data 0.001	Loss 1.95	Acc@1 98.4	Acc@5 100.0
Epoch: [225][211/704]	Time 0.122	Data 0.001	Loss 2.10	Acc@1 89.1	Acc@5 100.0
Epoch: [225][221/704]	Time 0.122	Data 0.001	Loss 2.46	Acc@1 95.3	Acc@5 100.0
Epoch: [225][231/704]	Time 0.122	Data 0.001	Loss 2.61	Acc@1 87.5	Acc@5 98.4
Epoch: [225][241/704]	Time 0.122	Data 0.001	Loss 2.77	Acc@1 90.6	Acc@5 100.0
Epoch: [225][251/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 98.4	Acc@5 100.0
Epoch: [225][261/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 92.2	Acc@5 98.4
Epoch: [225][271/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [225][281/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [225][291/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [225][301/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 90.6	Acc@5 98.4
Epoch: [225][311/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [225][321/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 90.6	Acc@5 100.0
Epoch: [225][331/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 90.6	Acc@5 100.0
Epoch: [225][341/704]	Time 0.121	Data 0.001	Loss 2.74	Acc@1 95.3	Acc@5 100.0
Epoch: [225][351/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [225][361/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [225][371/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 100.0
Epoch: [225][381/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [225][391/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 95.3	Acc@5 100.0
Epoch: [225][401/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [225][411/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [225][421/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 90.6	Acc@5 100.0
Epoch: [225][431/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 92.2	Acc@5 100.0
Epoch: [225][441/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 90.6	Acc@5 98.4
Epoch: [225][451/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 87.5	Acc@5 96.9
Epoch: [225][461/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [225][471/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [225][481/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 90.6	Acc@5 100.0
Epoch: [225][491/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [225][501/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 98.4
Epoch: [225][511/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 89.1	Acc@5 100.0
Epoch: [225][521/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 90.6	Acc@5 100.0
Epoch: [225][531/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 92.2	Acc@5 100.0
Epoch: [225][541/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 90.6	Acc@5 100.0
Epoch: [225][551/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 95.3	Acc@5 100.0
Epoch: [225][561/704]	Time 0.121	Data 0.001	Loss 2.94	Acc@1 87.5	Acc@5 98.4
Epoch: [225][571/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 93.8	Acc@5 100.0
Epoch: [225][581/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 98.4
Epoch: [225][591/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [225][601/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 92.2	Acc@5 100.0
Epoch: [225][611/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [225][621/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [225][631/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 98.4
Epoch: [225][641/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 92.2	Acc@5 98.4
Epoch: [225][651/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [225][661/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 89.1	Acc@5 100.0
Epoch: [225][671/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 90.6	Acc@5 100.0
Epoch: [225][681/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 100.0
Epoch: [225][691/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [225][701/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 82.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.5206	Acc@1 64.0625	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 9.3662	Acc@1 59.3750	Acc@5 82.8125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.6537	Acc@1 64.0625	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 8.2988	Acc@1 64.0625	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.2766	Acc@1 75.0000	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.8108	Acc@1 76.5625	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7917	Acc@1 67.1875	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.7662	Acc@1 73.4375	Acc@5 90.6250
 * prec@1 57.740 prec@5 85.380
 * prec@1 62.480 prec@5 88.360
 * prec@1 66.360 prec@5 90.460
 * prec@1 69.100 prec@5 91.380
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_225.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_225.pth.tar'
Epoch: [226][1/704]	Time 0.296	Data 0.128	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [226][11/704]	Time 0.137	Data 0.012	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [226][21/704]	Time 0.129	Data 0.006	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [226][31/704]	Time 0.126	Data 0.004	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [226][41/704]	Time 0.125	Data 0.003	Loss 2.09	Acc@1 93.8	Acc@5 98.4
Epoch: [226][51/704]	Time 0.124	Data 0.003	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [226][61/704]	Time 0.123	Data 0.002	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [226][71/704]	Time 0.123	Data 0.002	Loss 2.18	Acc@1 95.3	Acc@5 100.0
Epoch: [226][81/704]	Time 0.123	Data 0.002	Loss 2.57	Acc@1 87.5	Acc@5 98.4
Epoch: [226][91/704]	Time 0.123	Data 0.002	Loss 2.35	Acc@1 89.1	Acc@5 100.0
Epoch: [226][101/704]	Time 0.123	Data 0.002	Loss 1.28	Acc@1 95.3	Acc@5 98.4
Epoch: [226][111/704]	Time 0.123	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [226][121/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [226][131/704]	Time 0.122	Data 0.001	Loss 1.92	Acc@1 89.1	Acc@5 98.4
Epoch: [226][141/704]	Time 0.122	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [226][151/704]	Time 0.122	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [226][161/704]	Time 0.122	Data 0.001	Loss 1.99	Acc@1 95.3	Acc@5 98.4
Epoch: [226][171/704]	Time 0.122	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [226][181/704]	Time 0.122	Data 0.001	Loss 1.95	Acc@1 100.0	Acc@5 100.0
Epoch: [226][191/704]	Time 0.122	Data 0.001	Loss 1.67	Acc@1 90.6	Acc@5 100.0
Epoch: [226][201/704]	Time 0.122	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [226][211/704]	Time 0.122	Data 0.001	Loss 2.23	Acc@1 95.3	Acc@5 100.0
Epoch: [226][221/704]	Time 0.122	Data 0.001	Loss 2.17	Acc@1 93.8	Acc@5 98.4
Epoch: [226][231/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 100.0	Acc@5 100.0
Epoch: [226][241/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [226][251/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 98.4
Epoch: [226][261/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 90.6	Acc@5 98.4
Epoch: [226][271/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [226][281/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 89.1	Acc@5 98.4
Epoch: [226][291/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 92.2	Acc@5 98.4
Epoch: [226][301/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 92.2	Acc@5 100.0
Epoch: [226][311/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 100.0	Acc@5 100.0
Epoch: [226][321/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 98.4
Epoch: [226][331/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [226][341/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 92.2	Acc@5 98.4
Epoch: [226][351/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 87.5	Acc@5 100.0
Epoch: [226][361/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 95.3	Acc@5 100.0
Epoch: [226][371/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 93.8	Acc@5 100.0
Epoch: [226][381/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [226][391/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [226][401/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 98.4
Epoch: [226][411/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 93.8	Acc@5 98.4
Epoch: [226][421/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 92.2	Acc@5 98.4
Epoch: [226][431/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [226][441/704]	Time 0.121	Data 0.001	Loss 2.63	Acc@1 92.2	Acc@5 98.4
Epoch: [226][451/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 96.9	Acc@5 100.0
Epoch: [226][461/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 98.4
Epoch: [226][471/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [226][481/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 100.0	Acc@5 100.0
Epoch: [226][491/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 89.1	Acc@5 100.0
Epoch: [226][501/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [226][511/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [226][521/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 90.6	Acc@5 100.0
Epoch: [226][531/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 96.9	Acc@5 98.4
Epoch: [226][541/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 92.2	Acc@5 100.0
Epoch: [226][551/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 92.2	Acc@5 98.4
Epoch: [226][561/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 100.0
Epoch: [226][571/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [226][581/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 98.4	Acc@5 100.0
Epoch: [226][591/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 100.0	Acc@5 100.0
Epoch: [226][601/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 98.4
Epoch: [226][611/704]	Time 0.121	Data 0.001	Loss 2.73	Acc@1 87.5	Acc@5 98.4
Epoch: [226][621/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 98.4	Acc@5 100.0
Epoch: [226][631/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 98.4
Epoch: [226][641/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 90.6	Acc@5 98.4
Epoch: [226][651/704]	Time 0.121	Data 0.001	Loss 2.55	Acc@1 89.1	Acc@5 100.0
Epoch: [226][661/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [226][671/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [226][681/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [226][691/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 90.6	Acc@5 100.0
Epoch: [226][701/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.2136	Acc@1 60.9375	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.8595	Acc@1 54.6875	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.3093	Acc@1 78.1250	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.8497	Acc@1 70.3125	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7066	Acc@1 64.0625	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1455	Acc@1 62.5000	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.6236	Acc@1 75.0000	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.3845	Acc@1 71.8750	Acc@5 92.1875
 * prec@1 58.040 prec@5 84.900
 * prec@1 62.840 prec@5 88.780
 * prec@1 66.800 prec@5 90.960
 * prec@1 68.740 prec@5 91.200
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_226.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_226.pth.tar'
Epoch: [227][1/704]	Time 0.298	Data 0.130	Loss 1.90	Acc@1 92.2	Acc@5 98.4
Epoch: [227][11/704]	Time 0.140	Data 0.012	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [227][21/704]	Time 0.131	Data 0.007	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [227][31/704]	Time 0.127	Data 0.005	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [227][41/704]	Time 0.125	Data 0.004	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [227][51/704]	Time 0.124	Data 0.003	Loss 1.44	Acc@1 100.0	Acc@5 100.0
Epoch: [227][61/704]	Time 0.124	Data 0.002	Loss 1.24	Acc@1 96.9	Acc@5 100.0
Epoch: [227][71/704]	Time 0.123	Data 0.002	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [227][81/704]	Time 0.123	Data 0.002	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [227][91/704]	Time 0.122	Data 0.002	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [227][101/704]	Time 0.122	Data 0.002	Loss 2.67	Acc@1 92.2	Acc@5 100.0
Epoch: [227][111/704]	Time 0.122	Data 0.001	Loss 2.61	Acc@1 90.6	Acc@5 100.0
Epoch: [227][121/704]	Time 0.122	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [227][131/704]	Time 0.122	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [227][141/704]	Time 0.122	Data 0.001	Loss 1.44	Acc@1 93.8	Acc@5 100.0
Epoch: [227][151/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [227][161/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 100.0	Acc@5 100.0
Epoch: [227][171/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [227][181/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [227][191/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [227][201/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 90.6	Acc@5 100.0
Epoch: [227][211/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 92.2	Acc@5 100.0
Epoch: [227][221/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 89.1	Acc@5 100.0
Epoch: [227][231/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 87.5	Acc@5 100.0
Epoch: [227][241/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 85.9	Acc@5 100.0
Epoch: [227][251/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [227][261/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [227][271/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [227][281/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 98.4	Acc@5 100.0
Epoch: [227][291/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 90.6	Acc@5 100.0
Epoch: [227][301/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 98.4
Epoch: [227][311/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 85.9	Acc@5 100.0
Epoch: [227][321/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [227][331/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [227][341/704]	Time 0.121	Data 0.001	Loss 2.65	Acc@1 92.2	Acc@5 100.0
Epoch: [227][351/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 98.4
Epoch: [227][361/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 98.4
Epoch: [227][371/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [227][381/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [227][391/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [227][401/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 95.3	Acc@5 100.0
Epoch: [227][411/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [227][421/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [227][431/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 84.4	Acc@5 100.0
Epoch: [227][441/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [227][451/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 93.8	Acc@5 98.4
Epoch: [227][461/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 89.1	Acc@5 100.0
Epoch: [227][471/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [227][481/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [227][491/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 89.1	Acc@5 100.0
Epoch: [227][501/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 93.8	Acc@5 100.0
Epoch: [227][511/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 96.9	Acc@5 100.0
Epoch: [227][521/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 92.2	Acc@5 100.0
Epoch: [227][531/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [227][541/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [227][551/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [227][561/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 92.2	Acc@5 100.0
Epoch: [227][571/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 96.9	Acc@5 98.4
Epoch: [227][581/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 100.0	Acc@5 100.0
Epoch: [227][591/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [227][601/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [227][611/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 98.4
Epoch: [227][621/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [227][631/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [227][641/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [227][651/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [227][661/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 93.8	Acc@5 100.0
Epoch: [227][671/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [227][681/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [227][691/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 96.9	Acc@5 98.4
Epoch: [227][701/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.5441	Acc@1 57.8125	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.0873	Acc@1 65.6250	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.9522	Acc@1 68.7500	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.6907	Acc@1 67.1875	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.0499	Acc@1 60.9375	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.3925	Acc@1 76.5625	Acc@5 98.4375
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.0211	Acc@1 71.8750	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.2794	Acc@1 65.6250	Acc@5 90.6250
 * prec@1 58.280 prec@5 84.940
 * prec@1 63.140 prec@5 88.560
 * prec@1 66.160 prec@5 90.600
 * prec@1 68.500 prec@5 91.440
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_227.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_227.pth.tar'
Epoch: [228][1/704]	Time 0.331	Data 0.164	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [228][11/704]	Time 0.140	Data 0.015	Loss 2.07	Acc@1 95.3	Acc@5 98.4
Epoch: [228][21/704]	Time 0.132	Data 0.008	Loss 2.15	Acc@1 95.3	Acc@5 100.0
Epoch: [228][31/704]	Time 0.128	Data 0.006	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [228][41/704]	Time 0.126	Data 0.004	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [228][51/704]	Time 0.125	Data 0.004	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [228][61/704]	Time 0.124	Data 0.003	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [228][71/704]	Time 0.124	Data 0.003	Loss 2.00	Acc@1 96.9	Acc@5 100.0
Epoch: [228][81/704]	Time 0.123	Data 0.002	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [228][91/704]	Time 0.123	Data 0.002	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [228][101/704]	Time 0.123	Data 0.002	Loss 1.58	Acc@1 92.2	Acc@5 100.0
Epoch: [228][111/704]	Time 0.123	Data 0.002	Loss 2.41	Acc@1 93.8	Acc@5 98.4
Epoch: [228][121/704]	Time 0.122	Data 0.002	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [228][131/704]	Time 0.122	Data 0.002	Loss 2.31	Acc@1 95.3	Acc@5 100.0
Epoch: [228][141/704]	Time 0.122	Data 0.001	Loss 2.23	Acc@1 92.2	Acc@5 100.0
Epoch: [228][151/704]	Time 0.122	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [228][161/704]	Time 0.122	Data 0.001	Loss 1.94	Acc@1 90.6	Acc@5 100.0
Epoch: [228][171/704]	Time 0.122	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 100.0
Epoch: [228][181/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [228][191/704]	Time 0.122	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 100.0
Epoch: [228][201/704]	Time 0.122	Data 0.001	Loss 1.69	Acc@1 98.4	Acc@5 100.0
Epoch: [228][211/704]	Time 0.122	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [228][221/704]	Time 0.122	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [228][231/704]	Time 0.122	Data 0.001	Loss 2.41	Acc@1 87.5	Acc@5 100.0
Epoch: [228][241/704]	Time 0.122	Data 0.001	Loss 2.20	Acc@1 93.8	Acc@5 96.9
Epoch: [228][251/704]	Time 0.122	Data 0.001	Loss 2.36	Acc@1 93.8	Acc@5 100.0
Epoch: [228][261/704]	Time 0.122	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [228][271/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [228][281/704]	Time 0.122	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [228][291/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 92.2	Acc@5 100.0
Epoch: [228][301/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [228][311/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [228][321/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 96.9	Acc@5 100.0
Epoch: [228][331/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [228][341/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [228][351/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 98.4	Acc@5 100.0
Epoch: [228][361/704]	Time 0.121	Data 0.001	Loss 1.14	Acc@1 100.0	Acc@5 100.0
Epoch: [228][371/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 92.2	Acc@5 100.0
Epoch: [228][381/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [228][391/704]	Time 0.121	Data 0.001	Loss 3.02	Acc@1 89.1	Acc@5 100.0
Epoch: [228][401/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [228][411/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 90.6	Acc@5 98.4
Epoch: [228][421/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 98.4	Acc@5 100.0
Epoch: [228][431/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [228][441/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 93.8	Acc@5 100.0
Epoch: [228][451/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 93.8	Acc@5 100.0
Epoch: [228][461/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 96.9	Acc@5 100.0
Epoch: [228][471/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [228][481/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [228][491/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 98.4
Epoch: [228][501/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [228][511/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 92.2	Acc@5 100.0
Epoch: [228][521/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [228][531/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 90.6	Acc@5 100.0
Epoch: [228][541/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 98.4	Acc@5 100.0
Epoch: [228][551/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [228][561/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 95.3	Acc@5 100.0
Epoch: [228][571/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 89.1	Acc@5 100.0
Epoch: [228][581/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [228][591/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [228][601/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [228][611/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 90.6	Acc@5 98.4
Epoch: [228][621/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [228][631/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 95.3	Acc@5 100.0
Epoch: [228][641/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [228][651/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [228][661/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [228][671/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [228][681/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [228][691/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 90.6	Acc@5 98.4
Epoch: [228][701/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 89.1	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.3598	Acc@1 64.0625	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.8442	Acc@1 68.7500	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.3716	Acc@1 60.9375	Acc@5 84.3750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.4096	Acc@1 73.4375	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.7674	Acc@1 70.3125	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.0269	Acc@1 64.0625	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.3228	Acc@1 78.1250	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.4908	Acc@1 67.1875	Acc@5 85.9375
 * prec@1 58.520 prec@5 85.700
 * prec@1 63.380 prec@5 88.820
 * prec@1 66.860 prec@5 90.640
 * prec@1 68.760 prec@5 91.320
Current best validation last_bloc_accuracy 69.5
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_228.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_228.pth.tar'
Epoch: [229][1/704]	Time 0.298	Data 0.131	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [229][11/704]	Time 0.137	Data 0.012	Loss 2.06	Acc@1 90.6	Acc@5 100.0
Epoch: [229][21/704]	Time 0.129	Data 0.007	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [229][31/704]	Time 0.126	Data 0.005	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [229][41/704]	Time 0.125	Data 0.004	Loss 1.91	Acc@1 93.8	Acc@5 98.4
Epoch: [229][51/704]	Time 0.124	Data 0.003	Loss 1.79	Acc@1 90.6	Acc@5 96.9
Epoch: [229][61/704]	Time 0.123	Data 0.002	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [229][71/704]	Time 0.123	Data 0.002	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [229][81/704]	Time 0.123	Data 0.002	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [229][91/704]	Time 0.122	Data 0.002	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [229][101/704]	Time 0.122	Data 0.002	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [229][111/704]	Time 0.122	Data 0.002	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [229][121/704]	Time 0.122	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [229][131/704]	Time 0.122	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [229][141/704]	Time 0.122	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [229][151/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [229][161/704]	Time 0.122	Data 0.001	Loss 1.33	Acc@1 93.8	Acc@5 100.0
Epoch: [229][171/704]	Time 0.122	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [229][181/704]	Time 0.122	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [229][191/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [229][201/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [229][211/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [229][221/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [229][231/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [229][241/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [229][251/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [229][261/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 90.6	Acc@5 100.0
Epoch: [229][271/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [229][281/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 93.8	Acc@5 98.4
Epoch: [229][291/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [229][301/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [229][311/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 92.2	Acc@5 100.0
Epoch: [229][321/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [229][331/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [229][341/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 92.2	Acc@5 100.0
Epoch: [229][351/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [229][361/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 98.4
Epoch: [229][371/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [229][381/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [229][391/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 89.1	Acc@5 100.0
Epoch: [229][401/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [229][411/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [229][421/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [229][431/704]	Time 0.121	Data 0.001	Loss 2.83	Acc@1 85.9	Acc@5 100.0
Epoch: [229][441/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 92.2	Acc@5 98.4
Epoch: [229][451/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 92.2	Acc@5 100.0
Epoch: [229][461/704]	Time 0.121	Data 0.001	Loss 2.70	Acc@1 95.3	Acc@5 100.0
Epoch: [229][471/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [229][481/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [229][491/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [229][501/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 90.6	Acc@5 100.0
Epoch: [229][511/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [229][521/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [229][531/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 90.6	Acc@5 100.0
Epoch: [229][541/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 93.8	Acc@5 100.0
Epoch: [229][551/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [229][561/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [229][571/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 100.0
Epoch: [229][581/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [229][591/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [229][601/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [229][611/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 98.4
Epoch: [229][621/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [229][631/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 90.6	Acc@5 100.0
Epoch: [229][641/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [229][651/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 98.4	Acc@5 100.0
Epoch: [229][661/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 98.4
Epoch: [229][671/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [229][681/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [229][691/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [229][701/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 90.6	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.6104	Acc@1 71.8750	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.5863	Acc@1 70.3125	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5352	Acc@1 75.0000	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.6976	Acc@1 68.7500	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.7170	Acc@1 75.0000	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.4573	Acc@1 65.6250	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.5892	Acc@1 62.5000	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.3189	Acc@1 70.3125	Acc@5 96.8750
 * prec@1 59.420 prec@5 85.500
 * prec@1 63.440 prec@5 88.520
 * prec@1 67.080 prec@5 91.220
 * prec@1 69.680 prec@5 92.060
New best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_229.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_229.pth.tar'
Epoch: [230][1/704]	Time 0.302	Data 0.134	Loss 1.46	Acc@1 100.0	Acc@5 100.0
Epoch: [230][11/704]	Time 0.137	Data 0.013	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [230][21/704]	Time 0.129	Data 0.007	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [230][31/704]	Time 0.126	Data 0.005	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [230][41/704]	Time 0.124	Data 0.004	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [230][51/704]	Time 0.124	Data 0.003	Loss 1.02	Acc@1 96.9	Acc@5 100.0
Epoch: [230][61/704]	Time 0.124	Data 0.003	Loss 1.52	Acc@1 93.8	Acc@5 100.0
Epoch: [230][71/704]	Time 0.123	Data 0.002	Loss 1.84	Acc@1 92.2	Acc@5 100.0
Epoch: [230][81/704]	Time 0.123	Data 0.002	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [230][91/704]	Time 0.123	Data 0.002	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [230][101/704]	Time 0.122	Data 0.002	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [230][111/704]	Time 0.122	Data 0.002	Loss 2.06	Acc@1 93.8	Acc@5 98.4
Epoch: [230][121/704]	Time 0.122	Data 0.001	Loss 2.04	Acc@1 90.6	Acc@5 100.0
Epoch: [230][131/704]	Time 0.122	Data 0.001	Loss 2.25	Acc@1 89.1	Acc@5 100.0
Epoch: [230][141/704]	Time 0.122	Data 0.001	Loss 1.21	Acc@1 95.3	Acc@5 100.0
Epoch: [230][151/704]	Time 0.122	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [230][161/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 90.6	Acc@5 100.0
Epoch: [230][171/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [230][181/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 98.4	Acc@5 100.0
Epoch: [230][191/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 90.6	Acc@5 100.0
Epoch: [230][201/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 95.3	Acc@5 98.4
Epoch: [230][211/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 98.4	Acc@5 100.0
Epoch: [230][221/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 90.6	Acc@5 100.0
Epoch: [230][231/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [230][241/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 100.0
Epoch: [230][251/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [230][261/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [230][271/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [230][281/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 100.0
Epoch: [230][291/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 90.6	Acc@5 100.0
Epoch: [230][301/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [230][311/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 92.2	Acc@5 100.0
Epoch: [230][321/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [230][331/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 95.3	Acc@5 100.0
Epoch: [230][341/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 89.1	Acc@5 100.0
Epoch: [230][351/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 98.4
Epoch: [230][361/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [230][371/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [230][381/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 87.5	Acc@5 100.0
Epoch: [230][391/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [230][401/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [230][411/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 89.1	Acc@5 98.4
Epoch: [230][421/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [230][431/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 90.6	Acc@5 100.0
Epoch: [230][441/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 96.9	Acc@5 100.0
Epoch: [230][451/704]	Time 0.121	Data 0.001	Loss 1.12	Acc@1 96.9	Acc@5 100.0
Epoch: [230][461/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 98.4
Epoch: [230][471/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 96.9	Acc@5 100.0
Epoch: [230][481/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [230][491/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 90.6	Acc@5 100.0
Epoch: [230][501/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 93.8	Acc@5 100.0
Epoch: [230][511/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 93.8	Acc@5 98.4
Epoch: [230][521/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 92.2	Acc@5 100.0
Epoch: [230][531/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [230][541/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [230][551/704]	Time 0.120	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [230][561/704]	Time 0.120	Data 0.001	Loss 2.22	Acc@1 89.1	Acc@5 98.4
Epoch: [230][571/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [230][581/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [230][591/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [230][601/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [230][611/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [230][621/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [230][631/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [230][641/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 87.5	Acc@5 100.0
Epoch: [230][651/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 100.0	Acc@5 100.0
Epoch: [230][661/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 92.2	Acc@5 98.4
Epoch: [230][671/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 87.5	Acc@5 100.0
Epoch: [230][681/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [230][691/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 96.9	Acc@5 100.0
Epoch: [230][701/704]	Time 0.120	Data 0.001	Loss 1.42	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.7908	Acc@1 70.3125	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.3533	Acc@1 60.9375	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2227	Acc@1 62.5000	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.1136	Acc@1 76.5625	Acc@5 100.0000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2396	Acc@1 70.3125	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0391	Acc@1 76.5625	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6599	Acc@1 71.8750	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.7489	Acc@1 68.7500	Acc@5 93.7500
 * prec@1 58.780 prec@5 85.640
 * prec@1 62.960 prec@5 88.800
 * prec@1 66.660 prec@5 90.760
 * prec@1 68.900 prec@5 91.580
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_230.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_230.pth.tar'
Epoch: [231][1/704]	Time 0.331	Data 0.165	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [231][11/704]	Time 0.140	Data 0.015	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [231][21/704]	Time 0.130	Data 0.008	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [231][31/704]	Time 0.127	Data 0.006	Loss 1.74	Acc@1 90.6	Acc@5 100.0
Epoch: [231][41/704]	Time 0.126	Data 0.004	Loss 1.41	Acc@1 98.4	Acc@5 98.4
Epoch: [231][51/704]	Time 0.125	Data 0.004	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [231][61/704]	Time 0.124	Data 0.003	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [231][71/704]	Time 0.123	Data 0.003	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [231][81/704]	Time 0.123	Data 0.002	Loss 2.12	Acc@1 90.6	Acc@5 100.0
Epoch: [231][91/704]	Time 0.123	Data 0.002	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [231][101/704]	Time 0.122	Data 0.002	Loss 2.21	Acc@1 92.2	Acc@5 100.0
Epoch: [231][111/704]	Time 0.122	Data 0.002	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [231][121/704]	Time 0.122	Data 0.002	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [231][131/704]	Time 0.122	Data 0.002	Loss 1.78	Acc@1 90.6	Acc@5 100.0
Epoch: [231][141/704]	Time 0.122	Data 0.002	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [231][151/704]	Time 0.122	Data 0.001	Loss 1.55	Acc@1 92.2	Acc@5 100.0
Epoch: [231][161/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [231][171/704]	Time 0.122	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [231][181/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [231][191/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [231][201/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 100.0	Acc@5 100.0
Epoch: [231][211/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 90.6	Acc@5 98.4
Epoch: [231][221/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [231][231/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 98.4	Acc@5 100.0
Epoch: [231][241/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 98.4
Epoch: [231][251/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [231][261/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [231][271/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [231][281/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [231][291/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 98.4
Epoch: [231][301/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [231][311/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [231][321/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 100.0	Acc@5 100.0
Epoch: [231][331/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [231][341/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [231][351/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [231][361/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 100.0
Epoch: [231][371/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [231][381/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 96.9	Acc@5 100.0
Epoch: [231][391/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [231][401/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [231][411/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 92.2	Acc@5 100.0
Epoch: [231][421/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [231][431/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [231][441/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [231][451/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [231][461/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [231][471/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [231][481/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [231][491/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 89.1	Acc@5 100.0
Epoch: [231][501/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [231][511/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 95.3	Acc@5 100.0
Epoch: [231][521/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 100.0	Acc@5 100.0
Epoch: [231][531/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 96.9	Acc@5 100.0
Epoch: [231][541/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 92.2	Acc@5 98.4
Epoch: [231][551/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [231][561/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 95.3	Acc@5 100.0
Epoch: [231][571/704]	Time 0.121	Data 0.001	Loss 2.81	Acc@1 85.9	Acc@5 100.0
Epoch: [231][581/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 96.9	Acc@5 100.0
Epoch: [231][591/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 100.0
Epoch: [231][601/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [231][611/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [231][621/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [231][631/704]	Time 0.121	Data 0.001	Loss 2.40	Acc@1 90.6	Acc@5 100.0
Epoch: [231][641/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [231][651/704]	Time 0.121	Data 0.001	Loss 2.62	Acc@1 89.1	Acc@5 100.0
Epoch: [231][661/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 96.9	Acc@5 100.0
Epoch: [231][671/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 89.1	Acc@5 100.0
Epoch: [231][681/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [231][691/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [231][701/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 4.7907	Acc@1 79.6875	Acc@5 96.8750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.7862	Acc@1 70.3125	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7673	Acc@1 67.1875	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.0137	Acc@1 71.8750	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.7560	Acc@1 75.0000	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.6336	Acc@1 64.0625	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.9902	Acc@1 54.6875	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.8762	Acc@1 67.1875	Acc@5 89.0625
 * prec@1 58.100 prec@5 85.960
 * prec@1 63.160 prec@5 88.880
 * prec@1 66.900 prec@5 91.180
 * prec@1 69.320 prec@5 91.720
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_231.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_231.pth.tar'
Epoch: [232][1/704]	Time 0.336	Data 0.169	Loss 2.39	Acc@1 93.8	Acc@5 100.0
Epoch: [232][11/704]	Time 0.140	Data 0.016	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [232][21/704]	Time 0.131	Data 0.008	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [232][31/704]	Time 0.128	Data 0.006	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [232][41/704]	Time 0.126	Data 0.004	Loss 2.01	Acc@1 90.6	Acc@5 100.0
Epoch: [232][51/704]	Time 0.125	Data 0.004	Loss 1.92	Acc@1 95.3	Acc@5 98.4
Epoch: [232][61/704]	Time 0.124	Data 0.003	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [232][71/704]	Time 0.124	Data 0.003	Loss 1.52	Acc@1 93.8	Acc@5 98.4
Epoch: [232][81/704]	Time 0.123	Data 0.002	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [232][91/704]	Time 0.123	Data 0.002	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [232][101/704]	Time 0.123	Data 0.002	Loss 1.94	Acc@1 96.9	Acc@5 100.0
Epoch: [232][111/704]	Time 0.123	Data 0.002	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [232][121/704]	Time 0.122	Data 0.002	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [232][131/704]	Time 0.122	Data 0.002	Loss 2.16	Acc@1 93.8	Acc@5 98.4
Epoch: [232][141/704]	Time 0.122	Data 0.002	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [232][151/704]	Time 0.122	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [232][161/704]	Time 0.122	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [232][171/704]	Time 0.122	Data 0.001	Loss 2.55	Acc@1 93.8	Acc@5 100.0
Epoch: [232][181/704]	Time 0.122	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [232][191/704]	Time 0.122	Data 0.001	Loss 2.27	Acc@1 93.8	Acc@5 100.0
Epoch: [232][201/704]	Time 0.122	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [232][211/704]	Time 0.122	Data 0.001	Loss 1.80	Acc@1 98.4	Acc@5 100.0
Epoch: [232][221/704]	Time 0.122	Data 0.001	Loss 2.30	Acc@1 95.3	Acc@5 98.4
Epoch: [232][231/704]	Time 0.122	Data 0.001	Loss 2.53	Acc@1 90.6	Acc@5 98.4
Epoch: [232][241/704]	Time 0.122	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [232][251/704]	Time 0.122	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [232][261/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [232][271/704]	Time 0.122	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [232][281/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [232][291/704]	Time 0.122	Data 0.001	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [232][301/704]	Time 0.122	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [232][311/704]	Time 0.121	Data 0.001	Loss 0.99	Acc@1 96.9	Acc@5 100.0
Epoch: [232][321/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 90.6	Acc@5 100.0
Epoch: [232][331/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 87.5	Acc@5 100.0
Epoch: [232][341/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [232][351/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [232][361/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [232][371/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [232][381/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 98.4
Epoch: [232][391/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 100.0	Acc@5 100.0
Epoch: [232][401/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [232][411/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [232][421/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [232][431/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 98.4
Epoch: [232][441/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [232][451/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 96.9	Acc@5 100.0
Epoch: [232][461/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 90.6	Acc@5 100.0
Epoch: [232][471/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 92.2	Acc@5 100.0
Epoch: [232][481/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 100.0
Epoch: [232][491/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [232][501/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [232][511/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [232][521/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 89.1	Acc@5 100.0
Epoch: [232][531/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 90.6	Acc@5 100.0
Epoch: [232][541/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [232][551/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [232][561/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [232][571/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [232][581/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [232][591/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 98.4	Acc@5 100.0
Epoch: [232][601/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [232][611/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 98.4
Epoch: [232][621/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 89.1	Acc@5 100.0
Epoch: [232][631/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [232][641/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 96.9	Acc@5 100.0
Epoch: [232][651/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 95.3	Acc@5 100.0
Epoch: [232][661/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [232][671/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 92.2	Acc@5 100.0
Epoch: [232][681/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [232][691/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [232][701/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.1527	Acc@1 67.1875	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 3.8431	Acc@1 75.0000	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.3024	Acc@1 57.8125	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.5548	Acc@1 73.4375	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.8591	Acc@1 68.7500	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.9442	Acc@1 76.5625	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.2242	Acc@1 60.9375	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.2480	Acc@1 68.7500	Acc@5 85.9375
 * prec@1 58.620 prec@5 85.780
 * prec@1 62.700 prec@5 88.420
 * prec@1 66.360 prec@5 90.440
 * prec@1 69.200 prec@5 91.140
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_232.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_232.pth.tar'
Epoch: [233][1/704]	Time 0.300	Data 0.132	Loss 2.07	Acc@1 96.9	Acc@5 98.4
Epoch: [233][11/704]	Time 0.136	Data 0.012	Loss 1.24	Acc@1 92.2	Acc@5 100.0
Epoch: [233][21/704]	Time 0.129	Data 0.007	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [233][31/704]	Time 0.126	Data 0.005	Loss 1.60	Acc@1 92.2	Acc@5 100.0
Epoch: [233][41/704]	Time 0.124	Data 0.004	Loss 1.63	Acc@1 100.0	Acc@5 100.0
Epoch: [233][51/704]	Time 0.123	Data 0.003	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [233][61/704]	Time 0.123	Data 0.003	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [233][71/704]	Time 0.123	Data 0.002	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [233][81/704]	Time 0.122	Data 0.002	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [233][91/704]	Time 0.122	Data 0.002	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [233][101/704]	Time 0.122	Data 0.002	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [233][111/704]	Time 0.122	Data 0.002	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [233][121/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 100.0	Acc@5 100.0
Epoch: [233][131/704]	Time 0.122	Data 0.001	Loss 2.09	Acc@1 95.3	Acc@5 98.4
Epoch: [233][141/704]	Time 0.122	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [233][151/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [233][161/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 89.1	Acc@5 98.4
Epoch: [233][171/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [233][181/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 92.2	Acc@5 100.0
Epoch: [233][191/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [233][201/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 90.6	Acc@5 98.4
Epoch: [233][211/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [233][221/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [233][231/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [233][241/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 98.4	Acc@5 100.0
Epoch: [233][251/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 89.1	Acc@5 100.0
Epoch: [233][261/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [233][271/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [233][281/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 93.8	Acc@5 100.0
Epoch: [233][291/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 90.6	Acc@5 100.0
Epoch: [233][301/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [233][311/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 98.4
Epoch: [233][321/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 93.8	Acc@5 100.0
Epoch: [233][331/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [233][341/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [233][351/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 90.6	Acc@5 98.4
Epoch: [233][361/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [233][371/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 93.8	Acc@5 100.0
Epoch: [233][381/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [233][391/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [233][401/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 95.3	Acc@5 100.0
Epoch: [233][411/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 95.3	Acc@5 100.0
Epoch: [233][421/704]	Time 0.121	Data 0.001	Loss 1.04	Acc@1 95.3	Acc@5 100.0
Epoch: [233][431/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 93.8	Acc@5 100.0
Epoch: [233][441/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [233][451/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 92.2	Acc@5 100.0
Epoch: [233][461/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [233][471/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [233][481/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 95.3	Acc@5 100.0
Epoch: [233][491/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [233][501/704]	Time 0.120	Data 0.001	Loss 3.15	Acc@1 90.6	Acc@5 100.0
Epoch: [233][511/704]	Time 0.120	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [233][521/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 98.4
Epoch: [233][531/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 96.9	Acc@5 98.4
Epoch: [233][541/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 100.0
Epoch: [233][551/704]	Time 0.120	Data 0.001	Loss 2.34	Acc@1 95.3	Acc@5 100.0
Epoch: [233][561/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [233][571/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [233][581/704]	Time 0.120	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [233][591/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 98.4
Epoch: [233][601/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [233][611/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 95.3	Acc@5 100.0
Epoch: [233][621/704]	Time 0.120	Data 0.001	Loss 2.64	Acc@1 89.1	Acc@5 100.0
Epoch: [233][631/704]	Time 0.120	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 98.4
Epoch: [233][641/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [233][651/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [233][661/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [233][671/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 96.9	Acc@5 100.0
Epoch: [233][681/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 92.2	Acc@5 100.0
Epoch: [233][691/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [233][701/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.6793	Acc@1 70.3125	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.6086	Acc@1 73.4375	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8777	Acc@1 78.1250	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.3589	Acc@1 64.0625	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.7395	Acc@1 65.6250	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.5110	Acc@1 67.1875	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.8922	Acc@1 60.9375	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.0032	Acc@1 67.1875	Acc@5 95.3125
 * prec@1 59.300 prec@5 85.920
 * prec@1 62.720 prec@5 88.940
 * prec@1 66.420 prec@5 91.180
 * prec@1 68.760 prec@5 91.480
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_233.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_233.pth.tar'
Epoch: [234][1/704]	Time 0.301	Data 0.133	Loss 2.22	Acc@1 92.2	Acc@5 98.4
Epoch: [234][11/704]	Time 0.140	Data 0.012	Loss 2.53	Acc@1 92.2	Acc@5 100.0
Epoch: [234][21/704]	Time 0.131	Data 0.007	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [234][31/704]	Time 0.127	Data 0.005	Loss 1.13	Acc@1 98.4	Acc@5 100.0
Epoch: [234][41/704]	Time 0.125	Data 0.004	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [234][51/704]	Time 0.124	Data 0.003	Loss 1.52	Acc@1 92.2	Acc@5 98.4
Epoch: [234][61/704]	Time 0.124	Data 0.002	Loss 1.76	Acc@1 92.2	Acc@5 100.0
Epoch: [234][71/704]	Time 0.123	Data 0.002	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [234][81/704]	Time 0.123	Data 0.002	Loss 1.70	Acc@1 96.9	Acc@5 98.4
Epoch: [234][91/704]	Time 0.122	Data 0.002	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [234][101/704]	Time 0.122	Data 0.002	Loss 1.96	Acc@1 92.2	Acc@5 98.4
Epoch: [234][111/704]	Time 0.122	Data 0.002	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [234][121/704]	Time 0.122	Data 0.001	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [234][131/704]	Time 0.122	Data 0.001	Loss 1.71	Acc@1 100.0	Acc@5 100.0
Epoch: [234][141/704]	Time 0.122	Data 0.001	Loss 1.87	Acc@1 93.8	Acc@5 100.0
Epoch: [234][151/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [234][161/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [234][171/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [234][181/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [234][191/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 92.2	Acc@5 100.0
Epoch: [234][201/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [234][211/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [234][221/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [234][231/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [234][241/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [234][251/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 98.4
Epoch: [234][261/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 100.0	Acc@5 100.0
Epoch: [234][271/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 100.0	Acc@5 100.0
Epoch: [234][281/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [234][291/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [234][301/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [234][311/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [234][321/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 98.4
Epoch: [234][331/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 89.1	Acc@5 100.0
Epoch: [234][341/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [234][351/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [234][361/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 89.1	Acc@5 100.0
Epoch: [234][371/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 92.2	Acc@5 98.4
Epoch: [234][381/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [234][391/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [234][401/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 98.4	Acc@5 100.0
Epoch: [234][411/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 96.9	Acc@5 100.0
Epoch: [234][421/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 100.0	Acc@5 100.0
Epoch: [234][431/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 87.5	Acc@5 98.4
Epoch: [234][441/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 96.9
Epoch: [234][451/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 96.9	Acc@5 100.0
Epoch: [234][461/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [234][471/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [234][481/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 98.4
Epoch: [234][491/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [234][501/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [234][511/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 93.8	Acc@5 100.0
Epoch: [234][521/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 100.0	Acc@5 100.0
Epoch: [234][531/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 98.4	Acc@5 100.0
Epoch: [234][541/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [234][551/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [234][561/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 93.8	Acc@5 100.0
Epoch: [234][571/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [234][581/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [234][591/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [234][601/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 100.0
Epoch: [234][611/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 92.2	Acc@5 100.0
Epoch: [234][621/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [234][631/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [234][641/704]	Time 0.120	Data 0.001	Loss 1.16	Acc@1 100.0	Acc@5 100.0
Epoch: [234][651/704]	Time 0.120	Data 0.001	Loss 2.69	Acc@1 93.8	Acc@5 98.4
Epoch: [234][661/704]	Time 0.120	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [234][671/704]	Time 0.120	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [234][681/704]	Time 0.120	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [234][691/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [234][701/704]	Time 0.120	Data 0.001	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.6680	Acc@1 60.9375	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.1518	Acc@1 60.9375	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 3.3980	Acc@1 78.1250	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.8530	Acc@1 65.6250	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6120	Acc@1 71.8750	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.0336	Acc@1 75.0000	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.5469	Acc@1 73.4375	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 3.7682	Acc@1 76.5625	Acc@5 98.4375
 * prec@1 58.040 prec@5 85.600
 * prec@1 62.800 prec@5 88.900
 * prec@1 66.980 prec@5 90.660
 * prec@1 68.740 prec@5 91.560
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_234.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_234.pth.tar'
Epoch: [235][1/704]	Time 0.336	Data 0.169	Loss 1.71	Acc@1 90.6	Acc@5 100.0
Epoch: [235][11/704]	Time 0.140	Data 0.016	Loss 1.88	Acc@1 96.9	Acc@5 100.0
Epoch: [235][21/704]	Time 0.131	Data 0.008	Loss 1.58	Acc@1 90.6	Acc@5 100.0
Epoch: [235][31/704]	Time 0.127	Data 0.006	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [235][41/704]	Time 0.125	Data 0.004	Loss 2.38	Acc@1 90.6	Acc@5 100.0
Epoch: [235][51/704]	Time 0.124	Data 0.004	Loss 1.24	Acc@1 95.3	Acc@5 100.0
Epoch: [235][61/704]	Time 0.124	Data 0.003	Loss 1.88	Acc@1 96.9	Acc@5 100.0
Epoch: [235][71/704]	Time 0.123	Data 0.003	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [235][81/704]	Time 0.123	Data 0.002	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [235][91/704]	Time 0.123	Data 0.002	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [235][101/704]	Time 0.122	Data 0.002	Loss 1.85	Acc@1 92.2	Acc@5 98.4
Epoch: [235][111/704]	Time 0.122	Data 0.002	Loss 1.54	Acc@1 90.6	Acc@5 100.0
Epoch: [235][121/704]	Time 0.122	Data 0.002	Loss 2.21	Acc@1 95.3	Acc@5 98.4
Epoch: [235][131/704]	Time 0.122	Data 0.002	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [235][141/704]	Time 0.122	Data 0.002	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [235][151/704]	Time 0.122	Data 0.001	Loss 2.51	Acc@1 96.9	Acc@5 100.0
Epoch: [235][161/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [235][171/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 92.2	Acc@5 100.0
Epoch: [235][181/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 90.6	Acc@5 100.0
Epoch: [235][191/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 98.4	Acc@5 100.0
Epoch: [235][201/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [235][211/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [235][221/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [235][231/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [235][241/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [235][251/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [235][261/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 90.6	Acc@5 100.0
Epoch: [235][271/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 98.4
Epoch: [235][281/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 90.6	Acc@5 100.0
Epoch: [235][291/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [235][301/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [235][311/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [235][321/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 96.9	Acc@5 100.0
Epoch: [235][331/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 96.9	Acc@5 100.0
Epoch: [235][341/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [235][351/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 100.0
Epoch: [235][361/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [235][371/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [235][381/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [235][391/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 90.6	Acc@5 100.0
Epoch: [235][401/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [235][411/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 100.0	Acc@5 100.0
Epoch: [235][421/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 98.4	Acc@5 100.0
Epoch: [235][431/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 98.4	Acc@5 100.0
Epoch: [235][441/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 95.3	Acc@5 100.0
Epoch: [235][451/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [235][461/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [235][471/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [235][481/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [235][491/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [235][501/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [235][511/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 100.0
Epoch: [235][521/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [235][531/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 90.6	Acc@5 100.0
Epoch: [235][541/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 93.8	Acc@5 98.4
Epoch: [235][551/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [235][561/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 90.6	Acc@5 100.0
Epoch: [235][571/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [235][581/704]	Time 0.120	Data 0.001	Loss 2.52	Acc@1 92.2	Acc@5 100.0
Epoch: [235][591/704]	Time 0.120	Data 0.001	Loss 2.56	Acc@1 93.8	Acc@5 100.0
Epoch: [235][601/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 92.2	Acc@5 100.0
Epoch: [235][611/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [235][621/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 96.9	Acc@5 98.4
Epoch: [235][631/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [235][641/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [235][651/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [235][661/704]	Time 0.120	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [235][671/704]	Time 0.120	Data 0.001	Loss 2.07	Acc@1 96.9	Acc@5 98.4
Epoch: [235][681/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 92.2	Acc@5 98.4
Epoch: [235][691/704]	Time 0.120	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [235][701/704]	Time 0.120	Data 0.001	Loss 1.23	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.9394	Acc@1 70.3125	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8381	Acc@1 71.8750	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.5555	Acc@1 71.8750	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.0215	Acc@1 84.3750	Acc@5 98.4375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.0183	Acc@1 70.3125	Acc@5 96.8750
Epoch: [51/79]	Time 0.019	Data 0.007	Loss 6.2264	Acc@1 60.9375	Acc@5 89.0625
Epoch: [61/79]	Time 0.019	Data 0.006	Loss 5.8650	Acc@1 64.0625	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.4008	Acc@1 65.6250	Acc@5 89.0625
 * prec@1 58.600 prec@5 85.440
 * prec@1 62.760 prec@5 88.540
 * prec@1 67.520 prec@5 91.020
 * prec@1 69.020 prec@5 91.660
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_235.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_235.pth.tar'
Epoch: [236][1/704]	Time 0.301	Data 0.134	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [236][11/704]	Time 0.137	Data 0.013	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [236][21/704]	Time 0.129	Data 0.007	Loss 1.89	Acc@1 90.6	Acc@5 100.0
Epoch: [236][31/704]	Time 0.127	Data 0.005	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [236][41/704]	Time 0.125	Data 0.004	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [236][51/704]	Time 0.124	Data 0.003	Loss 2.11	Acc@1 95.3	Acc@5 100.0
Epoch: [236][61/704]	Time 0.124	Data 0.003	Loss 2.39	Acc@1 90.6	Acc@5 98.4
Epoch: [236][71/704]	Time 0.123	Data 0.002	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [236][81/704]	Time 0.123	Data 0.002	Loss 1.02	Acc@1 98.4	Acc@5 100.0
Epoch: [236][91/704]	Time 0.123	Data 0.002	Loss 1.18	Acc@1 96.9	Acc@5 100.0
Epoch: [236][101/704]	Time 0.122	Data 0.002	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [236][111/704]	Time 0.122	Data 0.002	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [236][121/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 95.3	Acc@5 100.0
Epoch: [236][131/704]	Time 0.122	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [236][141/704]	Time 0.122	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [236][151/704]	Time 0.122	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [236][161/704]	Time 0.122	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 98.4
Epoch: [236][171/704]	Time 0.122	Data 0.001	Loss 1.54	Acc@1 96.9	Acc@5 98.4
Epoch: [236][181/704]	Time 0.122	Data 0.001	Loss 2.07	Acc@1 92.2	Acc@5 100.0
Epoch: [236][191/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 93.8	Acc@5 100.0
Epoch: [236][201/704]	Time 0.122	Data 0.001	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [236][211/704]	Time 0.122	Data 0.001	Loss 1.50	Acc@1 93.8	Acc@5 98.4
Epoch: [236][221/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [236][231/704]	Time 0.122	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [236][241/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [236][251/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 90.6	Acc@5 100.0
Epoch: [236][261/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 92.2	Acc@5 100.0
Epoch: [236][271/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [236][281/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 98.4	Acc@5 100.0
Epoch: [236][291/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [236][301/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 100.0	Acc@5 100.0
Epoch: [236][311/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 93.8	Acc@5 98.4
Epoch: [236][321/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [236][331/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [236][341/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [236][351/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 92.2	Acc@5 100.0
Epoch: [236][361/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [236][371/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 95.3	Acc@5 100.0
Epoch: [236][381/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [236][391/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [236][401/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [236][411/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [236][421/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [236][431/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [236][441/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [236][451/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [236][461/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 92.2	Acc@5 100.0
Epoch: [236][471/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [236][481/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 90.6	Acc@5 100.0
Epoch: [236][491/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 98.4	Acc@5 100.0
Epoch: [236][501/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [236][511/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [236][521/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 93.8	Acc@5 100.0
Epoch: [236][531/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [236][541/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [236][551/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [236][561/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [236][571/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [236][581/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 90.6	Acc@5 100.0
Epoch: [236][591/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [236][601/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [236][611/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [236][621/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 98.4	Acc@5 100.0
Epoch: [236][631/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [236][641/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [236][651/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 98.4	Acc@5 100.0
Epoch: [236][661/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [236][671/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [236][681/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 92.2	Acc@5 100.0
Epoch: [236][691/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 96.9
Epoch: [236][701/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 4.7652	Acc@1 71.8750	Acc@5 96.8750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.1590	Acc@1 67.1875	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2252	Acc@1 62.5000	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3362	Acc@1 67.1875	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.2854	Acc@1 65.6250	Acc@5 81.2500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.5803	Acc@1 68.7500	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.1018	Acc@1 78.1250	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 9.0442	Acc@1 53.1250	Acc@5 79.6875
 * prec@1 59.300 prec@5 85.620
 * prec@1 62.840 prec@5 88.600
 * prec@1 67.200 prec@5 90.900
 * prec@1 69.540 prec@5 91.080
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_236.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_236.pth.tar'
Epoch: [237][1/704]	Time 0.301	Data 0.133	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [237][11/704]	Time 0.137	Data 0.012	Loss 2.37	Acc@1 90.6	Acc@5 98.4
Epoch: [237][21/704]	Time 0.129	Data 0.007	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [237][31/704]	Time 0.126	Data 0.005	Loss 2.26	Acc@1 87.5	Acc@5 100.0
Epoch: [237][41/704]	Time 0.125	Data 0.004	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [237][51/704]	Time 0.124	Data 0.003	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [237][61/704]	Time 0.124	Data 0.003	Loss 2.09	Acc@1 95.3	Acc@5 100.0
Epoch: [237][71/704]	Time 0.123	Data 0.002	Loss 1.64	Acc@1 89.1	Acc@5 100.0
Epoch: [237][81/704]	Time 0.123	Data 0.002	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [237][91/704]	Time 0.123	Data 0.002	Loss 1.38	Acc@1 100.0	Acc@5 100.0
Epoch: [237][101/704]	Time 0.122	Data 0.002	Loss 1.32	Acc@1 98.4	Acc@5 100.0
Epoch: [237][111/704]	Time 0.122	Data 0.002	Loss 1.93	Acc@1 95.3	Acc@5 98.4
Epoch: [237][121/704]	Time 0.122	Data 0.002	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [237][131/704]	Time 0.122	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [237][141/704]	Time 0.122	Data 0.001	Loss 1.76	Acc@1 92.2	Acc@5 100.0
Epoch: [237][151/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 98.4
Epoch: [237][161/704]	Time 0.122	Data 0.001	Loss 2.76	Acc@1 89.1	Acc@5 98.4
Epoch: [237][171/704]	Time 0.122	Data 0.001	Loss 2.41	Acc@1 89.1	Acc@5 100.0
Epoch: [237][181/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 90.6	Acc@5 100.0
Epoch: [237][191/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 98.4	Acc@5 100.0
Epoch: [237][201/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [237][211/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 98.4	Acc@5 100.0
Epoch: [237][221/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [237][231/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [237][241/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 93.8	Acc@5 100.0
Epoch: [237][251/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [237][261/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [237][271/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 98.4
Epoch: [237][281/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [237][291/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [237][301/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 95.3	Acc@5 100.0
Epoch: [237][311/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 100.0
Epoch: [237][321/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [237][331/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 92.2	Acc@5 100.0
Epoch: [237][341/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [237][351/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [237][361/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 98.4
Epoch: [237][371/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [237][381/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 92.2	Acc@5 100.0
Epoch: [237][391/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 96.9	Acc@5 100.0
Epoch: [237][401/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [237][411/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [237][421/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [237][431/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [237][441/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [237][451/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [237][461/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 89.1	Acc@5 100.0
Epoch: [237][471/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 95.3	Acc@5 100.0
Epoch: [237][481/704]	Time 0.121	Data 0.001	Loss 2.64	Acc@1 98.4	Acc@5 100.0
Epoch: [237][491/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [237][501/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [237][511/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [237][521/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 95.3	Acc@5 100.0
Epoch: [237][531/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [237][541/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [237][551/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 87.5	Acc@5 100.0
Epoch: [237][561/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [237][571/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 93.8	Acc@5 100.0
Epoch: [237][581/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [237][591/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 96.9	Acc@5 100.0
Epoch: [237][601/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [237][611/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 93.8	Acc@5 100.0
Epoch: [237][621/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 92.2	Acc@5 100.0
Epoch: [237][631/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [237][641/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [237][651/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 92.2	Acc@5 100.0
Epoch: [237][661/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 92.2	Acc@5 100.0
Epoch: [237][671/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [237][681/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 98.4
Epoch: [237][691/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [237][701/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.4776	Acc@1 73.4375	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7905	Acc@1 64.0625	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7737	Acc@1 65.6250	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7442	Acc@1 73.4375	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.2457	Acc@1 79.6875	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6563	Acc@1 64.0625	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.1687	Acc@1 65.6250	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.7338	Acc@1 71.8750	Acc@5 90.6250
 * prec@1 58.320 prec@5 85.760
 * prec@1 62.720 prec@5 88.500
 * prec@1 67.440 prec@5 90.660
 * prec@1 69.240 prec@5 91.620
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_237.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_237.pth.tar'
Epoch: [238][1/704]	Time 0.334	Data 0.169	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [238][11/704]	Time 0.140	Data 0.016	Loss 1.23	Acc@1 100.0	Acc@5 100.0
Epoch: [238][21/704]	Time 0.130	Data 0.008	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [238][31/704]	Time 0.127	Data 0.006	Loss 1.63	Acc@1 100.0	Acc@5 100.0
Epoch: [238][41/704]	Time 0.125	Data 0.004	Loss 2.61	Acc@1 92.2	Acc@5 100.0
Epoch: [238][51/704]	Time 0.124	Data 0.004	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [238][61/704]	Time 0.123	Data 0.003	Loss 2.14	Acc@1 93.8	Acc@5 100.0
Epoch: [238][71/704]	Time 0.123	Data 0.003	Loss 2.09	Acc@1 100.0	Acc@5 100.0
Epoch: [238][81/704]	Time 0.123	Data 0.002	Loss 2.26	Acc@1 92.2	Acc@5 100.0
Epoch: [238][91/704]	Time 0.122	Data 0.002	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [238][101/704]	Time 0.122	Data 0.002	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [238][111/704]	Time 0.122	Data 0.002	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [238][121/704]	Time 0.122	Data 0.002	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [238][131/704]	Time 0.122	Data 0.002	Loss 1.94	Acc@1 96.9	Acc@5 100.0
Epoch: [238][141/704]	Time 0.122	Data 0.002	Loss 2.31	Acc@1 95.3	Acc@5 100.0
Epoch: [238][151/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 98.4
Epoch: [238][161/704]	Time 0.121	Data 0.001	Loss 2.89	Acc@1 90.6	Acc@5 98.4
Epoch: [238][171/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [238][181/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 100.0	Acc@5 100.0
Epoch: [238][191/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 90.6	Acc@5 100.0
Epoch: [238][201/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 92.2	Acc@5 100.0
Epoch: [238][211/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 100.0
Epoch: [238][221/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 93.8	Acc@5 100.0
Epoch: [238][231/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 98.4	Acc@5 100.0
Epoch: [238][241/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 92.2	Acc@5 100.0
Epoch: [238][251/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [238][261/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [238][271/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [238][281/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [238][291/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [238][301/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 95.3	Acc@5 100.0
Epoch: [238][311/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [238][321/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 85.9	Acc@5 100.0
Epoch: [238][331/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [238][341/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [238][351/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [238][361/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [238][371/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 93.8	Acc@5 98.4
Epoch: [238][381/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 96.9	Acc@5 100.0
Epoch: [238][391/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [238][401/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [238][411/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [238][421/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [238][431/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 98.4
Epoch: [238][441/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [238][451/704]	Time 0.121	Data 0.001	Loss 2.52	Acc@1 96.9	Acc@5 100.0
Epoch: [238][461/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [238][471/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 100.0	Acc@5 100.0
Epoch: [238][481/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 96.9	Acc@5 100.0
Epoch: [238][491/704]	Time 0.120	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [238][501/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [238][511/704]	Time 0.120	Data 0.001	Loss 1.79	Acc@1 89.1	Acc@5 98.4
Epoch: [238][521/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [238][531/704]	Time 0.120	Data 0.001	Loss 1.87	Acc@1 89.1	Acc@5 100.0
Epoch: [238][541/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 100.0
Epoch: [238][551/704]	Time 0.120	Data 0.001	Loss 2.39	Acc@1 92.2	Acc@5 96.9
Epoch: [238][561/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 93.8	Acc@5 100.0
Epoch: [238][571/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 96.9	Acc@5 100.0
Epoch: [238][581/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 95.3	Acc@5 100.0
Epoch: [238][591/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [238][601/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [238][611/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [238][621/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [238][631/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [238][641/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [238][651/704]	Time 0.120	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [238][661/704]	Time 0.120	Data 0.001	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [238][671/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 100.0	Acc@5 100.0
Epoch: [238][681/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [238][691/704]	Time 0.120	Data 0.001	Loss 2.54	Acc@1 89.1	Acc@5 98.4
Epoch: [238][701/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 92.2	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.8452	Acc@1 75.0000	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.1780	Acc@1 75.0000	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.0167	Acc@1 70.3125	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.1588	Acc@1 57.8125	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.3475	Acc@1 81.2500	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.4394	Acc@1 65.6250	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.1644	Acc@1 75.0000	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.6326	Acc@1 70.3125	Acc@5 92.1875
 * prec@1 58.200 prec@5 85.520
 * prec@1 63.200 prec@5 88.800
 * prec@1 67.220 prec@5 90.760
 * prec@1 69.340 prec@5 91.040
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_238.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_238.pth.tar'
Epoch: [239][1/704]	Time 0.335	Data 0.169	Loss 2.15	Acc@1 90.6	Acc@5 100.0
Epoch: [239][11/704]	Time 0.140	Data 0.016	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [239][21/704]	Time 0.130	Data 0.008	Loss 1.53	Acc@1 100.0	Acc@5 100.0
Epoch: [239][31/704]	Time 0.127	Data 0.006	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [239][41/704]	Time 0.125	Data 0.004	Loss 1.25	Acc@1 93.8	Acc@5 100.0
Epoch: [239][51/704]	Time 0.124	Data 0.004	Loss 2.58	Acc@1 90.6	Acc@5 100.0
Epoch: [239][61/704]	Time 0.124	Data 0.003	Loss 1.74	Acc@1 96.9	Acc@5 98.4
Epoch: [239][71/704]	Time 0.123	Data 0.003	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [239][81/704]	Time 0.123	Data 0.002	Loss 1.35	Acc@1 93.8	Acc@5 100.0
Epoch: [239][91/704]	Time 0.122	Data 0.002	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [239][101/704]	Time 0.122	Data 0.002	Loss 2.29	Acc@1 95.3	Acc@5 98.4
Epoch: [239][111/704]	Time 0.122	Data 0.002	Loss 1.85	Acc@1 98.4	Acc@5 100.0
Epoch: [239][121/704]	Time 0.122	Data 0.002	Loss 2.44	Acc@1 92.2	Acc@5 100.0
Epoch: [239][131/704]	Time 0.122	Data 0.002	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [239][141/704]	Time 0.122	Data 0.002	Loss 2.41	Acc@1 96.9	Acc@5 100.0
Epoch: [239][151/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 98.4	Acc@5 98.4
Epoch: [239][161/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 98.4
Epoch: [239][171/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [239][181/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [239][191/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 85.9	Acc@5 100.0
Epoch: [239][201/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [239][211/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [239][221/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [239][231/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 98.4	Acc@5 98.4
Epoch: [239][241/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [239][251/704]	Time 0.121	Data 0.001	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [239][261/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 95.3	Acc@5 98.4
Epoch: [239][271/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [239][281/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 98.4
Epoch: [239][291/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 98.4
Epoch: [239][301/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 96.9	Acc@5 100.0
Epoch: [239][311/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 87.5	Acc@5 100.0
Epoch: [239][321/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [239][331/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 95.3	Acc@5 100.0
Epoch: [239][341/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [239][351/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [239][361/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 96.9	Acc@5 100.0
Epoch: [239][371/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [239][381/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [239][391/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [239][401/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 96.9	Acc@5 100.0
Epoch: [239][411/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [239][421/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 90.6	Acc@5 100.0
Epoch: [239][431/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [239][441/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 87.5	Acc@5 100.0
Epoch: [239][451/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [239][461/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [239][471/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 92.2	Acc@5 100.0
Epoch: [239][481/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 90.6	Acc@5 100.0
Epoch: [239][491/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [239][501/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [239][511/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 98.4
Epoch: [239][521/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [239][531/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [239][541/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [239][551/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 90.6	Acc@5 100.0
Epoch: [239][561/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 98.4
Epoch: [239][571/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [239][581/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [239][591/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [239][601/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [239][611/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 98.4
Epoch: [239][621/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 98.4
Epoch: [239][631/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [239][641/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 95.3	Acc@5 100.0
Epoch: [239][651/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [239][661/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [239][671/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 92.2	Acc@5 100.0
Epoch: [239][681/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [239][691/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [239][701/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.6939	Acc@1 65.6250	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1577	Acc@1 65.6250	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.0281	Acc@1 71.8750	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.1300	Acc@1 65.6250	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.6637	Acc@1 59.3750	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.3923	Acc@1 71.8750	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.2716	Acc@1 70.3125	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.1767	Acc@1 75.0000	Acc@5 96.8750
 * prec@1 58.880 prec@5 85.760
 * prec@1 63.220 prec@5 88.780
 * prec@1 66.680 prec@5 90.800
 * prec@1 69.000 prec@5 91.360
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_239.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_239.pth.tar'
Epoch: [240][1/704]	Time 0.301	Data 0.133	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [240][11/704]	Time 0.137	Data 0.012	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [240][21/704]	Time 0.129	Data 0.007	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [240][31/704]	Time 0.126	Data 0.005	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [240][41/704]	Time 0.124	Data 0.004	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [240][51/704]	Time 0.124	Data 0.003	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [240][61/704]	Time 0.123	Data 0.003	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [240][71/704]	Time 0.123	Data 0.002	Loss 1.59	Acc@1 92.2	Acc@5 100.0
Epoch: [240][81/704]	Time 0.122	Data 0.002	Loss 1.52	Acc@1 93.8	Acc@5 100.0
Epoch: [240][91/704]	Time 0.122	Data 0.002	Loss 2.59	Acc@1 90.6	Acc@5 98.4
Epoch: [240][101/704]	Time 0.122	Data 0.002	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [240][111/704]	Time 0.122	Data 0.002	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [240][121/704]	Time 0.122	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [240][131/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 98.4	Acc@5 100.0
Epoch: [240][141/704]	Time 0.122	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [240][151/704]	Time 0.122	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [240][161/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 93.8	Acc@5 100.0
Epoch: [240][171/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 93.8	Acc@5 100.0
Epoch: [240][181/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 98.4	Acc@5 100.0
Epoch: [240][191/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [240][201/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 90.6	Acc@5 100.0
Epoch: [240][211/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 95.3	Acc@5 100.0
Epoch: [240][221/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 100.0	Acc@5 100.0
Epoch: [240][231/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [240][241/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 98.4	Acc@5 100.0
Epoch: [240][251/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [240][261/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 96.9	Acc@5 100.0
Epoch: [240][271/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [240][281/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [240][291/704]	Time 0.121	Data 0.001	Loss 2.61	Acc@1 93.8	Acc@5 100.0
Epoch: [240][301/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [240][311/704]	Time 0.121	Data 0.001	Loss 1.15	Acc@1 98.4	Acc@5 100.0
Epoch: [240][321/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 100.0	Acc@5 100.0
Epoch: [240][331/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [240][341/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [240][351/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [240][361/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 90.6	Acc@5 100.0
Epoch: [240][371/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 93.8	Acc@5 98.4
Epoch: [240][381/704]	Time 0.121	Data 0.001	Loss 1.14	Acc@1 98.4	Acc@5 100.0
Epoch: [240][391/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [240][401/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [240][411/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 92.2	Acc@5 100.0
Epoch: [240][421/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 92.2	Acc@5 100.0
Epoch: [240][431/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [240][441/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [240][451/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 98.4
Epoch: [240][461/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 95.3	Acc@5 100.0
Epoch: [240][471/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [240][481/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 96.9	Acc@5 100.0
Epoch: [240][491/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [240][501/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 98.4
Epoch: [240][511/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 95.3	Acc@5 100.0
Epoch: [240][521/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [240][531/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [240][541/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [240][551/704]	Time 0.120	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [240][561/704]	Time 0.120	Data 0.001	Loss 1.44	Acc@1 95.3	Acc@5 100.0
Epoch: [240][571/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [240][581/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [240][591/704]	Time 0.120	Data 0.001	Loss 1.49	Acc@1 93.8	Acc@5 100.0
Epoch: [240][601/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [240][611/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [240][621/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [240][631/704]	Time 0.120	Data 0.001	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [240][641/704]	Time 0.120	Data 0.001	Loss 1.28	Acc@1 100.0	Acc@5 100.0
Epoch: [240][651/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 92.2	Acc@5 98.4
Epoch: [240][661/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [240][671/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [240][681/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [240][691/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [240][701/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.0364	Acc@1 76.5625	Acc@5 92.1875
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 4.3799	Acc@1 70.3125	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8596	Acc@1 62.5000	Acc@5 87.5000
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 6.9342	Acc@1 64.0625	Acc@5 81.2500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.6683	Acc@1 60.9375	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9780	Acc@1 68.7500	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6587	Acc@1 65.6250	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.0303	Acc@1 71.8750	Acc@5 93.7500
 * prec@1 58.860 prec@5 85.580
 * prec@1 63.020 prec@5 88.440
 * prec@1 66.580 prec@5 90.640
 * prec@1 68.840 prec@5 91.340
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_240.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_240.pth.tar'
Epoch: [241][1/704]	Time 0.302	Data 0.133	Loss 1.70	Acc@1 93.8	Acc@5 98.4
Epoch: [241][11/704]	Time 0.141	Data 0.012	Loss 1.23	Acc@1 96.9	Acc@5 100.0
Epoch: [241][21/704]	Time 0.131	Data 0.007	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [241][31/704]	Time 0.128	Data 0.005	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [241][41/704]	Time 0.126	Data 0.004	Loss 1.28	Acc@1 96.9	Acc@5 100.0
Epoch: [241][51/704]	Time 0.125	Data 0.003	Loss 1.64	Acc@1 93.8	Acc@5 100.0
Epoch: [241][61/704]	Time 0.124	Data 0.003	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [241][71/704]	Time 0.123	Data 0.002	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [241][81/704]	Time 0.123	Data 0.002	Loss 1.83	Acc@1 100.0	Acc@5 100.0
Epoch: [241][91/704]	Time 0.123	Data 0.002	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [241][101/704]	Time 0.122	Data 0.002	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [241][111/704]	Time 0.122	Data 0.002	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [241][121/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [241][131/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [241][141/704]	Time 0.122	Data 0.001	Loss 2.20	Acc@1 89.1	Acc@5 100.0
Epoch: [241][151/704]	Time 0.122	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [241][161/704]	Time 0.122	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 98.4
Epoch: [241][171/704]	Time 0.122	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [241][181/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [241][191/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 100.0	Acc@5 100.0
Epoch: [241][201/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 95.3	Acc@5 98.4
Epoch: [241][211/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 95.3	Acc@5 98.4
Epoch: [241][221/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [241][231/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [241][241/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [241][251/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [241][261/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 96.9	Acc@5 100.0
Epoch: [241][271/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [241][281/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [241][291/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [241][301/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 92.2	Acc@5 98.4
Epoch: [241][311/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 95.3	Acc@5 100.0
Epoch: [241][321/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [241][331/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [241][341/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 98.4
Epoch: [241][351/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [241][361/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 89.1	Acc@5 98.4
Epoch: [241][371/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 90.6	Acc@5 100.0
Epoch: [241][381/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [241][391/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [241][401/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 98.4
Epoch: [241][411/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [241][421/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [241][431/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 92.2	Acc@5 100.0
Epoch: [241][441/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [241][451/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 95.3	Acc@5 100.0
Epoch: [241][461/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [241][471/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 92.2	Acc@5 100.0
Epoch: [241][481/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [241][491/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [241][501/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [241][511/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [241][521/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 98.4
Epoch: [241][531/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [241][541/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [241][551/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 93.8	Acc@5 100.0
Epoch: [241][561/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 95.3	Acc@5 100.0
Epoch: [241][571/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [241][581/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [241][591/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 92.2	Acc@5 100.0
Epoch: [241][601/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [241][611/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 92.2	Acc@5 100.0
Epoch: [241][621/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [241][631/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [241][641/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [241][651/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 96.9	Acc@5 98.4
Epoch: [241][661/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [241][671/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [241][681/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [241][691/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [241][701/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.9024	Acc@1 70.3125	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.7038	Acc@1 57.8125	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.6169	Acc@1 75.0000	Acc@5 90.6250
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 7.0039	Acc@1 67.1875	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.1848	Acc@1 73.4375	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.8941	Acc@1 60.9375	Acc@5 84.3750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.9703	Acc@1 64.0625	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 7.5374	Acc@1 65.6250	Acc@5 85.9375
 * prec@1 59.040 prec@5 85.520
 * prec@1 63.260 prec@5 89.140
 * prec@1 66.640 prec@5 90.820
 * prec@1 69.280 prec@5 91.820
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_241.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_241.pth.tar'
Epoch: [242][1/704]	Time 0.336	Data 0.169	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [242][11/704]	Time 0.140	Data 0.016	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [242][21/704]	Time 0.131	Data 0.008	Loss 1.44	Acc@1 96.9	Acc@5 98.4
Epoch: [242][31/704]	Time 0.128	Data 0.006	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [242][41/704]	Time 0.126	Data 0.004	Loss 2.20	Acc@1 92.2	Acc@5 98.4
Epoch: [242][51/704]	Time 0.125	Data 0.004	Loss 1.61	Acc@1 100.0	Acc@5 100.0
Epoch: [242][61/704]	Time 0.124	Data 0.003	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [242][71/704]	Time 0.124	Data 0.003	Loss 1.32	Acc@1 98.4	Acc@5 100.0
Epoch: [242][81/704]	Time 0.123	Data 0.002	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [242][91/704]	Time 0.123	Data 0.002	Loss 2.02	Acc@1 96.9	Acc@5 100.0
Epoch: [242][101/704]	Time 0.123	Data 0.002	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [242][111/704]	Time 0.123	Data 0.002	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [242][121/704]	Time 0.122	Data 0.002	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [242][131/704]	Time 0.122	Data 0.002	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [242][141/704]	Time 0.122	Data 0.002	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [242][151/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [242][161/704]	Time 0.122	Data 0.001	Loss 1.79	Acc@1 100.0	Acc@5 100.0
Epoch: [242][171/704]	Time 0.122	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [242][181/704]	Time 0.122	Data 0.001	Loss 1.52	Acc@1 100.0	Acc@5 100.0
Epoch: [242][191/704]	Time 0.122	Data 0.001	Loss 1.31	Acc@1 100.0	Acc@5 100.0
Epoch: [242][201/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [242][211/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [242][221/704]	Time 0.122	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [242][231/704]	Time 0.122	Data 0.001	Loss 1.29	Acc@1 100.0	Acc@5 100.0
Epoch: [242][241/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [242][251/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [242][261/704]	Time 0.121	Data 0.001	Loss 0.82	Acc@1 96.9	Acc@5 100.0
Epoch: [242][271/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [242][281/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 95.3	Acc@5 100.0
Epoch: [242][291/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 95.3	Acc@5 100.0
Epoch: [242][301/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 93.8	Acc@5 100.0
Epoch: [242][311/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [242][321/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [242][331/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 100.0
Epoch: [242][341/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [242][351/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [242][361/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [242][371/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [242][381/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [242][391/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [242][401/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [242][411/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 95.3	Acc@5 100.0
Epoch: [242][421/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 100.0	Acc@5 100.0
Epoch: [242][431/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 98.4	Acc@5 100.0
Epoch: [242][441/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [242][451/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [242][461/704]	Time 0.121	Data 0.001	Loss 2.82	Acc@1 90.6	Acc@5 100.0
Epoch: [242][471/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [242][481/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [242][491/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 96.9	Acc@5 100.0
Epoch: [242][501/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [242][511/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 90.6	Acc@5 100.0
Epoch: [242][521/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 100.0	Acc@5 100.0
Epoch: [242][531/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 95.3	Acc@5 100.0
Epoch: [242][541/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 98.4	Acc@5 100.0
Epoch: [242][551/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [242][561/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [242][571/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [242][581/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [242][591/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [242][601/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 92.2	Acc@5 100.0
Epoch: [242][611/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 95.3	Acc@5 100.0
Epoch: [242][621/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [242][631/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [242][641/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [242][651/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 95.3	Acc@5 100.0
Epoch: [242][661/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 95.3	Acc@5 100.0
Epoch: [242][671/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [242][681/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [242][691/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [242][701/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.9063	Acc@1 65.6250	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.4447	Acc@1 65.6250	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5068	Acc@1 68.7500	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.7112	Acc@1 67.1875	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.2835	Acc@1 73.4375	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6088	Acc@1 73.4375	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.3830	Acc@1 75.0000	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.9820	Acc@1 67.1875	Acc@5 92.1875
 * prec@1 58.680 prec@5 85.200
 * prec@1 63.680 prec@5 88.660
 * prec@1 67.280 prec@5 91.360
 * prec@1 69.100 prec@5 91.760
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_242.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_242.pth.tar'
Epoch: [243][1/704]	Time 0.302	Data 0.134	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [243][11/704]	Time 0.137	Data 0.012	Loss 1.50	Acc@1 93.8	Acc@5 100.0
Epoch: [243][21/704]	Time 0.129	Data 0.007	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [243][31/704]	Time 0.126	Data 0.005	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [243][41/704]	Time 0.125	Data 0.004	Loss 2.26	Acc@1 90.6	Acc@5 98.4
Epoch: [243][51/704]	Time 0.124	Data 0.003	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [243][61/704]	Time 0.123	Data 0.003	Loss 1.76	Acc@1 98.4	Acc@5 100.0
Epoch: [243][71/704]	Time 0.123	Data 0.002	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [243][81/704]	Time 0.122	Data 0.002	Loss 1.86	Acc@1 100.0	Acc@5 100.0
Epoch: [243][91/704]	Time 0.122	Data 0.002	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [243][101/704]	Time 0.122	Data 0.002	Loss 1.79	Acc@1 90.6	Acc@5 100.0
Epoch: [243][111/704]	Time 0.122	Data 0.002	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [243][121/704]	Time 0.122	Data 0.001	Loss 1.42	Acc@1 93.8	Acc@5 100.0
Epoch: [243][131/704]	Time 0.122	Data 0.001	Loss 2.43	Acc@1 85.9	Acc@5 98.4
Epoch: [243][141/704]	Time 0.122	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [243][151/704]	Time 0.122	Data 0.001	Loss 1.48	Acc@1 100.0	Acc@5 100.0
Epoch: [243][161/704]	Time 0.122	Data 0.001	Loss 1.18	Acc@1 96.9	Acc@5 100.0
Epoch: [243][171/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 98.4	Acc@5 100.0
Epoch: [243][181/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [243][191/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [243][201/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [243][211/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [243][221/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 96.9	Acc@5 100.0
Epoch: [243][231/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 93.8	Acc@5 100.0
Epoch: [243][241/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [243][251/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [243][261/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [243][271/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [243][281/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [243][291/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [243][301/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 95.3	Acc@5 100.0
Epoch: [243][311/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [243][321/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [243][331/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 98.4
Epoch: [243][341/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [243][351/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 98.4
Epoch: [243][361/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [243][371/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 96.9	Acc@5 100.0
Epoch: [243][381/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [243][391/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [243][401/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 95.3	Acc@5 100.0
Epoch: [243][411/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 92.2	Acc@5 100.0
Epoch: [243][421/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 96.9	Acc@5 98.4
Epoch: [243][431/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 93.8	Acc@5 100.0
Epoch: [243][441/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 90.6	Acc@5 100.0
Epoch: [243][451/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 95.3	Acc@5 100.0
Epoch: [243][461/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [243][471/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 100.0	Acc@5 100.0
Epoch: [243][481/704]	Time 0.121	Data 0.001	Loss 1.08	Acc@1 96.9	Acc@5 100.0
Epoch: [243][491/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 95.3	Acc@5 100.0
Epoch: [243][501/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [243][511/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [243][521/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 93.8	Acc@5 100.0
Epoch: [243][531/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 90.6	Acc@5 100.0
Epoch: [243][541/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [243][551/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 95.3	Acc@5 100.0
Epoch: [243][561/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 100.0	Acc@5 100.0
Epoch: [243][571/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [243][581/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [243][591/704]	Time 0.120	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [243][601/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [243][611/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [243][621/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [243][631/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 89.1	Acc@5 100.0
Epoch: [243][641/704]	Time 0.120	Data 0.001	Loss 1.20	Acc@1 98.4	Acc@5 100.0
Epoch: [243][651/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [243][661/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [243][671/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 87.5	Acc@5 100.0
Epoch: [243][681/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 98.4	Acc@5 100.0
Epoch: [243][691/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [243][701/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.7269	Acc@1 68.7500	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.3357	Acc@1 68.7500	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.6099	Acc@1 68.7500	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7606	Acc@1 75.0000	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.0969	Acc@1 73.4375	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6469	Acc@1 70.3125	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.5074	Acc@1 65.6250	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.5803	Acc@1 56.2500	Acc@5 92.1875
 * prec@1 57.860 prec@5 85.140
 * prec@1 62.860 prec@5 88.700
 * prec@1 67.280 prec@5 91.260
 * prec@1 69.180 prec@5 91.680
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_243.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_243.pth.tar'
Epoch: [244][1/704]	Time 0.300	Data 0.132	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [244][11/704]	Time 0.137	Data 0.012	Loss 2.42	Acc@1 92.2	Acc@5 100.0
Epoch: [244][21/704]	Time 0.129	Data 0.007	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [244][31/704]	Time 0.126	Data 0.005	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [244][41/704]	Time 0.125	Data 0.004	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [244][51/704]	Time 0.124	Data 0.003	Loss 1.15	Acc@1 98.4	Acc@5 100.0
Epoch: [244][61/704]	Time 0.124	Data 0.003	Loss 1.10	Acc@1 100.0	Acc@5 100.0
Epoch: [244][71/704]	Time 0.124	Data 0.002	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [244][81/704]	Time 0.123	Data 0.002	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [244][91/704]	Time 0.123	Data 0.002	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [244][101/704]	Time 0.123	Data 0.002	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [244][111/704]	Time 0.123	Data 0.002	Loss 1.53	Acc@1 92.2	Acc@5 100.0
Epoch: [244][121/704]	Time 0.122	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [244][131/704]	Time 0.122	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [244][141/704]	Time 0.122	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [244][151/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [244][161/704]	Time 0.122	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [244][171/704]	Time 0.122	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [244][181/704]	Time 0.122	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [244][191/704]	Time 0.122	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [244][201/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [244][211/704]	Time 0.122	Data 0.001	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [244][221/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [244][231/704]	Time 0.122	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [244][241/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [244][251/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [244][261/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [244][271/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 92.2	Acc@5 100.0
Epoch: [244][281/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [244][291/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 100.0	Acc@5 100.0
Epoch: [244][301/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [244][311/704]	Time 0.121	Data 0.001	Loss 1.11	Acc@1 100.0	Acc@5 100.0
Epoch: [244][321/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [244][331/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [244][341/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [244][351/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [244][361/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [244][371/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 96.9	Acc@5 100.0
Epoch: [244][381/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [244][391/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [244][401/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 90.6	Acc@5 100.0
Epoch: [244][411/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [244][421/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [244][431/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 98.4
Epoch: [244][441/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [244][451/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [244][461/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 98.4
Epoch: [244][471/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [244][481/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 90.6	Acc@5 100.0
Epoch: [244][491/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [244][501/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 100.0	Acc@5 100.0
Epoch: [244][511/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [244][521/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 92.2	Acc@5 100.0
Epoch: [244][531/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [244][541/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [244][551/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [244][561/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 100.0	Acc@5 100.0
Epoch: [244][571/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [244][581/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 92.2	Acc@5 98.4
Epoch: [244][591/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [244][601/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 95.3	Acc@5 100.0
Epoch: [244][611/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [244][621/704]	Time 0.121	Data 0.001	Loss 1.14	Acc@1 98.4	Acc@5 100.0
Epoch: [244][631/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [244][641/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [244][651/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [244][661/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [244][671/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [244][681/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 90.6	Acc@5 100.0
Epoch: [244][691/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [244][701/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.9222	Acc@1 75.0000	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.0903	Acc@1 68.7500	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.3146	Acc@1 62.5000	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.2158	Acc@1 70.3125	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.1854	Acc@1 70.3125	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.5213	Acc@1 73.4375	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5816	Acc@1 70.3125	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.2869	Acc@1 70.3125	Acc@5 95.3125
 * prec@1 57.920 prec@5 85.320
 * prec@1 63.100 prec@5 88.480
 * prec@1 67.580 prec@5 91.160
 * prec@1 69.220 prec@5 91.380
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_244.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_244.pth.tar'
Epoch: [245][1/704]	Time 0.338	Data 0.171	Loss 1.94	Acc@1 96.9	Acc@5 98.4
Epoch: [245][11/704]	Time 0.141	Data 0.016	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [245][21/704]	Time 0.131	Data 0.008	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [245][31/704]	Time 0.128	Data 0.006	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [245][41/704]	Time 0.126	Data 0.005	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [245][51/704]	Time 0.125	Data 0.004	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [245][61/704]	Time 0.124	Data 0.003	Loss 2.15	Acc@1 96.9	Acc@5 100.0
Epoch: [245][71/704]	Time 0.124	Data 0.003	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [245][81/704]	Time 0.123	Data 0.002	Loss 1.54	Acc@1 98.4	Acc@5 98.4
Epoch: [245][91/704]	Time 0.123	Data 0.002	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [245][101/704]	Time 0.123	Data 0.002	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [245][111/704]	Time 0.122	Data 0.002	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [245][121/704]	Time 0.122	Data 0.002	Loss 1.86	Acc@1 98.4	Acc@5 100.0
Epoch: [245][131/704]	Time 0.122	Data 0.002	Loss 1.27	Acc@1 95.3	Acc@5 100.0
Epoch: [245][141/704]	Time 0.122	Data 0.002	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [245][151/704]	Time 0.122	Data 0.001	Loss 1.91	Acc@1 92.2	Acc@5 100.0
Epoch: [245][161/704]	Time 0.122	Data 0.001	Loss 1.58	Acc@1 100.0	Acc@5 100.0
Epoch: [245][171/704]	Time 0.122	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [245][181/704]	Time 0.122	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [245][191/704]	Time 0.122	Data 0.001	Loss 1.52	Acc@1 93.8	Acc@5 100.0
Epoch: [245][201/704]	Time 0.122	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 100.0
Epoch: [245][211/704]	Time 0.121	Data 0.001	Loss 0.86	Acc@1 98.4	Acc@5 100.0
Epoch: [245][221/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [245][231/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 92.2	Acc@5 100.0
Epoch: [245][241/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [245][251/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [245][261/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [245][271/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [245][281/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [245][291/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 96.9	Acc@5 100.0
Epoch: [245][301/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [245][311/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [245][321/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [245][331/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 100.0	Acc@5 100.0
Epoch: [245][341/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [245][351/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [245][361/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 100.0	Acc@5 100.0
Epoch: [245][371/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [245][381/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 92.2	Acc@5 98.4
Epoch: [245][391/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [245][401/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 96.9	Acc@5 100.0
Epoch: [245][411/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [245][421/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [245][431/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 98.4
Epoch: [245][441/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 89.1	Acc@5 100.0
Epoch: [245][451/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [245][461/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [245][471/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 98.4	Acc@5 100.0
Epoch: [245][481/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [245][491/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [245][501/704]	Time 0.121	Data 0.001	Loss 2.43	Acc@1 95.3	Acc@5 98.4
Epoch: [245][511/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [245][521/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [245][531/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 100.0	Acc@5 100.0
Epoch: [245][541/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 93.8	Acc@5 100.0
Epoch: [245][551/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 90.6	Acc@5 100.0
Epoch: [245][561/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [245][571/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [245][581/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 92.2	Acc@5 98.4
Epoch: [245][591/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [245][601/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [245][611/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 93.8	Acc@5 100.0
Epoch: [245][621/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [245][631/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [245][641/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 96.9	Acc@5 100.0
Epoch: [245][651/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [245][661/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [245][671/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [245][681/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [245][691/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [245][701/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.1575	Acc@1 75.0000	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.7681	Acc@1 57.8125	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.3558	Acc@1 65.6250	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9028	Acc@1 62.5000	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.6110	Acc@1 70.3125	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.7823	Acc@1 51.5625	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.8725	Acc@1 71.8750	Acc@5 98.4375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.2188	Acc@1 56.2500	Acc@5 84.3750
 * prec@1 58.560 prec@5 85.460
 * prec@1 62.480 prec@5 88.600
 * prec@1 66.040 prec@5 90.960
 * prec@1 68.440 prec@5 91.500
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_245.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_245.pth.tar'
Epoch: [246][1/704]	Time 0.334	Data 0.168	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [246][11/704]	Time 0.140	Data 0.016	Loss 1.45	Acc@1 93.8	Acc@5 100.0
Epoch: [246][21/704]	Time 0.130	Data 0.008	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [246][31/704]	Time 0.127	Data 0.006	Loss 1.69	Acc@1 92.2	Acc@5 100.0
Epoch: [246][41/704]	Time 0.125	Data 0.004	Loss 2.69	Acc@1 92.2	Acc@5 100.0
Epoch: [246][51/704]	Time 0.124	Data 0.004	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [246][61/704]	Time 0.124	Data 0.003	Loss 1.53	Acc@1 93.8	Acc@5 100.0
Epoch: [246][71/704]	Time 0.123	Data 0.003	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [246][81/704]	Time 0.123	Data 0.002	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [246][91/704]	Time 0.122	Data 0.002	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [246][101/704]	Time 0.122	Data 0.002	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [246][111/704]	Time 0.122	Data 0.002	Loss 1.81	Acc@1 100.0	Acc@5 100.0
Epoch: [246][121/704]	Time 0.122	Data 0.002	Loss 2.22	Acc@1 93.8	Acc@5 100.0
Epoch: [246][131/704]	Time 0.122	Data 0.002	Loss 2.53	Acc@1 92.2	Acc@5 100.0
Epoch: [246][141/704]	Time 0.122	Data 0.002	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [246][151/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 98.4
Epoch: [246][161/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [246][171/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [246][181/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [246][191/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [246][201/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [246][211/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [246][221/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [246][231/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [246][241/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [246][251/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 92.2	Acc@5 100.0
Epoch: [246][261/704]	Time 0.121	Data 0.001	Loss 2.51	Acc@1 90.6	Acc@5 98.4
Epoch: [246][271/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 90.6	Acc@5 100.0
Epoch: [246][281/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [246][291/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 95.3	Acc@5 100.0
Epoch: [246][301/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 92.2	Acc@5 100.0
Epoch: [246][311/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 100.0	Acc@5 100.0
Epoch: [246][321/704]	Time 0.121	Data 0.001	Loss 0.99	Acc@1 96.9	Acc@5 100.0
Epoch: [246][331/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 98.4
Epoch: [246][341/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [246][351/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [246][361/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [246][371/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 92.2	Acc@5 100.0
Epoch: [246][381/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 100.0
Epoch: [246][391/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 89.1	Acc@5 100.0
Epoch: [246][401/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 96.9	Acc@5 100.0
Epoch: [246][411/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [246][421/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [246][431/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [246][441/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [246][451/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [246][461/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [246][471/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [246][481/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [246][491/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [246][501/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 90.6	Acc@5 100.0
Epoch: [246][511/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 98.4
Epoch: [246][521/704]	Time 0.120	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [246][531/704]	Time 0.120	Data 0.001	Loss 2.18	Acc@1 96.9	Acc@5 100.0
Epoch: [246][541/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [246][551/704]	Time 0.120	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [246][561/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [246][571/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [246][581/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [246][591/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [246][601/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [246][611/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 100.0	Acc@5 100.0
Epoch: [246][621/704]	Time 0.120	Data 0.001	Loss 1.60	Acc@1 98.4	Acc@5 100.0
Epoch: [246][631/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [246][641/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [246][651/704]	Time 0.120	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [246][661/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 95.3	Acc@5 100.0
Epoch: [246][671/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [246][681/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [246][691/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 93.8	Acc@5 100.0
Epoch: [246][701/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 96.9	Acc@5 98.4
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 3.7817	Acc@1 79.6875	Acc@5 98.4375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.7756	Acc@1 75.0000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.1724	Acc@1 65.6250	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.2798	Acc@1 59.3750	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.7406	Acc@1 60.9375	Acc@5 98.4375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0895	Acc@1 64.0625	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.9200	Acc@1 62.5000	Acc@5 81.2500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.4684	Acc@1 75.0000	Acc@5 92.1875
 * prec@1 58.060 prec@5 85.360
 * prec@1 62.480 prec@5 88.960
 * prec@1 67.100 prec@5 90.820
 * prec@1 69.100 prec@5 91.480
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_246.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_246.pth.tar'
Epoch: [247][1/704]	Time 0.300	Data 0.132	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [247][11/704]	Time 0.137	Data 0.012	Loss 1.24	Acc@1 100.0	Acc@5 100.0
Epoch: [247][21/704]	Time 0.129	Data 0.007	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [247][31/704]	Time 0.126	Data 0.005	Loss 1.14	Acc@1 96.9	Acc@5 100.0
Epoch: [247][41/704]	Time 0.125	Data 0.004	Loss 1.98	Acc@1 100.0	Acc@5 100.0
Epoch: [247][51/704]	Time 0.124	Data 0.003	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [247][61/704]	Time 0.124	Data 0.002	Loss 0.93	Acc@1 98.4	Acc@5 100.0
Epoch: [247][71/704]	Time 0.123	Data 0.002	Loss 1.22	Acc@1 100.0	Acc@5 100.0
Epoch: [247][81/704]	Time 0.123	Data 0.002	Loss 1.50	Acc@1 93.8	Acc@5 100.0
Epoch: [247][91/704]	Time 0.123	Data 0.002	Loss 2.23	Acc@1 96.9	Acc@5 100.0
Epoch: [247][101/704]	Time 0.123	Data 0.002	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [247][111/704]	Time 0.123	Data 0.001	Loss 1.62	Acc@1 93.8	Acc@5 100.0
Epoch: [247][121/704]	Time 0.123	Data 0.001	Loss 1.85	Acc@1 89.1	Acc@5 100.0
Epoch: [247][131/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [247][141/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [247][151/704]	Time 0.122	Data 0.001	Loss 2.32	Acc@1 95.3	Acc@5 100.0
Epoch: [247][161/704]	Time 0.122	Data 0.001	Loss 2.35	Acc@1 93.8	Acc@5 100.0
Epoch: [247][171/704]	Time 0.122	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 100.0
Epoch: [247][181/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 100.0	Acc@5 100.0
Epoch: [247][191/704]	Time 0.122	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [247][201/704]	Time 0.122	Data 0.001	Loss 1.99	Acc@1 98.4	Acc@5 100.0
Epoch: [247][211/704]	Time 0.122	Data 0.001	Loss 1.24	Acc@1 100.0	Acc@5 100.0
Epoch: [247][221/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 98.4
Epoch: [247][231/704]	Time 0.122	Data 0.001	Loss 1.28	Acc@1 93.8	Acc@5 100.0
Epoch: [247][241/704]	Time 0.122	Data 0.001	Loss 2.05	Acc@1 87.5	Acc@5 100.0
Epoch: [247][251/704]	Time 0.122	Data 0.001	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [247][261/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [247][271/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [247][281/704]	Time 0.121	Data 0.001	Loss 2.47	Acc@1 95.3	Acc@5 100.0
Epoch: [247][291/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [247][301/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [247][311/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [247][321/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 93.8	Acc@5 100.0
Epoch: [247][331/704]	Time 0.121	Data 0.001	Loss 1.03	Acc@1 98.4	Acc@5 100.0
Epoch: [247][341/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 92.2	Acc@5 100.0
Epoch: [247][351/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [247][361/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [247][371/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [247][381/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 98.4
Epoch: [247][391/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [247][401/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 92.2	Acc@5 100.0
Epoch: [247][411/704]	Time 0.121	Data 0.001	Loss 1.14	Acc@1 96.9	Acc@5 100.0
Epoch: [247][421/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 90.6	Acc@5 100.0
Epoch: [247][431/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [247][441/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [247][451/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [247][461/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [247][471/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 95.3	Acc@5 100.0
Epoch: [247][481/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [247][491/704]	Time 0.121	Data 0.001	Loss 2.67	Acc@1 85.9	Acc@5 100.0
Epoch: [247][501/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 93.8	Acc@5 100.0
Epoch: [247][511/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [247][521/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [247][531/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [247][541/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 93.8	Acc@5 100.0
Epoch: [247][551/704]	Time 0.121	Data 0.001	Loss 1.06	Acc@1 96.9	Acc@5 100.0
Epoch: [247][561/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 90.6	Acc@5 98.4
Epoch: [247][571/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 96.9	Acc@5 100.0
Epoch: [247][581/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [247][591/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [247][601/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 95.3	Acc@5 96.9
Epoch: [247][611/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [247][621/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 100.0
Epoch: [247][631/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [247][641/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [247][651/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [247][661/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 96.9
Epoch: [247][671/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [247][681/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 93.8	Acc@5 100.0
Epoch: [247][691/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [247][701/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.9170	Acc@1 70.3125	Acc@5 92.1875
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 5.4616	Acc@1 71.8750	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 3.3875	Acc@1 82.8125	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.1314	Acc@1 71.8750	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.7255	Acc@1 67.1875	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.3227	Acc@1 70.3125	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6253	Acc@1 65.6250	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.9580	Acc@1 68.7500	Acc@5 87.5000
 * prec@1 58.240 prec@5 85.380
 * prec@1 63.120 prec@5 88.720
 * prec@1 66.240 prec@5 90.680
 * prec@1 68.840 prec@5 90.940
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_247.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_247.pth.tar'
Epoch: [248][1/704]	Time 0.341	Data 0.131	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [248][11/704]	Time 0.140	Data 0.012	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [248][21/704]	Time 0.131	Data 0.006	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [248][31/704]	Time 0.127	Data 0.005	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [248][41/704]	Time 0.125	Data 0.003	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [248][51/704]	Time 0.124	Data 0.003	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [248][61/704]	Time 0.124	Data 0.002	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [248][71/704]	Time 0.123	Data 0.002	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [248][81/704]	Time 0.123	Data 0.002	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [248][91/704]	Time 0.122	Data 0.002	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [248][101/704]	Time 0.122	Data 0.002	Loss 1.89	Acc@1 95.3	Acc@5 98.4
Epoch: [248][111/704]	Time 0.122	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 100.0
Epoch: [248][121/704]	Time 0.122	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [248][131/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [248][141/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [248][151/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [248][161/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [248][171/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [248][181/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 93.8	Acc@5 100.0
Epoch: [248][191/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [248][201/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 95.3	Acc@5 100.0
Epoch: [248][211/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [248][221/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 92.2	Acc@5 98.4
Epoch: [248][231/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 92.2	Acc@5 100.0
Epoch: [248][241/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [248][251/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [248][261/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [248][271/704]	Time 0.121	Data 0.001	Loss 1.12	Acc@1 96.9	Acc@5 100.0
Epoch: [248][281/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [248][291/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 98.4	Acc@5 100.0
Epoch: [248][301/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [248][311/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [248][321/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 92.2	Acc@5 100.0
Epoch: [248][331/704]	Time 0.121	Data 0.001	Loss 1.12	Acc@1 98.4	Acc@5 100.0
Epoch: [248][341/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 100.0	Acc@5 100.0
Epoch: [248][351/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 93.8	Acc@5 100.0
Epoch: [248][361/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [248][371/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [248][381/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [248][391/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [248][401/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [248][411/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [248][421/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 96.9	Acc@5 100.0
Epoch: [248][431/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [248][441/704]	Time 0.121	Data 0.001	Loss 1.07	Acc@1 100.0	Acc@5 100.0
Epoch: [248][451/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [248][461/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [248][471/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 100.0	Acc@5 100.0
Epoch: [248][481/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [248][491/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [248][501/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [248][511/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [248][521/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [248][531/704]	Time 0.121	Data 0.001	Loss 1.11	Acc@1 100.0	Acc@5 100.0
Epoch: [248][541/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [248][551/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [248][561/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 89.1	Acc@5 98.4
Epoch: [248][571/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 96.9	Acc@5 100.0
Epoch: [248][581/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 95.3	Acc@5 100.0
Epoch: [248][591/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 92.2	Acc@5 100.0
Epoch: [248][601/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 100.0	Acc@5 100.0
Epoch: [248][611/704]	Time 0.121	Data 0.001	Loss 1.03	Acc@1 98.4	Acc@5 100.0
Epoch: [248][621/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 92.2	Acc@5 100.0
Epoch: [248][631/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [248][641/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [248][651/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [248][661/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [248][671/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [248][681/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [248][691/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [248][701/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 92.2	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.5537	Acc@1 71.8750	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.3919	Acc@1 76.5625	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.1315	Acc@1 75.0000	Acc@5 90.6250
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 5.0344	Acc@1 65.6250	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.6514	Acc@1 70.3125	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.3272	Acc@1 62.5000	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.7823	Acc@1 56.2500	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1733	Acc@1 71.8750	Acc@5 87.5000
 * prec@1 58.840 prec@5 85.520
 * prec@1 63.300 prec@5 88.620
 * prec@1 67.460 prec@5 91.200
 * prec@1 68.500 prec@5 91.200
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_248.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_248.pth.tar'
Epoch: [249][1/704]	Time 0.337	Data 0.170	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [249][11/704]	Time 0.140	Data 0.016	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [249][21/704]	Time 0.131	Data 0.008	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [249][31/704]	Time 0.127	Data 0.006	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [249][41/704]	Time 0.126	Data 0.005	Loss 1.80	Acc@1 90.6	Acc@5 100.0
Epoch: [249][51/704]	Time 0.125	Data 0.004	Loss 1.74	Acc@1 98.4	Acc@5 100.0
Epoch: [249][61/704]	Time 0.124	Data 0.003	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [249][71/704]	Time 0.123	Data 0.003	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [249][81/704]	Time 0.123	Data 0.002	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [249][91/704]	Time 0.123	Data 0.002	Loss 1.07	Acc@1 98.4	Acc@5 100.0
Epoch: [249][101/704]	Time 0.122	Data 0.002	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [249][111/704]	Time 0.122	Data 0.002	Loss 2.29	Acc@1 95.3	Acc@5 98.4
Epoch: [249][121/704]	Time 0.122	Data 0.002	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [249][131/704]	Time 0.122	Data 0.002	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [249][141/704]	Time 0.122	Data 0.002	Loss 1.82	Acc@1 95.3	Acc@5 98.4
Epoch: [249][151/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [249][161/704]	Time 0.122	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [249][171/704]	Time 0.122	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [249][181/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 98.4
Epoch: [249][191/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [249][201/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 98.4	Acc@5 100.0
Epoch: [249][211/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 87.5	Acc@5 100.0
Epoch: [249][221/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 93.8	Acc@5 100.0
Epoch: [249][231/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [249][241/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [249][251/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [249][261/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [249][271/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 90.6	Acc@5 100.0
Epoch: [249][281/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [249][291/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [249][301/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [249][311/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [249][321/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [249][331/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 100.0	Acc@5 100.0
Epoch: [249][341/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [249][351/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 100.0
Epoch: [249][361/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 100.0	Acc@5 100.0
Epoch: [249][371/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [249][381/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 95.3	Acc@5 100.0
Epoch: [249][391/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 100.0	Acc@5 100.0
Epoch: [249][401/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [249][411/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 93.8	Acc@5 100.0
Epoch: [249][421/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [249][431/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [249][441/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [249][451/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 92.2	Acc@5 100.0
Epoch: [249][461/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [249][471/704]	Time 0.121	Data 0.001	Loss 0.95	Acc@1 98.4	Acc@5 100.0
Epoch: [249][481/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 92.2	Acc@5 100.0
Epoch: [249][491/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [249][501/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 100.0	Acc@5 100.0
Epoch: [249][511/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [249][521/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [249][531/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 93.8	Acc@5 100.0
Epoch: [249][541/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [249][551/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 100.0
Epoch: [249][561/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [249][571/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [249][581/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [249][591/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [249][601/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [249][611/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 90.6	Acc@5 100.0
Epoch: [249][621/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 92.2	Acc@5 100.0
Epoch: [249][631/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 93.8	Acc@5 100.0
Epoch: [249][641/704]	Time 0.121	Data 0.001	Loss 2.29	Acc@1 95.3	Acc@5 98.4
Epoch: [249][651/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [249][661/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 95.3	Acc@5 100.0
Epoch: [249][671/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [249][681/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 98.4	Acc@5 100.0
Epoch: [249][691/704]	Time 0.121	Data 0.001	Loss 1.06	Acc@1 93.8	Acc@5 100.0
Epoch: [249][701/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.6807	Acc@1 70.3125	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.8643	Acc@1 65.6250	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.3629	Acc@1 73.4375	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.8653	Acc@1 78.1250	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.0129	Acc@1 65.6250	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9239	Acc@1 67.1875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.8854	Acc@1 70.3125	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.7573	Acc@1 62.5000	Acc@5 84.3750
 * prec@1 58.860 prec@5 86.180
 * prec@1 63.240 prec@5 88.880
 * prec@1 66.860 prec@5 91.200
 * prec@1 68.780 prec@5 91.560
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_249.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_249.pth.tar'
Epoch: [250][1/704]	Time 0.300	Data 0.133	Loss 1.78	Acc@1 89.1	Acc@5 100.0
Epoch: [250][11/704]	Time 0.136	Data 0.012	Loss 1.77	Acc@1 95.3	Acc@5 98.4
Epoch: [250][21/704]	Time 0.129	Data 0.007	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [250][31/704]	Time 0.126	Data 0.005	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [250][41/704]	Time 0.124	Data 0.004	Loss 1.43	Acc@1 96.9	Acc@5 98.4
Epoch: [250][51/704]	Time 0.123	Data 0.003	Loss 0.97	Acc@1 98.4	Acc@5 100.0
Epoch: [250][61/704]	Time 0.123	Data 0.003	Loss 1.17	Acc@1 96.9	Acc@5 100.0
Epoch: [250][71/704]	Time 0.122	Data 0.002	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [250][81/704]	Time 0.122	Data 0.002	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [250][91/704]	Time 0.122	Data 0.002	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [250][101/704]	Time 0.122	Data 0.002	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [250][111/704]	Time 0.121	Data 0.002	Loss 1.45	Acc@1 93.8	Acc@5 100.0
Epoch: [250][121/704]	Time 0.121	Data 0.001	Loss 0.99	Acc@1 96.9	Acc@5 100.0
Epoch: [250][131/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [250][141/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [250][151/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 95.3	Acc@5 100.0
Epoch: [250][161/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [250][171/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [250][181/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [250][191/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [250][201/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 98.4	Acc@5 100.0
Epoch: [250][211/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 96.9	Acc@5 100.0
Epoch: [250][221/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 89.1	Acc@5 100.0
Epoch: [250][231/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 92.2	Acc@5 100.0
Epoch: [250][241/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 92.2	Acc@5 100.0
Epoch: [250][251/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [250][261/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [250][271/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [250][281/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [250][291/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 89.1	Acc@5 100.0
Epoch: [250][301/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 98.4	Acc@5 98.4
Epoch: [250][311/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 100.0
Epoch: [250][321/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 100.0	Acc@5 100.0
Epoch: [250][331/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [250][341/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [250][351/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 95.3	Acc@5 100.0
Epoch: [250][361/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [250][371/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [250][381/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [250][391/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [250][401/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [250][411/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [250][421/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 90.6	Acc@5 100.0
Epoch: [250][431/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 89.1	Acc@5 100.0
Epoch: [250][441/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [250][451/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 95.3	Acc@5 100.0
Epoch: [250][461/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 96.9	Acc@5 100.0
Epoch: [250][471/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [250][481/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 98.4	Acc@5 98.4
Epoch: [250][491/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 93.8	Acc@5 100.0
Epoch: [250][501/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 96.9	Acc@5 100.0
Epoch: [250][511/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [250][521/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [250][531/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [250][541/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [250][551/704]	Time 0.120	Data 0.001	Loss 1.29	Acc@1 95.3	Acc@5 100.0
Epoch: [250][561/704]	Time 0.120	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [250][571/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [250][581/704]	Time 0.120	Data 0.001	Loss 1.21	Acc@1 95.3	Acc@5 98.4
Epoch: [250][591/704]	Time 0.120	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [250][601/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 89.1	Acc@5 100.0
Epoch: [250][611/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [250][621/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [250][631/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [250][641/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [250][651/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 100.0	Acc@5 100.0
Epoch: [250][661/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 96.9	Acc@5 100.0
Epoch: [250][671/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [250][681/704]	Time 0.120	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [250][691/704]	Time 0.120	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 98.4
Epoch: [250][701/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.9359	Acc@1 70.3125	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.8978	Acc@1 75.0000	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2745	Acc@1 64.0625	Acc@5 89.0625
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 7.3791	Acc@1 59.3750	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.6894	Acc@1 71.8750	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.0975	Acc@1 60.9375	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.0931	Acc@1 68.7500	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.3511	Acc@1 62.5000	Acc@5 89.0625
 * prec@1 58.880 prec@5 85.920
 * prec@1 63.000 prec@5 88.440
 * prec@1 67.140 prec@5 91.020
 * prec@1 69.000 prec@5 91.400
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_250.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_250.pth.tar'
Epoch: [251][1/704]	Time 0.301	Data 0.133	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [251][11/704]	Time 0.137	Data 0.013	Loss 2.23	Acc@1 96.9	Acc@5 100.0
Epoch: [251][21/704]	Time 0.129	Data 0.007	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [251][31/704]	Time 0.126	Data 0.005	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [251][41/704]	Time 0.125	Data 0.004	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [251][51/704]	Time 0.124	Data 0.003	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [251][61/704]	Time 0.124	Data 0.003	Loss 2.01	Acc@1 96.9	Acc@5 98.4
Epoch: [251][71/704]	Time 0.124	Data 0.002	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [251][81/704]	Time 0.123	Data 0.002	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [251][91/704]	Time 0.123	Data 0.002	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [251][101/704]	Time 0.123	Data 0.002	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [251][111/704]	Time 0.123	Data 0.002	Loss 1.82	Acc@1 100.0	Acc@5 100.0
Epoch: [251][121/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [251][131/704]	Time 0.122	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [251][141/704]	Time 0.122	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [251][151/704]	Time 0.122	Data 0.001	Loss 1.79	Acc@1 90.6	Acc@5 98.4
Epoch: [251][161/704]	Time 0.122	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [251][171/704]	Time 0.122	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [251][181/704]	Time 0.122	Data 0.001	Loss 2.08	Acc@1 87.5	Acc@5 100.0
Epoch: [251][191/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [251][201/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [251][211/704]	Time 0.122	Data 0.001	Loss 2.12	Acc@1 96.9	Acc@5 100.0
Epoch: [251][221/704]	Time 0.122	Data 0.001	Loss 1.79	Acc@1 90.6	Acc@5 100.0
Epoch: [251][231/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 90.6	Acc@5 100.0
Epoch: [251][241/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [251][251/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [251][261/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 92.2	Acc@5 98.4
Epoch: [251][271/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 92.2	Acc@5 100.0
Epoch: [251][281/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [251][291/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [251][301/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [251][311/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 100.0
Epoch: [251][321/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 90.6	Acc@5 100.0
Epoch: [251][331/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [251][341/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [251][351/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [251][361/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [251][371/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 93.8	Acc@5 100.0
Epoch: [251][381/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 98.4
Epoch: [251][391/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 100.0
Epoch: [251][401/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [251][411/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 85.9	Acc@5 100.0
Epoch: [251][421/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 98.4	Acc@5 100.0
Epoch: [251][431/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [251][441/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [251][451/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [251][461/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [251][471/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [251][481/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [251][491/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [251][501/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [251][511/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [251][521/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [251][531/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [251][541/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [251][551/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [251][561/704]	Time 0.121	Data 0.001	Loss 2.46	Acc@1 93.8	Acc@5 100.0
Epoch: [251][571/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 92.2	Acc@5 100.0
Epoch: [251][581/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [251][591/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 93.8	Acc@5 100.0
Epoch: [251][601/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 93.8	Acc@5 100.0
Epoch: [251][611/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [251][621/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 98.4	Acc@5 100.0
Epoch: [251][631/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 93.8	Acc@5 98.4
Epoch: [251][641/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [251][651/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [251][661/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 98.4
Epoch: [251][671/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [251][681/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [251][691/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [251][701/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.8431	Acc@1 62.5000	Acc@5 89.0625
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 5.4975	Acc@1 70.3125	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.4212	Acc@1 64.0625	Acc@5 92.1875
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 5.4577	Acc@1 70.3125	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.5695	Acc@1 70.3125	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.3691	Acc@1 73.4375	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.4738	Acc@1 67.1875	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.6770	Acc@1 64.0625	Acc@5 95.3125
 * prec@1 58.580 prec@5 85.040
 * prec@1 63.100 prec@5 88.740
 * prec@1 66.500 prec@5 91.060
 * prec@1 69.440 prec@5 91.560
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_251.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_251.pth.tar'
Epoch: [252][1/704]	Time 0.337	Data 0.171	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [252][11/704]	Time 0.141	Data 0.016	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [252][21/704]	Time 0.131	Data 0.009	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [252][31/704]	Time 0.128	Data 0.006	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [252][41/704]	Time 0.126	Data 0.005	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [252][51/704]	Time 0.125	Data 0.004	Loss 2.09	Acc@1 98.4	Acc@5 100.0
Epoch: [252][61/704]	Time 0.124	Data 0.003	Loss 2.25	Acc@1 93.8	Acc@5 98.4
Epoch: [252][71/704]	Time 0.124	Data 0.003	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [252][81/704]	Time 0.123	Data 0.003	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [252][91/704]	Time 0.123	Data 0.002	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [252][101/704]	Time 0.123	Data 0.002	Loss 2.07	Acc@1 96.9	Acc@5 100.0
Epoch: [252][111/704]	Time 0.123	Data 0.002	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [252][121/704]	Time 0.122	Data 0.002	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [252][131/704]	Time 0.122	Data 0.002	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [252][141/704]	Time 0.122	Data 0.002	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [252][151/704]	Time 0.122	Data 0.002	Loss 3.05	Acc@1 90.6	Acc@5 100.0
Epoch: [252][161/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [252][171/704]	Time 0.122	Data 0.001	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [252][181/704]	Time 0.122	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [252][191/704]	Time 0.122	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [252][201/704]	Time 0.122	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [252][211/704]	Time 0.122	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [252][221/704]	Time 0.122	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [252][231/704]	Time 0.122	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [252][241/704]	Time 0.122	Data 0.001	Loss 1.88	Acc@1 96.9	Acc@5 100.0
Epoch: [252][251/704]	Time 0.122	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [252][261/704]	Time 0.122	Data 0.001	Loss 2.05	Acc@1 95.3	Acc@5 98.4
Epoch: [252][271/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 98.4	Acc@5 100.0
Epoch: [252][281/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [252][291/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [252][301/704]	Time 0.121	Data 0.001	Loss 2.90	Acc@1 89.1	Acc@5 100.0
Epoch: [252][311/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [252][321/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [252][331/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 98.4	Acc@5 100.0
Epoch: [252][341/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 87.5	Acc@5 100.0
Epoch: [252][351/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 95.3	Acc@5 100.0
Epoch: [252][361/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 96.9	Acc@5 100.0
Epoch: [252][371/704]	Time 0.121	Data 0.001	Loss 1.05	Acc@1 100.0	Acc@5 100.0
Epoch: [252][381/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [252][391/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 96.9	Acc@5 100.0
Epoch: [252][401/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [252][411/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [252][421/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [252][431/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [252][441/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [252][451/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [252][461/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 95.3	Acc@5 98.4
Epoch: [252][471/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 89.1	Acc@5 100.0
Epoch: [252][481/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [252][491/704]	Time 0.121	Data 0.001	Loss 1.11	Acc@1 98.4	Acc@5 100.0
Epoch: [252][501/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [252][511/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 98.4	Acc@5 98.4
Epoch: [252][521/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [252][531/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [252][541/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [252][551/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [252][561/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 96.9	Acc@5 100.0
Epoch: [252][571/704]	Time 0.121	Data 0.001	Loss 1.13	Acc@1 98.4	Acc@5 100.0
Epoch: [252][581/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [252][591/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [252][601/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 98.4
Epoch: [252][611/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [252][621/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [252][631/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 98.4	Acc@5 100.0
Epoch: [252][641/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [252][651/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [252][661/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 92.2	Acc@5 100.0
Epoch: [252][671/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [252][681/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [252][691/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [252][701/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 98.4
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.9883	Acc@1 67.1875	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.9737	Acc@1 62.5000	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2868	Acc@1 60.9375	Acc@5 92.1875
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 6.5036	Acc@1 59.3750	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.2781	Acc@1 70.3125	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.0866	Acc@1 68.7500	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.3046	Acc@1 70.3125	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.7981	Acc@1 64.0625	Acc@5 89.0625
 * prec@1 58.200 prec@5 85.700
 * prec@1 63.040 prec@5 88.280
 * prec@1 67.000 prec@5 90.760
 * prec@1 68.540 prec@5 91.420
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_252.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_252.pth.tar'
Epoch: [253][1/704]	Time 0.336	Data 0.169	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [253][11/704]	Time 0.140	Data 0.016	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [253][21/704]	Time 0.131	Data 0.008	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [253][31/704]	Time 0.127	Data 0.006	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [253][41/704]	Time 0.126	Data 0.004	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [253][51/704]	Time 0.125	Data 0.004	Loss 2.20	Acc@1 96.9	Acc@5 100.0
Epoch: [253][61/704]	Time 0.124	Data 0.003	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [253][71/704]	Time 0.123	Data 0.003	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [253][81/704]	Time 0.123	Data 0.002	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [253][91/704]	Time 0.122	Data 0.002	Loss 1.86	Acc@1 87.5	Acc@5 100.0
Epoch: [253][101/704]	Time 0.122	Data 0.002	Loss 2.37	Acc@1 92.2	Acc@5 100.0
Epoch: [253][111/704]	Time 0.122	Data 0.002	Loss 1.38	Acc@1 100.0	Acc@5 100.0
Epoch: [253][121/704]	Time 0.122	Data 0.002	Loss 2.02	Acc@1 90.6	Acc@5 100.0
Epoch: [253][131/704]	Time 0.122	Data 0.002	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [253][141/704]	Time 0.122	Data 0.002	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [253][151/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 98.4	Acc@5 100.0
Epoch: [253][161/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [253][171/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [253][181/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [253][191/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 98.4	Acc@5 100.0
Epoch: [253][201/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [253][211/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 98.4	Acc@5 100.0
Epoch: [253][221/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [253][231/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [253][241/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [253][251/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [253][261/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [253][271/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [253][281/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [253][291/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [253][301/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 98.4
Epoch: [253][311/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [253][321/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [253][331/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [253][341/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [253][351/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 85.9	Acc@5 100.0
Epoch: [253][361/704]	Time 0.121	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 100.0
Epoch: [253][371/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 96.9	Acc@5 100.0
Epoch: [253][381/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 95.3	Acc@5 100.0
Epoch: [253][391/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 98.4
Epoch: [253][401/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [253][411/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 90.6	Acc@5 100.0
Epoch: [253][421/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [253][431/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [253][441/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [253][451/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [253][461/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [253][471/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 92.2	Acc@5 100.0
Epoch: [253][481/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 96.9	Acc@5 100.0
Epoch: [253][491/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [253][501/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [253][511/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [253][521/704]	Time 0.121	Data 0.001	Loss 2.39	Acc@1 93.8	Acc@5 100.0
Epoch: [253][531/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 96.9	Acc@5 100.0
Epoch: [253][541/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [253][551/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 98.4	Acc@5 100.0
Epoch: [253][561/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [253][571/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [253][581/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 98.4	Acc@5 100.0
Epoch: [253][591/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 98.4	Acc@5 100.0
Epoch: [253][601/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [253][611/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [253][621/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [253][631/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [253][641/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [253][651/704]	Time 0.120	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [253][661/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [253][671/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 92.2	Acc@5 100.0
Epoch: [253][681/704]	Time 0.120	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [253][691/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [253][701/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.3233	Acc@1 65.6250	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4209	Acc@1 73.4375	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.2371	Acc@1 76.5625	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.8056	Acc@1 73.4375	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.2802	Acc@1 64.0625	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.5906	Acc@1 70.3125	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.5222	Acc@1 60.9375	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.8858	Acc@1 73.4375	Acc@5 92.1875
 * prec@1 59.080 prec@5 85.260
 * prec@1 63.240 prec@5 88.640
 * prec@1 66.600 prec@5 91.380
 * prec@1 68.160 prec@5 91.300
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_253.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_253.pth.tar'
Epoch: [254][1/704]	Time 0.299	Data 0.131	Loss 1.17	Acc@1 96.9	Acc@5 100.0
Epoch: [254][11/704]	Time 0.137	Data 0.012	Loss 1.22	Acc@1 95.3	Acc@5 100.0
Epoch: [254][21/704]	Time 0.129	Data 0.007	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [254][31/704]	Time 0.126	Data 0.005	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [254][41/704]	Time 0.125	Data 0.004	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [254][51/704]	Time 0.124	Data 0.003	Loss 1.21	Acc@1 100.0	Acc@5 100.0
Epoch: [254][61/704]	Time 0.123	Data 0.002	Loss 1.44	Acc@1 93.8	Acc@5 100.0
Epoch: [254][71/704]	Time 0.123	Data 0.002	Loss 1.29	Acc@1 100.0	Acc@5 100.0
Epoch: [254][81/704]	Time 0.122	Data 0.002	Loss 1.85	Acc@1 96.9	Acc@5 100.0
Epoch: [254][91/704]	Time 0.122	Data 0.002	Loss 1.56	Acc@1 90.6	Acc@5 100.0
Epoch: [254][101/704]	Time 0.122	Data 0.002	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [254][111/704]	Time 0.122	Data 0.002	Loss 1.69	Acc@1 98.4	Acc@5 100.0
Epoch: [254][121/704]	Time 0.122	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [254][131/704]	Time 0.122	Data 0.001	Loss 0.92	Acc@1 100.0	Acc@5 100.0
Epoch: [254][141/704]	Time 0.122	Data 0.001	Loss 1.42	Acc@1 100.0	Acc@5 100.0
Epoch: [254][151/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [254][161/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [254][171/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [254][181/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [254][191/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [254][201/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 100.0	Acc@5 100.0
Epoch: [254][211/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [254][221/704]	Time 0.121	Data 0.001	Loss 0.93	Acc@1 98.4	Acc@5 100.0
Epoch: [254][231/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [254][241/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 93.8	Acc@5 100.0
Epoch: [254][251/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [254][261/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 100.0	Acc@5 100.0
Epoch: [254][271/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 89.1	Acc@5 100.0
Epoch: [254][281/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 100.0	Acc@5 100.0
Epoch: [254][291/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [254][301/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [254][311/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [254][321/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [254][331/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [254][341/704]	Time 0.121	Data 0.001	Loss 0.97	Acc@1 98.4	Acc@5 100.0
Epoch: [254][351/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 96.9	Acc@5 100.0
Epoch: [254][361/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [254][371/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 98.4
Epoch: [254][381/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [254][391/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 95.3	Acc@5 100.0
Epoch: [254][401/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [254][411/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [254][421/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [254][431/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [254][441/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 92.2	Acc@5 100.0
Epoch: [254][451/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [254][461/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [254][471/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 98.4
Epoch: [254][481/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 100.0	Acc@5 100.0
Epoch: [254][491/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 100.0	Acc@5 100.0
Epoch: [254][501/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [254][511/704]	Time 0.120	Data 0.001	Loss 2.52	Acc@1 89.1	Acc@5 100.0
Epoch: [254][521/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [254][531/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 92.2	Acc@5 100.0
Epoch: [254][541/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [254][551/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [254][561/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [254][571/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [254][581/704]	Time 0.120	Data 0.001	Loss 2.31	Acc@1 95.3	Acc@5 100.0
Epoch: [254][591/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 98.4	Acc@5 100.0
Epoch: [254][601/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 98.4
Epoch: [254][611/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [254][621/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [254][631/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [254][641/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 92.2	Acc@5 100.0
Epoch: [254][651/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [254][661/704]	Time 0.120	Data 0.001	Loss 1.27	Acc@1 93.8	Acc@5 100.0
Epoch: [254][671/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [254][681/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [254][691/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [254][701/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.3146	Acc@1 71.8750	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.8440	Acc@1 65.6250	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.2287	Acc@1 60.9375	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.1909	Acc@1 67.1875	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3044	Acc@1 73.4375	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.5233	Acc@1 71.8750	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.8087	Acc@1 75.0000	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.2205	Acc@1 65.6250	Acc@5 90.6250
 * prec@1 58.480 prec@5 85.840
 * prec@1 62.900 prec@5 88.580
 * prec@1 66.660 prec@5 90.880
 * prec@1 69.320 prec@5 91.700
Current best validation last_bloc_accuracy 69.68
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_254.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_254.pth.tar'
Epoch: [255][1/704]	Time 0.301	Data 0.133	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [255][11/704]	Time 0.141	Data 0.012	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [255][21/704]	Time 0.131	Data 0.007	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [255][31/704]	Time 0.128	Data 0.005	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [255][41/704]	Time 0.127	Data 0.004	Loss 1.53	Acc@1 92.2	Acc@5 100.0
Epoch: [255][51/704]	Time 0.125	Data 0.003	Loss 1.89	Acc@1 89.1	Acc@5 100.0
Epoch: [255][61/704]	Time 0.125	Data 0.003	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [255][71/704]	Time 0.124	Data 0.002	Loss 1.49	Acc@1 92.2	Acc@5 100.0
Epoch: [255][81/704]	Time 0.123	Data 0.002	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [255][91/704]	Time 0.123	Data 0.002	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [255][101/704]	Time 0.123	Data 0.002	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [255][111/704]	Time 0.123	Data 0.002	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [255][121/704]	Time 0.122	Data 0.001	Loss 1.07	Acc@1 96.9	Acc@5 100.0
Epoch: [255][131/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [255][141/704]	Time 0.122	Data 0.001	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [255][151/704]	Time 0.122	Data 0.001	Loss 1.26	Acc@1 100.0	Acc@5 100.0
Epoch: [255][161/704]	Time 0.122	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [255][171/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 98.4
Epoch: [255][181/704]	Time 0.122	Data 0.001	Loss 1.18	Acc@1 100.0	Acc@5 100.0
Epoch: [255][191/704]	Time 0.122	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [255][201/704]	Time 0.122	Data 0.001	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [255][211/704]	Time 0.122	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [255][221/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [255][231/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [255][241/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [255][251/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 92.2	Acc@5 100.0
Epoch: [255][261/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [255][271/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [255][281/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [255][291/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 98.4
Epoch: [255][301/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 98.4
Epoch: [255][311/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 92.2	Acc@5 100.0
Epoch: [255][321/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [255][331/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 95.3	Acc@5 100.0
Epoch: [255][341/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [255][351/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [255][361/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [255][371/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [255][381/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 100.0	Acc@5 100.0
Epoch: [255][391/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [255][401/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [255][411/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [255][421/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 98.4
Epoch: [255][431/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [255][441/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [255][451/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [255][461/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [255][471/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 90.6	Acc@5 100.0
Epoch: [255][481/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 87.5	Acc@5 98.4
Epoch: [255][491/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [255][501/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 98.4
Epoch: [255][511/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [255][521/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [255][531/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [255][541/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [255][551/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 98.4	Acc@5 100.0
Epoch: [255][561/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 96.9	Acc@5 100.0
Epoch: [255][571/704]	Time 0.121	Data 0.001	Loss 1.00	Acc@1 98.4	Acc@5 100.0
Epoch: [255][581/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 100.0	Acc@5 100.0
Epoch: [255][591/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [255][601/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 100.0	Acc@5 100.0
Epoch: [255][611/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [255][621/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 98.4	Acc@5 100.0
Epoch: [255][631/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [255][641/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 98.4
Epoch: [255][651/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 93.8	Acc@5 100.0
Epoch: [255][661/704]	Time 0.121	Data 0.001	Loss 2.44	Acc@1 98.4	Acc@5 100.0
Epoch: [255][671/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 98.4	Acc@5 100.0
Epoch: [255][681/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [255][691/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [255][701/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.0311	Acc@1 70.3125	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.4922	Acc@1 60.9375	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8856	Acc@1 68.7500	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.2780	Acc@1 57.8125	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.8802	Acc@1 75.0000	Acc@5 98.4375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.2478	Acc@1 75.0000	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4121	Acc@1 71.8750	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.9652	Acc@1 67.1875	Acc@5 93.7500
 * prec@1 58.780 prec@5 85.700
 * prec@1 63.860 prec@5 88.320
 * prec@1 67.360 prec@5 90.720
 * prec@1 70.000 prec@5 91.740
New best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_255.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_255.pth.tar'
Epoch: [256][1/704]	Time 0.332	Data 0.165	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [256][11/704]	Time 0.140	Data 0.015	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [256][21/704]	Time 0.131	Data 0.008	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [256][31/704]	Time 0.127	Data 0.006	Loss 1.92	Acc@1 95.3	Acc@5 100.0
Epoch: [256][41/704]	Time 0.125	Data 0.004	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [256][51/704]	Time 0.124	Data 0.004	Loss 1.55	Acc@1 93.8	Acc@5 100.0
Epoch: [256][61/704]	Time 0.124	Data 0.003	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [256][71/704]	Time 0.123	Data 0.003	Loss 1.95	Acc@1 98.4	Acc@5 100.0
Epoch: [256][81/704]	Time 0.123	Data 0.002	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [256][91/704]	Time 0.123	Data 0.002	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [256][101/704]	Time 0.122	Data 0.002	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [256][111/704]	Time 0.122	Data 0.002	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [256][121/704]	Time 0.122	Data 0.002	Loss 2.14	Acc@1 95.3	Acc@5 98.4
Epoch: [256][131/704]	Time 0.122	Data 0.002	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [256][141/704]	Time 0.122	Data 0.002	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [256][151/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [256][161/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [256][171/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 90.6	Acc@5 100.0
Epoch: [256][181/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 95.3	Acc@5 98.4
Epoch: [256][191/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [256][201/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [256][211/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [256][221/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [256][231/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [256][241/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 96.9	Acc@5 100.0
Epoch: [256][251/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [256][261/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [256][271/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 92.2	Acc@5 100.0
Epoch: [256][281/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 98.4
Epoch: [256][291/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 95.3	Acc@5 100.0
Epoch: [256][301/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [256][311/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [256][321/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [256][331/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [256][341/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [256][351/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [256][361/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [256][371/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 93.8	Acc@5 100.0
Epoch: [256][381/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 92.2	Acc@5 100.0
Epoch: [256][391/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [256][401/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 100.0	Acc@5 100.0
Epoch: [256][411/704]	Time 0.121	Data 0.001	Loss 1.00	Acc@1 96.9	Acc@5 100.0
Epoch: [256][421/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [256][431/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 98.4
Epoch: [256][441/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [256][451/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [256][461/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [256][471/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 100.0	Acc@5 100.0
Epoch: [256][481/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [256][491/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [256][501/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 93.8	Acc@5 98.4
Epoch: [256][511/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [256][521/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [256][531/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 98.4
Epoch: [256][541/704]	Time 0.121	Data 0.001	Loss 1.13	Acc@1 92.2	Acc@5 100.0
Epoch: [256][551/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [256][561/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [256][571/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 90.6	Acc@5 100.0
Epoch: [256][581/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [256][591/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [256][601/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 87.5	Acc@5 100.0
Epoch: [256][611/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 95.3	Acc@5 100.0
Epoch: [256][621/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 92.2	Acc@5 100.0
Epoch: [256][631/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 100.0	Acc@5 100.0
Epoch: [256][641/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [256][651/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [256][661/704]	Time 0.121	Data 0.001	Loss 2.45	Acc@1 92.2	Acc@5 100.0
Epoch: [256][671/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [256][681/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [256][691/704]	Time 0.120	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [256][701/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.0017	Acc@1 65.6250	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1893	Acc@1 65.6250	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.1989	Acc@1 68.7500	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.8651	Acc@1 65.6250	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5573	Acc@1 64.0625	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6623	Acc@1 68.7500	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.2724	Acc@1 51.5625	Acc@5 79.6875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.4932	Acc@1 70.3125	Acc@5 92.1875
 * prec@1 59.140 prec@5 86.040
 * prec@1 62.320 prec@5 89.080
 * prec@1 66.760 prec@5 90.840
 * prec@1 68.760 prec@5 91.020
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_256.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_256.pth.tar'
Epoch: [257][1/704]	Time 0.302	Data 0.134	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [257][11/704]	Time 0.137	Data 0.013	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [257][21/704]	Time 0.129	Data 0.007	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [257][31/704]	Time 0.126	Data 0.005	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [257][41/704]	Time 0.125	Data 0.004	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [257][51/704]	Time 0.124	Data 0.003	Loss 1.51	Acc@1 96.9	Acc@5 98.4
Epoch: [257][61/704]	Time 0.123	Data 0.003	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [257][71/704]	Time 0.123	Data 0.002	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [257][81/704]	Time 0.123	Data 0.002	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [257][91/704]	Time 0.122	Data 0.002	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [257][101/704]	Time 0.122	Data 0.002	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [257][111/704]	Time 0.122	Data 0.002	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [257][121/704]	Time 0.122	Data 0.002	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [257][131/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [257][141/704]	Time 0.122	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [257][151/704]	Time 0.122	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [257][161/704]	Time 0.122	Data 0.001	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [257][171/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 90.6	Acc@5 100.0
Epoch: [257][181/704]	Time 0.122	Data 0.001	Loss 1.44	Acc@1 93.8	Acc@5 100.0
Epoch: [257][191/704]	Time 0.122	Data 0.001	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [257][201/704]	Time 0.122	Data 0.001	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [257][211/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [257][221/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 96.9	Acc@5 100.0
Epoch: [257][231/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [257][241/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [257][251/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 93.8	Acc@5 98.4
Epoch: [257][261/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [257][271/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 98.4	Acc@5 100.0
Epoch: [257][281/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 93.8	Acc@5 98.4
Epoch: [257][291/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [257][301/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 92.2	Acc@5 100.0
Epoch: [257][311/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [257][321/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [257][331/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 93.8	Acc@5 100.0
Epoch: [257][341/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [257][351/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 98.4	Acc@5 100.0
Epoch: [257][361/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 98.4
Epoch: [257][371/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [257][381/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 90.6	Acc@5 100.0
Epoch: [257][391/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [257][401/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 92.2	Acc@5 100.0
Epoch: [257][411/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [257][421/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 96.9	Acc@5 100.0
Epoch: [257][431/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [257][441/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [257][451/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [257][461/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [257][471/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [257][481/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [257][491/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [257][501/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 90.6	Acc@5 100.0
Epoch: [257][511/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [257][521/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 98.4
Epoch: [257][531/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 98.4
Epoch: [257][541/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 98.4	Acc@5 100.0
Epoch: [257][551/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [257][561/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [257][571/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [257][581/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 95.3	Acc@5 100.0
Epoch: [257][591/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [257][601/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [257][611/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [257][621/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [257][631/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [257][641/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [257][651/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 95.3	Acc@5 100.0
Epoch: [257][661/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [257][671/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [257][681/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [257][691/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 92.2	Acc@5 100.0
Epoch: [257][701/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.9190	Acc@1 70.3125	Acc@5 89.0625
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.5709	Acc@1 62.5000	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.4054	Acc@1 75.0000	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.9615	Acc@1 65.6250	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3657	Acc@1 71.8750	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.8499	Acc@1 70.3125	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.3904	Acc@1 64.0625	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 5.5545	Acc@1 71.8750	Acc@5 92.1875
 * prec@1 58.880 prec@5 85.840
 * prec@1 62.740 prec@5 88.400
 * prec@1 67.420 prec@5 91.180
 * prec@1 69.000 prec@5 91.560
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_257.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_257.pth.tar'
Epoch: [258][1/704]	Time 0.298	Data 0.131	Loss 1.22	Acc@1 96.9	Acc@5 100.0
Epoch: [258][11/704]	Time 0.136	Data 0.012	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [258][21/704]	Time 0.129	Data 0.006	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [258][31/704]	Time 0.126	Data 0.004	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [258][41/704]	Time 0.124	Data 0.003	Loss 1.49	Acc@1 93.8	Acc@5 100.0
Epoch: [258][51/704]	Time 0.124	Data 0.003	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [258][61/704]	Time 0.124	Data 0.002	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [258][71/704]	Time 0.123	Data 0.002	Loss 2.62	Acc@1 90.6	Acc@5 98.4
Epoch: [258][81/704]	Time 0.123	Data 0.002	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [258][91/704]	Time 0.122	Data 0.002	Loss 1.61	Acc@1 92.2	Acc@5 100.0
Epoch: [258][101/704]	Time 0.122	Data 0.002	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [258][111/704]	Time 0.122	Data 0.002	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [258][121/704]	Time 0.122	Data 0.001	Loss 1.67	Acc@1 100.0	Acc@5 100.0
Epoch: [258][131/704]	Time 0.122	Data 0.001	Loss 1.53	Acc@1 92.2	Acc@5 100.0
Epoch: [258][141/704]	Time 0.122	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [258][151/704]	Time 0.122	Data 0.001	Loss 1.15	Acc@1 96.9	Acc@5 100.0
Epoch: [258][161/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 90.6	Acc@5 98.4
Epoch: [258][171/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 100.0	Acc@5 100.0
Epoch: [258][181/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 100.0
Epoch: [258][191/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [258][201/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 92.2	Acc@5 100.0
Epoch: [258][211/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 98.4	Acc@5 100.0
Epoch: [258][221/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 100.0	Acc@5 100.0
Epoch: [258][231/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [258][241/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [258][251/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [258][261/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 98.4
Epoch: [258][271/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [258][281/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [258][291/704]	Time 0.121	Data 0.001	Loss 1.15	Acc@1 95.3	Acc@5 98.4
Epoch: [258][301/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [258][311/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [258][321/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 92.2	Acc@5 100.0
Epoch: [258][331/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [258][341/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [258][351/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [258][361/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [258][371/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [258][381/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 98.4	Acc@5 100.0
Epoch: [258][391/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [258][401/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [258][411/704]	Time 0.121	Data 0.001	Loss 0.99	Acc@1 100.0	Acc@5 100.0
Epoch: [258][421/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [258][431/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 93.8	Acc@5 100.0
Epoch: [258][441/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [258][451/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [258][461/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 95.3	Acc@5 100.0
Epoch: [258][471/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [258][481/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [258][491/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 100.0	Acc@5 100.0
Epoch: [258][501/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [258][511/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 98.4
Epoch: [258][521/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [258][531/704]	Time 0.120	Data 0.001	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [258][541/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [258][551/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [258][561/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [258][571/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [258][581/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [258][591/704]	Time 0.120	Data 0.001	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [258][601/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 98.4	Acc@5 100.0
Epoch: [258][611/704]	Time 0.120	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [258][621/704]	Time 0.120	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [258][631/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 96.9	Acc@5 100.0
Epoch: [258][641/704]	Time 0.120	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [258][651/704]	Time 0.120	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [258][661/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [258][671/704]	Time 0.120	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [258][681/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [258][691/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [258][701/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.6367	Acc@1 73.4375	Acc@5 93.7500
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 5.7932	Acc@1 70.3125	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.4259	Acc@1 70.3125	Acc@5 87.5000
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 7.6114	Acc@1 53.1250	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5178	Acc@1 68.7500	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0155	Acc@1 68.7500	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.4213	Acc@1 73.4375	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 7.4062	Acc@1 65.6250	Acc@5 92.1875
 * prec@1 58.360 prec@5 85.280
 * prec@1 62.680 prec@5 88.480
 * prec@1 66.300 prec@5 90.780
 * prec@1 69.120 prec@5 91.420
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_258.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_258.pth.tar'
Epoch: [259][1/704]	Time 0.332	Data 0.166	Loss 1.15	Acc@1 100.0	Acc@5 100.0
Epoch: [259][11/704]	Time 0.140	Data 0.016	Loss 1.65	Acc@1 92.2	Acc@5 100.0
Epoch: [259][21/704]	Time 0.131	Data 0.008	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [259][31/704]	Time 0.127	Data 0.006	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [259][41/704]	Time 0.126	Data 0.004	Loss 1.46	Acc@1 100.0	Acc@5 100.0
Epoch: [259][51/704]	Time 0.125	Data 0.004	Loss 1.61	Acc@1 90.6	Acc@5 100.0
Epoch: [259][61/704]	Time 0.124	Data 0.003	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [259][71/704]	Time 0.123	Data 0.003	Loss 2.32	Acc@1 95.3	Acc@5 100.0
Epoch: [259][81/704]	Time 0.123	Data 0.002	Loss 1.11	Acc@1 100.0	Acc@5 100.0
Epoch: [259][91/704]	Time 0.123	Data 0.002	Loss 2.32	Acc@1 90.6	Acc@5 100.0
Epoch: [259][101/704]	Time 0.122	Data 0.002	Loss 2.15	Acc@1 96.9	Acc@5 100.0
Epoch: [259][111/704]	Time 0.122	Data 0.002	Loss 1.28	Acc@1 95.3	Acc@5 100.0
Epoch: [259][121/704]	Time 0.122	Data 0.002	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [259][131/704]	Time 0.122	Data 0.002	Loss 1.75	Acc@1 98.4	Acc@5 100.0
Epoch: [259][141/704]	Time 0.122	Data 0.002	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [259][151/704]	Time 0.122	Data 0.002	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [259][161/704]	Time 0.122	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [259][171/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [259][181/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 98.4	Acc@5 100.0
Epoch: [259][191/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 90.6	Acc@5 100.0
Epoch: [259][201/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [259][211/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 92.2	Acc@5 98.4
Epoch: [259][221/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [259][231/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 98.4
Epoch: [259][241/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [259][251/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [259][261/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [259][271/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 96.9	Acc@5 100.0
Epoch: [259][281/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [259][291/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [259][301/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 90.6	Acc@5 100.0
Epoch: [259][311/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 95.3	Acc@5 98.4
Epoch: [259][321/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 98.4
Epoch: [259][331/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 98.4	Acc@5 100.0
Epoch: [259][341/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [259][351/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 85.9	Acc@5 100.0
Epoch: [259][361/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [259][371/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [259][381/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [259][391/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 98.4	Acc@5 100.0
Epoch: [259][401/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 90.6	Acc@5 98.4
Epoch: [259][411/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [259][421/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [259][431/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [259][441/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 90.6	Acc@5 100.0
Epoch: [259][451/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [259][461/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [259][471/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [259][481/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [259][491/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [259][501/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [259][511/704]	Time 0.121	Data 0.001	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [259][521/704]	Time 0.121	Data 0.001	Loss 2.27	Acc@1 92.2	Acc@5 100.0
Epoch: [259][531/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 100.0
Epoch: [259][541/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [259][551/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [259][561/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 89.1	Acc@5 100.0
Epoch: [259][571/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [259][581/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 92.2	Acc@5 100.0
Epoch: [259][591/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [259][601/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 90.6	Acc@5 98.4
Epoch: [259][611/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [259][621/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [259][631/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [259][641/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [259][651/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [259][661/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [259][671/704]	Time 0.120	Data 0.001	Loss 1.27	Acc@1 95.3	Acc@5 100.0
Epoch: [259][681/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 98.4
Epoch: [259][691/704]	Time 0.120	Data 0.001	Loss 1.46	Acc@1 92.2	Acc@5 98.4
Epoch: [259][701/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 85.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 7.7018	Acc@1 59.3750	Acc@5 84.3750
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8274	Acc@1 59.3750	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7670	Acc@1 70.3125	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.2795	Acc@1 79.6875	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6290	Acc@1 65.6250	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9237	Acc@1 70.3125	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.6200	Acc@1 76.5625	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.4428	Acc@1 65.6250	Acc@5 93.7500
 * prec@1 57.960 prec@5 85.560
 * prec@1 62.740 prec@5 88.500
 * prec@1 67.560 prec@5 91.200
 * prec@1 69.020 prec@5 91.500
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_259.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_259.pth.tar'
Epoch: [260][1/704]	Time 0.331	Data 0.165	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [260][11/704]	Time 0.140	Data 0.015	Loss 2.08	Acc@1 90.6	Acc@5 100.0
Epoch: [260][21/704]	Time 0.131	Data 0.008	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [260][31/704]	Time 0.127	Data 0.006	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [260][41/704]	Time 0.126	Data 0.004	Loss 1.84	Acc@1 98.4	Acc@5 100.0
Epoch: [260][51/704]	Time 0.125	Data 0.004	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [260][61/704]	Time 0.124	Data 0.003	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [260][71/704]	Time 0.123	Data 0.003	Loss 1.77	Acc@1 100.0	Acc@5 100.0
Epoch: [260][81/704]	Time 0.123	Data 0.002	Loss 1.10	Acc@1 96.9	Acc@5 100.0
Epoch: [260][91/704]	Time 0.123	Data 0.002	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [260][101/704]	Time 0.122	Data 0.002	Loss 1.16	Acc@1 96.9	Acc@5 100.0
Epoch: [260][111/704]	Time 0.122	Data 0.002	Loss 1.83	Acc@1 90.6	Acc@5 100.0
Epoch: [260][121/704]	Time 0.122	Data 0.002	Loss 1.60	Acc@1 100.0	Acc@5 100.0
Epoch: [260][131/704]	Time 0.122	Data 0.002	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [260][141/704]	Time 0.122	Data 0.002	Loss 1.22	Acc@1 96.9	Acc@5 100.0
Epoch: [260][151/704]	Time 0.122	Data 0.002	Loss 1.91	Acc@1 89.1	Acc@5 100.0
Epoch: [260][161/704]	Time 0.122	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [260][171/704]	Time 0.122	Data 0.001	Loss 1.71	Acc@1 98.4	Acc@5 100.0
Epoch: [260][181/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [260][191/704]	Time 0.122	Data 0.001	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [260][201/704]	Time 0.122	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [260][211/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 92.2	Acc@5 100.0
Epoch: [260][221/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 98.4
Epoch: [260][231/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [260][241/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [260][251/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [260][261/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [260][271/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [260][281/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [260][291/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 92.2	Acc@5 100.0
Epoch: [260][301/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [260][311/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [260][321/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [260][331/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [260][341/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [260][351/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [260][361/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [260][371/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [260][381/704]	Time 0.121	Data 0.001	Loss 2.57	Acc@1 95.3	Acc@5 100.0
Epoch: [260][391/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [260][401/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 90.6	Acc@5 100.0
Epoch: [260][411/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 98.4
Epoch: [260][421/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [260][431/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 95.3	Acc@5 98.4
Epoch: [260][441/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [260][451/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 100.0	Acc@5 100.0
Epoch: [260][461/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [260][471/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [260][481/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [260][491/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 100.0	Acc@5 100.0
Epoch: [260][501/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [260][511/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 96.9	Acc@5 100.0
Epoch: [260][521/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 96.9	Acc@5 100.0
Epoch: [260][531/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 100.0
Epoch: [260][541/704]	Time 0.121	Data 0.001	Loss 2.28	Acc@1 92.2	Acc@5 100.0
Epoch: [260][551/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [260][561/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [260][571/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [260][581/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [260][591/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 90.6	Acc@5 100.0
Epoch: [260][601/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [260][611/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [260][621/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 96.9	Acc@5 100.0
Epoch: [260][631/704]	Time 0.121	Data 0.001	Loss 2.31	Acc@1 90.6	Acc@5 100.0
Epoch: [260][641/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [260][651/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [260][661/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 87.5	Acc@5 100.0
Epoch: [260][671/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 100.0	Acc@5 100.0
Epoch: [260][681/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [260][691/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [260][701/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [1/79]	Time 0.103	Data 0.088	Loss 6.7995	Acc@1 65.6250	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.6041	Acc@1 68.7500	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.8073	Acc@1 54.6875	Acc@5 85.9375
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.8330	Acc@1 68.7500	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7396	Acc@1 59.3750	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.8258	Acc@1 73.4375	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6905	Acc@1 67.1875	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.3788	Acc@1 56.2500	Acc@5 84.3750
 * prec@1 58.700 prec@5 85.320
 * prec@1 63.380 prec@5 89.360
 * prec@1 67.480 prec@5 90.940
 * prec@1 69.780 prec@5 91.680
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_260.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_260.pth.tar'
Epoch: [261][1/704]	Time 0.296	Data 0.129	Loss 1.44	Acc@1 93.8	Acc@5 98.4
Epoch: [261][11/704]	Time 0.136	Data 0.012	Loss 0.89	Acc@1 100.0	Acc@5 100.0
Epoch: [261][21/704]	Time 0.129	Data 0.007	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [261][31/704]	Time 0.126	Data 0.005	Loss 1.49	Acc@1 93.8	Acc@5 100.0
Epoch: [261][41/704]	Time 0.124	Data 0.004	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [261][51/704]	Time 0.124	Data 0.003	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [261][61/704]	Time 0.123	Data 0.003	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [261][71/704]	Time 0.123	Data 0.002	Loss 1.36	Acc@1 92.2	Acc@5 100.0
Epoch: [261][81/704]	Time 0.122	Data 0.002	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [261][91/704]	Time 0.123	Data 0.002	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [261][101/704]	Time 0.122	Data 0.002	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [261][111/704]	Time 0.122	Data 0.002	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [261][121/704]	Time 0.122	Data 0.002	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [261][131/704]	Time 0.122	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [261][141/704]	Time 0.122	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [261][151/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [261][161/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 93.8	Acc@5 100.0
Epoch: [261][171/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [261][181/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 90.6	Acc@5 98.4
Epoch: [261][191/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [261][201/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 92.2	Acc@5 100.0
Epoch: [261][211/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 96.9	Acc@5 100.0
Epoch: [261][221/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 98.4	Acc@5 100.0
Epoch: [261][231/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 100.0	Acc@5 100.0
Epoch: [261][241/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [261][251/704]	Time 0.121	Data 0.001	Loss 0.87	Acc@1 100.0	Acc@5 100.0
Epoch: [261][261/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [261][271/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [261][281/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [261][291/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 98.4
Epoch: [261][301/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 96.9
Epoch: [261][311/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [261][321/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [261][331/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 96.9	Acc@5 100.0
Epoch: [261][341/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [261][351/704]	Time 0.121	Data 0.001	Loss 1.14	Acc@1 96.9	Acc@5 100.0
Epoch: [261][361/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [261][371/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [261][381/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [261][391/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [261][401/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [261][411/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [261][421/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [261][431/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [261][441/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 90.6	Acc@5 100.0
Epoch: [261][451/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [261][461/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [261][471/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [261][481/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [261][491/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 98.4	Acc@5 100.0
Epoch: [261][501/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 95.3	Acc@5 100.0
Epoch: [261][511/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [261][521/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [261][531/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [261][541/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [261][551/704]	Time 0.121	Data 0.001	Loss 1.10	Acc@1 98.4	Acc@5 100.0
Epoch: [261][561/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [261][571/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 96.9	Acc@5 100.0
Epoch: [261][581/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [261][591/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 100.0
Epoch: [261][601/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [261][611/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 98.4	Acc@5 100.0
Epoch: [261][621/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [261][631/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 92.2	Acc@5 100.0
Epoch: [261][641/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [261][651/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [261][661/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [261][671/704]	Time 0.120	Data 0.001	Loss 2.14	Acc@1 93.8	Acc@5 100.0
Epoch: [261][681/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [261][691/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [261][701/704]	Time 0.120	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.2580	Acc@1 68.7500	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.0636	Acc@1 68.7500	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.1113	Acc@1 65.6250	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.4313	Acc@1 64.0625	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.0288	Acc@1 65.6250	Acc@5 89.0625
Epoch: [51/79]	Time 0.019	Data 0.006	Loss 6.6661	Acc@1 65.6250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.1809	Acc@1 76.5625	Acc@5 96.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.5636	Acc@1 78.1250	Acc@5 90.6250
 * prec@1 59.420 prec@5 85.360
 * prec@1 63.260 prec@5 88.720
 * prec@1 67.520 prec@5 90.880
 * prec@1 69.120 prec@5 91.560
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_261.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_261.pth.tar'
Epoch: [262][1/704]	Time 0.298	Data 0.130	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [262][11/704]	Time 0.140	Data 0.012	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [262][21/704]	Time 0.130	Data 0.007	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [262][31/704]	Time 0.127	Data 0.005	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [262][41/704]	Time 0.125	Data 0.004	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [262][51/704]	Time 0.124	Data 0.003	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [262][61/704]	Time 0.124	Data 0.002	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [262][71/704]	Time 0.123	Data 0.002	Loss 1.49	Acc@1 96.9	Acc@5 98.4
Epoch: [262][81/704]	Time 0.123	Data 0.002	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [262][91/704]	Time 0.122	Data 0.002	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [262][101/704]	Time 0.122	Data 0.002	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [262][111/704]	Time 0.122	Data 0.002	Loss 1.89	Acc@1 93.8	Acc@5 98.4
Epoch: [262][121/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [262][131/704]	Time 0.122	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [262][141/704]	Time 0.122	Data 0.001	Loss 1.41	Acc@1 93.8	Acc@5 100.0
Epoch: [262][151/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [262][161/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [262][171/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [262][181/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [262][191/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 100.0	Acc@5 100.0
Epoch: [262][201/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [262][211/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 98.4	Acc@5 100.0
Epoch: [262][221/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [262][231/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [262][241/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [262][251/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 96.9	Acc@5 100.0
Epoch: [262][261/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 98.4	Acc@5 100.0
Epoch: [262][271/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [262][281/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [262][291/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [262][301/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [262][311/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 92.2	Acc@5 100.0
Epoch: [262][321/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [262][331/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [262][341/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [262][351/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 100.0	Acc@5 100.0
Epoch: [262][361/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [262][371/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [262][381/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [262][391/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [262][401/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 92.2	Acc@5 98.4
Epoch: [262][411/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [262][421/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [262][431/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 100.0	Acc@5 100.0
Epoch: [262][441/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 93.8	Acc@5 100.0
Epoch: [262][451/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [262][461/704]	Time 0.121	Data 0.001	Loss 1.27	Acc@1 95.3	Acc@5 100.0
Epoch: [262][471/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 98.4
Epoch: [262][481/704]	Time 0.120	Data 0.001	Loss 2.34	Acc@1 89.1	Acc@5 96.9
Epoch: [262][491/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [262][501/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [262][511/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 98.4
Epoch: [262][521/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 98.4	Acc@5 100.0
Epoch: [262][531/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [262][541/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 92.2	Acc@5 100.0
Epoch: [262][551/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [262][561/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [262][571/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 98.4	Acc@5 100.0
Epoch: [262][581/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 92.2	Acc@5 100.0
Epoch: [262][591/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [262][601/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [262][611/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 89.1	Acc@5 100.0
Epoch: [262][621/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [262][631/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 93.8	Acc@5 100.0
Epoch: [262][641/704]	Time 0.120	Data 0.001	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [262][651/704]	Time 0.120	Data 0.001	Loss 1.38	Acc@1 100.0	Acc@5 100.0
Epoch: [262][661/704]	Time 0.120	Data 0.001	Loss 2.38	Acc@1 95.3	Acc@5 100.0
Epoch: [262][671/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [262][681/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [262][691/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 98.4	Acc@5 100.0
Epoch: [262][701/704]	Time 0.120	Data 0.001	Loss 1.25	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.2424	Acc@1 73.4375	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.3451	Acc@1 70.3125	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8634	Acc@1 67.1875	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9589	Acc@1 62.5000	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.7439	Acc@1 67.1875	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.2580	Acc@1 67.1875	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.6003	Acc@1 73.4375	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.0372	Acc@1 70.3125	Acc@5 84.3750
 * prec@1 58.240 prec@5 85.480
 * prec@1 62.780 prec@5 88.880
 * prec@1 66.960 prec@5 90.860
 * prec@1 69.280 prec@5 91.340
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_262.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_262.pth.tar'
Epoch: [263][1/704]	Time 0.332	Data 0.165	Loss 1.16	Acc@1 93.8	Acc@5 100.0
Epoch: [263][11/704]	Time 0.140	Data 0.015	Loss 2.09	Acc@1 93.8	Acc@5 98.4
Epoch: [263][21/704]	Time 0.130	Data 0.008	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [263][31/704]	Time 0.127	Data 0.006	Loss 2.40	Acc@1 89.1	Acc@5 100.0
Epoch: [263][41/704]	Time 0.125	Data 0.004	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [263][51/704]	Time 0.124	Data 0.004	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [263][61/704]	Time 0.124	Data 0.003	Loss 1.15	Acc@1 95.3	Acc@5 100.0
Epoch: [263][71/704]	Time 0.123	Data 0.003	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [263][81/704]	Time 0.123	Data 0.002	Loss 1.89	Acc@1 100.0	Acc@5 100.0
Epoch: [263][91/704]	Time 0.123	Data 0.002	Loss 1.89	Acc@1 98.4	Acc@5 100.0
Epoch: [263][101/704]	Time 0.122	Data 0.002	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [263][111/704]	Time 0.122	Data 0.002	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [263][121/704]	Time 0.122	Data 0.002	Loss 1.26	Acc@1 96.9	Acc@5 100.0
Epoch: [263][131/704]	Time 0.122	Data 0.002	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [263][141/704]	Time 0.122	Data 0.002	Loss 1.69	Acc@1 92.2	Acc@5 100.0
Epoch: [263][151/704]	Time 0.122	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [263][161/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [263][171/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [263][181/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [263][191/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 98.4	Acc@5 100.0
Epoch: [263][201/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [263][211/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [263][221/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 100.0	Acc@5 100.0
Epoch: [263][231/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [263][241/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [263][251/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 96.9	Acc@5 100.0
Epoch: [263][261/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [263][271/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [263][281/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 98.4
Epoch: [263][291/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 100.0	Acc@5 100.0
Epoch: [263][301/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [263][311/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 92.2	Acc@5 100.0
Epoch: [263][321/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 90.6	Acc@5 98.4
Epoch: [263][331/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 95.3	Acc@5 100.0
Epoch: [263][341/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [263][351/704]	Time 0.121	Data 0.001	Loss 1.11	Acc@1 96.9	Acc@5 100.0
Epoch: [263][361/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 95.3	Acc@5 98.4
Epoch: [263][371/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [263][381/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [263][391/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [263][401/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [263][411/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [263][421/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [263][431/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [263][441/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 93.8	Acc@5 100.0
Epoch: [263][451/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [263][461/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 96.9	Acc@5 98.4
Epoch: [263][471/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [263][481/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [263][491/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [263][501/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 92.2	Acc@5 100.0
Epoch: [263][511/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 100.0	Acc@5 100.0
Epoch: [263][521/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [263][531/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 95.3	Acc@5 100.0
Epoch: [263][541/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [263][551/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [263][561/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [263][571/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [263][581/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 98.4	Acc@5 100.0
Epoch: [263][591/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [263][601/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [263][611/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [263][621/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [263][631/704]	Time 0.120	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [263][641/704]	Time 0.120	Data 0.001	Loss 1.23	Acc@1 100.0	Acc@5 100.0
Epoch: [263][651/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 98.4	Acc@5 100.0
Epoch: [263][661/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [263][671/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [263][681/704]	Time 0.120	Data 0.001	Loss 2.45	Acc@1 93.8	Acc@5 100.0
Epoch: [263][691/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [263][701/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 3.8230	Acc@1 79.6875	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.6092	Acc@1 67.1875	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.6354	Acc@1 67.1875	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.9576	Acc@1 67.1875	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.8861	Acc@1 73.4375	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9348	Acc@1 59.3750	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 3.9462	Acc@1 73.4375	Acc@5 96.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 8.2808	Acc@1 57.8125	Acc@5 81.2500
 * prec@1 58.700 prec@5 86.120
 * prec@1 62.900 prec@5 88.580
 * prec@1 66.540 prec@5 91.500
 * prec@1 68.760 prec@5 91.540
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_263.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_263.pth.tar'
Epoch: [264][1/704]	Time 0.299	Data 0.132	Loss 1.99	Acc@1 96.9	Acc@5 100.0
Epoch: [264][11/704]	Time 0.136	Data 0.012	Loss 0.81	Acc@1 96.9	Acc@5 100.0
Epoch: [264][21/704]	Time 0.128	Data 0.007	Loss 1.60	Acc@1 98.4	Acc@5 100.0
Epoch: [264][31/704]	Time 0.126	Data 0.005	Loss 2.59	Acc@1 90.6	Acc@5 100.0
Epoch: [264][41/704]	Time 0.124	Data 0.004	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [264][51/704]	Time 0.123	Data 0.003	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [264][61/704]	Time 0.123	Data 0.003	Loss 1.17	Acc@1 98.4	Acc@5 100.0
Epoch: [264][71/704]	Time 0.123	Data 0.002	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [264][81/704]	Time 0.122	Data 0.002	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [264][91/704]	Time 0.122	Data 0.002	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [264][101/704]	Time 0.122	Data 0.002	Loss 1.78	Acc@1 89.1	Acc@5 100.0
Epoch: [264][111/704]	Time 0.122	Data 0.002	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [264][121/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 93.8	Acc@5 100.0
Epoch: [264][131/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [264][141/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [264][151/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 92.2	Acc@5 100.0
Epoch: [264][161/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [264][171/704]	Time 0.121	Data 0.001	Loss 1.27	Acc@1 95.3	Acc@5 100.0
Epoch: [264][181/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [264][191/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [264][201/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 100.0	Acc@5 100.0
Epoch: [264][211/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [264][221/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 90.6	Acc@5 100.0
Epoch: [264][231/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [264][241/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 100.0	Acc@5 100.0
Epoch: [264][251/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [264][261/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [264][271/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [264][281/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [264][291/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [264][301/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 96.9	Acc@5 100.0
Epoch: [264][311/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [264][321/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 98.4	Acc@5 100.0
Epoch: [264][331/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [264][341/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [264][351/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 100.0	Acc@5 100.0
Epoch: [264][361/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 100.0	Acc@5 100.0
Epoch: [264][371/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [264][381/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [264][391/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [264][401/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [264][411/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [264][421/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [264][431/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 95.3	Acc@5 98.4
Epoch: [264][441/704]	Time 0.120	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [264][451/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [264][461/704]	Time 0.120	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [264][471/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [264][481/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [264][491/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [264][501/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [264][511/704]	Time 0.120	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [264][521/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [264][531/704]	Time 0.120	Data 0.001	Loss 1.62	Acc@1 89.1	Acc@5 100.0
Epoch: [264][541/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 100.0
Epoch: [264][551/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [264][561/704]	Time 0.120	Data 0.001	Loss 1.11	Acc@1 98.4	Acc@5 100.0
Epoch: [264][571/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 100.0	Acc@5 100.0
Epoch: [264][581/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [264][591/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [264][601/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 92.2	Acc@5 100.0
Epoch: [264][611/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [264][621/704]	Time 0.120	Data 0.001	Loss 2.30	Acc@1 92.2	Acc@5 100.0
Epoch: [264][631/704]	Time 0.120	Data 0.001	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [264][641/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [264][651/704]	Time 0.120	Data 0.001	Loss 1.29	Acc@1 100.0	Acc@5 100.0
Epoch: [264][661/704]	Time 0.120	Data 0.001	Loss 1.52	Acc@1 93.8	Acc@5 100.0
Epoch: [264][671/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 93.8	Acc@5 100.0
Epoch: [264][681/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 98.4	Acc@5 100.0
Epoch: [264][691/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [264][701/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 3.8398	Acc@1 81.2500	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.5907	Acc@1 71.8750	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.9067	Acc@1 59.3750	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.5712	Acc@1 75.0000	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9352	Acc@1 62.5000	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.7577	Acc@1 65.6250	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5499	Acc@1 75.0000	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.2160	Acc@1 68.7500	Acc@5 84.3750
 * prec@1 58.880 prec@5 86.080
 * prec@1 63.680 prec@5 88.580
 * prec@1 67.400 prec@5 91.340
 * prec@1 69.500 prec@5 91.540
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_264.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_264.pth.tar'
Epoch: [265][1/704]	Time 0.302	Data 0.133	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [265][11/704]	Time 0.137	Data 0.012	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [265][21/704]	Time 0.129	Data 0.007	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [265][31/704]	Time 0.126	Data 0.005	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [265][41/704]	Time 0.125	Data 0.004	Loss 1.17	Acc@1 98.4	Acc@5 100.0
Epoch: [265][51/704]	Time 0.124	Data 0.003	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [265][61/704]	Time 0.124	Data 0.002	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [265][71/704]	Time 0.123	Data 0.002	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [265][81/704]	Time 0.123	Data 0.002	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [265][91/704]	Time 0.123	Data 0.002	Loss 1.99	Acc@1 89.1	Acc@5 100.0
Epoch: [265][101/704]	Time 0.123	Data 0.002	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [265][111/704]	Time 0.122	Data 0.002	Loss 1.79	Acc@1 90.6	Acc@5 100.0
Epoch: [265][121/704]	Time 0.122	Data 0.001	Loss 2.06	Acc@1 95.3	Acc@5 100.0
Epoch: [265][131/704]	Time 0.122	Data 0.001	Loss 1.60	Acc@1 100.0	Acc@5 100.0
Epoch: [265][141/704]	Time 0.122	Data 0.001	Loss 2.41	Acc@1 92.2	Acc@5 98.4
Epoch: [265][151/704]	Time 0.122	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [265][161/704]	Time 0.122	Data 0.001	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [265][171/704]	Time 0.122	Data 0.001	Loss 2.05	Acc@1 95.3	Acc@5 98.4
Epoch: [265][181/704]	Time 0.122	Data 0.001	Loss 1.69	Acc@1 98.4	Acc@5 100.0
Epoch: [265][191/704]	Time 0.122	Data 0.001	Loss 1.22	Acc@1 95.3	Acc@5 100.0
Epoch: [265][201/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [265][211/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 93.8	Acc@5 100.0
Epoch: [265][221/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [265][231/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [265][241/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [265][251/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [265][261/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [265][271/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 92.2	Acc@5 100.0
Epoch: [265][281/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [265][291/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 95.3	Acc@5 100.0
Epoch: [265][301/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [265][311/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [265][321/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [265][331/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [265][341/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [265][351/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [265][361/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [265][371/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 92.2	Acc@5 100.0
Epoch: [265][381/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [265][391/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [265][401/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 90.6	Acc@5 100.0
Epoch: [265][411/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 96.9	Acc@5 100.0
Epoch: [265][421/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [265][431/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [265][441/704]	Time 0.121	Data 0.001	Loss 0.84	Acc@1 100.0	Acc@5 100.0
Epoch: [265][451/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [265][461/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 93.8	Acc@5 100.0
Epoch: [265][471/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 100.0	Acc@5 100.0
Epoch: [265][481/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [265][491/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [265][501/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [265][511/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 98.4
Epoch: [265][521/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [265][531/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [265][541/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [265][551/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 93.8	Acc@5 100.0
Epoch: [265][561/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [265][571/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 100.0	Acc@5 100.0
Epoch: [265][581/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [265][591/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [265][601/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [265][611/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 100.0	Acc@5 100.0
Epoch: [265][621/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 100.0	Acc@5 100.0
Epoch: [265][631/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [265][641/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [265][651/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [265][661/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [265][671/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [265][681/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [265][691/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [265][701/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.2526	Acc@1 60.9375	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.9054	Acc@1 71.8750	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.6941	Acc@1 59.3750	Acc@5 85.9375
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 4.7816	Acc@1 75.0000	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.8772	Acc@1 76.5625	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7711	Acc@1 67.1875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.0221	Acc@1 67.1875	Acc@5 98.4375
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 4.6550	Acc@1 71.8750	Acc@5 92.1875
 * prec@1 58.840 prec@5 85.760
 * prec@1 63.700 prec@5 88.400
 * prec@1 66.900 prec@5 90.720
 * prec@1 68.860 prec@5 91.300
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_265.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_265.pth.tar'
Epoch: [266][1/704]	Time 0.332	Data 0.166	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [266][11/704]	Time 0.139	Data 0.015	Loss 1.44	Acc@1 95.3	Acc@5 100.0
Epoch: [266][21/704]	Time 0.130	Data 0.008	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [266][31/704]	Time 0.127	Data 0.006	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [266][41/704]	Time 0.125	Data 0.004	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [266][51/704]	Time 0.124	Data 0.004	Loss 1.18	Acc@1 98.4	Acc@5 100.0
Epoch: [266][61/704]	Time 0.123	Data 0.003	Loss 1.33	Acc@1 98.4	Acc@5 98.4
Epoch: [266][71/704]	Time 0.123	Data 0.003	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [266][81/704]	Time 0.123	Data 0.002	Loss 2.34	Acc@1 90.6	Acc@5 96.9
Epoch: [266][91/704]	Time 0.122	Data 0.002	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [266][101/704]	Time 0.122	Data 0.002	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [266][111/704]	Time 0.122	Data 0.002	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [266][121/704]	Time 0.122	Data 0.002	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [266][131/704]	Time 0.122	Data 0.002	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [266][141/704]	Time 0.122	Data 0.002	Loss 2.29	Acc@1 95.3	Acc@5 100.0
Epoch: [266][151/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 100.0	Acc@5 100.0
Epoch: [266][161/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 93.8	Acc@5 100.0
Epoch: [266][171/704]	Time 0.121	Data 0.001	Loss 2.48	Acc@1 93.8	Acc@5 100.0
Epoch: [266][181/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 93.8	Acc@5 100.0
Epoch: [266][191/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [266][201/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 100.0	Acc@5 100.0
Epoch: [266][211/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [266][221/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 100.0
Epoch: [266][231/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 93.8	Acc@5 98.4
Epoch: [266][241/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [266][251/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [266][261/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [266][271/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 100.0	Acc@5 100.0
Epoch: [266][281/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [266][291/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 100.0	Acc@5 100.0
Epoch: [266][301/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [266][311/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 96.9	Acc@5 100.0
Epoch: [266][321/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [266][331/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [266][341/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [266][351/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [266][361/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 98.4	Acc@5 100.0
Epoch: [266][371/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 100.0	Acc@5 100.0
Epoch: [266][381/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 92.2	Acc@5 100.0
Epoch: [266][391/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [266][401/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [266][411/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 100.0	Acc@5 100.0
Epoch: [266][421/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [266][431/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 96.9	Acc@5 100.0
Epoch: [266][441/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [266][451/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 100.0	Acc@5 100.0
Epoch: [266][461/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [266][471/704]	Time 0.120	Data 0.001	Loss 1.99	Acc@1 96.9	Acc@5 98.4
Epoch: [266][481/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [266][491/704]	Time 0.120	Data 0.001	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [266][501/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [266][511/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 98.4	Acc@5 100.0
Epoch: [266][521/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [266][531/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [266][541/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 98.4	Acc@5 100.0
Epoch: [266][551/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [266][561/704]	Time 0.120	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [266][571/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [266][581/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 89.1	Acc@5 100.0
Epoch: [266][591/704]	Time 0.120	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [266][601/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [266][611/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [266][621/704]	Time 0.120	Data 0.001	Loss 2.04	Acc@1 93.8	Acc@5 100.0
Epoch: [266][631/704]	Time 0.120	Data 0.001	Loss 2.28	Acc@1 92.2	Acc@5 100.0
Epoch: [266][641/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 92.2	Acc@5 100.0
Epoch: [266][651/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [266][661/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 98.4	Acc@5 100.0
Epoch: [266][671/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [266][681/704]	Time 0.120	Data 0.001	Loss 1.11	Acc@1 98.4	Acc@5 100.0
Epoch: [266][691/704]	Time 0.120	Data 0.001	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [266][701/704]	Time 0.120	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.8454	Acc@1 65.6250	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.4508	Acc@1 79.6875	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.5251	Acc@1 68.7500	Acc@5 90.6250
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 6.3242	Acc@1 68.7500	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.1180	Acc@1 71.8750	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.5745	Acc@1 76.5625	Acc@5 96.8750
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 8.1940	Acc@1 54.6875	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.4027	Acc@1 75.0000	Acc@5 95.3125
 * prec@1 58.360 prec@5 85.500
 * prec@1 63.840 prec@5 89.100
 * prec@1 67.640 prec@5 91.320
 * prec@1 69.280 prec@5 91.540
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_266.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_266.pth.tar'
Epoch: [267][1/704]	Time 0.332	Data 0.165	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [267][11/704]	Time 0.140	Data 0.015	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [267][21/704]	Time 0.131	Data 0.008	Loss 2.32	Acc@1 95.3	Acc@5 100.0
Epoch: [267][31/704]	Time 0.127	Data 0.006	Loss 1.86	Acc@1 98.4	Acc@5 100.0
Epoch: [267][41/704]	Time 0.126	Data 0.004	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [267][51/704]	Time 0.125	Data 0.004	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [267][61/704]	Time 0.124	Data 0.003	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [267][71/704]	Time 0.123	Data 0.003	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [267][81/704]	Time 0.123	Data 0.002	Loss 1.89	Acc@1 98.4	Acc@5 98.4
Epoch: [267][91/704]	Time 0.123	Data 0.002	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [267][101/704]	Time 0.123	Data 0.002	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [267][111/704]	Time 0.122	Data 0.002	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [267][121/704]	Time 0.122	Data 0.002	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [267][131/704]	Time 0.122	Data 0.002	Loss 1.48	Acc@1 93.8	Acc@5 100.0
Epoch: [267][141/704]	Time 0.122	Data 0.002	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [267][151/704]	Time 0.122	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [267][161/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [267][171/704]	Time 0.122	Data 0.001	Loss 2.01	Acc@1 92.2	Acc@5 100.0
Epoch: [267][181/704]	Time 0.122	Data 0.001	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [267][191/704]	Time 0.122	Data 0.001	Loss 1.18	Acc@1 100.0	Acc@5 100.0
Epoch: [267][201/704]	Time 0.122	Data 0.001	Loss 2.13	Acc@1 96.9	Acc@5 100.0
Epoch: [267][211/704]	Time 0.122	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [267][221/704]	Time 0.122	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [267][231/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [267][241/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [267][251/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [267][261/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [267][271/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [267][281/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [267][291/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 90.6	Acc@5 100.0
Epoch: [267][301/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [267][311/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [267][321/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [267][331/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 93.8	Acc@5 100.0
Epoch: [267][341/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [267][351/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [267][361/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [267][371/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 92.2	Acc@5 100.0
Epoch: [267][381/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [267][391/704]	Time 0.121	Data 0.001	Loss 1.09	Acc@1 98.4	Acc@5 100.0
Epoch: [267][401/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 100.0	Acc@5 100.0
Epoch: [267][411/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [267][421/704]	Time 0.121	Data 0.001	Loss 2.49	Acc@1 95.3	Acc@5 100.0
Epoch: [267][431/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [267][441/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [267][451/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [267][461/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 100.0	Acc@5 100.0
Epoch: [267][471/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 100.0	Acc@5 100.0
Epoch: [267][481/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [267][491/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [267][501/704]	Time 0.121	Data 0.001	Loss 1.03	Acc@1 98.4	Acc@5 100.0
Epoch: [267][511/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 98.4	Acc@5 100.0
Epoch: [267][521/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 89.1	Acc@5 100.0
Epoch: [267][531/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 98.4
Epoch: [267][541/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [267][551/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 90.6	Acc@5 100.0
Epoch: [267][561/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 90.6	Acc@5 100.0
Epoch: [267][571/704]	Time 0.121	Data 0.001	Loss 0.88	Acc@1 100.0	Acc@5 100.0
Epoch: [267][581/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [267][591/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 95.3	Acc@5 100.0
Epoch: [267][601/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [267][611/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 96.9	Acc@5 100.0
Epoch: [267][621/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [267][631/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [267][641/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 92.2	Acc@5 100.0
Epoch: [267][651/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [267][661/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [267][671/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [267][681/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [267][691/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [267][701/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.9491	Acc@1 64.0625	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.2882	Acc@1 73.4375	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.6863	Acc@1 70.3125	Acc@5 90.6250
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 6.6864	Acc@1 68.7500	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.9269	Acc@1 76.5625	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.4764	Acc@1 73.4375	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.3482	Acc@1 62.5000	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.1412	Acc@1 60.9375	Acc@5 82.8125
 * prec@1 59.320 prec@5 86.300
 * prec@1 63.080 prec@5 88.680
 * prec@1 67.700 prec@5 91.520
 * prec@1 69.580 prec@5 91.680
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_267.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_267.pth.tar'
Epoch: [268][1/704]	Time 0.300	Data 0.132	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [268][11/704]	Time 0.137	Data 0.012	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [268][21/704]	Time 0.129	Data 0.007	Loss 1.18	Acc@1 92.2	Acc@5 98.4
Epoch: [268][31/704]	Time 0.126	Data 0.005	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [268][41/704]	Time 0.124	Data 0.004	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [268][51/704]	Time 0.124	Data 0.003	Loss 1.43	Acc@1 100.0	Acc@5 100.0
Epoch: [268][61/704]	Time 0.123	Data 0.003	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [268][71/704]	Time 0.123	Data 0.002	Loss 1.98	Acc@1 96.9	Acc@5 100.0
Epoch: [268][81/704]	Time 0.122	Data 0.002	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [268][91/704]	Time 0.122	Data 0.002	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [268][101/704]	Time 0.122	Data 0.002	Loss 1.95	Acc@1 98.4	Acc@5 100.0
Epoch: [268][111/704]	Time 0.122	Data 0.002	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [268][121/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [268][131/704]	Time 0.122	Data 0.001	Loss 2.06	Acc@1 95.3	Acc@5 100.0
Epoch: [268][141/704]	Time 0.122	Data 0.001	Loss 1.70	Acc@1 100.0	Acc@5 100.0
Epoch: [268][151/704]	Time 0.122	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [268][161/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [268][171/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [268][181/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [268][191/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 89.1	Acc@5 100.0
Epoch: [268][201/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [268][211/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [268][221/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [268][231/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 98.4	Acc@5 100.0
Epoch: [268][241/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 90.6	Acc@5 100.0
Epoch: [268][251/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [268][261/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [268][271/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 98.4	Acc@5 100.0
Epoch: [268][281/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [268][291/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [268][301/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [268][311/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 98.4
Epoch: [268][321/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [268][331/704]	Time 0.121	Data 0.001	Loss 1.04	Acc@1 100.0	Acc@5 100.0
Epoch: [268][341/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [268][351/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 96.9	Acc@5 100.0
Epoch: [268][361/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [268][371/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [268][381/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [268][391/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [268][401/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 87.5	Acc@5 100.0
Epoch: [268][411/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 98.4	Acc@5 100.0
Epoch: [268][421/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 96.9	Acc@5 100.0
Epoch: [268][431/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 98.4
Epoch: [268][441/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [268][451/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 95.3	Acc@5 98.4
Epoch: [268][461/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 98.4	Acc@5 100.0
Epoch: [268][471/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [268][481/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 98.4
Epoch: [268][491/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [268][501/704]	Time 0.121	Data 0.001	Loss 2.36	Acc@1 92.2	Acc@5 100.0
Epoch: [268][511/704]	Time 0.121	Data 0.001	Loss 1.15	Acc@1 96.9	Acc@5 100.0
Epoch: [268][521/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [268][531/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 100.0	Acc@5 100.0
Epoch: [268][541/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 100.0	Acc@5 100.0
Epoch: [268][551/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 96.9	Acc@5 100.0
Epoch: [268][561/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [268][571/704]	Time 0.120	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [268][581/704]	Time 0.120	Data 0.001	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [268][591/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 100.0	Acc@5 100.0
Epoch: [268][601/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 98.4	Acc@5 100.0
Epoch: [268][611/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 93.8	Acc@5 100.0
Epoch: [268][621/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 92.2	Acc@5 98.4
Epoch: [268][631/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [268][641/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [268][651/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [268][661/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [268][671/704]	Time 0.120	Data 0.001	Loss 1.05	Acc@1 95.3	Acc@5 100.0
Epoch: [268][681/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [268][691/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [268][701/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 6.4424	Acc@1 65.6250	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.5415	Acc@1 68.7500	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8807	Acc@1 70.3125	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.7367	Acc@1 70.3125	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3509	Acc@1 75.0000	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.5327	Acc@1 73.4375	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.3519	Acc@1 71.8750	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.4415	Acc@1 65.6250	Acc@5 93.7500
 * prec@1 59.280 prec@5 85.180
 * prec@1 62.600 prec@5 89.320
 * prec@1 66.300 prec@5 90.800
 * prec@1 69.240 prec@5 91.380
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_268.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_268.pth.tar'
Epoch: [269][1/704]	Time 0.301	Data 0.132	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [269][11/704]	Time 0.141	Data 0.012	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [269][21/704]	Time 0.131	Data 0.007	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [269][31/704]	Time 0.128	Data 0.005	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [269][41/704]	Time 0.126	Data 0.004	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [269][51/704]	Time 0.125	Data 0.003	Loss 1.99	Acc@1 98.4	Acc@5 100.0
Epoch: [269][61/704]	Time 0.124	Data 0.002	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [269][71/704]	Time 0.124	Data 0.002	Loss 1.97	Acc@1 90.6	Acc@5 100.0
Epoch: [269][81/704]	Time 0.123	Data 0.002	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [269][91/704]	Time 0.123	Data 0.002	Loss 1.41	Acc@1 95.3	Acc@5 100.0
Epoch: [269][101/704]	Time 0.123	Data 0.002	Loss 1.23	Acc@1 95.3	Acc@5 100.0
Epoch: [269][111/704]	Time 0.123	Data 0.002	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [269][121/704]	Time 0.122	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [269][131/704]	Time 0.122	Data 0.001	Loss 2.59	Acc@1 85.9	Acc@5 100.0
Epoch: [269][141/704]	Time 0.122	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 100.0
Epoch: [269][151/704]	Time 0.122	Data 0.001	Loss 2.06	Acc@1 95.3	Acc@5 98.4
Epoch: [269][161/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [269][171/704]	Time 0.122	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [269][181/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [269][191/704]	Time 0.122	Data 0.001	Loss 1.29	Acc@1 95.3	Acc@5 100.0
Epoch: [269][201/704]	Time 0.122	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [269][211/704]	Time 0.122	Data 0.001	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [269][221/704]	Time 0.122	Data 0.001	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [269][231/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 89.1	Acc@5 100.0
Epoch: [269][241/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [269][251/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [269][261/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [269][271/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 95.3	Acc@5 100.0
Epoch: [269][281/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [269][291/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 100.0	Acc@5 100.0
Epoch: [269][301/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [269][311/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [269][321/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [269][331/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 98.4	Acc@5 100.0
Epoch: [269][341/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [269][351/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [269][361/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 93.8	Acc@5 100.0
Epoch: [269][371/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [269][381/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [269][391/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [269][401/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 100.0	Acc@5 100.0
Epoch: [269][411/704]	Time 0.121	Data 0.001	Loss 2.22	Acc@1 96.9	Acc@5 100.0
Epoch: [269][421/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [269][431/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [269][441/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [269][451/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [269][461/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 92.2	Acc@5 100.0
Epoch: [269][471/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [269][481/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 100.0	Acc@5 100.0
Epoch: [269][491/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [269][501/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 98.4	Acc@5 100.0
Epoch: [269][511/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 93.8	Acc@5 100.0
Epoch: [269][521/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [269][531/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [269][541/704]	Time 0.121	Data 0.001	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [269][551/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [269][561/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [269][571/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [269][581/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [269][591/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 96.9	Acc@5 100.0
Epoch: [269][601/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [269][611/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [269][621/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 98.4	Acc@5 100.0
Epoch: [269][631/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [269][641/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [269][651/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 100.0	Acc@5 100.0
Epoch: [269][661/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [269][671/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [269][681/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [269][691/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [269][701/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.4631	Acc@1 64.0625	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.3913	Acc@1 71.8750	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.4563	Acc@1 71.8750	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7866	Acc@1 67.1875	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.2696	Acc@1 64.0625	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.3327	Acc@1 76.5625	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.6810	Acc@1 70.3125	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.6106	Acc@1 73.4375	Acc@5 92.1875
 * prec@1 58.020 prec@5 84.960
 * prec@1 63.360 prec@5 88.500
 * prec@1 66.280 prec@5 90.700
 * prec@1 69.320 prec@5 91.460
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_269.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_269.pth.tar'
Epoch: [270][1/704]	Time 0.331	Data 0.164	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [270][11/704]	Time 0.139	Data 0.015	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [270][21/704]	Time 0.130	Data 0.008	Loss 1.10	Acc@1 96.9	Acc@5 100.0
Epoch: [270][31/704]	Time 0.127	Data 0.006	Loss 1.49	Acc@1 95.3	Acc@5 100.0
Epoch: [270][41/704]	Time 0.125	Data 0.004	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [270][51/704]	Time 0.124	Data 0.004	Loss 2.17	Acc@1 96.9	Acc@5 100.0
Epoch: [270][61/704]	Time 0.123	Data 0.003	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [270][71/704]	Time 0.123	Data 0.003	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [270][81/704]	Time 0.123	Data 0.002	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [270][91/704]	Time 0.122	Data 0.002	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [270][101/704]	Time 0.122	Data 0.002	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [270][111/704]	Time 0.122	Data 0.002	Loss 1.26	Acc@1 92.2	Acc@5 100.0
Epoch: [270][121/704]	Time 0.122	Data 0.002	Loss 2.00	Acc@1 95.3	Acc@5 100.0
Epoch: [270][131/704]	Time 0.122	Data 0.002	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [270][141/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 98.4	Acc@5 100.0
Epoch: [270][151/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 98.4
Epoch: [270][161/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [270][171/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 100.0	Acc@5 100.0
Epoch: [270][181/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [270][191/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [270][201/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [270][211/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [270][221/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 92.2	Acc@5 100.0
Epoch: [270][231/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 93.8	Acc@5 100.0
Epoch: [270][241/704]	Time 0.121	Data 0.001	Loss 1.11	Acc@1 100.0	Acc@5 100.0
Epoch: [270][251/704]	Time 0.121	Data 0.001	Loss 2.58	Acc@1 93.8	Acc@5 100.0
Epoch: [270][261/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [270][271/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [270][281/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 100.0	Acc@5 100.0
Epoch: [270][291/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [270][301/704]	Time 0.121	Data 0.001	Loss 1.01	Acc@1 100.0	Acc@5 100.0
Epoch: [270][311/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [270][321/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [270][331/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [270][341/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [270][351/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [270][361/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 95.3	Acc@5 100.0
Epoch: [270][371/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [270][381/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 92.2	Acc@5 100.0
Epoch: [270][391/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 100.0	Acc@5 100.0
Epoch: [270][401/704]	Time 0.121	Data 0.001	Loss 1.03	Acc@1 95.3	Acc@5 100.0
Epoch: [270][411/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [270][421/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [270][431/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [270][441/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [270][451/704]	Time 0.120	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [270][461/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [270][471/704]	Time 0.120	Data 0.001	Loss 1.20	Acc@1 100.0	Acc@5 100.0
Epoch: [270][481/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [270][491/704]	Time 0.120	Data 0.001	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [270][501/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 90.6	Acc@5 100.0
Epoch: [270][511/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 98.4	Acc@5 100.0
Epoch: [270][521/704]	Time 0.120	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [270][531/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [270][541/704]	Time 0.120	Data 0.001	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [270][551/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [270][561/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [270][571/704]	Time 0.120	Data 0.001	Loss 2.48	Acc@1 89.1	Acc@5 100.0
Epoch: [270][581/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [270][591/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 100.0	Acc@5 100.0
Epoch: [270][601/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [270][611/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [270][621/704]	Time 0.120	Data 0.001	Loss 2.55	Acc@1 93.8	Acc@5 100.0
Epoch: [270][631/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [270][641/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [270][651/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [270][661/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [270][671/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 85.9	Acc@5 100.0
Epoch: [270][681/704]	Time 0.120	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [270][691/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [270][701/704]	Time 0.120	Data 0.001	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.8049	Acc@1 62.5000	Acc@5 87.5000
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.1690	Acc@1 59.3750	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.3600	Acc@1 64.0625	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7237	Acc@1 67.1875	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.0388	Acc@1 68.7500	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9647	Acc@1 65.6250	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.1165	Acc@1 60.9375	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.7194	Acc@1 71.8750	Acc@5 93.7500
 * prec@1 58.120 prec@5 85.680
 * prec@1 62.900 prec@5 88.780
 * prec@1 66.760 prec@5 91.260
 * prec@1 69.140 prec@5 91.900
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_270.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_270.pth.tar'
Epoch: [271][1/704]	Time 0.302	Data 0.135	Loss 2.11	Acc@1 96.9	Acc@5 100.0
Epoch: [271][11/704]	Time 0.137	Data 0.013	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [271][21/704]	Time 0.129	Data 0.007	Loss 2.27	Acc@1 96.9	Acc@5 98.4
Epoch: [271][31/704]	Time 0.126	Data 0.005	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [271][41/704]	Time 0.125	Data 0.004	Loss 1.73	Acc@1 92.2	Acc@5 100.0
Epoch: [271][51/704]	Time 0.124	Data 0.003	Loss 1.79	Acc@1 93.8	Acc@5 98.4
Epoch: [271][61/704]	Time 0.123	Data 0.003	Loss 1.88	Acc@1 96.9	Acc@5 100.0
Epoch: [271][71/704]	Time 0.123	Data 0.002	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [271][81/704]	Time 0.123	Data 0.002	Loss 1.67	Acc@1 100.0	Acc@5 100.0
Epoch: [271][91/704]	Time 0.122	Data 0.002	Loss 1.51	Acc@1 100.0	Acc@5 100.0
Epoch: [271][101/704]	Time 0.122	Data 0.002	Loss 2.42	Acc@1 95.3	Acc@5 100.0
Epoch: [271][111/704]	Time 0.122	Data 0.002	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [271][121/704]	Time 0.122	Data 0.001	Loss 1.22	Acc@1 95.3	Acc@5 98.4
Epoch: [271][131/704]	Time 0.122	Data 0.001	Loss 1.27	Acc@1 98.4	Acc@5 100.0
Epoch: [271][141/704]	Time 0.122	Data 0.001	Loss 1.70	Acc@1 92.2	Acc@5 100.0
Epoch: [271][151/704]	Time 0.122	Data 0.001	Loss 1.21	Acc@1 95.3	Acc@5 100.0
Epoch: [271][161/704]	Time 0.122	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [271][171/704]	Time 0.122	Data 0.001	Loss 1.21	Acc@1 100.0	Acc@5 100.0
Epoch: [271][181/704]	Time 0.122	Data 0.001	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [271][191/704]	Time 0.122	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [271][201/704]	Time 0.122	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [271][211/704]	Time 0.122	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [271][221/704]	Time 0.121	Data 0.001	Loss 1.13	Acc@1 98.4	Acc@5 100.0
Epoch: [271][231/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [271][241/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [271][251/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [271][261/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [271][271/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 90.6	Acc@5 100.0
Epoch: [271][281/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 96.9	Acc@5 100.0
Epoch: [271][291/704]	Time 0.121	Data 0.001	Loss 1.13	Acc@1 93.8	Acc@5 100.0
Epoch: [271][301/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [271][311/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [271][321/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 92.2	Acc@5 100.0
Epoch: [271][331/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [271][341/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 89.1	Acc@5 100.0
Epoch: [271][351/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 95.3	Acc@5 100.0
Epoch: [271][361/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [271][371/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [271][381/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [271][391/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [271][401/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [271][411/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [271][421/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [271][431/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [271][441/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [271][451/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [271][461/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 100.0	Acc@5 100.0
Epoch: [271][471/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 100.0	Acc@5 100.0
Epoch: [271][481/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [271][491/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [271][501/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 98.4	Acc@5 100.0
Epoch: [271][511/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 96.9	Acc@5 100.0
Epoch: [271][521/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [271][531/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 100.0	Acc@5 100.0
Epoch: [271][541/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [271][551/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 95.3	Acc@5 100.0
Epoch: [271][561/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 95.3	Acc@5 100.0
Epoch: [271][571/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [271][581/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [271][591/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [271][601/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 95.3	Acc@5 98.4
Epoch: [271][611/704]	Time 0.121	Data 0.001	Loss 1.15	Acc@1 95.3	Acc@5 100.0
Epoch: [271][621/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [271][631/704]	Time 0.121	Data 0.001	Loss 2.14	Acc@1 95.3	Acc@5 100.0
Epoch: [271][641/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 96.9	Acc@5 100.0
Epoch: [271][651/704]	Time 0.121	Data 0.001	Loss 1.04	Acc@1 100.0	Acc@5 100.0
Epoch: [271][661/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 96.9	Acc@5 100.0
Epoch: [271][671/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 90.6	Acc@5 100.0
Epoch: [271][681/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 93.8	Acc@5 98.4
Epoch: [271][691/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [271][701/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.6895	Acc@1 68.7500	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.7920	Acc@1 68.7500	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.8204	Acc@1 76.5625	Acc@5 93.7500
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 4.2652	Acc@1 76.5625	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.3611	Acc@1 65.6250	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.9586	Acc@1 59.3750	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.4476	Acc@1 64.0625	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 4.0294	Acc@1 79.6875	Acc@5 92.1875
 * prec@1 57.500 prec@5 85.480
 * prec@1 62.380 prec@5 88.720
 * prec@1 66.880 prec@5 91.380
 * prec@1 69.080 prec@5 91.440
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_271.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_271.pth.tar'
Epoch: [272][1/704]	Time 0.302	Data 0.133	Loss 1.44	Acc@1 95.3	Acc@5 100.0
Epoch: [272][11/704]	Time 0.137	Data 0.012	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [272][21/704]	Time 0.129	Data 0.007	Loss 1.49	Acc@1 92.2	Acc@5 100.0
Epoch: [272][31/704]	Time 0.126	Data 0.005	Loss 1.97	Acc@1 95.3	Acc@5 98.4
Epoch: [272][41/704]	Time 0.125	Data 0.004	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [272][51/704]	Time 0.124	Data 0.003	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [272][61/704]	Time 0.124	Data 0.002	Loss 1.24	Acc@1 96.9	Acc@5 100.0
Epoch: [272][71/704]	Time 0.124	Data 0.002	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [272][81/704]	Time 0.124	Data 0.002	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [272][91/704]	Time 0.123	Data 0.002	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [272][101/704]	Time 0.123	Data 0.002	Loss 1.05	Acc@1 98.4	Acc@5 100.0
Epoch: [272][111/704]	Time 0.123	Data 0.002	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [272][121/704]	Time 0.123	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [272][131/704]	Time 0.122	Data 0.001	Loss 1.74	Acc@1 98.4	Acc@5 100.0
Epoch: [272][141/704]	Time 0.122	Data 0.001	Loss 2.23	Acc@1 87.5	Acc@5 100.0
Epoch: [272][151/704]	Time 0.122	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [272][161/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [272][171/704]	Time 0.122	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [272][181/704]	Time 0.122	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [272][191/704]	Time 0.122	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [272][201/704]	Time 0.122	Data 0.001	Loss 1.21	Acc@1 100.0	Acc@5 100.0
Epoch: [272][211/704]	Time 0.122	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [272][221/704]	Time 0.122	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [272][231/704]	Time 0.122	Data 0.001	Loss 1.44	Acc@1 100.0	Acc@5 100.0
Epoch: [272][241/704]	Time 0.122	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [272][251/704]	Time 0.122	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [272][261/704]	Time 0.122	Data 0.001	Loss 1.24	Acc@1 98.4	Acc@5 100.0
Epoch: [272][271/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [272][281/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [272][291/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 92.2	Acc@5 100.0
Epoch: [272][301/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [272][311/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [272][321/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [272][331/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [272][341/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 93.8	Acc@5 100.0
Epoch: [272][351/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [272][361/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 98.4
Epoch: [272][371/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [272][381/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 100.0	Acc@5 100.0
Epoch: [272][391/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [272][401/704]	Time 0.121	Data 0.001	Loss 1.06	Acc@1 100.0	Acc@5 100.0
Epoch: [272][411/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [272][421/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [272][431/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [272][441/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [272][451/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [272][461/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [272][471/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 96.9	Acc@5 100.0
Epoch: [272][481/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [272][491/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 98.4	Acc@5 100.0
Epoch: [272][501/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [272][511/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [272][521/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [272][531/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [272][541/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [272][551/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [272][561/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [272][571/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [272][581/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [272][591/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [272][601/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [272][611/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [272][621/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 96.9	Acc@5 100.0
Epoch: [272][631/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 95.3	Acc@5 100.0
Epoch: [272][641/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [272][651/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 100.0	Acc@5 100.0
Epoch: [272][661/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [272][671/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 95.3	Acc@5 100.0
Epoch: [272][681/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [272][691/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [272][701/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.103	Data 0.088	Loss 8.1136	Acc@1 57.8125	Acc@5 84.3750
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 4.7500	Acc@1 76.5625	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8296	Acc@1 73.4375	Acc@5 92.1875
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 4.4976	Acc@1 76.5625	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.6555	Acc@1 67.1875	Acc@5 84.3750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.8585	Acc@1 62.5000	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.2610	Acc@1 76.5625	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.6921	Acc@1 71.8750	Acc@5 96.8750
 * prec@1 58.900 prec@5 85.880
 * prec@1 63.300 prec@5 88.800
 * prec@1 66.940 prec@5 91.020
 * prec@1 68.920 prec@5 91.380
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_272.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_272.pth.tar'
Epoch: [273][1/704]	Time 0.334	Data 0.167	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [273][11/704]	Time 0.140	Data 0.016	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [273][21/704]	Time 0.130	Data 0.008	Loss 1.22	Acc@1 100.0	Acc@5 100.0
Epoch: [273][31/704]	Time 0.127	Data 0.006	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [273][41/704]	Time 0.125	Data 0.004	Loss 1.09	Acc@1 96.9	Acc@5 100.0
Epoch: [273][51/704]	Time 0.124	Data 0.004	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [273][61/704]	Time 0.124	Data 0.003	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [273][71/704]	Time 0.123	Data 0.003	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [273][81/704]	Time 0.123	Data 0.002	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [273][91/704]	Time 0.122	Data 0.002	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [273][101/704]	Time 0.122	Data 0.002	Loss 0.84	Acc@1 98.4	Acc@5 100.0
Epoch: [273][111/704]	Time 0.122	Data 0.002	Loss 1.91	Acc@1 90.6	Acc@5 100.0
Epoch: [273][121/704]	Time 0.122	Data 0.002	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [273][131/704]	Time 0.122	Data 0.002	Loss 1.99	Acc@1 95.3	Acc@5 100.0
Epoch: [273][141/704]	Time 0.122	Data 0.002	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [273][151/704]	Time 0.121	Data 0.001	Loss 2.34	Acc@1 93.8	Acc@5 100.0
Epoch: [273][161/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [273][171/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 90.6	Acc@5 100.0
Epoch: [273][181/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [273][191/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [273][201/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [273][211/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [273][221/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [273][231/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [273][241/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [273][251/704]	Time 0.121	Data 0.001	Loss 2.60	Acc@1 95.3	Acc@5 100.0
Epoch: [273][261/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [273][271/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [273][281/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [273][291/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [273][301/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [273][311/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [273][321/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 89.1	Acc@5 100.0
Epoch: [273][331/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 92.2	Acc@5 100.0
Epoch: [273][341/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 98.4
Epoch: [273][351/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [273][361/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 92.2	Acc@5 100.0
Epoch: [273][371/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 100.0	Acc@5 100.0
Epoch: [273][381/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 89.1	Acc@5 100.0
Epoch: [273][391/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 100.0	Acc@5 100.0
Epoch: [273][401/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [273][411/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [273][421/704]	Time 0.121	Data 0.001	Loss 2.30	Acc@1 98.4	Acc@5 100.0
Epoch: [273][431/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 93.8	Acc@5 100.0
Epoch: [273][441/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [273][451/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [273][461/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [273][471/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [273][481/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 96.9	Acc@5 100.0
Epoch: [273][491/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [273][501/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [273][511/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 100.0	Acc@5 100.0
Epoch: [273][521/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [273][531/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 89.1	Acc@5 100.0
Epoch: [273][541/704]	Time 0.121	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [273][551/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 92.2	Acc@5 100.0
Epoch: [273][561/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [273][571/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 100.0	Acc@5 100.0
Epoch: [273][581/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [273][591/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 93.8	Acc@5 100.0
Epoch: [273][601/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [273][611/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [273][621/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [273][631/704]	Time 0.120	Data 0.001	Loss 1.79	Acc@1 98.4	Acc@5 100.0
Epoch: [273][641/704]	Time 0.120	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [273][651/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [273][661/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [273][671/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 90.6	Acc@5 100.0
Epoch: [273][681/704]	Time 0.120	Data 0.001	Loss 1.13	Acc@1 95.3	Acc@5 100.0
Epoch: [273][691/704]	Time 0.120	Data 0.001	Loss 2.11	Acc@1 96.9	Acc@5 100.0
Epoch: [273][701/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.8957	Acc@1 71.8750	Acc@5 89.0625
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 5.7472	Acc@1 76.5625	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.9305	Acc@1 59.3750	Acc@5 90.6250
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 6.8730	Acc@1 65.6250	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.8824	Acc@1 79.6875	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.0380	Acc@1 75.0000	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7617	Acc@1 68.7500	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.2077	Acc@1 84.3750	Acc@5 92.1875
 * prec@1 59.360 prec@5 85.600
 * prec@1 63.340 prec@5 88.780
 * prec@1 67.220 prec@5 91.060
 * prec@1 69.280 prec@5 91.360
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_273.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_273.pth.tar'
Epoch: [274][1/704]	Time 0.331	Data 0.165	Loss 1.29	Acc@1 95.3	Acc@5 100.0
Epoch: [274][11/704]	Time 0.140	Data 0.015	Loss 1.11	Acc@1 98.4	Acc@5 100.0
Epoch: [274][21/704]	Time 0.131	Data 0.008	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [274][31/704]	Time 0.127	Data 0.006	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [274][41/704]	Time 0.126	Data 0.004	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [274][51/704]	Time 0.125	Data 0.004	Loss 2.15	Acc@1 90.6	Acc@5 100.0
Epoch: [274][61/704]	Time 0.124	Data 0.003	Loss 1.48	Acc@1 92.2	Acc@5 100.0
Epoch: [274][71/704]	Time 0.123	Data 0.003	Loss 1.32	Acc@1 98.4	Acc@5 100.0
Epoch: [274][81/704]	Time 0.123	Data 0.002	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [274][91/704]	Time 0.123	Data 0.002	Loss 1.73	Acc@1 100.0	Acc@5 100.0
Epoch: [274][101/704]	Time 0.123	Data 0.002	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [274][111/704]	Time 0.122	Data 0.002	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [274][121/704]	Time 0.122	Data 0.002	Loss 1.49	Acc@1 93.8	Acc@5 100.0
Epoch: [274][131/704]	Time 0.122	Data 0.002	Loss 1.94	Acc@1 89.1	Acc@5 100.0
Epoch: [274][141/704]	Time 0.122	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [274][151/704]	Time 0.122	Data 0.001	Loss 1.24	Acc@1 96.9	Acc@5 100.0
Epoch: [274][161/704]	Time 0.122	Data 0.001	Loss 2.41	Acc@1 95.3	Acc@5 100.0
Epoch: [274][171/704]	Time 0.122	Data 0.001	Loss 1.57	Acc@1 90.6	Acc@5 100.0
Epoch: [274][181/704]	Time 0.122	Data 0.001	Loss 0.98	Acc@1 98.4	Acc@5 100.0
Epoch: [274][191/704]	Time 0.122	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [274][201/704]	Time 0.122	Data 0.001	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [274][211/704]	Time 0.121	Data 0.001	Loss 0.94	Acc@1 98.4	Acc@5 100.0
Epoch: [274][221/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [274][231/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [274][241/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [274][251/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 100.0	Acc@5 100.0
Epoch: [274][261/704]	Time 0.121	Data 0.001	Loss 0.98	Acc@1 100.0	Acc@5 100.0
Epoch: [274][271/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 89.1	Acc@5 100.0
Epoch: [274][281/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 89.1	Acc@5 100.0
Epoch: [274][291/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 90.6	Acc@5 100.0
Epoch: [274][301/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 100.0	Acc@5 100.0
Epoch: [274][311/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [274][321/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [274][331/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [274][341/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 100.0	Acc@5 100.0
Epoch: [274][351/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 96.9	Acc@5 100.0
Epoch: [274][361/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 95.3	Acc@5 98.4
Epoch: [274][371/704]	Time 0.121	Data 0.001	Loss 2.04	Acc@1 96.9	Acc@5 100.0
Epoch: [274][381/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 98.4	Acc@5 100.0
Epoch: [274][391/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [274][401/704]	Time 0.121	Data 0.001	Loss 1.13	Acc@1 100.0	Acc@5 100.0
Epoch: [274][411/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [274][421/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [274][431/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [274][441/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [274][451/704]	Time 0.121	Data 0.001	Loss 2.33	Acc@1 93.8	Acc@5 100.0
Epoch: [274][461/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 92.2	Acc@5 100.0
Epoch: [274][471/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 98.4	Acc@5 100.0
Epoch: [274][481/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [274][491/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [274][501/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 90.6	Acc@5 100.0
Epoch: [274][511/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [274][521/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [274][531/704]	Time 0.121	Data 0.001	Loss 1.11	Acc@1 96.9	Acc@5 100.0
Epoch: [274][541/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [274][551/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [274][561/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 96.9	Acc@5 100.0
Epoch: [274][571/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [274][581/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [274][591/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [274][601/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [274][611/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 100.0	Acc@5 100.0
Epoch: [274][621/704]	Time 0.120	Data 0.001	Loss 1.17	Acc@1 98.4	Acc@5 100.0
Epoch: [274][631/704]	Time 0.120	Data 0.001	Loss 2.40	Acc@1 93.8	Acc@5 98.4
Epoch: [274][641/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [274][651/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [274][661/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 90.6	Acc@5 100.0
Epoch: [274][671/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [274][681/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [274][691/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 100.0	Acc@5 100.0
Epoch: [274][701/704]	Time 0.120	Data 0.001	Loss 2.12	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.3723	Acc@1 67.1875	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4095	Acc@1 70.3125	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2213	Acc@1 76.5625	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.2207	Acc@1 76.5625	Acc@5 95.3125
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.1760	Acc@1 67.1875	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.3937	Acc@1 70.3125	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.0600	Acc@1 75.0000	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.5742	Acc@1 68.7500	Acc@5 95.3125
 * prec@1 58.440 prec@5 85.340
 * prec@1 63.220 prec@5 88.460
 * prec@1 67.140 prec@5 91.020
 * prec@1 69.300 prec@5 91.540
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_274.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_274.pth.tar'
Epoch: [275][1/704]	Time 0.299	Data 0.132	Loss 1.21	Acc@1 96.9	Acc@5 100.0
Epoch: [275][11/704]	Time 0.136	Data 0.012	Loss 1.27	Acc@1 96.9	Acc@5 100.0
Epoch: [275][21/704]	Time 0.128	Data 0.007	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [275][31/704]	Time 0.126	Data 0.005	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [275][41/704]	Time 0.124	Data 0.004	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [275][51/704]	Time 0.124	Data 0.003	Loss 1.09	Acc@1 100.0	Acc@5 100.0
Epoch: [275][61/704]	Time 0.123	Data 0.002	Loss 1.55	Acc@1 93.8	Acc@5 100.0
Epoch: [275][71/704]	Time 0.122	Data 0.002	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [275][81/704]	Time 0.122	Data 0.002	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [275][91/704]	Time 0.122	Data 0.002	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [275][101/704]	Time 0.122	Data 0.002	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [275][111/704]	Time 0.122	Data 0.002	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [275][121/704]	Time 0.122	Data 0.001	Loss 1.40	Acc@1 92.2	Acc@5 100.0
Epoch: [275][131/704]	Time 0.122	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [275][141/704]	Time 0.122	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [275][151/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 100.0
Epoch: [275][161/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [275][171/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 90.6	Acc@5 100.0
Epoch: [275][181/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 98.4
Epoch: [275][191/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [275][201/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [275][211/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 100.0	Acc@5 100.0
Epoch: [275][221/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [275][231/704]	Time 0.121	Data 0.001	Loss 1.08	Acc@1 95.3	Acc@5 100.0
Epoch: [275][241/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [275][251/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 100.0	Acc@5 100.0
Epoch: [275][261/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [275][271/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [275][281/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [275][291/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [275][301/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 98.4	Acc@5 100.0
Epoch: [275][311/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [275][321/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 98.4
Epoch: [275][331/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [275][341/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 95.3	Acc@5 100.0
Epoch: [275][351/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [275][361/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [275][371/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [275][381/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [275][391/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [275][401/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [275][411/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [275][421/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [275][431/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [275][441/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [275][451/704]	Time 0.120	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [275][461/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 100.0
Epoch: [275][471/704]	Time 0.120	Data 0.001	Loss 1.00	Acc@1 98.4	Acc@5 100.0
Epoch: [275][481/704]	Time 0.120	Data 0.001	Loss 1.62	Acc@1 93.8	Acc@5 100.0
Epoch: [275][491/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [275][501/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 100.0	Acc@5 100.0
Epoch: [275][511/704]	Time 0.120	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [275][521/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [275][531/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 95.3	Acc@5 100.0
Epoch: [275][541/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 92.2	Acc@5 100.0
Epoch: [275][551/704]	Time 0.120	Data 0.001	Loss 1.13	Acc@1 98.4	Acc@5 100.0
Epoch: [275][561/704]	Time 0.120	Data 0.001	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [275][571/704]	Time 0.120	Data 0.001	Loss 2.27	Acc@1 90.6	Acc@5 98.4
Epoch: [275][581/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [275][591/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 90.6	Acc@5 100.0
Epoch: [275][601/704]	Time 0.120	Data 0.001	Loss 1.17	Acc@1 100.0	Acc@5 100.0
Epoch: [275][611/704]	Time 0.120	Data 0.001	Loss 0.90	Acc@1 98.4	Acc@5 100.0
Epoch: [275][621/704]	Time 0.120	Data 0.000	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [275][631/704]	Time 0.120	Data 0.000	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [275][641/704]	Time 0.120	Data 0.000	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [275][651/704]	Time 0.120	Data 0.000	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [275][661/704]	Time 0.120	Data 0.000	Loss 1.83	Acc@1 90.6	Acc@5 100.0
Epoch: [275][671/704]	Time 0.120	Data 0.000	Loss 1.20	Acc@1 96.9	Acc@5 100.0
Epoch: [275][681/704]	Time 0.120	Data 0.000	Loss 1.39	Acc@1 93.8	Acc@5 98.4
Epoch: [275][691/704]	Time 0.120	Data 0.000	Loss 1.06	Acc@1 98.4	Acc@5 100.0
Epoch: [275][701/704]	Time 0.120	Data 0.000	Loss 1.07	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.8709	Acc@1 65.6250	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4005	Acc@1 71.8750	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.3990	Acc@1 71.8750	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.1363	Acc@1 71.8750	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.9093	Acc@1 67.1875	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.4452	Acc@1 56.2500	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 7.2456	Acc@1 59.3750	Acc@5 82.8125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.1520	Acc@1 64.0625	Acc@5 93.7500
 * prec@1 59.000 prec@5 86.140
 * prec@1 63.520 prec@5 89.420
 * prec@1 67.180 prec@5 91.340
 * prec@1 69.280 prec@5 91.740
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_275.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_275.pth.tar'
Epoch: [276][1/704]	Time 0.302	Data 0.133	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [276][11/704]	Time 0.141	Data 0.012	Loss 1.15	Acc@1 95.3	Acc@5 100.0
Epoch: [276][21/704]	Time 0.131	Data 0.007	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [276][31/704]	Time 0.128	Data 0.005	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [276][41/704]	Time 0.126	Data 0.004	Loss 1.35	Acc@1 93.8	Acc@5 100.0
Epoch: [276][51/704]	Time 0.125	Data 0.003	Loss 1.33	Acc@1 93.8	Acc@5 100.0
Epoch: [276][61/704]	Time 0.125	Data 0.002	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [276][71/704]	Time 0.124	Data 0.002	Loss 1.77	Acc@1 96.9	Acc@5 98.4
Epoch: [276][81/704]	Time 0.124	Data 0.002	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [276][91/704]	Time 0.123	Data 0.002	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [276][101/704]	Time 0.123	Data 0.002	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [276][111/704]	Time 0.123	Data 0.002	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [276][121/704]	Time 0.123	Data 0.001	Loss 1.68	Acc@1 92.2	Acc@5 100.0
Epoch: [276][131/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 92.2	Acc@5 100.0
Epoch: [276][141/704]	Time 0.122	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [276][151/704]	Time 0.122	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [276][161/704]	Time 0.122	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [276][171/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [276][181/704]	Time 0.122	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [276][191/704]	Time 0.122	Data 0.001	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [276][201/704]	Time 0.122	Data 0.001	Loss 1.51	Acc@1 100.0	Acc@5 100.0
Epoch: [276][211/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [276][221/704]	Time 0.122	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [276][231/704]	Time 0.122	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [276][241/704]	Time 0.122	Data 0.001	Loss 1.75	Acc@1 98.4	Acc@5 100.0
Epoch: [276][251/704]	Time 0.122	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [276][261/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [276][271/704]	Time 0.122	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [276][281/704]	Time 0.122	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [276][291/704]	Time 0.122	Data 0.001	Loss 1.10	Acc@1 98.4	Acc@5 100.0
Epoch: [276][301/704]	Time 0.122	Data 0.001	Loss 1.34	Acc@1 89.1	Acc@5 100.0
Epoch: [276][311/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [276][321/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [276][331/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 87.5	Acc@5 100.0
Epoch: [276][341/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [276][351/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 93.8	Acc@5 100.0
Epoch: [276][361/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [276][371/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 93.8	Acc@5 100.0
Epoch: [276][381/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [276][391/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 100.0	Acc@5 100.0
Epoch: [276][401/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 93.8	Acc@5 100.0
Epoch: [276][411/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 90.6	Acc@5 100.0
Epoch: [276][421/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [276][431/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [276][441/704]	Time 0.121	Data 0.001	Loss 1.16	Acc@1 100.0	Acc@5 100.0
Epoch: [276][451/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [276][461/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 98.4	Acc@5 100.0
Epoch: [276][471/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 93.8	Acc@5 100.0
Epoch: [276][481/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 89.1	Acc@5 100.0
Epoch: [276][491/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [276][501/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 95.3	Acc@5 98.4
Epoch: [276][511/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [276][521/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 98.4	Acc@5 100.0
Epoch: [276][531/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [276][541/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [276][551/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [276][561/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 89.1	Acc@5 100.0
Epoch: [276][571/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [276][581/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [276][591/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [276][601/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 92.2	Acc@5 100.0
Epoch: [276][611/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [276][621/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [276][631/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 95.3	Acc@5 98.4
Epoch: [276][641/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [276][651/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 100.0	Acc@5 100.0
Epoch: [276][661/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 98.4	Acc@5 98.4
Epoch: [276][671/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [276][681/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [276][691/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [276][701/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 92.2	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.7189	Acc@1 70.3125	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.7408	Acc@1 67.1875	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.7257	Acc@1 68.7500	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3590	Acc@1 68.7500	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.1499	Acc@1 70.3125	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.5257	Acc@1 67.1875	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.6932	Acc@1 67.1875	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.0730	Acc@1 68.7500	Acc@5 92.1875
 * prec@1 58.540 prec@5 85.820
 * prec@1 63.300 prec@5 88.100
 * prec@1 66.700 prec@5 90.840
 * prec@1 69.940 prec@5 91.320
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_276.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_276.pth.tar'
Epoch: [277][1/704]	Time 0.333	Data 0.166	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [277][11/704]	Time 0.140	Data 0.015	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [277][21/704]	Time 0.131	Data 0.008	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [277][31/704]	Time 0.127	Data 0.006	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [277][41/704]	Time 0.126	Data 0.004	Loss 1.14	Acc@1 96.9	Acc@5 100.0
Epoch: [277][51/704]	Time 0.125	Data 0.004	Loss 2.20	Acc@1 95.3	Acc@5 98.4
Epoch: [277][61/704]	Time 0.124	Data 0.003	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [277][71/704]	Time 0.123	Data 0.003	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [277][81/704]	Time 0.123	Data 0.002	Loss 1.57	Acc@1 100.0	Acc@5 100.0
Epoch: [277][91/704]	Time 0.123	Data 0.002	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [277][101/704]	Time 0.123	Data 0.002	Loss 1.64	Acc@1 93.8	Acc@5 100.0
Epoch: [277][111/704]	Time 0.122	Data 0.002	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [277][121/704]	Time 0.122	Data 0.002	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [277][131/704]	Time 0.122	Data 0.002	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [277][141/704]	Time 0.122	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [277][151/704]	Time 0.122	Data 0.001	Loss 1.36	Acc@1 89.1	Acc@5 100.0
Epoch: [277][161/704]	Time 0.122	Data 0.001	Loss 1.42	Acc@1 95.3	Acc@5 100.0
Epoch: [277][171/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 96.9	Acc@5 100.0
Epoch: [277][181/704]	Time 0.122	Data 0.001	Loss 2.02	Acc@1 95.3	Acc@5 100.0
Epoch: [277][191/704]	Time 0.122	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [277][201/704]	Time 0.122	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [277][211/704]	Time 0.122	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [277][221/704]	Time 0.122	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [277][231/704]	Time 0.122	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [277][241/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [277][251/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [277][261/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [277][271/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [277][281/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [277][291/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 98.4
Epoch: [277][301/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [277][311/704]	Time 0.121	Data 0.001	Loss 2.50	Acc@1 93.8	Acc@5 100.0
Epoch: [277][321/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [277][331/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [277][341/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [277][351/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [277][361/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 90.6	Acc@5 98.4
Epoch: [277][371/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [277][381/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [277][391/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [277][401/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 98.4	Acc@5 100.0
Epoch: [277][411/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 100.0	Acc@5 100.0
Epoch: [277][421/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [277][431/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [277][441/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [277][451/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 93.8	Acc@5 100.0
Epoch: [277][461/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [277][471/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [277][481/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 95.3	Acc@5 100.0
Epoch: [277][491/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 98.4
Epoch: [277][501/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [277][511/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 100.0
Epoch: [277][521/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [277][531/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [277][541/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 93.8	Acc@5 100.0
Epoch: [277][551/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 92.2	Acc@5 100.0
Epoch: [277][561/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [277][571/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 93.8	Acc@5 100.0
Epoch: [277][581/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [277][591/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 98.4
Epoch: [277][601/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [277][611/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [277][621/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [277][631/704]	Time 0.121	Data 0.001	Loss 2.37	Acc@1 95.3	Acc@5 100.0
Epoch: [277][641/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [277][651/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 92.2	Acc@5 100.0
Epoch: [277][661/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [277][671/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [277][681/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [277][691/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [277][701/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.5843	Acc@1 64.0625	Acc@5 98.4375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.8530	Acc@1 59.3750	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 3.8754	Acc@1 78.1250	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.4844	Acc@1 73.4375	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 3.9956	Acc@1 76.5625	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9894	Acc@1 67.1875	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 3.8138	Acc@1 79.6875	Acc@5 96.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.2538	Acc@1 59.3750	Acc@5 93.7500
 * prec@1 58.780 prec@5 85.400
 * prec@1 62.940 prec@5 89.280
 * prec@1 67.340 prec@5 90.880
 * prec@1 69.220 prec@5 92.020
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_277.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_277.pth.tar'
Epoch: [278][1/704]	Time 0.303	Data 0.134	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [278][11/704]	Time 0.138	Data 0.012	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [278][21/704]	Time 0.130	Data 0.007	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [278][31/704]	Time 0.127	Data 0.005	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [278][41/704]	Time 0.125	Data 0.004	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [278][51/704]	Time 0.125	Data 0.003	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [278][61/704]	Time 0.124	Data 0.003	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [278][71/704]	Time 0.124	Data 0.002	Loss 1.76	Acc@1 95.3	Acc@5 98.4
Epoch: [278][81/704]	Time 0.123	Data 0.002	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [278][91/704]	Time 0.123	Data 0.002	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [278][101/704]	Time 0.123	Data 0.002	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [278][111/704]	Time 0.123	Data 0.002	Loss 2.22	Acc@1 89.1	Acc@5 100.0
Epoch: [278][121/704]	Time 0.123	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [278][131/704]	Time 0.122	Data 0.001	Loss 1.15	Acc@1 98.4	Acc@5 100.0
Epoch: [278][141/704]	Time 0.123	Data 0.001	Loss 1.75	Acc@1 98.4	Acc@5 100.0
Epoch: [278][151/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [278][161/704]	Time 0.122	Data 0.001	Loss 1.71	Acc@1 92.2	Acc@5 100.0
Epoch: [278][171/704]	Time 0.122	Data 0.001	Loss 2.00	Acc@1 96.9	Acc@5 100.0
Epoch: [278][181/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [278][191/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [278][201/704]	Time 0.122	Data 0.001	Loss 1.41	Acc@1 100.0	Acc@5 100.0
Epoch: [278][211/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [278][221/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [278][231/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 92.2	Acc@5 100.0
Epoch: [278][241/704]	Time 0.122	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [278][251/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [278][261/704]	Time 0.122	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [278][271/704]	Time 0.122	Data 0.001	Loss 1.11	Acc@1 95.3	Acc@5 100.0
Epoch: [278][281/704]	Time 0.122	Data 0.001	Loss 1.51	Acc@1 92.2	Acc@5 100.0
Epoch: [278][291/704]	Time 0.122	Data 0.001	Loss 1.11	Acc@1 98.4	Acc@5 100.0
Epoch: [278][301/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [278][311/704]	Time 0.122	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [278][321/704]	Time 0.122	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 98.4
Epoch: [278][331/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [278][341/704]	Time 0.122	Data 0.001	Loss 1.11	Acc@1 98.4	Acc@5 100.0
Epoch: [278][351/704]	Time 0.122	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [278][361/704]	Time 0.122	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 98.4
Epoch: [278][371/704]	Time 0.122	Data 0.001	Loss 1.44	Acc@1 95.3	Acc@5 100.0
Epoch: [278][381/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 92.2	Acc@5 100.0
Epoch: [278][391/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [278][401/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 100.0	Acc@5 100.0
Epoch: [278][411/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 89.1	Acc@5 100.0
Epoch: [278][421/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 100.0	Acc@5 100.0
Epoch: [278][431/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 98.4	Acc@5 100.0
Epoch: [278][441/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [278][451/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [278][461/704]	Time 0.121	Data 0.001	Loss 2.15	Acc@1 89.1	Acc@5 100.0
Epoch: [278][471/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 90.6	Acc@5 100.0
Epoch: [278][481/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [278][491/704]	Time 0.121	Data 0.001	Loss 1.13	Acc@1 98.4	Acc@5 100.0
Epoch: [278][501/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [278][511/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 100.0	Acc@5 100.0
Epoch: [278][521/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 87.5	Acc@5 100.0
Epoch: [278][531/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [278][541/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [278][551/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [278][561/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [278][571/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [278][581/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [278][591/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 93.8	Acc@5 100.0
Epoch: [278][601/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 90.6	Acc@5 100.0
Epoch: [278][611/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [278][621/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 93.8	Acc@5 98.4
Epoch: [278][631/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [278][641/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [278][651/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 98.4	Acc@5 100.0
Epoch: [278][661/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 92.2	Acc@5 100.0
Epoch: [278][671/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [278][681/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 98.4	Acc@5 100.0
Epoch: [278][691/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [278][701/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 4.8790	Acc@1 73.4375	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.4554	Acc@1 67.1875	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.6820	Acc@1 64.0625	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.8211	Acc@1 62.5000	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.3309	Acc@1 60.9375	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.6433	Acc@1 71.8750	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.6141	Acc@1 73.4375	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.8201	Acc@1 73.4375	Acc@5 95.3125
 * prec@1 58.720 prec@5 85.560
 * prec@1 63.260 prec@5 88.680
 * prec@1 66.660 prec@5 91.340
 * prec@1 69.660 prec@5 91.520
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_278.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_278.pth.tar'
Epoch: [279][1/704]	Time 0.300	Data 0.132	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [279][11/704]	Time 0.137	Data 0.012	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [279][21/704]	Time 0.129	Data 0.007	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [279][31/704]	Time 0.126	Data 0.005	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [279][41/704]	Time 0.125	Data 0.004	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [279][51/704]	Time 0.124	Data 0.003	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [279][61/704]	Time 0.124	Data 0.003	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [279][71/704]	Time 0.124	Data 0.002	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [279][81/704]	Time 0.123	Data 0.002	Loss 1.27	Acc@1 98.4	Acc@5 100.0
Epoch: [279][91/704]	Time 0.123	Data 0.002	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [279][101/704]	Time 0.123	Data 0.002	Loss 1.50	Acc@1 100.0	Acc@5 100.0
Epoch: [279][111/704]	Time 0.122	Data 0.002	Loss 1.10	Acc@1 100.0	Acc@5 100.0
Epoch: [279][121/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [279][131/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 100.0	Acc@5 100.0
Epoch: [279][141/704]	Time 0.122	Data 0.001	Loss 2.18	Acc@1 95.3	Acc@5 100.0
Epoch: [279][151/704]	Time 0.122	Data 0.001	Loss 1.26	Acc@1 96.9	Acc@5 100.0
Epoch: [279][161/704]	Time 0.122	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [279][171/704]	Time 0.122	Data 0.001	Loss 2.19	Acc@1 90.6	Acc@5 100.0
Epoch: [279][181/704]	Time 0.122	Data 0.001	Loss 1.91	Acc@1 98.4	Acc@5 100.0
Epoch: [279][191/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 92.2	Acc@5 100.0
Epoch: [279][201/704]	Time 0.122	Data 0.001	Loss 1.17	Acc@1 96.9	Acc@5 100.0
Epoch: [279][211/704]	Time 0.122	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [279][221/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 92.2	Acc@5 100.0
Epoch: [279][231/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [279][241/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 93.8	Acc@5 100.0
Epoch: [279][251/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 92.2	Acc@5 100.0
Epoch: [279][261/704]	Time 0.121	Data 0.001	Loss 1.14	Acc@1 100.0	Acc@5 100.0
Epoch: [279][271/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [279][281/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [279][291/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [279][301/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [279][311/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [279][321/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [279][331/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [279][341/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 92.2	Acc@5 100.0
Epoch: [279][351/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 96.9	Acc@5 100.0
Epoch: [279][361/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [279][371/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 96.9	Acc@5 100.0
Epoch: [279][381/704]	Time 0.121	Data 0.001	Loss 1.10	Acc@1 96.9	Acc@5 100.0
Epoch: [279][391/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [279][401/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 96.9	Acc@5 100.0
Epoch: [279][411/704]	Time 0.121	Data 0.001	Loss 2.25	Acc@1 96.9	Acc@5 98.4
Epoch: [279][421/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 96.9	Acc@5 100.0
Epoch: [279][431/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 100.0	Acc@5 100.0
Epoch: [279][441/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [279][451/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [279][461/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [279][471/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [279][481/704]	Time 0.121	Data 0.001	Loss 1.27	Acc@1 95.3	Acc@5 100.0
Epoch: [279][491/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 96.9	Acc@5 100.0
Epoch: [279][501/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [279][511/704]	Time 0.121	Data 0.001	Loss 1.16	Acc@1 95.3	Acc@5 100.0
Epoch: [279][521/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 96.9	Acc@5 100.0
Epoch: [279][531/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [279][541/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [279][551/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [279][561/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 96.9	Acc@5 98.4
Epoch: [279][571/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [279][581/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [279][591/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [279][601/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 95.3	Acc@5 98.4
Epoch: [279][611/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [279][621/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 100.0	Acc@5 100.0
Epoch: [279][631/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [279][641/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [279][651/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 92.2	Acc@5 100.0
Epoch: [279][661/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [279][671/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [279][681/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [279][691/704]	Time 0.121	Data 0.001	Loss 0.91	Acc@1 100.0	Acc@5 100.0
Epoch: [279][701/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.9538	Acc@1 65.6250	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.0224	Acc@1 70.3125	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.5179	Acc@1 73.4375	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.2703	Acc@1 64.0625	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3867	Acc@1 76.5625	Acc@5 98.4375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 8.1730	Acc@1 59.3750	Acc@5 82.8125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.5945	Acc@1 67.1875	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.3137	Acc@1 67.1875	Acc@5 95.3125
 * prec@1 59.080 prec@5 85.980
 * prec@1 63.440 prec@5 88.780
 * prec@1 67.320 prec@5 91.000
 * prec@1 69.040 prec@5 91.420
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_279.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_279.pth.tar'
Epoch: [280][1/704]	Time 0.331	Data 0.165	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [280][11/704]	Time 0.139	Data 0.015	Loss 1.19	Acc@1 100.0	Acc@5 100.0
Epoch: [280][21/704]	Time 0.130	Data 0.008	Loss 1.50	Acc@1 100.0	Acc@5 100.0
Epoch: [280][31/704]	Time 0.127	Data 0.006	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [280][41/704]	Time 0.125	Data 0.004	Loss 1.30	Acc@1 95.3	Acc@5 100.0
Epoch: [280][51/704]	Time 0.124	Data 0.004	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [280][61/704]	Time 0.123	Data 0.003	Loss 1.32	Acc@1 98.4	Acc@5 100.0
Epoch: [280][71/704]	Time 0.123	Data 0.003	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [280][81/704]	Time 0.122	Data 0.002	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [280][91/704]	Time 0.122	Data 0.002	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [280][101/704]	Time 0.122	Data 0.002	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [280][111/704]	Time 0.122	Data 0.002	Loss 1.09	Acc@1 96.9	Acc@5 100.0
Epoch: [280][121/704]	Time 0.122	Data 0.002	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [280][131/704]	Time 0.121	Data 0.002	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [280][141/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [280][151/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 96.9	Acc@5 100.0
Epoch: [280][161/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [280][171/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [280][181/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [280][191/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [280][201/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [280][211/704]	Time 0.121	Data 0.001	Loss 1.10	Acc@1 96.9	Acc@5 100.0
Epoch: [280][221/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [280][231/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [280][241/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [280][251/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [280][261/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [280][271/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [280][281/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 93.8	Acc@5 100.0
Epoch: [280][291/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 90.6	Acc@5 100.0
Epoch: [280][301/704]	Time 0.121	Data 0.001	Loss 1.27	Acc@1 95.3	Acc@5 100.0
Epoch: [280][311/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 96.9	Acc@5 100.0
Epoch: [280][321/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [280][331/704]	Time 0.120	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [280][341/704]	Time 0.120	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [280][351/704]	Time 0.121	Data 0.001	Loss 0.94	Acc@1 98.4	Acc@5 100.0
Epoch: [280][361/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [280][371/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [280][381/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 92.2	Acc@5 100.0
Epoch: [280][391/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [280][401/704]	Time 0.120	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [280][411/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [280][421/704]	Time 0.120	Data 0.001	Loss 1.25	Acc@1 95.3	Acc@5 98.4
Epoch: [280][431/704]	Time 0.120	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [280][441/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [280][451/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [280][461/704]	Time 0.120	Data 0.001	Loss 1.07	Acc@1 98.4	Acc@5 100.0
Epoch: [280][471/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [280][481/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 96.9	Acc@5 100.0
Epoch: [280][491/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [280][501/704]	Time 0.120	Data 0.001	Loss 2.09	Acc@1 96.9	Acc@5 100.0
Epoch: [280][511/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [280][521/704]	Time 0.120	Data 0.001	Loss 1.18	Acc@1 98.4	Acc@5 100.0
Epoch: [280][531/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [280][541/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [280][551/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 92.2	Acc@5 100.0
Epoch: [280][561/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [280][571/704]	Time 0.120	Data 0.001	Loss 1.35	Acc@1 93.8	Acc@5 100.0
Epoch: [280][581/704]	Time 0.120	Data 0.001	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [280][591/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [280][601/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [280][611/704]	Time 0.120	Data 0.001	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [280][621/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 98.4
Epoch: [280][631/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [280][641/704]	Time 0.120	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [280][651/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [280][661/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 98.4	Acc@5 100.0
Epoch: [280][671/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [280][681/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [280][691/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 98.4
Epoch: [280][701/704]	Time 0.120	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.7669	Acc@1 78.1250	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 6.4129	Acc@1 70.3125	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.4774	Acc@1 79.6875	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.7673	Acc@1 71.8750	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3796	Acc@1 68.7500	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8886	Acc@1 73.4375	Acc@5 93.7500
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.9203	Acc@1 70.3125	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.5816	Acc@1 79.6875	Acc@5 96.8750
 * prec@1 58.200 prec@5 85.100
 * prec@1 62.880 prec@5 88.120
 * prec@1 66.900 prec@5 90.820
 * prec@1 69.220 prec@5 91.380
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_280.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_280.pth.tar'
Epoch: [281][1/704]	Time 0.331	Data 0.164	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [281][11/704]	Time 0.140	Data 0.015	Loss 1.44	Acc@1 100.0	Acc@5 100.0
Epoch: [281][21/704]	Time 0.131	Data 0.008	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [281][31/704]	Time 0.128	Data 0.006	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [281][41/704]	Time 0.126	Data 0.004	Loss 1.08	Acc@1 98.4	Acc@5 100.0
Epoch: [281][51/704]	Time 0.125	Data 0.004	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [281][61/704]	Time 0.124	Data 0.003	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [281][71/704]	Time 0.124	Data 0.003	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [281][81/704]	Time 0.123	Data 0.002	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [281][91/704]	Time 0.123	Data 0.002	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [281][101/704]	Time 0.123	Data 0.002	Loss 2.03	Acc@1 96.9	Acc@5 100.0
Epoch: [281][111/704]	Time 0.123	Data 0.002	Loss 1.30	Acc@1 95.3	Acc@5 100.0
Epoch: [281][121/704]	Time 0.122	Data 0.002	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [281][131/704]	Time 0.122	Data 0.002	Loss 1.69	Acc@1 98.4	Acc@5 98.4
Epoch: [281][141/704]	Time 0.122	Data 0.002	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [281][151/704]	Time 0.122	Data 0.002	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [281][161/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [281][171/704]	Time 0.122	Data 0.001	Loss 2.12	Acc@1 92.2	Acc@5 100.0
Epoch: [281][181/704]	Time 0.122	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [281][191/704]	Time 0.122	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [281][201/704]	Time 0.122	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [281][211/704]	Time 0.122	Data 0.001	Loss 1.17	Acc@1 98.4	Acc@5 100.0
Epoch: [281][221/704]	Time 0.122	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [281][231/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [281][241/704]	Time 0.121	Data 0.001	Loss 1.14	Acc@1 96.9	Acc@5 100.0
Epoch: [281][251/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [281][261/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [281][271/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [281][281/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [281][291/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 92.2	Acc@5 100.0
Epoch: [281][301/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 98.4
Epoch: [281][311/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [281][321/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [281][331/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 100.0	Acc@5 100.0
Epoch: [281][341/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 100.0	Acc@5 100.0
Epoch: [281][351/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 95.3	Acc@5 100.0
Epoch: [281][361/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 100.0	Acc@5 100.0
Epoch: [281][371/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [281][381/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [281][391/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [281][401/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [281][411/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [281][421/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [281][431/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [281][441/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 96.9	Acc@5 100.0
Epoch: [281][451/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [281][461/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [281][471/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [281][481/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [281][491/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 96.9	Acc@5 100.0
Epoch: [281][501/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 100.0	Acc@5 100.0
Epoch: [281][511/704]	Time 0.121	Data 0.001	Loss 2.02	Acc@1 96.9	Acc@5 100.0
Epoch: [281][521/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [281][531/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [281][541/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 100.0
Epoch: [281][551/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 95.3	Acc@5 100.0
Epoch: [281][561/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [281][571/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [281][581/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [281][591/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [281][601/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 93.8	Acc@5 100.0
Epoch: [281][611/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [281][621/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 95.3	Acc@5 100.0
Epoch: [281][631/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [281][641/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [281][651/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 87.5	Acc@5 100.0
Epoch: [281][661/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [281][671/704]	Time 0.120	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [281][681/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [281][691/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [281][701/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.3373	Acc@1 56.2500	Acc@5 82.8125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.1146	Acc@1 75.0000	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8143	Acc@1 65.6250	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.2747	Acc@1 71.8750	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.5102	Acc@1 60.9375	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.7921	Acc@1 67.1875	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.9442	Acc@1 70.3125	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.1295	Acc@1 71.8750	Acc@5 95.3125
 * prec@1 58.660 prec@5 85.620
 * prec@1 63.080 prec@5 88.500
 * prec@1 66.620 prec@5 91.000
 * prec@1 68.580 prec@5 91.380
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_281.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_281.pth.tar'
Epoch: [282][1/704]	Time 0.301	Data 0.133	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [282][11/704]	Time 0.137	Data 0.012	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [282][21/704]	Time 0.129	Data 0.007	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [282][31/704]	Time 0.126	Data 0.005	Loss 0.95	Acc@1 98.4	Acc@5 100.0
Epoch: [282][41/704]	Time 0.125	Data 0.004	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [282][51/704]	Time 0.124	Data 0.003	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [282][61/704]	Time 0.124	Data 0.002	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [282][71/704]	Time 0.123	Data 0.002	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [282][81/704]	Time 0.123	Data 0.002	Loss 1.92	Acc@1 93.8	Acc@5 98.4
Epoch: [282][91/704]	Time 0.123	Data 0.002	Loss 1.74	Acc@1 98.4	Acc@5 100.0
Epoch: [282][101/704]	Time 0.123	Data 0.002	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [282][111/704]	Time 0.123	Data 0.002	Loss 1.68	Acc@1 93.8	Acc@5 98.4
Epoch: [282][121/704]	Time 0.122	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [282][131/704]	Time 0.122	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [282][141/704]	Time 0.122	Data 0.001	Loss 1.81	Acc@1 90.6	Acc@5 100.0
Epoch: [282][151/704]	Time 0.122	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [282][161/704]	Time 0.122	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [282][171/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [282][181/704]	Time 0.122	Data 0.001	Loss 1.47	Acc@1 100.0	Acc@5 100.0
Epoch: [282][191/704]	Time 0.122	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [282][201/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [282][211/704]	Time 0.122	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [282][221/704]	Time 0.122	Data 0.001	Loss 1.53	Acc@1 93.8	Acc@5 100.0
Epoch: [282][231/704]	Time 0.122	Data 0.001	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [282][241/704]	Time 0.122	Data 0.001	Loss 1.41	Acc@1 95.3	Acc@5 100.0
Epoch: [282][251/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 98.4	Acc@5 100.0
Epoch: [282][261/704]	Time 0.121	Data 0.001	Loss 2.87	Acc@1 84.4	Acc@5 98.4
Epoch: [282][271/704]	Time 0.121	Data 0.001	Loss 0.97	Acc@1 100.0	Acc@5 100.0
Epoch: [282][281/704]	Time 0.121	Data 0.001	Loss 1.09	Acc@1 98.4	Acc@5 100.0
Epoch: [282][291/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 93.8	Acc@5 100.0
Epoch: [282][301/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 92.2	Acc@5 100.0
Epoch: [282][311/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [282][321/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 93.8	Acc@5 100.0
Epoch: [282][331/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [282][341/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [282][351/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 95.3	Acc@5 100.0
Epoch: [282][361/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [282][371/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [282][381/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 100.0	Acc@5 100.0
Epoch: [282][391/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [282][401/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [282][411/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [282][421/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 96.9	Acc@5 100.0
Epoch: [282][431/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [282][441/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 90.6	Acc@5 100.0
Epoch: [282][451/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [282][461/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 92.2	Acc@5 100.0
Epoch: [282][471/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [282][481/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [282][491/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 100.0	Acc@5 100.0
Epoch: [282][501/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [282][511/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [282][521/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [282][531/704]	Time 0.121	Data 0.001	Loss 1.10	Acc@1 95.3	Acc@5 100.0
Epoch: [282][541/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 90.6	Acc@5 100.0
Epoch: [282][551/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 93.8	Acc@5 100.0
Epoch: [282][561/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 95.3	Acc@5 100.0
Epoch: [282][571/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 98.4	Acc@5 100.0
Epoch: [282][581/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 92.2	Acc@5 100.0
Epoch: [282][591/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [282][601/704]	Time 0.121	Data 0.001	Loss 1.08	Acc@1 100.0	Acc@5 100.0
Epoch: [282][611/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [282][621/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [282][631/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [282][641/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [282][651/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [282][661/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [282][671/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 100.0	Acc@5 100.0
Epoch: [282][681/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [282][691/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [282][701/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.100	Data 0.085	Loss 6.9886	Acc@1 65.6250	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1663	Acc@1 70.3125	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8811	Acc@1 73.4375	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.3732	Acc@1 73.4375	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.1098	Acc@1 54.6875	Acc@5 85.9375
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.3345	Acc@1 62.5000	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.9845	Acc@1 70.3125	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.1168	Acc@1 79.6875	Acc@5 89.0625
 * prec@1 58.320 prec@5 85.600
 * prec@1 63.060 prec@5 88.260
 * prec@1 67.300 prec@5 90.800
 * prec@1 69.060 prec@5 91.160
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_282.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_282.pth.tar'
Epoch: [283][1/704]	Time 0.300	Data 0.131	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [283][11/704]	Time 0.140	Data 0.012	Loss 1.23	Acc@1 100.0	Acc@5 100.0
Epoch: [283][21/704]	Time 0.130	Data 0.007	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [283][31/704]	Time 0.127	Data 0.005	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [283][41/704]	Time 0.125	Data 0.004	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [283][51/704]	Time 0.124	Data 0.003	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [283][61/704]	Time 0.124	Data 0.003	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [283][71/704]	Time 0.123	Data 0.002	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [283][81/704]	Time 0.123	Data 0.002	Loss 1.91	Acc@1 95.3	Acc@5 96.9
Epoch: [283][91/704]	Time 0.122	Data 0.002	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [283][101/704]	Time 0.122	Data 0.002	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [283][111/704]	Time 0.122	Data 0.002	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [283][121/704]	Time 0.122	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [283][131/704]	Time 0.122	Data 0.001	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [283][141/704]	Time 0.122	Data 0.001	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [283][151/704]	Time 0.122	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [283][161/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 92.2	Acc@5 100.0
Epoch: [283][171/704]	Time 0.122	Data 0.001	Loss 1.84	Acc@1 93.8	Acc@5 98.4
Epoch: [283][181/704]	Time 0.122	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [283][191/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [283][201/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 96.9	Acc@5 100.0
Epoch: [283][211/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 93.8	Acc@5 100.0
Epoch: [283][221/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 100.0	Acc@5 100.0
Epoch: [283][231/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 90.6	Acc@5 100.0
Epoch: [283][241/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [283][251/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [283][261/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [283][271/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [283][281/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [283][291/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 96.9	Acc@5 100.0
Epoch: [283][301/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [283][311/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 100.0	Acc@5 100.0
Epoch: [283][321/704]	Time 0.121	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [283][331/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 100.0
Epoch: [283][341/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [283][351/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 90.6	Acc@5 100.0
Epoch: [283][361/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [283][371/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 95.3	Acc@5 100.0
Epoch: [283][381/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 98.4	Acc@5 100.0
Epoch: [283][391/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [283][401/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [283][411/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 98.4
Epoch: [283][421/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [283][431/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [283][441/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [283][451/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [283][461/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [283][471/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 100.0	Acc@5 100.0
Epoch: [283][481/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [283][491/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 100.0	Acc@5 100.0
Epoch: [283][501/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 96.9	Acc@5 100.0
Epoch: [283][511/704]	Time 0.121	Data 0.001	Loss 2.18	Acc@1 89.1	Acc@5 100.0
Epoch: [283][521/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [283][531/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [283][541/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [283][551/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 90.6	Acc@5 100.0
Epoch: [283][561/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 93.8	Acc@5 100.0
Epoch: [283][571/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [283][581/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 93.8	Acc@5 100.0
Epoch: [283][591/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [283][601/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [283][611/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [283][621/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [283][631/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [283][641/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 93.8	Acc@5 100.0
Epoch: [283][651/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [283][661/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [283][671/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [283][681/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [283][691/704]	Time 0.120	Data 0.001	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [283][701/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 3.9928	Acc@1 84.3750	Acc@5 96.8750
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 4.2714	Acc@1 76.5625	Acc@5 96.8750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.0482	Acc@1 65.6250	Acc@5 90.6250
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 5.1087	Acc@1 76.5625	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.4548	Acc@1 71.8750	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.5395	Acc@1 67.1875	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.2005	Acc@1 65.6250	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 6.4221	Acc@1 67.1875	Acc@5 87.5000
 * prec@1 58.420 prec@5 85.260
 * prec@1 63.500 prec@5 88.480
 * prec@1 66.860 prec@5 90.700
 * prec@1 69.420 prec@5 91.400
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_283.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_283.pth.tar'
Epoch: [284][1/704]	Time 0.326	Data 0.159	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [284][11/704]	Time 0.139	Data 0.015	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [284][21/704]	Time 0.130	Data 0.008	Loss 1.55	Acc@1 92.2	Acc@5 100.0
Epoch: [284][31/704]	Time 0.127	Data 0.005	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [284][41/704]	Time 0.125	Data 0.004	Loss 2.01	Acc@1 100.0	Acc@5 100.0
Epoch: [284][51/704]	Time 0.124	Data 0.004	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [284][61/704]	Time 0.123	Data 0.003	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [284][71/704]	Time 0.123	Data 0.003	Loss 1.16	Acc@1 96.9	Acc@5 100.0
Epoch: [284][81/704]	Time 0.122	Data 0.002	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [284][91/704]	Time 0.122	Data 0.002	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [284][101/704]	Time 0.122	Data 0.002	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [284][111/704]	Time 0.122	Data 0.002	Loss 1.53	Acc@1 92.2	Acc@5 100.0
Epoch: [284][121/704]	Time 0.122	Data 0.002	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [284][131/704]	Time 0.122	Data 0.002	Loss 1.26	Acc@1 96.9	Acc@5 100.0
Epoch: [284][141/704]	Time 0.121	Data 0.002	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [284][151/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 100.0	Acc@5 100.0
Epoch: [284][161/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [284][171/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [284][181/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [284][191/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [284][201/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 98.4	Acc@5 100.0
Epoch: [284][211/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [284][221/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [284][231/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 92.2	Acc@5 98.4
Epoch: [284][241/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [284][251/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [284][261/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [284][271/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [284][281/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 92.2	Acc@5 100.0
Epoch: [284][291/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 100.0	Acc@5 100.0
Epoch: [284][301/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [284][311/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [284][321/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [284][331/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 100.0	Acc@5 100.0
Epoch: [284][341/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [284][351/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [284][361/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 95.3	Acc@5 100.0
Epoch: [284][371/704]	Time 0.121	Data 0.001	Loss 1.15	Acc@1 100.0	Acc@5 100.0
Epoch: [284][381/704]	Time 0.121	Data 0.001	Loss 0.91	Acc@1 100.0	Acc@5 100.0
Epoch: [284][391/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [284][401/704]	Time 0.121	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 98.4
Epoch: [284][411/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [284][421/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [284][431/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [284][441/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [284][451/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 98.4	Acc@5 100.0
Epoch: [284][461/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 100.0	Acc@5 100.0
Epoch: [284][471/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 98.4	Acc@5 100.0
Epoch: [284][481/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 96.9	Acc@5 100.0
Epoch: [284][491/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [284][501/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [284][511/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [284][521/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [284][531/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 93.8	Acc@5 100.0
Epoch: [284][541/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [284][551/704]	Time 0.120	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [284][561/704]	Time 0.120	Data 0.001	Loss 1.27	Acc@1 96.9	Acc@5 100.0
Epoch: [284][571/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [284][581/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [284][591/704]	Time 0.120	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [284][601/704]	Time 0.120	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [284][611/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [284][621/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 93.8	Acc@5 100.0
Epoch: [284][631/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [284][641/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [284][651/704]	Time 0.120	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [284][661/704]	Time 0.120	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [284][671/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [284][681/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [284][691/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 95.3	Acc@5 100.0
Epoch: [284][701/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.103	Data 0.087	Loss 7.0136	Acc@1 59.3750	Acc@5 87.5000
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 4.8126	Acc@1 73.4375	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.8678	Acc@1 68.7500	Acc@5 92.1875
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 5.2610	Acc@1 75.0000	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3646	Acc@1 70.3125	Acc@5 87.5000
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8844	Acc@1 64.0625	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 5.7846	Acc@1 73.4375	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.3128	Acc@1 71.8750	Acc@5 98.4375
 * prec@1 57.960 prec@5 85.740
 * prec@1 62.960 prec@5 88.700
 * prec@1 66.160 prec@5 91.200
 * prec@1 68.960 prec@5 91.700
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_284.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_284.pth.tar'
Epoch: [285][1/704]	Time 0.302	Data 0.134	Loss 1.86	Acc@1 95.3	Acc@5 98.4
Epoch: [285][11/704]	Time 0.137	Data 0.012	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [285][21/704]	Time 0.129	Data 0.007	Loss 1.43	Acc@1 100.0	Acc@5 100.0
Epoch: [285][31/704]	Time 0.127	Data 0.005	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [285][41/704]	Time 0.125	Data 0.004	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [285][51/704]	Time 0.124	Data 0.003	Loss 1.58	Acc@1 100.0	Acc@5 100.0
Epoch: [285][61/704]	Time 0.124	Data 0.002	Loss 1.20	Acc@1 96.9	Acc@5 100.0
Epoch: [285][71/704]	Time 0.123	Data 0.002	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [285][81/704]	Time 0.123	Data 0.002	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [285][91/704]	Time 0.123	Data 0.002	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [285][101/704]	Time 0.122	Data 0.002	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [285][111/704]	Time 0.122	Data 0.002	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [285][121/704]	Time 0.122	Data 0.001	Loss 1.30	Acc@1 92.2	Acc@5 100.0
Epoch: [285][131/704]	Time 0.122	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [285][141/704]	Time 0.122	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 100.0
Epoch: [285][151/704]	Time 0.122	Data 0.001	Loss 2.04	Acc@1 96.9	Acc@5 100.0
Epoch: [285][161/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [285][171/704]	Time 0.122	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [285][181/704]	Time 0.122	Data 0.001	Loss 2.01	Acc@1 90.6	Acc@5 100.0
Epoch: [285][191/704]	Time 0.122	Data 0.001	Loss 1.31	Acc@1 95.3	Acc@5 100.0
Epoch: [285][201/704]	Time 0.122	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [285][211/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [285][221/704]	Time 0.122	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [285][231/704]	Time 0.122	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [285][241/704]	Time 0.122	Data 0.001	Loss 2.18	Acc@1 93.8	Acc@5 98.4
Epoch: [285][251/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 93.8	Acc@5 100.0
Epoch: [285][261/704]	Time 0.121	Data 0.001	Loss 2.24	Acc@1 98.4	Acc@5 100.0
Epoch: [285][271/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 100.0
Epoch: [285][281/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 95.3	Acc@5 100.0
Epoch: [285][291/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [285][301/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [285][311/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [285][321/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [285][331/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 93.8	Acc@5 100.0
Epoch: [285][341/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [285][351/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 95.3	Acc@5 100.0
Epoch: [285][361/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [285][371/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 100.0
Epoch: [285][381/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 96.9	Acc@5 98.4
Epoch: [285][391/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [285][401/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [285][411/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 96.9	Acc@5 98.4
Epoch: [285][421/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 95.3	Acc@5 100.0
Epoch: [285][431/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [285][441/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [285][451/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [285][461/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [285][471/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [285][481/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [285][491/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [285][501/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [285][511/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [285][521/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [285][531/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [285][541/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 96.9	Acc@5 100.0
Epoch: [285][551/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [285][561/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [285][571/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [285][581/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [285][591/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [285][601/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 93.8	Acc@5 100.0
Epoch: [285][611/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [285][621/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [285][631/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 95.3	Acc@5 100.0
Epoch: [285][641/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 92.2	Acc@5 98.4
Epoch: [285][651/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [285][661/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 100.0	Acc@5 100.0
Epoch: [285][671/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [285][681/704]	Time 0.121	Data 0.001	Loss 1.12	Acc@1 98.4	Acc@5 100.0
Epoch: [285][691/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [285][701/704]	Time 0.121	Data 0.001	Loss 1.12	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.104	Data 0.088	Loss 5.5848	Acc@1 75.0000	Acc@5 92.1875
Epoch: [11/79]	Time 0.025	Data 0.012	Loss 6.7607	Acc@1 60.9375	Acc@5 89.0625
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.8562	Acc@1 64.0625	Acc@5 89.0625
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 6.7716	Acc@1 62.5000	Acc@5 96.8750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.9636	Acc@1 59.3750	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.9510	Acc@1 70.3125	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 4.7366	Acc@1 68.7500	Acc@5 92.1875
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.7175	Acc@1 71.8750	Acc@5 98.4375
 * prec@1 58.620 prec@5 85.180
 * prec@1 62.500 prec@5 88.600
 * prec@1 66.600 prec@5 90.680
 * prec@1 69.060 prec@5 91.200
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_285.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_285.pth.tar'
Epoch: [286][1/704]	Time 0.301	Data 0.133	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [286][11/704]	Time 0.137	Data 0.012	Loss 1.98	Acc@1 90.6	Acc@5 100.0
Epoch: [286][21/704]	Time 0.129	Data 0.007	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [286][31/704]	Time 0.126	Data 0.005	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [286][41/704]	Time 0.125	Data 0.004	Loss 1.04	Acc@1 96.9	Acc@5 100.0
Epoch: [286][51/704]	Time 0.124	Data 0.003	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [286][61/704]	Time 0.124	Data 0.002	Loss 1.84	Acc@1 92.2	Acc@5 98.4
Epoch: [286][71/704]	Time 0.124	Data 0.002	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [286][81/704]	Time 0.123	Data 0.002	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [286][91/704]	Time 0.123	Data 0.002	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [286][101/704]	Time 0.123	Data 0.002	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [286][111/704]	Time 0.122	Data 0.002	Loss 1.85	Acc@1 96.9	Acc@5 98.4
Epoch: [286][121/704]	Time 0.122	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [286][131/704]	Time 0.122	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [286][141/704]	Time 0.122	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [286][151/704]	Time 0.122	Data 0.001	Loss 2.24	Acc@1 95.3	Acc@5 100.0
Epoch: [286][161/704]	Time 0.122	Data 0.001	Loss 1.81	Acc@1 98.4	Acc@5 100.0
Epoch: [286][171/704]	Time 0.122	Data 0.001	Loss 1.29	Acc@1 95.3	Acc@5 100.0
Epoch: [286][181/704]	Time 0.122	Data 0.001	Loss 1.25	Acc@1 92.2	Acc@5 100.0
Epoch: [286][191/704]	Time 0.122	Data 0.001	Loss 0.88	Acc@1 96.9	Acc@5 100.0
Epoch: [286][201/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [286][211/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [286][221/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [286][231/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 98.4
Epoch: [286][241/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [286][251/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [286][261/704]	Time 0.121	Data 0.001	Loss 2.26	Acc@1 90.6	Acc@5 100.0
Epoch: [286][271/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [286][281/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [286][291/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [286][301/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [286][311/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [286][321/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [286][331/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 100.0	Acc@5 100.0
Epoch: [286][341/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 89.1	Acc@5 100.0
Epoch: [286][351/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [286][361/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 98.4	Acc@5 100.0
Epoch: [286][371/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 98.4	Acc@5 100.0
Epoch: [286][381/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [286][391/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [286][401/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [286][411/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [286][421/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [286][431/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 96.9	Acc@5 100.0
Epoch: [286][441/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 95.3	Acc@5 100.0
Epoch: [286][451/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [286][461/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 93.8	Acc@5 100.0
Epoch: [286][471/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 100.0	Acc@5 100.0
Epoch: [286][481/704]	Time 0.121	Data 0.001	Loss 0.96	Acc@1 100.0	Acc@5 100.0
Epoch: [286][491/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [286][501/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [286][511/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [286][521/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [286][531/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 92.2	Acc@5 100.0
Epoch: [286][541/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [286][551/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [286][561/704]	Time 0.121	Data 0.001	Loss 1.15	Acc@1 95.3	Acc@5 100.0
Epoch: [286][571/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [286][581/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [286][591/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [286][601/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [286][611/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 96.9	Acc@5 100.0
Epoch: [286][621/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [286][631/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [286][641/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 100.0	Acc@5 100.0
Epoch: [286][651/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [286][661/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [286][671/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [286][681/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 95.3	Acc@5 100.0
Epoch: [286][691/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [286][701/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.4207	Acc@1 57.8125	Acc@5 85.9375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.2066	Acc@1 75.0000	Acc@5 87.5000
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.9125	Acc@1 73.4375	Acc@5 87.5000
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.0499	Acc@1 68.7500	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.2788	Acc@1 67.1875	Acc@5 95.3125
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.1216	Acc@1 65.6250	Acc@5 85.9375
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 5.6421	Acc@1 73.4375	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.7260	Acc@1 68.7500	Acc@5 90.6250
 * prec@1 58.640 prec@5 86.080
 * prec@1 63.100 prec@5 88.740
 * prec@1 67.700 prec@5 91.200
 * prec@1 69.640 prec@5 91.400
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_286.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_286.pth.tar'
Epoch: [287][1/704]	Time 0.333	Data 0.167	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [287][11/704]	Time 0.140	Data 0.015	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [287][21/704]	Time 0.130	Data 0.008	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [287][31/704]	Time 0.127	Data 0.006	Loss 2.01	Acc@1 96.9	Acc@5 100.0
Epoch: [287][41/704]	Time 0.125	Data 0.004	Loss 1.15	Acc@1 98.4	Acc@5 100.0
Epoch: [287][51/704]	Time 0.124	Data 0.004	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [287][61/704]	Time 0.124	Data 0.003	Loss 1.30	Acc@1 95.3	Acc@5 100.0
Epoch: [287][71/704]	Time 0.123	Data 0.003	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [287][81/704]	Time 0.123	Data 0.002	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [287][91/704]	Time 0.122	Data 0.002	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [287][101/704]	Time 0.122	Data 0.002	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [287][111/704]	Time 0.122	Data 0.002	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [287][121/704]	Time 0.122	Data 0.002	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [287][131/704]	Time 0.122	Data 0.002	Loss 1.92	Acc@1 93.8	Acc@5 96.9
Epoch: [287][141/704]	Time 0.122	Data 0.002	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [287][151/704]	Time 0.122	Data 0.001	Loss 1.08	Acc@1 98.4	Acc@5 100.0
Epoch: [287][161/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 98.4	Acc@5 100.0
Epoch: [287][171/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 93.8	Acc@5 100.0
Epoch: [287][181/704]	Time 0.121	Data 0.001	Loss 2.38	Acc@1 93.8	Acc@5 100.0
Epoch: [287][191/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 100.0	Acc@5 100.0
Epoch: [287][201/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 98.4
Epoch: [287][211/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 98.4
Epoch: [287][221/704]	Time 0.121	Data 0.001	Loss 1.16	Acc@1 96.9	Acc@5 100.0
Epoch: [287][231/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [287][241/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 92.2	Acc@5 100.0
Epoch: [287][251/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [287][261/704]	Time 0.121	Data 0.001	Loss 1.01	Acc@1 96.9	Acc@5 100.0
Epoch: [287][271/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [287][281/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [287][291/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [287][301/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [287][311/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [287][321/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 93.8	Acc@5 100.0
Epoch: [287][331/704]	Time 0.121	Data 0.001	Loss 1.04	Acc@1 100.0	Acc@5 100.0
Epoch: [287][341/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 95.3	Acc@5 100.0
Epoch: [287][351/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [287][361/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [287][371/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 93.8	Acc@5 100.0
Epoch: [287][381/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [287][391/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 100.0	Acc@5 100.0
Epoch: [287][401/704]	Time 0.121	Data 0.001	Loss 1.08	Acc@1 100.0	Acc@5 100.0
Epoch: [287][411/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 95.3	Acc@5 100.0
Epoch: [287][421/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [287][431/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [287][441/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [287][451/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [287][461/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [287][471/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 98.4	Acc@5 100.0
Epoch: [287][481/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 93.8	Acc@5 100.0
Epoch: [287][491/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [287][501/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [287][511/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 90.6	Acc@5 100.0
Epoch: [287][521/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 100.0	Acc@5 100.0
Epoch: [287][531/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [287][541/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [287][551/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [287][561/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [287][571/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [287][581/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [287][591/704]	Time 0.121	Data 0.001	Loss 1.16	Acc@1 100.0	Acc@5 100.0
Epoch: [287][601/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [287][611/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [287][621/704]	Time 0.120	Data 0.001	Loss 1.98	Acc@1 92.2	Acc@5 100.0
Epoch: [287][631/704]	Time 0.120	Data 0.001	Loss 2.20	Acc@1 96.9	Acc@5 100.0
Epoch: [287][641/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [287][651/704]	Time 0.120	Data 0.001	Loss 1.15	Acc@1 98.4	Acc@5 100.0
Epoch: [287][661/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [287][671/704]	Time 0.120	Data 0.001	Loss 1.15	Acc@1 100.0	Acc@5 100.0
Epoch: [287][681/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [287][691/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [287][701/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.1622	Acc@1 68.7500	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.6217	Acc@1 65.6250	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.3788	Acc@1 71.8750	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.9193	Acc@1 64.0625	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9309	Acc@1 68.7500	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.6446	Acc@1 70.3125	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.6359	Acc@1 57.8125	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.8818	Acc@1 75.0000	Acc@5 95.3125
 * prec@1 58.580 prec@5 84.820
 * prec@1 62.920 prec@5 89.140
 * prec@1 66.560 prec@5 90.920
 * prec@1 68.900 prec@5 91.280
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_287.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_287.pth.tar'
Epoch: [288][1/704]	Time 0.329	Data 0.163	Loss 1.77	Acc@1 96.9	Acc@5 98.4
Epoch: [288][11/704]	Time 0.139	Data 0.015	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [288][21/704]	Time 0.130	Data 0.008	Loss 1.12	Acc@1 98.4	Acc@5 100.0
Epoch: [288][31/704]	Time 0.127	Data 0.006	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [288][41/704]	Time 0.125	Data 0.004	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [288][51/704]	Time 0.124	Data 0.004	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [288][61/704]	Time 0.124	Data 0.003	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [288][71/704]	Time 0.123	Data 0.003	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [288][81/704]	Time 0.123	Data 0.002	Loss 1.36	Acc@1 98.4	Acc@5 100.0
Epoch: [288][91/704]	Time 0.122	Data 0.002	Loss 2.14	Acc@1 92.2	Acc@5 100.0
Epoch: [288][101/704]	Time 0.122	Data 0.002	Loss 1.67	Acc@1 92.2	Acc@5 100.0
Epoch: [288][111/704]	Time 0.122	Data 0.002	Loss 1.03	Acc@1 98.4	Acc@5 100.0
Epoch: [288][121/704]	Time 0.122	Data 0.002	Loss 2.22	Acc@1 95.3	Acc@5 100.0
Epoch: [288][131/704]	Time 0.122	Data 0.002	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [288][141/704]	Time 0.122	Data 0.002	Loss 1.97	Acc@1 98.4	Acc@5 100.0
Epoch: [288][151/704]	Time 0.122	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 100.0
Epoch: [288][161/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [288][171/704]	Time 0.122	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [288][181/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 93.8	Acc@5 98.4
Epoch: [288][191/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 98.4
Epoch: [288][201/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 95.3	Acc@5 100.0
Epoch: [288][211/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [288][221/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [288][231/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [288][241/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 95.3	Acc@5 100.0
Epoch: [288][251/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [288][261/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [288][271/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [288][281/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 98.4	Acc@5 100.0
Epoch: [288][291/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [288][301/704]	Time 0.121	Data 0.001	Loss 1.32	Acc@1 95.3	Acc@5 100.0
Epoch: [288][311/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [288][321/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 98.4
Epoch: [288][331/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [288][341/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 93.8	Acc@5 98.4
Epoch: [288][351/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [288][361/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 100.0	Acc@5 100.0
Epoch: [288][371/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 100.0	Acc@5 100.0
Epoch: [288][381/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 98.4
Epoch: [288][391/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 100.0	Acc@5 100.0
Epoch: [288][401/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [288][411/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 100.0	Acc@5 100.0
Epoch: [288][421/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [288][431/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [288][441/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [288][451/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 95.3	Acc@5 100.0
Epoch: [288][461/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [288][471/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [288][481/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 95.3	Acc@5 100.0
Epoch: [288][491/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 100.0	Acc@5 100.0
Epoch: [288][501/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 95.3	Acc@5 100.0
Epoch: [288][511/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 100.0
Epoch: [288][521/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 93.8	Acc@5 100.0
Epoch: [288][531/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 98.4
Epoch: [288][541/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 95.3	Acc@5 100.0
Epoch: [288][551/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 93.8	Acc@5 98.4
Epoch: [288][561/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [288][571/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 95.3	Acc@5 100.0
Epoch: [288][581/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 98.4	Acc@5 100.0
Epoch: [288][591/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 98.4	Acc@5 100.0
Epoch: [288][601/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 92.2	Acc@5 100.0
Epoch: [288][611/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 93.8	Acc@5 96.9
Epoch: [288][621/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 92.2	Acc@5 100.0
Epoch: [288][631/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 100.0	Acc@5 100.0
Epoch: [288][641/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 98.4	Acc@5 100.0
Epoch: [288][651/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [288][661/704]	Time 0.120	Data 0.001	Loss 1.21	Acc@1 96.9	Acc@5 100.0
Epoch: [288][671/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [288][681/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 96.9	Acc@5 100.0
Epoch: [288][691/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [288][701/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.3935	Acc@1 78.1250	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.1958	Acc@1 71.8750	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 8.2497	Acc@1 53.1250	Acc@5 93.7500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.3152	Acc@1 70.3125	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3351	Acc@1 70.3125	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1941	Acc@1 71.8750	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.3793	Acc@1 65.6250	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.5681	Acc@1 59.3750	Acc@5 93.7500
 * prec@1 58.620 prec@5 85.640
 * prec@1 63.040 prec@5 88.580
 * prec@1 67.000 prec@5 90.420
 * prec@1 69.540 prec@5 91.080
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_288.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_288.pth.tar'
Epoch: [289][1/704]	Time 0.300	Data 0.132	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [289][11/704]	Time 0.137	Data 0.012	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [289][21/704]	Time 0.129	Data 0.007	Loss 1.76	Acc@1 100.0	Acc@5 100.0
Epoch: [289][31/704]	Time 0.126	Data 0.005	Loss 1.22	Acc@1 95.3	Acc@5 100.0
Epoch: [289][41/704]	Time 0.125	Data 0.004	Loss 2.47	Acc@1 87.5	Acc@5 100.0
Epoch: [289][51/704]	Time 0.124	Data 0.003	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [289][61/704]	Time 0.123	Data 0.003	Loss 1.31	Acc@1 93.8	Acc@5 100.0
Epoch: [289][71/704]	Time 0.123	Data 0.002	Loss 1.46	Acc@1 90.6	Acc@5 100.0
Epoch: [289][81/704]	Time 0.122	Data 0.002	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [289][91/704]	Time 0.123	Data 0.002	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [289][101/704]	Time 0.122	Data 0.002	Loss 1.05	Acc@1 96.9	Acc@5 100.0
Epoch: [289][111/704]	Time 0.122	Data 0.002	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [289][121/704]	Time 0.122	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [289][131/704]	Time 0.122	Data 0.001	Loss 1.81	Acc@1 98.4	Acc@5 100.0
Epoch: [289][141/704]	Time 0.122	Data 0.001	Loss 1.85	Acc@1 98.4	Acc@5 100.0
Epoch: [289][151/704]	Time 0.122	Data 0.001	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [289][161/704]	Time 0.122	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [289][171/704]	Time 0.122	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [289][181/704]	Time 0.122	Data 0.001	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [289][191/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [289][201/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [289][211/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 93.8	Acc@5 100.0
Epoch: [289][221/704]	Time 0.121	Data 0.001	Loss 1.07	Acc@1 98.4	Acc@5 100.0
Epoch: [289][231/704]	Time 0.121	Data 0.001	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [289][241/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 95.3	Acc@5 100.0
Epoch: [289][251/704]	Time 0.121	Data 0.001	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [289][261/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [289][271/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [289][281/704]	Time 0.121	Data 0.001	Loss 1.15	Acc@1 95.3	Acc@5 100.0
Epoch: [289][291/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [289][301/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [289][311/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [289][321/704]	Time 0.121	Data 0.001	Loss 2.09	Acc@1 93.8	Acc@5 100.0
Epoch: [289][331/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [289][341/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [289][351/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [289][361/704]	Time 0.121	Data 0.001	Loss 2.17	Acc@1 96.9	Acc@5 100.0
Epoch: [289][371/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [289][381/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 93.8	Acc@5 100.0
Epoch: [289][391/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [289][401/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [289][411/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [289][421/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 100.0	Acc@5 100.0
Epoch: [289][431/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 93.8	Acc@5 100.0
Epoch: [289][441/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [289][451/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 98.4	Acc@5 100.0
Epoch: [289][461/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [289][471/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 100.0	Acc@5 100.0
Epoch: [289][481/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [289][491/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 95.3	Acc@5 100.0
Epoch: [289][501/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 93.8	Acc@5 100.0
Epoch: [289][511/704]	Time 0.121	Data 0.001	Loss 2.12	Acc@1 93.8	Acc@5 100.0
Epoch: [289][521/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [289][531/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [289][541/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [289][551/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 100.0	Acc@5 100.0
Epoch: [289][561/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [289][571/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 100.0	Acc@5 100.0
Epoch: [289][581/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 93.8	Acc@5 100.0
Epoch: [289][591/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 93.8	Acc@5 100.0
Epoch: [289][601/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [289][611/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [289][621/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 100.0	Acc@5 100.0
Epoch: [289][631/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 96.9	Acc@5 100.0
Epoch: [289][641/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [289][651/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [289][661/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [289][671/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 93.8	Acc@5 100.0
Epoch: [289][681/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 100.0	Acc@5 100.0
Epoch: [289][691/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [289][701/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.086	Loss 5.5391	Acc@1 67.1875	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0002	Acc@1 76.5625	Acc@5 84.3750
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.0197	Acc@1 60.9375	Acc@5 81.2500
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.6913	Acc@1 56.2500	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.7441	Acc@1 71.8750	Acc@5 96.8750
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 7.2006	Acc@1 70.3125	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 3.5158	Acc@1 71.8750	Acc@5 96.8750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.9512	Acc@1 71.8750	Acc@5 93.7500
 * prec@1 58.940 prec@5 85.820
 * prec@1 62.720 prec@5 88.420
 * prec@1 66.240 prec@5 91.300
 * prec@1 69.240 prec@5 91.320
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_289.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_289.pth.tar'
Epoch: [290][1/704]	Time 0.302	Data 0.133	Loss 2.17	Acc@1 93.8	Acc@5 100.0
Epoch: [290][11/704]	Time 0.141	Data 0.012	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [290][21/704]	Time 0.131	Data 0.007	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [290][31/704]	Time 0.127	Data 0.005	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [290][41/704]	Time 0.126	Data 0.004	Loss 1.09	Acc@1 95.3	Acc@5 100.0
Epoch: [290][51/704]	Time 0.124	Data 0.003	Loss 1.12	Acc@1 98.4	Acc@5 100.0
Epoch: [290][61/704]	Time 0.124	Data 0.002	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [290][71/704]	Time 0.123	Data 0.002	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [290][81/704]	Time 0.123	Data 0.002	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [290][91/704]	Time 0.122	Data 0.002	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [290][101/704]	Time 0.122	Data 0.002	Loss 1.40	Acc@1 98.4	Acc@5 100.0
Epoch: [290][111/704]	Time 0.122	Data 0.002	Loss 1.31	Acc@1 100.0	Acc@5 100.0
Epoch: [290][121/704]	Time 0.122	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [290][131/704]	Time 0.122	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [290][141/704]	Time 0.122	Data 0.001	Loss 1.26	Acc@1 95.3	Acc@5 100.0
Epoch: [290][151/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [290][161/704]	Time 0.121	Data 0.001	Loss 1.10	Acc@1 100.0	Acc@5 100.0
Epoch: [290][171/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 95.3	Acc@5 100.0
Epoch: [290][181/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 92.2	Acc@5 100.0
Epoch: [290][191/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 95.3	Acc@5 98.4
Epoch: [290][201/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 100.0	Acc@5 100.0
Epoch: [290][211/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [290][221/704]	Time 0.121	Data 0.001	Loss 2.53	Acc@1 85.9	Acc@5 98.4
Epoch: [290][231/704]	Time 0.121	Data 0.001	Loss 0.91	Acc@1 98.4	Acc@5 100.0
Epoch: [290][241/704]	Time 0.121	Data 0.001	Loss 1.26	Acc@1 93.8	Acc@5 100.0
Epoch: [290][251/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [290][261/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [290][271/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 100.0	Acc@5 100.0
Epoch: [290][281/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 98.4	Acc@5 100.0
Epoch: [290][291/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 92.2	Acc@5 100.0
Epoch: [290][301/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [290][311/704]	Time 0.121	Data 0.001	Loss 1.17	Acc@1 100.0	Acc@5 100.0
Epoch: [290][321/704]	Time 0.121	Data 0.001	Loss 2.00	Acc@1 95.3	Acc@5 100.0
Epoch: [290][331/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 100.0	Acc@5 100.0
Epoch: [290][341/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [290][351/704]	Time 0.121	Data 0.001	Loss 2.11	Acc@1 95.3	Acc@5 100.0
Epoch: [290][361/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [290][371/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [290][381/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 98.4	Acc@5 100.0
Epoch: [290][391/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 93.8	Acc@5 100.0
Epoch: [290][401/704]	Time 0.120	Data 0.001	Loss 1.94	Acc@1 96.9	Acc@5 100.0
Epoch: [290][411/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 90.6	Acc@5 100.0
Epoch: [290][421/704]	Time 0.120	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [290][431/704]	Time 0.120	Data 0.001	Loss 1.60	Acc@1 98.4	Acc@5 100.0
Epoch: [290][441/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [290][451/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 96.9	Acc@5 100.0
Epoch: [290][461/704]	Time 0.120	Data 0.001	Loss 1.40	Acc@1 100.0	Acc@5 100.0
Epoch: [290][471/704]	Time 0.120	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [290][481/704]	Time 0.120	Data 0.001	Loss 1.52	Acc@1 93.8	Acc@5 100.0
Epoch: [290][491/704]	Time 0.120	Data 0.001	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [290][501/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [290][511/704]	Time 0.120	Data 0.001	Loss 1.87	Acc@1 92.2	Acc@5 100.0
Epoch: [290][521/704]	Time 0.120	Data 0.001	Loss 2.32	Acc@1 92.2	Acc@5 100.0
Epoch: [290][531/704]	Time 0.120	Data 0.001	Loss 2.28	Acc@1 95.3	Acc@5 100.0
Epoch: [290][541/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 92.2	Acc@5 100.0
Epoch: [290][551/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [290][561/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [290][571/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 98.4	Acc@5 100.0
Epoch: [290][581/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 89.1	Acc@5 100.0
Epoch: [290][591/704]	Time 0.120	Data 0.001	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [290][601/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 92.2	Acc@5 100.0
Epoch: [290][611/704]	Time 0.120	Data 0.001	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [290][621/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [290][631/704]	Time 0.120	Data 0.001	Loss 0.83	Acc@1 100.0	Acc@5 100.0
Epoch: [290][641/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [290][651/704]	Time 0.120	Data 0.001	Loss 1.33	Acc@1 95.3	Acc@5 100.0
Epoch: [290][661/704]	Time 0.120	Data 0.001	Loss 1.49	Acc@1 95.3	Acc@5 100.0
Epoch: [290][671/704]	Time 0.120	Data 0.001	Loss 2.02	Acc@1 89.1	Acc@5 98.4
Epoch: [290][681/704]	Time 0.120	Data 0.001	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [290][691/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 93.8	Acc@5 100.0
Epoch: [290][701/704]	Time 0.120	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 4.1894	Acc@1 75.0000	Acc@5 93.7500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.6267	Acc@1 81.2500	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.4704	Acc@1 68.7500	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3766	Acc@1 64.0625	Acc@5 84.3750
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9951	Acc@1 73.4375	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.5910	Acc@1 71.8750	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.0613	Acc@1 75.0000	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.4944	Acc@1 73.4375	Acc@5 93.7500
 * prec@1 59.320 prec@5 85.420
 * prec@1 63.540 prec@5 88.760
 * prec@1 67.140 prec@5 91.160
 * prec@1 69.520 prec@5 91.420
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_290.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_290.pth.tar'
Epoch: [291][1/704]	Time 0.330	Data 0.164	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [291][11/704]	Time 0.139	Data 0.015	Loss 2.03	Acc@1 96.9	Acc@5 100.0
Epoch: [291][21/704]	Time 0.130	Data 0.008	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [291][31/704]	Time 0.127	Data 0.006	Loss 1.14	Acc@1 98.4	Acc@5 100.0
Epoch: [291][41/704]	Time 0.125	Data 0.004	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [291][51/704]	Time 0.124	Data 0.003	Loss 1.89	Acc@1 96.9	Acc@5 100.0
Epoch: [291][61/704]	Time 0.123	Data 0.003	Loss 1.27	Acc@1 93.8	Acc@5 100.0
Epoch: [291][71/704]	Time 0.123	Data 0.003	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [291][81/704]	Time 0.122	Data 0.002	Loss 1.94	Acc@1 93.8	Acc@5 100.0
Epoch: [291][91/704]	Time 0.122	Data 0.002	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [291][101/704]	Time 0.122	Data 0.002	Loss 1.55	Acc@1 100.0	Acc@5 100.0
Epoch: [291][111/704]	Time 0.122	Data 0.002	Loss 1.64	Acc@1 96.9	Acc@5 100.0
Epoch: [291][121/704]	Time 0.122	Data 0.002	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [291][131/704]	Time 0.121	Data 0.002	Loss 1.69	Acc@1 98.4	Acc@5 100.0
Epoch: [291][141/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [291][151/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 100.0	Acc@5 100.0
Epoch: [291][161/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 100.0	Acc@5 100.0
Epoch: [291][171/704]	Time 0.121	Data 0.001	Loss 2.21	Acc@1 98.4	Acc@5 100.0
Epoch: [291][181/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [291][191/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [291][201/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 96.9	Acc@5 100.0
Epoch: [291][211/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [291][221/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 100.0	Acc@5 100.0
Epoch: [291][231/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [291][241/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [291][251/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 98.4
Epoch: [291][261/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 98.4	Acc@5 100.0
Epoch: [291][271/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [291][281/704]	Time 0.121	Data 0.001	Loss 1.21	Acc@1 98.4	Acc@5 100.0
Epoch: [291][291/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [291][301/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [291][311/704]	Time 0.120	Data 0.001	Loss 2.24	Acc@1 96.9	Acc@5 98.4
Epoch: [291][321/704]	Time 0.120	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [291][331/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 96.9	Acc@5 100.0
Epoch: [291][341/704]	Time 0.120	Data 0.001	Loss 1.14	Acc@1 100.0	Acc@5 100.0
Epoch: [291][351/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 95.3	Acc@5 100.0
Epoch: [291][361/704]	Time 0.120	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [291][371/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [291][381/704]	Time 0.120	Data 0.001	Loss 2.05	Acc@1 96.9	Acc@5 100.0
Epoch: [291][391/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 95.3	Acc@5 100.0
Epoch: [291][401/704]	Time 0.120	Data 0.001	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [291][411/704]	Time 0.120	Data 0.001	Loss 1.29	Acc@1 100.0	Acc@5 100.0
Epoch: [291][421/704]	Time 0.120	Data 0.001	Loss 1.23	Acc@1 96.9	Acc@5 100.0
Epoch: [291][431/704]	Time 0.120	Data 0.001	Loss 1.49	Acc@1 93.8	Acc@5 100.0
Epoch: [291][441/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [291][451/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [291][461/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [291][471/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 90.6	Acc@5 100.0
Epoch: [291][481/704]	Time 0.120	Data 0.001	Loss 1.87	Acc@1 98.4	Acc@5 100.0
Epoch: [291][491/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [291][501/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [291][511/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [291][521/704]	Time 0.120	Data 0.001	Loss 1.49	Acc@1 100.0	Acc@5 100.0
Epoch: [291][531/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [291][541/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [291][551/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [291][561/704]	Time 0.120	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [291][571/704]	Time 0.120	Data 0.001	Loss 1.08	Acc@1 98.4	Acc@5 100.0
Epoch: [291][581/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 98.4	Acc@5 100.0
Epoch: [291][591/704]	Time 0.120	Data 0.001	Loss 1.34	Acc@1 93.8	Acc@5 100.0
Epoch: [291][601/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 92.2	Acc@5 100.0
Epoch: [291][611/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 100.0	Acc@5 100.0
Epoch: [291][621/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 100.0	Acc@5 100.0
Epoch: [291][631/704]	Time 0.120	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [291][641/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 98.4	Acc@5 100.0
Epoch: [291][651/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 98.4	Acc@5 100.0
Epoch: [291][661/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 98.4
Epoch: [291][671/704]	Time 0.120	Data 0.001	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [291][681/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [291][691/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [291][701/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.9621	Acc@1 75.0000	Acc@5 95.3125
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 4.6127	Acc@1 73.4375	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.1320	Acc@1 76.5625	Acc@5 96.8750
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.5424	Acc@1 62.5000	Acc@5 93.7500
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.1931	Acc@1 65.6250	Acc@5 93.7500
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.4620	Acc@1 76.5625	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 4.0371	Acc@1 81.2500	Acc@5 98.4375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.5567	Acc@1 78.1250	Acc@5 90.6250
 * prec@1 58.520 prec@5 85.680
 * prec@1 62.480 prec@5 88.540
 * prec@1 66.760 prec@5 91.080
 * prec@1 69.440 prec@5 91.300
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_291.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_291.pth.tar'
Epoch: [292][1/704]	Time 0.300	Data 0.133	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [292][11/704]	Time 0.136	Data 0.012	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [292][21/704]	Time 0.128	Data 0.007	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [292][31/704]	Time 0.126	Data 0.005	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [292][41/704]	Time 0.124	Data 0.004	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [292][51/704]	Time 0.123	Data 0.003	Loss 1.45	Acc@1 90.6	Acc@5 100.0
Epoch: [292][61/704]	Time 0.123	Data 0.003	Loss 2.25	Acc@1 95.3	Acc@5 100.0
Epoch: [292][71/704]	Time 0.122	Data 0.002	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [292][81/704]	Time 0.122	Data 0.002	Loss 1.68	Acc@1 92.2	Acc@5 100.0
Epoch: [292][91/704]	Time 0.122	Data 0.002	Loss 1.49	Acc@1 95.3	Acc@5 100.0
Epoch: [292][101/704]	Time 0.122	Data 0.002	Loss 1.26	Acc@1 100.0	Acc@5 100.0
Epoch: [292][111/704]	Time 0.121	Data 0.002	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [292][121/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [292][131/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 100.0	Acc@5 100.0
Epoch: [292][141/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 93.8	Acc@5 100.0
Epoch: [292][151/704]	Time 0.121	Data 0.001	Loss 1.27	Acc@1 98.4	Acc@5 100.0
Epoch: [292][161/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [292][171/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [292][181/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 95.3	Acc@5 100.0
Epoch: [292][191/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 100.0
Epoch: [292][201/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [292][211/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 100.0	Acc@5 100.0
Epoch: [292][221/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 90.6	Acc@5 100.0
Epoch: [292][231/704]	Time 0.121	Data 0.001	Loss 2.19	Acc@1 92.2	Acc@5 100.0
Epoch: [292][241/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [292][251/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 100.0	Acc@5 100.0
Epoch: [292][261/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [292][271/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [292][281/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [292][291/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 98.4	Acc@5 100.0
Epoch: [292][301/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [292][311/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [292][321/704]	Time 0.120	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [292][331/704]	Time 0.120	Data 0.001	Loss 1.46	Acc@1 96.9	Acc@5 100.0
Epoch: [292][341/704]	Time 0.120	Data 0.001	Loss 1.92	Acc@1 92.2	Acc@5 100.0
Epoch: [292][351/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [292][361/704]	Time 0.120	Data 0.001	Loss 1.78	Acc@1 96.9	Acc@5 100.0
Epoch: [292][371/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [292][381/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [292][391/704]	Time 0.120	Data 0.001	Loss 1.15	Acc@1 100.0	Acc@5 100.0
Epoch: [292][401/704]	Time 0.120	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [292][411/704]	Time 0.120	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [292][421/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 98.4
Epoch: [292][431/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 92.2	Acc@5 98.4
Epoch: [292][441/704]	Time 0.120	Data 0.001	Loss 1.90	Acc@1 100.0	Acc@5 100.0
Epoch: [292][451/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 93.8	Acc@5 100.0
Epoch: [292][461/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [292][471/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [292][481/704]	Time 0.120	Data 0.001	Loss 1.08	Acc@1 98.4	Acc@5 100.0
Epoch: [292][491/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 95.3	Acc@5 100.0
Epoch: [292][501/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [292][511/704]	Time 0.120	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [292][521/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [292][531/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [292][541/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 93.8	Acc@5 100.0
Epoch: [292][551/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 98.4
Epoch: [292][561/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [292][571/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 92.2	Acc@5 100.0
Epoch: [292][581/704]	Time 0.120	Data 0.001	Loss 1.60	Acc@1 98.4	Acc@5 100.0
Epoch: [292][591/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 98.4	Acc@5 100.0
Epoch: [292][601/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [292][611/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [292][621/704]	Time 0.120	Data 0.001	Loss 1.12	Acc@1 96.9	Acc@5 100.0
Epoch: [292][631/704]	Time 0.120	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [292][641/704]	Time 0.120	Data 0.001	Loss 1.26	Acc@1 98.4	Acc@5 100.0
Epoch: [292][651/704]	Time 0.120	Data 0.001	Loss 2.35	Acc@1 93.8	Acc@5 100.0
Epoch: [292][661/704]	Time 0.120	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [292][671/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 93.8	Acc@5 100.0
Epoch: [292][681/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [292][691/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 95.3	Acc@5 100.0
Epoch: [292][701/704]	Time 0.120	Data 0.001	Loss 1.16	Acc@1 98.4	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 7.5760	Acc@1 56.2500	Acc@5 81.2500
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 7.0818	Acc@1 70.3125	Acc@5 85.9375
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.2560	Acc@1 71.8750	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.1395	Acc@1 68.7500	Acc@5 87.5000
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.2274	Acc@1 65.6250	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.7839	Acc@1 62.5000	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.8166	Acc@1 65.6250	Acc@5 90.6250
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.9372	Acc@1 73.4375	Acc@5 92.1875
 * prec@1 58.740 prec@5 85.320
 * prec@1 62.780 prec@5 88.920
 * prec@1 66.480 prec@5 90.700
 * prec@1 69.460 prec@5 91.160
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_292.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_292.pth.tar'
Epoch: [293][1/704]	Time 0.298	Data 0.132	Loss 1.21	Acc@1 96.9	Acc@5 100.0
Epoch: [293][11/704]	Time 0.136	Data 0.012	Loss 1.15	Acc@1 100.0	Acc@5 100.0
Epoch: [293][21/704]	Time 0.128	Data 0.007	Loss 1.90	Acc@1 93.8	Acc@5 100.0
Epoch: [293][31/704]	Time 0.125	Data 0.005	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [293][41/704]	Time 0.124	Data 0.004	Loss 1.71	Acc@1 98.4	Acc@5 100.0
Epoch: [293][51/704]	Time 0.123	Data 0.003	Loss 1.07	Acc@1 98.4	Acc@5 100.0
Epoch: [293][61/704]	Time 0.123	Data 0.002	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [293][71/704]	Time 0.123	Data 0.002	Loss 1.93	Acc@1 98.4	Acc@5 100.0
Epoch: [293][81/704]	Time 0.122	Data 0.002	Loss 1.62	Acc@1 95.3	Acc@5 100.0
Epoch: [293][91/704]	Time 0.122	Data 0.002	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [293][101/704]	Time 0.122	Data 0.002	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [293][111/704]	Time 0.122	Data 0.001	Loss 1.25	Acc@1 95.3	Acc@5 100.0
Epoch: [293][121/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 95.3	Acc@5 100.0
Epoch: [293][131/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 92.2	Acc@5 100.0
Epoch: [293][141/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 98.4	Acc@5 100.0
Epoch: [293][151/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [293][161/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 93.8	Acc@5 100.0
Epoch: [293][171/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [293][181/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [293][191/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [293][201/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [293][211/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 93.8	Acc@5 100.0
Epoch: [293][221/704]	Time 0.121	Data 0.001	Loss 0.98	Acc@1 98.4	Acc@5 100.0
Epoch: [293][231/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 92.2	Acc@5 100.0
Epoch: [293][241/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 100.0
Epoch: [293][251/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [293][261/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [293][271/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [293][281/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [293][291/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 93.8	Acc@5 100.0
Epoch: [293][301/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [293][311/704]	Time 0.120	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [293][321/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [293][331/704]	Time 0.120	Data 0.001	Loss 1.44	Acc@1 96.9	Acc@5 100.0
Epoch: [293][341/704]	Time 0.120	Data 0.001	Loss 1.26	Acc@1 100.0	Acc@5 100.0
Epoch: [293][351/704]	Time 0.120	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [293][361/704]	Time 0.120	Data 0.001	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [293][371/704]	Time 0.120	Data 0.001	Loss 1.34	Acc@1 96.9	Acc@5 100.0
Epoch: [293][381/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 90.6	Acc@5 100.0
Epoch: [293][391/704]	Time 0.120	Data 0.001	Loss 1.25	Acc@1 95.3	Acc@5 100.0
Epoch: [293][401/704]	Time 0.120	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 98.4
Epoch: [293][411/704]	Time 0.120	Data 0.001	Loss 1.69	Acc@1 93.8	Acc@5 100.0
Epoch: [293][421/704]	Time 0.120	Data 0.001	Loss 1.89	Acc@1 93.8	Acc@5 100.0
Epoch: [293][431/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 92.2	Acc@5 100.0
Epoch: [293][441/704]	Time 0.120	Data 0.001	Loss 1.20	Acc@1 96.9	Acc@5 100.0
Epoch: [293][451/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [293][461/704]	Time 0.120	Data 0.001	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [293][471/704]	Time 0.120	Data 0.001	Loss 1.40	Acc@1 96.9	Acc@5 100.0
Epoch: [293][481/704]	Time 0.120	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [293][491/704]	Time 0.120	Data 0.001	Loss 1.82	Acc@1 93.8	Acc@5 100.0
Epoch: [293][501/704]	Time 0.120	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [293][511/704]	Time 0.120	Data 0.001	Loss 1.49	Acc@1 95.3	Acc@5 100.0
Epoch: [293][521/704]	Time 0.120	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [293][531/704]	Time 0.120	Data 0.001	Loss 1.90	Acc@1 100.0	Acc@5 100.0
Epoch: [293][541/704]	Time 0.120	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [293][551/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 93.8	Acc@5 100.0
Epoch: [293][561/704]	Time 0.120	Data 0.001	Loss 1.58	Acc@1 92.2	Acc@5 100.0
Epoch: [293][571/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 98.4	Acc@5 100.0
Epoch: [293][581/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [293][591/704]	Time 0.120	Data 0.001	Loss 1.52	Acc@1 100.0	Acc@5 100.0
Epoch: [293][601/704]	Time 0.120	Data 0.001	Loss 1.62	Acc@1 96.9	Acc@5 100.0
Epoch: [293][611/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [293][621/704]	Time 0.120	Data 0.001	Loss 1.23	Acc@1 93.8	Acc@5 100.0
Epoch: [293][631/704]	Time 0.120	Data 0.001	Loss 2.15	Acc@1 92.2	Acc@5 100.0
Epoch: [293][641/704]	Time 0.120	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [293][651/704]	Time 0.120	Data 0.001	Loss 1.47	Acc@1 92.2	Acc@5 100.0
Epoch: [293][661/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 95.3	Acc@5 100.0
Epoch: [293][671/704]	Time 0.120	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [293][681/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 96.9	Acc@5 100.0
Epoch: [293][691/704]	Time 0.120	Data 0.001	Loss 2.01	Acc@1 93.8	Acc@5 100.0
Epoch: [293][701/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 4.5463	Acc@1 71.8750	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.3423	Acc@1 71.8750	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.3494	Acc@1 79.6875	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 4.7334	Acc@1 76.5625	Acc@5 92.1875
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 7.3395	Acc@1 65.6250	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.9522	Acc@1 67.1875	Acc@5 95.3125
Epoch: [61/79]	Time 0.018	Data 0.006	Loss 6.2722	Acc@1 68.7500	Acc@5 93.7500
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.7588	Acc@1 64.0625	Acc@5 92.1875
 * prec@1 58.340 prec@5 85.760
 * prec@1 62.920 prec@5 88.400
 * prec@1 67.160 prec@5 91.360
 * prec@1 68.880 prec@5 91.580
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_293.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_293.pth.tar'
Epoch: [294][1/704]	Time 0.336	Data 0.170	Loss 1.31	Acc@1 95.3	Acc@5 100.0
Epoch: [294][11/704]	Time 0.140	Data 0.016	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [294][21/704]	Time 0.130	Data 0.008	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [294][31/704]	Time 0.127	Data 0.006	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [294][41/704]	Time 0.125	Data 0.004	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [294][51/704]	Time 0.124	Data 0.004	Loss 1.54	Acc@1 96.9	Acc@5 100.0
Epoch: [294][61/704]	Time 0.123	Data 0.003	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [294][71/704]	Time 0.123	Data 0.003	Loss 1.67	Acc@1 100.0	Acc@5 100.0
Epoch: [294][81/704]	Time 0.122	Data 0.002	Loss 1.73	Acc@1 96.9	Acc@5 100.0
Epoch: [294][91/704]	Time 0.122	Data 0.002	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [294][101/704]	Time 0.122	Data 0.002	Loss 1.81	Acc@1 100.0	Acc@5 100.0
Epoch: [294][111/704]	Time 0.122	Data 0.002	Loss 1.90	Acc@1 98.4	Acc@5 100.0
Epoch: [294][121/704]	Time 0.122	Data 0.002	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [294][131/704]	Time 0.121	Data 0.002	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [294][141/704]	Time 0.121	Data 0.002	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [294][151/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [294][161/704]	Time 0.121	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [294][171/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 98.4	Acc@5 100.0
Epoch: [294][181/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [294][191/704]	Time 0.121	Data 0.001	Loss 1.24	Acc@1 96.9	Acc@5 100.0
Epoch: [294][201/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [294][211/704]	Time 0.121	Data 0.001	Loss 1.97	Acc@1 96.9	Acc@5 100.0
Epoch: [294][221/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 98.4	Acc@5 100.0
Epoch: [294][231/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [294][241/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 96.9	Acc@5 100.0
Epoch: [294][251/704]	Time 0.121	Data 0.001	Loss 1.98	Acc@1 89.1	Acc@5 100.0
Epoch: [294][261/704]	Time 0.121	Data 0.001	Loss 1.69	Acc@1 96.9	Acc@5 100.0
Epoch: [294][271/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 92.2	Acc@5 100.0
Epoch: [294][281/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [294][291/704]	Time 0.120	Data 0.001	Loss 2.25	Acc@1 92.2	Acc@5 98.4
Epoch: [294][301/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 93.8	Acc@5 98.4
Epoch: [294][311/704]	Time 0.120	Data 0.001	Loss 2.00	Acc@1 93.8	Acc@5 100.0
Epoch: [294][321/704]	Time 0.120	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [294][331/704]	Time 0.120	Data 0.001	Loss 1.85	Acc@1 98.4	Acc@5 100.0
Epoch: [294][341/704]	Time 0.120	Data 0.001	Loss 1.13	Acc@1 100.0	Acc@5 100.0
Epoch: [294][351/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [294][361/704]	Time 0.120	Data 0.001	Loss 1.07	Acc@1 100.0	Acc@5 100.0
Epoch: [294][371/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 95.3	Acc@5 100.0
Epoch: [294][381/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 93.8	Acc@5 100.0
Epoch: [294][391/704]	Time 0.120	Data 0.001	Loss 0.98	Acc@1 96.9	Acc@5 100.0
Epoch: [294][401/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 98.4	Acc@5 100.0
Epoch: [294][411/704]	Time 0.120	Data 0.001	Loss 1.37	Acc@1 100.0	Acc@5 100.0
Epoch: [294][421/704]	Time 0.120	Data 0.001	Loss 2.10	Acc@1 95.3	Acc@5 100.0
Epoch: [294][431/704]	Time 0.120	Data 0.001	Loss 1.84	Acc@1 92.2	Acc@5 100.0
Epoch: [294][441/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 93.8	Acc@5 100.0
Epoch: [294][451/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 93.8	Acc@5 100.0
Epoch: [294][461/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 98.4	Acc@5 100.0
Epoch: [294][471/704]	Time 0.120	Data 0.001	Loss 1.10	Acc@1 95.3	Acc@5 100.0
Epoch: [294][481/704]	Time 0.120	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [294][491/704]	Time 0.120	Data 0.001	Loss 1.57	Acc@1 95.3	Acc@5 100.0
Epoch: [294][501/704]	Time 0.120	Data 0.001	Loss 1.32	Acc@1 100.0	Acc@5 100.0
Epoch: [294][511/704]	Time 0.120	Data 0.001	Loss 1.71	Acc@1 96.9	Acc@5 100.0
Epoch: [294][521/704]	Time 0.120	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [294][531/704]	Time 0.120	Data 0.001	Loss 2.13	Acc@1 96.9	Acc@5 100.0
Epoch: [294][541/704]	Time 0.120	Data 0.001	Loss 1.34	Acc@1 100.0	Acc@5 100.0
Epoch: [294][551/704]	Time 0.120	Data 0.001	Loss 1.14	Acc@1 96.9	Acc@5 100.0
Epoch: [294][561/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 92.2	Acc@5 100.0
Epoch: [294][571/704]	Time 0.120	Data 0.001	Loss 1.42	Acc@1 96.9	Acc@5 100.0
Epoch: [294][581/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [294][591/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [294][601/704]	Time 0.120	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [294][611/704]	Time 0.120	Data 0.001	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [294][621/704]	Time 0.120	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [294][631/704]	Time 0.120	Data 0.001	Loss 1.83	Acc@1 96.9	Acc@5 100.0
Epoch: [294][641/704]	Time 0.120	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [294][651/704]	Time 0.120	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [294][661/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 96.9	Acc@5 100.0
Epoch: [294][671/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 96.9	Acc@5 100.0
Epoch: [294][681/704]	Time 0.120	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [294][691/704]	Time 0.120	Data 0.001	Loss 1.33	Acc@1 98.4	Acc@5 100.0
Epoch: [294][701/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.103	Data 0.088	Loss 5.1314	Acc@1 71.8750	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1569	Acc@1 67.1875	Acc@5 93.7500
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.0908	Acc@1 68.7500	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.3735	Acc@1 68.7500	Acc@5 89.0625
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.9160	Acc@1 65.6250	Acc@5 90.6250
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 6.1696	Acc@1 68.7500	Acc@5 87.5000
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.0077	Acc@1 71.8750	Acc@5 85.9375
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.0695	Acc@1 71.8750	Acc@5 95.3125
 * prec@1 58.340 prec@5 85.300
 * prec@1 63.580 prec@5 88.240
 * prec@1 67.220 prec@5 90.820
 * prec@1 69.180 prec@5 91.300
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_294.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_294.pth.tar'
Epoch: [295][1/704]	Time 0.335	Data 0.169	Loss 1.51	Acc@1 98.4	Acc@5 100.0
Epoch: [295][11/704]	Time 0.140	Data 0.016	Loss 1.52	Acc@1 95.3	Acc@5 100.0
Epoch: [295][21/704]	Time 0.131	Data 0.008	Loss 1.22	Acc@1 96.9	Acc@5 100.0
Epoch: [295][31/704]	Time 0.128	Data 0.006	Loss 2.42	Acc@1 95.3	Acc@5 100.0
Epoch: [295][41/704]	Time 0.126	Data 0.004	Loss 1.94	Acc@1 96.9	Acc@5 100.0
Epoch: [295][51/704]	Time 0.125	Data 0.004	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [295][61/704]	Time 0.124	Data 0.003	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [295][71/704]	Time 0.124	Data 0.003	Loss 1.45	Acc@1 93.8	Acc@5 100.0
Epoch: [295][81/704]	Time 0.123	Data 0.002	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [295][91/704]	Time 0.123	Data 0.002	Loss 1.20	Acc@1 100.0	Acc@5 100.0
Epoch: [295][101/704]	Time 0.123	Data 0.002	Loss 1.31	Acc@1 100.0	Acc@5 100.0
Epoch: [295][111/704]	Time 0.122	Data 0.002	Loss 1.34	Acc@1 93.8	Acc@5 100.0
Epoch: [295][121/704]	Time 0.122	Data 0.002	Loss 1.22	Acc@1 98.4	Acc@5 100.0
Epoch: [295][131/704]	Time 0.122	Data 0.002	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [295][141/704]	Time 0.122	Data 0.002	Loss 1.97	Acc@1 95.3	Acc@5 100.0
Epoch: [295][151/704]	Time 0.122	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [295][161/704]	Time 0.122	Data 0.001	Loss 1.64	Acc@1 95.3	Acc@5 100.0
Epoch: [295][171/704]	Time 0.122	Data 0.001	Loss 1.66	Acc@1 96.9	Acc@5 100.0
Epoch: [295][181/704]	Time 0.122	Data 0.001	Loss 1.98	Acc@1 93.8	Acc@5 100.0
Epoch: [295][191/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [295][201/704]	Time 0.122	Data 0.001	Loss 1.92	Acc@1 96.9	Acc@5 100.0
Epoch: [295][211/704]	Time 0.122	Data 0.001	Loss 2.09	Acc@1 92.2	Acc@5 100.0
Epoch: [295][221/704]	Time 0.122	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [295][231/704]	Time 0.122	Data 0.001	Loss 2.15	Acc@1 95.3	Acc@5 100.0
Epoch: [295][241/704]	Time 0.122	Data 0.001	Loss 2.14	Acc@1 93.8	Acc@5 100.0
Epoch: [295][251/704]	Time 0.122	Data 0.001	Loss 1.77	Acc@1 93.8	Acc@5 100.0
Epoch: [295][261/704]	Time 0.122	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [295][271/704]	Time 0.122	Data 0.001	Loss 1.83	Acc@1 100.0	Acc@5 100.0
Epoch: [295][281/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [295][291/704]	Time 0.121	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [295][301/704]	Time 0.121	Data 0.001	Loss 1.10	Acc@1 100.0	Acc@5 100.0
Epoch: [295][311/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [295][321/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [295][331/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 95.3	Acc@5 100.0
Epoch: [295][341/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [295][351/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [295][361/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 98.4	Acc@5 100.0
Epoch: [295][371/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [295][381/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [295][391/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 90.6	Acc@5 100.0
Epoch: [295][401/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [295][411/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 98.4	Acc@5 100.0
Epoch: [295][421/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 98.4	Acc@5 100.0
Epoch: [295][431/704]	Time 0.121	Data 0.001	Loss 1.41	Acc@1 96.9	Acc@5 100.0
Epoch: [295][441/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 93.8	Acc@5 100.0
Epoch: [295][451/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [295][461/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [295][471/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 95.3	Acc@5 100.0
Epoch: [295][481/704]	Time 0.121	Data 0.001	Loss 2.16	Acc@1 96.9	Acc@5 100.0
Epoch: [295][491/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [295][501/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [295][511/704]	Time 0.121	Data 0.001	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [295][521/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [295][531/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 96.9	Acc@5 100.0
Epoch: [295][541/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 93.8	Acc@5 100.0
Epoch: [295][551/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 95.3	Acc@5 100.0
Epoch: [295][561/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 96.9	Acc@5 100.0
Epoch: [295][571/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [295][581/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 100.0	Acc@5 100.0
Epoch: [295][591/704]	Time 0.121	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [295][601/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 98.4	Acc@5 100.0
Epoch: [295][611/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [295][621/704]	Time 0.121	Data 0.001	Loss 1.94	Acc@1 95.3	Acc@5 100.0
Epoch: [295][631/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 100.0	Acc@5 100.0
Epoch: [295][641/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [295][651/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 98.4	Acc@5 100.0
Epoch: [295][661/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 92.2	Acc@5 100.0
Epoch: [295][671/704]	Time 0.121	Data 0.001	Loss 2.08	Acc@1 96.9	Acc@5 100.0
Epoch: [295][681/704]	Time 0.121	Data 0.001	Loss 1.23	Acc@1 95.3	Acc@5 100.0
Epoch: [295][691/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 98.4	Acc@5 100.0
Epoch: [295][701/704]	Time 0.121	Data 0.001	Loss 1.73	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 6.0676	Acc@1 73.4375	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.011	Loss 5.3503	Acc@1 76.5625	Acc@5 96.8750
Epoch: [21/79]	Time 0.020	Data 0.008	Loss 6.3556	Acc@1 71.8750	Acc@5 95.3125
Epoch: [31/79]	Time 0.020	Data 0.007	Loss 6.6630	Acc@1 70.3125	Acc@5 85.9375
Epoch: [41/79]	Time 0.020	Data 0.007	Loss 7.9114	Acc@1 56.2500	Acc@5 87.5000
Epoch: [51/79]	Time 0.019	Data 0.006	Loss 5.9380	Acc@1 71.8750	Acc@5 93.7500
Epoch: [61/79]	Time 0.019	Data 0.006	Loss 4.5632	Acc@1 71.8750	Acc@5 98.4375
Epoch: [71/79]	Time 0.018	Data 0.006	Loss 4.9558	Acc@1 70.3125	Acc@5 93.7500
 * prec@1 57.940 prec@5 85.340
 * prec@1 63.600 prec@5 88.280
 * prec@1 67.320 prec@5 90.820
 * prec@1 69.640 prec@5 91.260
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_295.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_295.pth.tar'
Epoch: [296][1/704]	Time 0.299	Data 0.132	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [296][11/704]	Time 0.136	Data 0.012	Loss 1.56	Acc@1 96.9	Acc@5 100.0
Epoch: [296][21/704]	Time 0.129	Data 0.007	Loss 1.58	Acc@1 93.8	Acc@5 100.0
Epoch: [296][31/704]	Time 0.126	Data 0.005	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [296][41/704]	Time 0.124	Data 0.004	Loss 1.28	Acc@1 96.9	Acc@5 100.0
Epoch: [296][51/704]	Time 0.123	Data 0.003	Loss 1.45	Acc@1 100.0	Acc@5 100.0
Epoch: [296][61/704]	Time 0.123	Data 0.003	Loss 1.50	Acc@1 98.4	Acc@5 100.0
Epoch: [296][71/704]	Time 0.122	Data 0.002	Loss 1.32	Acc@1 100.0	Acc@5 100.0
Epoch: [296][81/704]	Time 0.122	Data 0.002	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [296][91/704]	Time 0.122	Data 0.002	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [296][101/704]	Time 0.122	Data 0.002	Loss 1.29	Acc@1 96.9	Acc@5 98.4
Epoch: [296][111/704]	Time 0.122	Data 0.002	Loss 1.28	Acc@1 96.9	Acc@5 100.0
Epoch: [296][121/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [296][131/704]	Time 0.122	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [296][141/704]	Time 0.122	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [296][151/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 93.8	Acc@5 100.0
Epoch: [296][161/704]	Time 0.121	Data 0.001	Loss 1.53	Acc@1 93.8	Acc@5 100.0
Epoch: [296][171/704]	Time 0.121	Data 0.001	Loss 1.11	Acc@1 100.0	Acc@5 100.0
Epoch: [296][181/704]	Time 0.121	Data 0.001	Loss 1.27	Acc@1 98.4	Acc@5 100.0
Epoch: [296][191/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [296][201/704]	Time 0.121	Data 0.001	Loss 1.13	Acc@1 100.0	Acc@5 100.0
Epoch: [296][211/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 100.0	Acc@5 100.0
Epoch: [296][221/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 98.4	Acc@5 100.0
Epoch: [296][231/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 93.8	Acc@5 100.0
Epoch: [296][241/704]	Time 0.121	Data 0.001	Loss 1.11	Acc@1 98.4	Acc@5 100.0
Epoch: [296][251/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 92.2	Acc@5 100.0
Epoch: [296][261/704]	Time 0.121	Data 0.001	Loss 1.25	Acc@1 96.9	Acc@5 98.4
Epoch: [296][271/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 95.3	Acc@5 100.0
Epoch: [296][281/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 100.0	Acc@5 100.0
Epoch: [296][291/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 96.9	Acc@5 100.0
Epoch: [296][301/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 100.0	Acc@5 100.0
Epoch: [296][311/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 95.3	Acc@5 100.0
Epoch: [296][321/704]	Time 0.121	Data 0.001	Loss 1.35	Acc@1 95.3	Acc@5 100.0
Epoch: [296][331/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [296][341/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 95.3	Acc@5 100.0
Epoch: [296][351/704]	Time 0.121	Data 0.001	Loss 2.20	Acc@1 93.8	Acc@5 100.0
Epoch: [296][361/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 95.3	Acc@5 100.0
Epoch: [296][371/704]	Time 0.121	Data 0.001	Loss 1.80	Acc@1 98.4	Acc@5 98.4
Epoch: [296][381/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [296][391/704]	Time 0.121	Data 0.001	Loss 1.92	Acc@1 100.0	Acc@5 100.0
Epoch: [296][401/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 93.8	Acc@5 100.0
Epoch: [296][411/704]	Time 0.121	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [296][421/704]	Time 0.121	Data 0.001	Loss 1.44	Acc@1 93.8	Acc@5 100.0
Epoch: [296][431/704]	Time 0.120	Data 0.001	Loss 1.25	Acc@1 98.4	Acc@5 100.0
Epoch: [296][441/704]	Time 0.120	Data 0.001	Loss 1.12	Acc@1 98.4	Acc@5 100.0
Epoch: [296][451/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [296][461/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [296][471/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [296][481/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [296][491/704]	Time 0.120	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [296][501/704]	Time 0.120	Data 0.001	Loss 2.08	Acc@1 93.8	Acc@5 100.0
Epoch: [296][511/704]	Time 0.120	Data 0.001	Loss 1.91	Acc@1 95.3	Acc@5 100.0
Epoch: [296][521/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 98.4	Acc@5 100.0
Epoch: [296][531/704]	Time 0.120	Data 0.001	Loss 2.47	Acc@1 87.5	Acc@5 100.0
Epoch: [296][541/704]	Time 0.120	Data 0.001	Loss 1.46	Acc@1 95.3	Acc@5 100.0
Epoch: [296][551/704]	Time 0.120	Data 0.001	Loss 1.35	Acc@1 98.4	Acc@5 100.0
Epoch: [296][561/704]	Time 0.120	Data 0.001	Loss 1.93	Acc@1 96.9	Acc@5 100.0
Epoch: [296][571/704]	Time 0.120	Data 0.001	Loss 1.96	Acc@1 98.4	Acc@5 100.0
Epoch: [296][581/704]	Time 0.120	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [296][591/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 100.0	Acc@5 100.0
Epoch: [296][601/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [296][611/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 100.0	Acc@5 100.0
Epoch: [296][621/704]	Time 0.120	Data 0.001	Loss 1.54	Acc@1 92.2	Acc@5 100.0
Epoch: [296][631/704]	Time 0.120	Data 0.001	Loss 1.39	Acc@1 100.0	Acc@5 100.0
Epoch: [296][641/704]	Time 0.120	Data 0.001	Loss 1.63	Acc@1 95.3	Acc@5 100.0
Epoch: [296][651/704]	Time 0.120	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [296][661/704]	Time 0.120	Data 0.001	Loss 1.35	Acc@1 100.0	Acc@5 100.0
Epoch: [296][671/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 92.2	Acc@5 100.0
Epoch: [296][681/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 96.9	Acc@5 100.0
Epoch: [296][691/704]	Time 0.120	Data 0.001	Loss 1.74	Acc@1 92.2	Acc@5 100.0
Epoch: [296][701/704]	Time 0.120	Data 0.001	Loss 1.16	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 6.2783	Acc@1 59.3750	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.6174	Acc@1 67.1875	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 7.2437	Acc@1 67.1875	Acc@5 90.6250
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.0557	Acc@1 68.7500	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.6100	Acc@1 67.1875	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 3.8819	Acc@1 78.1250	Acc@5 92.1875
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.2270	Acc@1 64.0625	Acc@5 84.3750
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 4.6405	Acc@1 78.1250	Acc@5 92.1875
 * prec@1 59.380 prec@5 85.620
 * prec@1 63.440 prec@5 88.540
 * prec@1 67.980 prec@5 90.800
 * prec@1 68.800 prec@5 91.260
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_296.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_296.pth.tar'
Epoch: [297][1/704]	Time 0.302	Data 0.133	Loss 2.03	Acc@1 95.3	Acc@5 100.0
Epoch: [297][11/704]	Time 0.141	Data 0.012	Loss 1.43	Acc@1 93.8	Acc@5 98.4
Epoch: [297][21/704]	Time 0.132	Data 0.007	Loss 1.27	Acc@1 93.8	Acc@5 100.0
Epoch: [297][31/704]	Time 0.129	Data 0.005	Loss 1.50	Acc@1 100.0	Acc@5 100.0
Epoch: [297][41/704]	Time 0.127	Data 0.003	Loss 1.48	Acc@1 98.4	Acc@5 100.0
Epoch: [297][51/704]	Time 0.126	Data 0.003	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [297][61/704]	Time 0.125	Data 0.002	Loss 1.38	Acc@1 95.3	Acc@5 100.0
Epoch: [297][71/704]	Time 0.124	Data 0.002	Loss 1.44	Acc@1 98.4	Acc@5 100.0
Epoch: [297][81/704]	Time 0.124	Data 0.002	Loss 1.89	Acc@1 96.9	Acc@5 100.0
Epoch: [297][91/704]	Time 0.124	Data 0.002	Loss 1.34	Acc@1 98.4	Acc@5 100.0
Epoch: [297][101/704]	Time 0.123	Data 0.002	Loss 2.18	Acc@1 92.2	Acc@5 98.4
Epoch: [297][111/704]	Time 0.123	Data 0.002	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [297][121/704]	Time 0.123	Data 0.001	Loss 1.26	Acc@1 98.4	Acc@5 100.0
Epoch: [297][131/704]	Time 0.123	Data 0.001	Loss 1.19	Acc@1 98.4	Acc@5 100.0
Epoch: [297][141/704]	Time 0.123	Data 0.001	Loss 1.27	Acc@1 100.0	Acc@5 100.0
Epoch: [297][151/704]	Time 0.123	Data 0.001	Loss 1.48	Acc@1 96.9	Acc@5 98.4
Epoch: [297][161/704]	Time 0.123	Data 0.001	Loss 2.06	Acc@1 93.8	Acc@5 98.4
Epoch: [297][171/704]	Time 0.122	Data 0.001	Loss 1.37	Acc@1 96.9	Acc@5 100.0
Epoch: [297][181/704]	Time 0.122	Data 0.001	Loss 1.73	Acc@1 95.3	Acc@5 100.0
Epoch: [297][191/704]	Time 0.122	Data 0.001	Loss 1.79	Acc@1 98.4	Acc@5 100.0
Epoch: [297][201/704]	Time 0.122	Data 0.001	Loss 2.15	Acc@1 96.9	Acc@5 100.0
Epoch: [297][211/704]	Time 0.122	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [297][221/704]	Time 0.122	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [297][231/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 96.9	Acc@5 100.0
Epoch: [297][241/704]	Time 0.122	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [297][251/704]	Time 0.122	Data 0.001	Loss 1.95	Acc@1 95.3	Acc@5 100.0
Epoch: [297][261/704]	Time 0.122	Data 0.001	Loss 2.32	Acc@1 95.3	Acc@5 100.0
Epoch: [297][271/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 95.3	Acc@5 100.0
Epoch: [297][281/704]	Time 0.122	Data 0.001	Loss 1.25	Acc@1 100.0	Acc@5 100.0
Epoch: [297][291/704]	Time 0.122	Data 0.001	Loss 1.38	Acc@1 98.4	Acc@5 100.0
Epoch: [297][301/704]	Time 0.122	Data 0.001	Loss 1.43	Acc@1 95.3	Acc@5 100.0
Epoch: [297][311/704]	Time 0.122	Data 0.001	Loss 1.61	Acc@1 93.8	Acc@5 100.0
Epoch: [297][321/704]	Time 0.122	Data 0.001	Loss 1.55	Acc@1 98.4	Acc@5 100.0
Epoch: [297][331/704]	Time 0.122	Data 0.001	Loss 2.14	Acc@1 93.8	Acc@5 100.0
Epoch: [297][341/704]	Time 0.122	Data 0.001	Loss 1.04	Acc@1 100.0	Acc@5 100.0
Epoch: [297][351/704]	Time 0.122	Data 0.001	Loss 1.90	Acc@1 96.9	Acc@5 100.0
Epoch: [297][361/704]	Time 0.122	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [297][371/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [297][381/704]	Time 0.122	Data 0.001	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [297][391/704]	Time 0.122	Data 0.001	Loss 1.15	Acc@1 96.9	Acc@5 100.0
Epoch: [297][401/704]	Time 0.122	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [297][411/704]	Time 0.122	Data 0.001	Loss 1.80	Acc@1 95.3	Acc@5 100.0
Epoch: [297][421/704]	Time 0.122	Data 0.001	Loss 1.86	Acc@1 92.2	Acc@5 100.0
Epoch: [297][431/704]	Time 0.122	Data 0.001	Loss 1.69	Acc@1 95.3	Acc@5 100.0
Epoch: [297][441/704]	Time 0.122	Data 0.001	Loss 2.21	Acc@1 93.8	Acc@5 100.0
Epoch: [297][451/704]	Time 0.122	Data 0.001	Loss 1.82	Acc@1 98.4	Acc@5 100.0
Epoch: [297][461/704]	Time 0.122	Data 0.001	Loss 2.34	Acc@1 90.6	Acc@5 98.4
Epoch: [297][471/704]	Time 0.122	Data 0.001	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [297][481/704]	Time 0.122	Data 0.001	Loss 1.63	Acc@1 98.4	Acc@5 100.0
Epoch: [297][491/704]	Time 0.122	Data 0.001	Loss 1.47	Acc@1 95.3	Acc@5 100.0
Epoch: [297][501/704]	Time 0.122	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [297][511/704]	Time 0.122	Data 0.001	Loss 1.29	Acc@1 100.0	Acc@5 100.0
Epoch: [297][521/704]	Time 0.122	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [297][531/704]	Time 0.122	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [297][541/704]	Time 0.122	Data 0.001	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [297][551/704]	Time 0.122	Data 0.001	Loss 1.56	Acc@1 98.4	Acc@5 100.0
Epoch: [297][561/704]	Time 0.122	Data 0.001	Loss 1.22	Acc@1 96.9	Acc@5 100.0
Epoch: [297][571/704]	Time 0.122	Data 0.001	Loss 1.35	Acc@1 96.9	Acc@5 100.0
Epoch: [297][581/704]	Time 0.122	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [297][591/704]	Time 0.122	Data 0.001	Loss 1.37	Acc@1 100.0	Acc@5 100.0
Epoch: [297][601/704]	Time 0.122	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [297][611/704]	Time 0.121	Data 0.001	Loss 1.27	Acc@1 98.4	Acc@5 100.0
Epoch: [297][621/704]	Time 0.121	Data 0.001	Loss 1.67	Acc@1 92.2	Acc@5 100.0
Epoch: [297][631/704]	Time 0.121	Data 0.001	Loss 1.89	Acc@1 95.3	Acc@5 100.0
Epoch: [297][641/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [297][651/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 96.9	Acc@5 100.0
Epoch: [297][661/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 96.9	Acc@5 100.0
Epoch: [297][671/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 100.0	Acc@5 100.0
Epoch: [297][681/704]	Time 0.121	Data 0.001	Loss 1.42	Acc@1 93.8	Acc@5 100.0
Epoch: [297][691/704]	Time 0.121	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [297][701/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.103	Data 0.087	Loss 3.7748	Acc@1 73.4375	Acc@5 98.4375
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.5694	Acc@1 67.1875	Acc@5 95.3125
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 6.4219	Acc@1 64.0625	Acc@5 89.0625
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 7.5975	Acc@1 60.9375	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 5.3083	Acc@1 68.7500	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.8710	Acc@1 68.7500	Acc@5 90.6250
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.9772	Acc@1 64.0625	Acc@5 87.5000
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.6735	Acc@1 67.1875	Acc@5 90.6250
 * prec@1 59.060 prec@5 85.660
 * prec@1 63.020 prec@5 88.300
 * prec@1 67.240 prec@5 90.860
 * prec@1 69.000 prec@5 91.260
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_297.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_297.pth.tar'
Epoch: [298][1/704]	Time 0.332	Data 0.165	Loss 1.49	Acc@1 98.4	Acc@5 100.0
Epoch: [298][11/704]	Time 0.140	Data 0.015	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [298][21/704]	Time 0.131	Data 0.008	Loss 1.83	Acc@1 98.4	Acc@5 100.0
Epoch: [298][31/704]	Time 0.127	Data 0.006	Loss 1.41	Acc@1 95.3	Acc@5 100.0
Epoch: [298][41/704]	Time 0.126	Data 0.004	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [298][51/704]	Time 0.125	Data 0.004	Loss 1.96	Acc@1 96.9	Acc@5 100.0
Epoch: [298][61/704]	Time 0.124	Data 0.003	Loss 2.01	Acc@1 95.3	Acc@5 100.0
Epoch: [298][71/704]	Time 0.124	Data 0.003	Loss 1.60	Acc@1 95.3	Acc@5 100.0
Epoch: [298][81/704]	Time 0.123	Data 0.002	Loss 1.87	Acc@1 95.3	Acc@5 100.0
Epoch: [298][91/704]	Time 0.123	Data 0.002	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [298][101/704]	Time 0.123	Data 0.002	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [298][111/704]	Time 0.122	Data 0.002	Loss 1.19	Acc@1 100.0	Acc@5 100.0
Epoch: [298][121/704]	Time 0.122	Data 0.002	Loss 1.27	Acc@1 98.4	Acc@5 100.0
Epoch: [298][131/704]	Time 0.122	Data 0.002	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [298][141/704]	Time 0.122	Data 0.002	Loss 1.29	Acc@1 96.9	Acc@5 100.0
Epoch: [298][151/704]	Time 0.122	Data 0.001	Loss 1.55	Acc@1 96.9	Acc@5 100.0
Epoch: [298][161/704]	Time 0.122	Data 0.001	Loss 1.39	Acc@1 96.9	Acc@5 100.0
Epoch: [298][171/704]	Time 0.122	Data 0.001	Loss 2.19	Acc@1 96.9	Acc@5 100.0
Epoch: [298][181/704]	Time 0.122	Data 0.001	Loss 1.77	Acc@1 95.3	Acc@5 100.0
Epoch: [298][191/704]	Time 0.122	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [298][201/704]	Time 0.122	Data 0.001	Loss 1.59	Acc@1 90.6	Acc@5 100.0
Epoch: [298][211/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 98.4	Acc@5 100.0
Epoch: [298][221/704]	Time 0.122	Data 0.001	Loss 1.27	Acc@1 98.4	Acc@5 100.0
Epoch: [298][231/704]	Time 0.122	Data 0.001	Loss 1.89	Acc@1 92.2	Acc@5 100.0
Epoch: [298][241/704]	Time 0.121	Data 0.001	Loss 1.14	Acc@1 96.9	Acc@5 100.0
Epoch: [298][251/704]	Time 0.121	Data 0.001	Loss 1.66	Acc@1 93.8	Acc@5 100.0
Epoch: [298][261/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [298][271/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 100.0	Acc@5 100.0
Epoch: [298][281/704]	Time 0.121	Data 0.001	Loss 1.20	Acc@1 98.4	Acc@5 100.0
Epoch: [298][291/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 98.4	Acc@5 100.0
Epoch: [298][301/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 95.3	Acc@5 100.0
Epoch: [298][311/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 95.3	Acc@5 100.0
Epoch: [298][321/704]	Time 0.121	Data 0.001	Loss 1.70	Acc@1 93.8	Acc@5 100.0
Epoch: [298][331/704]	Time 0.121	Data 0.001	Loss 1.79	Acc@1 96.9	Acc@5 100.0
Epoch: [298][341/704]	Time 0.121	Data 0.001	Loss 1.36	Acc@1 96.9	Acc@5 100.0
Epoch: [298][351/704]	Time 0.121	Data 0.001	Loss 1.75	Acc@1 96.9	Acc@5 100.0
Epoch: [298][361/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [298][371/704]	Time 0.121	Data 0.001	Loss 1.49	Acc@1 96.9	Acc@5 100.0
Epoch: [298][381/704]	Time 0.121	Data 0.001	Loss 1.77	Acc@1 96.9	Acc@5 100.0
Epoch: [298][391/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 92.2	Acc@5 100.0
Epoch: [298][401/704]	Time 0.121	Data 0.001	Loss 2.23	Acc@1 90.6	Acc@5 100.0
Epoch: [298][411/704]	Time 0.121	Data 0.001	Loss 1.43	Acc@1 96.9	Acc@5 100.0
Epoch: [298][421/704]	Time 0.121	Data 0.001	Loss 1.60	Acc@1 96.9	Acc@5 100.0
Epoch: [298][431/704]	Time 0.121	Data 0.001	Loss 1.09	Acc@1 96.9	Acc@5 100.0
Epoch: [298][441/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 98.4	Acc@5 100.0
Epoch: [298][451/704]	Time 0.121	Data 0.001	Loss 1.48	Acc@1 95.3	Acc@5 100.0
Epoch: [298][461/704]	Time 0.121	Data 0.001	Loss 2.07	Acc@1 93.8	Acc@5 100.0
Epoch: [298][471/704]	Time 0.121	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [298][481/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 93.8	Acc@5 100.0
Epoch: [298][491/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 92.2	Acc@5 100.0
Epoch: [298][501/704]	Time 0.121	Data 0.001	Loss 1.18	Acc@1 95.3	Acc@5 100.0
Epoch: [298][511/704]	Time 0.121	Data 0.001	Loss 1.19	Acc@1 100.0	Acc@5 100.0
Epoch: [298][521/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [298][531/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 98.4	Acc@5 100.0
Epoch: [298][541/704]	Time 0.121	Data 0.001	Loss 1.85	Acc@1 95.3	Acc@5 100.0
Epoch: [298][551/704]	Time 0.121	Data 0.001	Loss 1.99	Acc@1 95.3	Acc@5 100.0
Epoch: [298][561/704]	Time 0.121	Data 0.001	Loss 1.88	Acc@1 96.9	Acc@5 100.0
Epoch: [298][571/704]	Time 0.121	Data 0.001	Loss 1.12	Acc@1 96.9	Acc@5 100.0
Epoch: [298][581/704]	Time 0.121	Data 0.001	Loss 1.37	Acc@1 98.4	Acc@5 100.0
Epoch: [298][591/704]	Time 0.121	Data 0.001	Loss 1.47	Acc@1 96.9	Acc@5 100.0
Epoch: [298][601/704]	Time 0.121	Data 0.001	Loss 1.82	Acc@1 95.3	Acc@5 100.0
Epoch: [298][611/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 95.3	Acc@5 100.0
Epoch: [298][621/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 96.9	Acc@5 100.0
Epoch: [298][631/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 93.8	Acc@5 100.0
Epoch: [298][641/704]	Time 0.121	Data 0.001	Loss 1.68	Acc@1 92.2	Acc@5 100.0
Epoch: [298][651/704]	Time 0.121	Data 0.001	Loss 1.84	Acc@1 96.9	Acc@5 100.0
Epoch: [298][661/704]	Time 0.121	Data 0.001	Loss 1.78	Acc@1 95.3	Acc@5 100.0
Epoch: [298][671/704]	Time 0.121	Data 0.001	Loss 1.57	Acc@1 96.9	Acc@5 100.0
Epoch: [298][681/704]	Time 0.121	Data 0.001	Loss 1.91	Acc@1 93.8	Acc@5 100.0
Epoch: [298][691/704]	Time 0.121	Data 0.001	Loss 2.05	Acc@1 92.2	Acc@5 100.0
Epoch: [298][701/704]	Time 0.121	Data 0.001	Loss 2.42	Acc@1 93.8	Acc@5 100.0
Epoch: [1/79]	Time 0.101	Data 0.086	Loss 5.3334	Acc@1 67.1875	Acc@5 92.1875
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 5.4264	Acc@1 71.8750	Acc@5 92.1875
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 4.9469	Acc@1 70.3125	Acc@5 92.1875
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 5.5645	Acc@1 70.3125	Acc@5 90.6250
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 4.7670	Acc@1 75.0000	Acc@5 92.1875
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 4.2052	Acc@1 84.3750	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 7.3052	Acc@1 56.2500	Acc@5 89.0625
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 6.7894	Acc@1 60.9375	Acc@5 87.5000
 * prec@1 58.940 prec@5 85.660
 * prec@1 62.440 prec@5 88.800
 * prec@1 67.340 prec@5 90.500
 * prec@1 69.660 prec@5 91.240
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_298.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_298.pth.tar'
Epoch: [299][1/704]	Time 0.299	Data 0.132	Loss 1.48	Acc@1 100.0	Acc@5 100.0
Epoch: [299][11/704]	Time 0.136	Data 0.012	Loss 1.54	Acc@1 98.4	Acc@5 100.0
Epoch: [299][21/704]	Time 0.129	Data 0.007	Loss 2.09	Acc@1 96.9	Acc@5 100.0
Epoch: [299][31/704]	Time 0.126	Data 0.005	Loss 1.79	Acc@1 92.2	Acc@5 100.0
Epoch: [299][41/704]	Time 0.124	Data 0.004	Loss 1.39	Acc@1 98.4	Acc@5 100.0
Epoch: [299][51/704]	Time 0.124	Data 0.003	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [299][61/704]	Time 0.123	Data 0.002	Loss 1.23	Acc@1 98.4	Acc@5 100.0
Epoch: [299][71/704]	Time 0.123	Data 0.002	Loss 1.26	Acc@1 96.9	Acc@5 100.0
Epoch: [299][81/704]	Time 0.122	Data 0.002	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [299][91/704]	Time 0.122	Data 0.002	Loss 1.45	Acc@1 96.9	Acc@5 100.0
Epoch: [299][101/704]	Time 0.122	Data 0.002	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [299][111/704]	Time 0.122	Data 0.002	Loss 1.69	Acc@1 92.2	Acc@5 100.0
Epoch: [299][121/704]	Time 0.121	Data 0.001	Loss 1.22	Acc@1 93.8	Acc@5 100.0
Epoch: [299][131/704]	Time 0.121	Data 0.001	Loss 1.15	Acc@1 96.9	Acc@5 100.0
Epoch: [299][141/704]	Time 0.122	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [299][151/704]	Time 0.121	Data 0.001	Loss 1.38	Acc@1 96.9	Acc@5 100.0
Epoch: [299][161/704]	Time 0.121	Data 0.001	Loss 1.95	Acc@1 96.9	Acc@5 100.0
Epoch: [299][171/704]	Time 0.121	Data 0.001	Loss 1.76	Acc@1 93.8	Acc@5 100.0
Epoch: [299][181/704]	Time 0.121	Data 0.001	Loss 2.13	Acc@1 95.3	Acc@5 100.0
Epoch: [299][191/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [299][201/704]	Time 0.121	Data 0.001	Loss 1.10	Acc@1 98.4	Acc@5 100.0
Epoch: [299][211/704]	Time 0.121	Data 0.001	Loss 1.46	Acc@1 98.4	Acc@5 100.0
Epoch: [299][221/704]	Time 0.121	Data 0.001	Loss 1.31	Acc@1 96.9	Acc@5 100.0
Epoch: [299][231/704]	Time 0.121	Data 0.001	Loss 1.93	Acc@1 100.0	Acc@5 100.0
Epoch: [299][241/704]	Time 0.121	Data 0.001	Loss 1.96	Acc@1 96.9	Acc@5 100.0
Epoch: [299][251/704]	Time 0.121	Data 0.001	Loss 1.64	Acc@1 98.4	Acc@5 100.0
Epoch: [299][261/704]	Time 0.121	Data 0.001	Loss 1.52	Acc@1 96.9	Acc@5 100.0
Epoch: [299][271/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 95.3	Acc@5 100.0
Epoch: [299][281/704]	Time 0.121	Data 0.001	Loss 1.59	Acc@1 98.4	Acc@5 100.0
Epoch: [299][291/704]	Time 0.121	Data 0.001	Loss 1.54	Acc@1 95.3	Acc@5 100.0
Epoch: [299][301/704]	Time 0.121	Data 0.001	Loss 1.58	Acc@1 96.9	Acc@5 100.0
Epoch: [299][311/704]	Time 0.121	Data 0.001	Loss 1.71	Acc@1 98.4	Acc@5 100.0
Epoch: [299][321/704]	Time 0.121	Data 0.001	Loss 1.81	Acc@1 95.3	Acc@5 100.0
Epoch: [299][331/704]	Time 0.121	Data 0.001	Loss 1.29	Acc@1 98.4	Acc@5 100.0
Epoch: [299][341/704]	Time 0.121	Data 0.001	Loss 1.40	Acc@1 95.3	Acc@5 100.0
Epoch: [299][351/704]	Time 0.121	Data 0.001	Loss 1.83	Acc@1 93.8	Acc@5 100.0
Epoch: [299][361/704]	Time 0.121	Data 0.001	Loss 1.72	Acc@1 100.0	Acc@5 100.0
Epoch: [299][371/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 96.9	Acc@5 100.0
Epoch: [299][381/704]	Time 0.121	Data 0.001	Loss 1.61	Acc@1 90.6	Acc@5 100.0
Epoch: [299][391/704]	Time 0.121	Data 0.001	Loss 2.35	Acc@1 92.2	Acc@5 100.0
Epoch: [299][401/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 100.0	Acc@5 100.0
Epoch: [299][411/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 100.0	Acc@5 100.0
Epoch: [299][421/704]	Time 0.121	Data 0.001	Loss 1.56	Acc@1 90.6	Acc@5 100.0
Epoch: [299][431/704]	Time 0.121	Data 0.001	Loss 1.74	Acc@1 95.3	Acc@5 100.0
Epoch: [299][441/704]	Time 0.121	Data 0.001	Loss 1.30	Acc@1 95.3	Acc@5 100.0
Epoch: [299][451/704]	Time 0.121	Data 0.001	Loss 1.33	Acc@1 96.9	Acc@5 100.0
Epoch: [299][461/704]	Time 0.121	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 98.4
Epoch: [299][471/704]	Time 0.121	Data 0.001	Loss 1.90	Acc@1 92.2	Acc@5 100.0
Epoch: [299][481/704]	Time 0.121	Data 0.001	Loss 1.28	Acc@1 98.4	Acc@5 100.0
Epoch: [299][491/704]	Time 0.121	Data 0.001	Loss 1.34	Acc@1 95.3	Acc@5 100.0
Epoch: [299][501/704]	Time 0.121	Data 0.001	Loss 1.86	Acc@1 95.3	Acc@5 100.0
Epoch: [299][511/704]	Time 0.121	Data 0.001	Loss 1.62	Acc@1 98.4	Acc@5 100.0
Epoch: [299][521/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [299][531/704]	Time 0.120	Data 0.001	Loss 1.67	Acc@1 96.9	Acc@5 100.0
Epoch: [299][541/704]	Time 0.120	Data 0.001	Loss 1.68	Acc@1 95.3	Acc@5 100.0
Epoch: [299][551/704]	Time 0.120	Data 0.001	Loss 1.81	Acc@1 92.2	Acc@5 100.0
Epoch: [299][561/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 95.3	Acc@5 100.0
Epoch: [299][571/704]	Time 0.120	Data 0.001	Loss 1.51	Acc@1 96.9	Acc@5 100.0
Epoch: [299][581/704]	Time 0.120	Data 0.001	Loss 1.45	Acc@1 98.4	Acc@5 100.0
Epoch: [299][591/704]	Time 0.120	Data 0.001	Loss 1.50	Acc@1 95.3	Acc@5 100.0
Epoch: [299][601/704]	Time 0.120	Data 0.001	Loss 1.07	Acc@1 98.4	Acc@5 100.0
Epoch: [299][611/704]	Time 0.120	Data 0.001	Loss 2.06	Acc@1 89.1	Acc@5 100.0
Epoch: [299][621/704]	Time 0.120	Data 0.001	Loss 1.00	Acc@1 96.9	Acc@5 100.0
Epoch: [299][631/704]	Time 0.120	Data 0.001	Loss 1.53	Acc@1 95.3	Acc@5 100.0
Epoch: [299][641/704]	Time 0.120	Data 0.001	Loss 1.70	Acc@1 96.9	Acc@5 100.0
Epoch: [299][651/704]	Time 0.120	Data 0.001	Loss 1.72	Acc@1 96.9	Acc@5 100.0
Epoch: [299][661/704]	Time 0.120	Data 0.001	Loss 1.43	Acc@1 93.8	Acc@5 100.0
Epoch: [299][671/704]	Time 0.120	Data 0.001	Loss 1.99	Acc@1 93.8	Acc@5 100.0
Epoch: [299][681/704]	Time 0.120	Data 0.001	Loss 1.55	Acc@1 95.3	Acc@5 100.0
Epoch: [299][691/704]	Time 0.120	Data 0.001	Loss 1.65	Acc@1 96.9	Acc@5 100.0
Epoch: [299][701/704]	Time 0.120	Data 0.001	Loss 1.59	Acc@1 95.3	Acc@5 100.0
Epoch: [1/79]	Time 0.102	Data 0.087	Loss 5.0856	Acc@1 68.7500	Acc@5 90.6250
Epoch: [11/79]	Time 0.024	Data 0.012	Loss 6.1895	Acc@1 60.9375	Acc@5 90.6250
Epoch: [21/79]	Time 0.021	Data 0.008	Loss 5.7972	Acc@1 67.1875	Acc@5 95.3125
Epoch: [31/79]	Time 0.019	Data 0.007	Loss 6.4297	Acc@1 71.8750	Acc@5 85.9375
Epoch: [41/79]	Time 0.019	Data 0.006	Loss 6.4149	Acc@1 78.1250	Acc@5 89.0625
Epoch: [51/79]	Time 0.018	Data 0.006	Loss 5.2437	Acc@1 76.5625	Acc@5 89.0625
Epoch: [61/79]	Time 0.018	Data 0.005	Loss 6.9557	Acc@1 64.0625	Acc@5 95.3125
Epoch: [71/79]	Time 0.018	Data 0.005	Loss 5.4145	Acc@1 71.8750	Acc@5 92.1875
 * prec@1 58.420 prec@5 85.140
 * prec@1 62.720 prec@5 88.300
 * prec@1 67.220 prec@5 90.720
 * prec@1 68.840 prec@5 90.900
Current best validation last_bloc_accuracy 70.0
Namespace(MIE=False, arch='msdnet', base=1, batch_size=64, bnFactor=[1, 2, 4], bottleneck=True, compute_only_laplace=False, data='cifar100', data_root='./CIFAR100/', decay_rate=0.1, epochs=300, evalmode=None, evaluate_from=None, gpu=None, grFactor=[1, 2, 4], growthRate=6, laplace=False, laplace_temperature=1.0, lr=0.1, lr_type='multistep', momentum=0.9, nBlocks=4, nChannels=16, nScales=3, n_flops=[6859876.0, 14350024.0, 26127404.0, 38042768.0], n_mc_samples=1, num_classes=100, optimize_temperature=False, optimize_var0=False, optimizer='sgd', print_freq=10, prune='max', reduction=0.5, resume=None, save='./MSDNet/cifar100_4', seed=0, splits=['train', 'val', 'test'], start_epoch=0, step=1, stepmode='lin_grow', temperature=1.0, use_valid=True, var0=2.0, weight_decay=0.0001, workers=1)
=> saving checkpoint './MSDNet/cifar100_4/save_models/checkpoint_299.pth.tar'
=> saved checkpoint './MSDNet/cifar100_4/save_models/checkpoint_299.pth.tar'
Best val_prec1: 70.0000 at epoch 255
Total training time: 25926.573709964752
********** Final prediction results with the best model **********
Epoch: [1/157]	Time 0.086	Data 0.070	Loss 5.5747	Acc@1 64.0625	Acc@5 92.1875
Epoch: [11/157]	Time 0.020	Data 0.007	Loss 6.1655	Acc@1 76.5625	Acc@5 89.0625
Epoch: [21/157]	Time 0.017	Data 0.004	Loss 5.8719	Acc@1 71.8750	Acc@5 90.6250
Epoch: [31/157]	Time 0.015	Data 0.002	Loss 4.7054	Acc@1 76.5625	Acc@5 98.4375
Epoch: [41/157]	Time 0.015	Data 0.002	Loss 6.5592	Acc@1 65.6250	Acc@5 92.1875
Epoch: [51/157]	Time 0.014	Data 0.002	Loss 6.5861	Acc@1 62.5000	Acc@5 92.1875
Epoch: [61/157]	Time 0.014	Data 0.001	Loss 5.4058	Acc@1 68.7500	Acc@5 92.1875
Epoch: [71/157]	Time 0.014	Data 0.001	Loss 5.9285	Acc@1 70.3125	Acc@5 93.7500
Epoch: [81/157]	Time 0.014	Data 0.001	Loss 5.1576	Acc@1 70.3125	Acc@5 92.1875
Epoch: [91/157]	Time 0.014	Data 0.001	Loss 4.8244	Acc@1 71.8750	Acc@5 96.8750
Epoch: [101/157]	Time 0.014	Data 0.001	Loss 3.8603	Acc@1 84.3750	Acc@5 96.8750
Epoch: [111/157]	Time 0.014	Data 0.001	Loss 5.6802	Acc@1 73.4375	Acc@5 85.9375
Epoch: [121/157]	Time 0.014	Data 0.001	Loss 5.9088	Acc@1 62.5000	Acc@5 92.1875
Epoch: [131/157]	Time 0.014	Data 0.001	Loss 4.8693	Acc@1 71.8750	Acc@5 93.7500
Epoch: [141/157]	Time 0.014	Data 0.001	Loss 5.9620	Acc@1 73.4375	Acc@5 87.5000
Epoch: [151/157]	Time 0.013	Data 0.001	Loss 4.4259	Acc@1 89.0625	Acc@5 95.3125
 * prec@1 61.390 prec@5 86.940
 * prec@1 65.070 prec@5 89.370
 * prec@1 69.120 prec@5 90.950
 * prec@1 70.480 prec@5 91.580
********** Precalculate Laplace approximation **********

0it [00:00, ?it/s]
2it [00:00, 15.93it/s]
6it [00:00, 18.68it/s]
10it [00:00, 21.26it/s]
14it [00:00, 23.54it/s]
18it [00:00, 25.43it/s]
22it [00:00, 26.95it/s]
26it [00:00, 28.12it/s]
30it [00:01, 29.02it/s]
34it [00:01, 29.69it/s]
38it [00:01, 30.18it/s]
42it [00:01, 30.52it/s]
46it [00:01, 30.79it/s]
50it [00:01, 30.95it/s]
54it [00:01, 31.09it/s]
58it [00:01, 31.10it/s]
62it [00:02, 31.17it/s]
66it [00:02, 31.22it/s]
70it [00:02, 31.26it/s]
74it [00:02, 31.29it/s]
78it [00:02, 31.34it/s]
82it [00:02, 31.36it/s]
86it [00:02, 31.36it/s]
90it [00:02, 31.37it/s]
94it [00:03, 31.40it/s]
98it [00:03, 31.44it/s]
102it [00:03, 31.46it/s]
106it [00:03, 31.46it/s]
110it [00:03, 31.47it/s]
114it [00:03, 31.45it/s]
118it [00:03, 31.43it/s]
122it [00:03, 31.41it/s]
126it [00:04, 31.42it/s]
130it [00:04, 31.41it/s]
134it [00:04, 31.41it/s]
138it [00:04, 31.41it/s]
142it [00:04, 31.41it/s]
146it [00:04, 31.42it/s]
150it [00:04, 31.44it/s]
154it [00:04, 31.43it/s]
158it [00:05, 31.43it/s]
162it [00:05, 31.38it/s]
166it [00:05, 31.40it/s]
170it [00:05, 31.40it/s]
174it [00:05, 31.39it/s]
178it [00:05, 31.37it/s]
182it [00:05, 31.37it/s]
186it [00:05, 31.33it/s]
190it [00:06, 31.35it/s]
194it [00:06, 31.37it/s]
198it [00:06, 31.38it/s]
202it [00:06, 31.39it/s]
206it [00:06, 31.37it/s]
210it [00:06, 31.37it/s]
214it [00:06, 31.37it/s]
218it [00:07, 31.38it/s]
222it [00:07, 31.38it/s]
226it [00:07, 31.39it/s]
230it [00:07, 31.40it/s]
234it [00:07, 31.39it/s]
238it [00:07, 31.39it/s]
242it [00:07, 31.38it/s]
246it [00:07, 31.41it/s]
250it [00:08, 31.37it/s]
254it [00:08, 31.36it/s]
258it [00:08, 31.37it/s]
262it [00:08, 31.38it/s]
266it [00:08, 31.38it/s]
270it [00:08, 31.35it/s]
274it [00:08, 31.38it/s]
278it [00:08, 31.41it/s]
282it [00:09, 31.42it/s]
286it [00:09, 31.43it/s]
290it [00:09, 31.42it/s]
294it [00:09, 31.43it/s]
298it [00:09, 31.45it/s]
302it [00:09, 31.43it/s]
306it [00:09, 31.43it/s]
310it [00:09, 31.44it/s]
314it [00:10, 31.43it/s]
318it [00:10, 31.45it/s]
322it [00:10, 31.14it/s]
326it [00:10, 31.21it/s]
330it [00:10, 31.29it/s]
334it [00:10, 31.35it/s]
338it [00:10, 31.37it/s]
342it [00:10, 31.40it/s]
346it [00:11, 31.43it/s]
350it [00:11, 31.45it/s]
354it [00:11, 31.46it/s]
358it [00:11, 31.47it/s]
362it [00:11, 31.49it/s]
366it [00:11, 31.49it/s]
370it [00:11, 31.48it/s]
374it [00:11, 31.47it/s]
378it [00:12, 31.40it/s]
382it [00:12, 31.42it/s]
386it [00:12, 31.44it/s]
390it [00:12, 31.46it/s]
394it [00:12, 31.47it/s]
398it [00:12, 31.48it/s]
402it [00:12, 31.50it/s]
406it [00:12, 31.50it/s]
410it [00:13, 31.47it/s]
414it [00:13, 31.46it/s]
418it [00:13, 31.46it/s]
422it [00:13, 31.44it/s]
426it [00:13, 31.44it/s]
430it [00:13, 31.45it/s]
434it [00:13, 31.45it/s]
438it [00:14, 31.46it/s]
442it [00:14, 31.45it/s]
446it [00:14, 31.47it/s]
450it [00:14, 31.44it/s]
454it [00:14, 31.44it/s]
458it [00:14, 31.46it/s]
462it [00:14, 31.46it/s]
466it [00:14, 31.46it/s]
470it [00:15, 31.45it/s]
474it [00:15, 31.45it/s]
478it [00:15, 31.45it/s]
482it [00:15, 31.46it/s]
486it [00:15, 31.43it/s]
490it [00:15, 31.43it/s]
494it [00:15, 31.44it/s]
498it [00:15, 31.46it/s]
502it [00:16, 31.44it/s]
506it [00:16, 31.44it/s]
510it [00:16, 31.44it/s]
514it [00:16, 31.43it/s]
518it [00:16, 31.46it/s]
522it [00:16, 31.45it/s]
526it [00:16, 31.46it/s]
530it [00:16, 31.46it/s]
534it [00:17, 31.48it/s]
538it [00:17, 31.51it/s]
542it [00:17, 31.53it/s]
546it [00:17, 31.52it/s]
550it [00:17, 31.50it/s]
554it [00:17, 31.52it/s]
558it [00:17, 31.53it/s]
562it [00:17, 31.52it/s]
566it [00:18, 31.50it/s]
570it [00:18, 31.48it/s]
574it [00:18, 31.49it/s]
578it [00:18, 31.48it/s]
582it [00:18, 31.43it/s]
586it [00:18, 31.44it/s]
590it [00:18, 31.46it/s]
594it [00:18, 31.45it/s]
598it [00:19, 31.45it/s]
602it [00:19, 31.51it/s]
606it [00:19, 31.51it/s]
610it [00:19, 31.51it/s]
614it [00:19, 31.51it/s]
618it [00:19, 31.48it/s]
622it [00:19, 31.45it/s]
626it [00:19, 31.46it/s]
630it [00:20, 31.45it/s]
634it [00:20, 31.48it/s]
638it [00:20, 31.48it/s]
642it [00:20, 31.49it/s]
646it [00:20, 31.48it/s]
650it [00:20, 31.49it/s]
654it [00:20, 31.49it/s]
658it [00:21, 31.49it/s]
662it [00:21, 31.49it/s]
666it [00:21, 31.49it/s]
670it [00:21, 31.50it/s]
674it [00:21, 31.51it/s]
678it [00:21, 31.50it/s]
682it [00:21, 31.49it/s]
686it [00:21, 31.47it/s]
690it [00:22, 31.46it/s]
694it [00:22, 31.48it/s]
698it [00:22, 31.43it/s]
702it [00:22, 30.58it/s]
704it [00:22, 31.23it/s]
Saving the hessians...
Laplace computation time: 22.675427675247192

JOB STATISTICS
==============
Job ID: 8498491
Cluster: snellius
User/Group: scur2884/scur2884
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 18
CPU Utilized: 08:16:11
CPU Efficiency: 6.37% of 5-09:53:24 core-walltime
Job Wall-clock time: 07:12:58
Memory Utilized: 3.88 GB
Memory Efficiency: 3.24% of 120.00 GB
